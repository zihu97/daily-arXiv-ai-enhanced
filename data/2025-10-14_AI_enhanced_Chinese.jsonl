{"id": "2510.08607", "categories": ["cs.MA", "cs.GT"], "pdf": "https://arxiv.org/pdf/2510.08607", "abs": "https://arxiv.org/abs/2510.08607", "authors": ["Zhaoqilin Yang", "Chanchan Li", "Tianqi Liu", "Hongxin Zhao", "Youliang Tian"], "title": "GRPO-GCC: Enhancing Cooperation in Spatial Public Goods Games via Group Relative Policy Optimization with Global Cooperation Constraint", "comment": null, "summary": "Inspired by the principle of self-regulating cooperation in collective\ninstitutions, we propose the Group Relative Policy Optimization with Global\nCooperation Constraint (GRPO-GCC) framework. This work is the first to\nintroduce GRPO into spatial public goods games, establishing a new deep\nreinforcement learning baseline for structured populations. GRPO-GCC integrates\ngroup relative policy optimization with a global cooperation constraint that\nstrengthens incentives at intermediate cooperation levels while weakening them\nat extremes. This mechanism aligns local decision making with sustainable\ncollective outcomes and prevents collapse into either universal defection or\nunconditional cooperation. The framework advances beyond existing approaches by\ncombining group-normalized advantage estimation, a reference-anchored KL\npenalty, and a global incentive term that dynamically adjusts cooperative\npayoffs. As a result, it achieves accelerated cooperation onset, stabilized\npolicy adaptation, and long-term sustainability. GRPO-GCC demonstrates how a\nsimple yet global signal can reshape incentives toward resilient cooperation,\nand provides a new paradigm for multi-agent reinforcement learning in\nsocio-technical systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86GRPO-GCC\u6846\u67b6\uff0c\u5c06\u7fa4\u4f53\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u4e0e\u5168\u5c40\u5408\u4f5c\u7ea6\u675f\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u7a7a\u95f4\u516c\u5171\u54c1\u535a\u5f08\uff0c\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u5408\u4f5c\u542f\u52a8\u3001\u7a33\u5b9a\u7684\u7b56\u7565\u9002\u5e94\u548c\u957f\u671f\u53ef\u6301\u7eed\u6027\u3002", "motivation": "\u53d7\u96c6\u4f53\u5236\u5ea6\u4e2d\u81ea\u8c03\u8282\u5408\u4f5c\u539f\u5219\u7684\u542f\u53d1\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u7ed3\u6784\u5316\u7fa4\u4f53\u4e2d\u96be\u4ee5\u7ef4\u6301\u53ef\u6301\u7eed\u5408\u4f5c\u7684\u95ee\u9898\uff0c\u907f\u514d\u9677\u5165\u5168\u9762\u80cc\u53db\u6216\u65e0\u6761\u4ef6\u5408\u4f5c\u7684\u6781\u7aef\u72b6\u6001\u3002", "method": "GRPO-GCC\u7ed3\u5408\u4e86\u7fa4\u4f53\u5f52\u4e00\u5316\u4f18\u52bf\u4f30\u8ba1\u3001\u53c2\u8003\u951a\u5b9a\u7684KL\u60e9\u7f5a\u9879\u548c\u52a8\u6001\u8c03\u6574\u5408\u4f5c\u6536\u76ca\u7684\u5168\u5c40\u6fc0\u52b1\u9879\uff0c\u5728\u7fa4\u4f53\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u57fa\u7840\u4e0a\u5f15\u5165\u5168\u5c40\u5408\u4f5c\u7ea6\u675f\u3002", "result": "\u8be5\u6846\u67b6\u5728\u7a7a\u95f4\u516c\u5171\u54c1\u535a\u5f08\u4e2d\u663e\u8457\u52a0\u901f\u4e86\u5408\u4f5c\u7684\u51fa\u73b0\uff0c\u7a33\u5b9a\u4e86\u7b56\u7565\u9002\u5e94\u8fc7\u7a0b\uff0c\u5e76\u5b9e\u73b0\u4e86\u957f\u671f\u53ef\u6301\u7eed\u7684\u5408\u4f5c\u884c\u4e3a\u3002", "conclusion": "GRPO-GCC\u901a\u8fc7\u4e00\u4e2a\u7b80\u5355\u800c\u5168\u5c40\u7684\u4fe1\u53f7\u91cd\u5851\u591a\u667a\u80fd\u4f53\u6fc0\u52b1\u673a\u5236\uff0c\u4e3a\u793e\u4f1a\u6280\u672f\u7cfb\u7edf\u4e2d\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2510.09469", "categories": ["cs.MA", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.09469", "abs": "https://arxiv.org/abs/2510.09469", "authors": ["Bharath Muppasani", "Ritirupa Dey", "Biplav Srivastava", "Vignesh Narayanan"], "title": "Scalable Multi-Agent Path Finding using Collision-Aware Dynamic Alert Mask and a Hybrid Execution Strategy", "comment": null, "summary": "Multi-agent pathfinding (MAPF) remains a critical problem in robotics and\nautonomous systems, where agents must navigate shared spaces efficiently while\navoiding conflicts. Traditional centralized algorithms that have global\ninformation, such as Conflict-Based Search (CBS), provide high-quality\nsolutions but become computationally expensive in large-scale scenarios due to\nthe combinatorial explosion of conflicts that need resolution. Conversely,\ndistributed approaches that have local information, particularly learning-based\nmethods, offer better scalability by operating with relaxed information\navailability, yet often at the cost of solution quality. To address these\nlimitations, we propose a hybrid framework that combines decentralized path\nplanning with a lightweight centralized coordinator. Our framework leverages\nreinforcement learning (RL) for decentralized planning, enabling agents to\nadapt their planning based on minimal, targeted alerts--such as static\nconflict-cell flags or brief conflict tracks--that are dynamically shared\ninformation from the central coordinator for effective conflict resolution. We\nempirically study the effect of the information available to an agent on its\nplanning performance. Our approach reduces the inter-agent information sharing\ncompared to fully centralized and distributed methods, while still consistently\nfinding feasible, collision-free solutions--even in large-scale scenarios\nhaving higher agent counts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53bb\u4e2d\u5fc3\u5316\u8def\u5f84\u89c4\u5212\u4e0e\u8f7b\u91cf\u7ea7\u4e2d\u5fc3\u5316\u534f\u8c03\u5668\u7684\u6df7\u5408\u6846\u67b6\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u53bb\u4e2d\u5fc3\u5316\u89c4\u5212\uff0c\u5e76\u901a\u8fc7\u4e2d\u5fc3\u534f\u8c03\u5668\u52a8\u6001\u63d0\u4f9b\u6700\u5c0f\u5316\u7684\u51b2\u7a81\u4fe1\u606f\uff08\u5982\u51b2\u7a81\u5355\u5143\u6807\u5fd7\u6216\u7b80\u77ed\u51b2\u7a81\u8f68\u8ff9\uff09\uff0c\u5728\u51cf\u5c11\u4fe1\u606f\u5171\u4eab\u7684\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u3001\u65e0\u78b0\u649e\u7684\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u3002", "motivation": "\u4f20\u7edf\u96c6\u4e2d\u5f0f\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff08\u5982CBS\uff09\u867d\u80fd\u63d0\u4f9b\u9ad8\u8d28\u91cf\u89e3\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u573a\u666f\u4e2d\u56e0\u51b2\u7a81\u7ec4\u5408\u7206\u70b8\u800c\u8ba1\u7b97\u5f00\u9500\u5927\uff1b\u800c\u5206\u5e03\u5f0f\u65b9\u6cd5\uff08\u5c24\u5176\u662f\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\uff09\u867d\u5177\u53ef\u6269\u5c55\u6027\uff0c\u5374\u5e38\u727a\u7272\u89e3\u7684\u8d28\u91cf\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u517c\u987e\u53ef\u6269\u5c55\u6027\u4e0e\u89e3\u8d28\u91cf\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u6846\u67b6\uff1a\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u53bb\u4e2d\u5fc3\u5316\u8def\u5f84\u89c4\u5212\uff0c\u540c\u65f6\u5f15\u5165\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u4e2d\u5fc3\u534f\u8c03\u5668\uff0c\u52a8\u6001\u5411\u667a\u80fd\u4f53\u63d0\u4f9b\u6700\u5c0f\u5316\u3001\u6709\u9488\u5bf9\u6027\u7684\u51b2\u7a81\u4fe1\u606f\uff08\u5982\u9759\u6001\u51b2\u7a81\u5355\u5143\u6807\u5fd7\u6216\u7b80\u77ed\u51b2\u7a81\u8f68\u8ff9\uff09\uff0c\u4ee5\u8f85\u52a9\u5176\u8c03\u6574\u8def\u5f84\u5e76\u907f\u514d\u51b2\u7a81\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u5b8c\u5168\u96c6\u4e2d\u5f0f\u6216\u5206\u5e03\u5f0f\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u667a\u80fd\u4f53\u95f4\u7684\u4fe1\u606f\u5171\u4eab\u91cf\uff0c\u540c\u65f6\u5728\u9ad8\u5bc6\u5ea6\u3001\u5927\u89c4\u6a21\u573a\u666f\u4e2d\u4ecd\u80fd\u7a33\u5b9a\u751f\u6210\u53ef\u884c\u4e14\u65e0\u78b0\u649e\u7684\u8def\u5f84\u89e3\u3002", "conclusion": "\u8be5\u6df7\u5408\u6846\u67b6\u6709\u6548\u5e73\u8861\u4e86\u8ba1\u7b97\u6548\u7387\u3001\u4fe1\u606f\u5f00\u9500\u4e0e\u89e3\u7684\u8d28\u91cf\uff0c\u4e3a\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08842", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.08842", "abs": "https://arxiv.org/abs/2510.08842", "authors": ["Molang Wu", "Zhao Zhang"], "title": "Maple: A Multi-agent System for Portable Deep Learning across Clusters", "comment": null, "summary": "Training deep learning (DL) models across Graphics Processing Unit (GPU)\nclusters is technically challenging. One aspect is that users have to compose\ncommand lines to adapt to the heterogeneous launchers, schedulers, affinity\noptions, DL framework arguments, and environment variables. Composing correct\ncommand lines is error-prone and can easily frustrate users, impeding research\nor wasting resources. In this work, we present Maple, a multi-agent system that\ngenerates correct DL command lines with users' natural language input. Maple\nconsists of four agents with the functionalities of information extraction,\ntemplate retrieval, command line verification, and error correction. We\nevaluate Maple on nine GPU clusters across national computing centers in the\nU.S., five representative deep learning model families, and four commonly used\nparallel DL training paradigms. Our experiments also cover schedulers of SLURM\nand PBS and heterogeneous architectures, such as NVIDIA A100/H200 GPUs and\nIntel Max series GPUs. Maple achieves 92.0% accuracy in generating command\nlines across the 567 test cases. Leverage multiple language models with an\naggregated size of 10B parameters, Maple delivers comparable performance to the\nstate-of-the-art models of GPT-5, Claude, and Gemini. Together, these results\nhighlight Maple's practical value in enabling portable and scalable distributed\nDL across heterogeneous HPC environments.", "AI": {"tldr": "Maple \u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u6839\u636e\u7528\u6237\u7684\u81ea\u7136\u8bed\u8a00\u8f93\u5165\u81ea\u52a8\u751f\u6210\u9002\u7528\u4e8e\u5f02\u6784 GPU \u96c6\u7fa4\u7684\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u547d\u4ee4\u884c\uff0c\u5728 567 \u4e2a\u6d4b\u8bd5\u7528\u4f8b\u4e2d\u51c6\u786e\u7387\u8fbe 92.0%\uff0c\u5c55\u73b0\u51fa\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u79fb\u690d\u3001\u53ef\u6269\u5c55\u5206\u5e03\u5f0f\u6df1\u5ea6\u5b66\u4e60\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u5728 GPU \u96c6\u7fa4\u4e0a\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9700\u7528\u6237\u624b\u52a8\u7f16\u5199\u590d\u6742\u7684\u547d\u4ee4\u884c\uff0c\u6d89\u53ca\u591a\u79cd\u542f\u52a8\u5668\u3001\u8c03\u5ea6\u5668\u3001\u4eb2\u548c\u6027\u8bbe\u7f6e\u3001\u6846\u67b6\u53c2\u6570\u548c\u73af\u5883\u53d8\u91cf\uff0c\u8fc7\u7a0b\u6613\u9519\u4e14\u7e41\u7410\uff0c\u963b\u788d\u7814\u7a76\u6548\u7387\u5e76\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "Maple \u91c7\u7528\u56db\u4e2a\u667a\u80fd\u4f53\u534f\u540c\u5de5\u4f5c\uff0c\u5206\u522b\u8d1f\u8d23\u4fe1\u606f\u63d0\u53d6\u3001\u6a21\u677f\u68c0\u7d22\u3001\u547d\u4ee4\u884c\u9a8c\u8bc1\u548c\u9519\u8bef\u4fee\u6b63\uff0c\u7ed3\u5408\u591a\u4e2a\u603b\u8ba1 10B \u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u652f\u6301\u591a\u79cd\u8c03\u5ea6\u5668\uff08SLURM/PBS\uff09\u548c\u5f02\u6784 GPU \u67b6\u6784\uff08\u5982 NVIDIA A100/H200 \u548c Intel Max \u7cfb\u5217\uff09\u3002", "result": "\u5728\u8986\u76d6\u7f8e\u56fd\u56fd\u5bb6\u8ba1\u7b97\u4e2d\u5fc3\u7684 9 \u4e2a GPU \u96c6\u7fa4\u30015 \u7c7b\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548c 4 \u79cd\u5e76\u884c\u8bad\u7ec3\u8303\u5f0f\u4e0a\uff0cMaple \u5728 567 \u4e2a\u6d4b\u8bd5\u7528\u4f8b\u4e2d\u8fbe\u5230 92.0% \u7684\u547d\u4ee4\u884c\u751f\u6210\u51c6\u786e\u7387\uff0c\u6027\u80fd\u5ab2\u7f8e GPT-5\u3001Claude \u548c Gemini \u7b49\u524d\u6cbf\u6a21\u578b\u3002", "conclusion": "Maple \u80fd\u6709\u6548\u7b80\u5316\u5f02\u6784\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u4e2d\u5206\u5e03\u5f0f\u6df1\u5ea6\u5b66\u4e60\u7684\u547d\u4ee4\u884c\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u5347\u7528\u6237\u6548\u7387\u4e0e\u7cfb\u7edf\u8d44\u6e90\u5229\u7528\u7387\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2510.08576", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.08576", "abs": "https://arxiv.org/abs/2510.08576", "authors": ["Justus Flerlage", "Alexander Acker", "Odej Kao"], "title": "Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions", "comment": null, "summary": "Large Language Models (LLMs) have emerged as transformative tools for natural\nlanguage understanding and user intent resolution, enabling tasks such as\ntranslation, summarization, and, increasingly, the orchestration of complex\nworkflows. This development signifies a paradigm shift from conventional,\nGUI-driven user interfaces toward intuitive, language-first interaction\nparadigms. Rather than manually navigating applications, users can articulate\ntheir objectives in natural language, enabling LLMs to orchestrate actions\nacross multiple applications in a dynamic and contextual manner. However,\nextant implementations frequently rely on cloud-based proprietary models, which\nintroduce limitations in terms of privacy, autonomy, and scalability. For\nlanguage-first interaction to become a truly robust and trusted interface\nparadigm, local deployment is not merely a convenience; it is an imperative.\nThis limitation underscores the importance of evaluating the feasibility of\nlocally deployable, open-source, and open-access LLMs as foundational\ncomponents for future intent-based operating systems. In this study, we examine\nthe capabilities of several open-source and open-access models in facilitating\nuser intention resolution through machine assistance. A comparative analysis is\nconducted against OpenAI's proprietary GPT-4-based systems to assess\nperformance in generating workflows for various user intentions. The present\nstudy offers empirical insights into the practical viability, performance\ntrade-offs, and potential of open LLMs as autonomous, locally operable\ncomponents in next-generation operating systems. The results of this study\ninform the broader discussion on the decentralization and democratization of AI\ninfrastructure and point toward a future where user-device interaction becomes\nmore seamless, adaptive, and privacy-conscious through locally embedded\nintelligence.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5f00\u6e90\u3001\u53ef\u672c\u5730\u90e8\u7f72\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b9e\u73b0\u7528\u6237\u610f\u56fe\u89e3\u6790\u548c\u5de5\u4f5c\u6d41\u7f16\u6392\u65b9\u9762\u7684\u53ef\u884c\u6027\uff0c\u5c06\u5176\u4e0eOpenAI\u7684GPT-4\u7cfb\u7edf\u8fdb\u884c\u5bf9\u6bd4\uff0c\u8bc4\u4f30\u5176\u5728\u4e0b\u4e00\u4ee3\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u4f5c\u4e3a\u672c\u5730\u667a\u80fd\u7ec4\u4ef6\u7684\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u4e91\u7684\u4e13\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9690\u79c1\u3001\u81ea\u4e3b\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u963b\u788d\u4e86\u8bed\u8a00\u4f18\u5148\u4ea4\u4e92\u8303\u5f0f\u7684\u53d1\u5c55\u3002\u4e3a\u6784\u5efa\u53ef\u4fe1\u3001\u7a33\u5065\u7684\u610f\u56fe\u9a71\u52a8\u64cd\u4f5c\u7cfb\u7edf\uff0c\u4e9f\u9700\u8bc4\u4f30\u672c\u5730\u90e8\u7f72\u7684\u5f00\u6e90LLM\u7684\u53ef\u884c\u6027\u3002", "method": "\u5bf9\u591a\u4e2a\u5f00\u6e90\u3001\u5f00\u653e\u8bbf\u95ee\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u80fd\u529b\u8bc4\u4f30\uff0c\u901a\u8fc7\u5bf9\u6bd4OpenAI\u7684GPT-4\u7cfb\u7edf\uff0c\u5206\u6790\u5b83\u4eec\u5728\u6839\u636e\u7528\u6237\u610f\u56fe\u751f\u6210\u5de5\u4f5c\u6d41\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u5f00\u6e90LLM\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u884c\u6027\u3001\u6027\u80fd\u6743\u8861\u53ca\u5176\u4f5c\u4e3a\u672c\u5730\u53ef\u64cd\u4f5c\u7ec4\u4ef6\u6f5c\u529b\u7684\u5b9e\u8bc1\u89c1\u89e3\u3002", "conclusion": "\u5f00\u6e90\u3001\u672c\u5730\u90e8\u7f72\u7684LLM\u6709\u671b\u652f\u6491\u53bb\u4e2d\u5fc3\u5316\u548c\u6c11\u4e3b\u5316\u7684AI\u57fa\u7840\u8bbe\u65bd\uff0c\u63a8\u52a8\u7528\u6237\u4e0e\u8bbe\u5907\u4e4b\u95f4\u5b9e\u73b0\u66f4\u65e0\u7f1d\u3001\u81ea\u9002\u5e94\u4e14\u6ce8\u91cd\u9690\u79c1\u7684\u4ea4\u4e92\u3002"}}
{"id": "2510.08874", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08874", "abs": "https://arxiv.org/abs/2510.08874", "authors": ["Benjamin Brock", "Renato Golin"], "title": "Slicing Is All You Need: Towards A Universal One-Sided Algorithm for Distributed Matrix Multiplication", "comment": null, "summary": "Many important applications across science, data analytics, and AI workloads\ndepend on distributed matrix multiplication. Prior work has developed a large\narray of algorithms suitable for different problem sizes and partitionings\nincluding 1D, 2D, 1.5D, and 2.5D algorithms. A limitation of current work is\nthat existing algorithms are limited to a subset of partitionings. Multiple\nalgorithm implementations are required to support the full space of possible\npartitionings. If no algorithm implementation is available for a particular set\nof partitionings, one or more operands must be redistributed, increasing\ncommunication costs. This paper presents a universal one-sided algorithm for\ndistributed matrix multiplication that supports all combinations of\npartitionings and replication factors. Our algorithm uses slicing (index\narithmetic) to compute the sets of overlapping tiles that must be multiplied\ntogether. This list of local matrix multiplies can then either be executed\ndirectly, or reordered and lowered to an optimized IR to maximize overlap. We\nimplement our algorithm using a high-level C++-based PGAS programming framework\nthat performs direct GPU-to-GPU communication using intra-node interconnects.\nWe evaluate performance for a wide variety of partitionings and replication\nfactors, finding that our work is competitive with PyTorch DTensor, a highly\noptimized distributed tensor library targeting AI models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u5355\u8fb9\u5206\u5e03\u5f0f\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\uff0c\u652f\u6301\u6240\u6709\u5212\u5206\u65b9\u5f0f\u548c\u590d\u5236\u56e0\u5b50\u7ec4\u5408\uff0c\u907f\u514d\u4e86\u56e0\u7f3a\u4e4f\u5bf9\u5e94\u7b97\u6cd5\u5b9e\u73b0\u800c\u5bfc\u81f4\u7684\u6570\u636e\u91cd\u5206\u5e03\u5f00\u9500\uff0c\u5e76\u5728\u591a\u79cd\u914d\u7f6e\u4e0b\u5c55\u73b0\u51fa\u4e0ePyTorch DTensor\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5206\u5e03\u5f0f\u77e9\u9635\u4e58\u6cd5\u7b97\u6cd5\u4ec5\u652f\u6301\u90e8\u5206\u5212\u5206\u65b9\u5f0f\uff08\u59821D\u30012D\u7b49\uff09\uff0c\u82e5\u76ee\u6807\u5212\u5206\u65e0\u5bf9\u5e94\u5b9e\u73b0\uff0c\u5219\u9700\u91cd\u5206\u5e03\u6570\u636e\uff0c\u589e\u52a0\u901a\u4fe1\u5f00\u9500\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u652f\u6301\u4efb\u610f\u5212\u5206\u7ec4\u5408\u7684\u901a\u7528\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5207\u7247\uff08\u7d22\u5f15\u7b97\u672f\uff09\u7684\u901a\u7528\u5355\u8fb9\u7b97\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u91cd\u53e0\u6570\u636e\u5757\u7684\u4e58\u6cd5\u4efb\u52a1\u5217\u8868\uff0c\u652f\u6301\u6240\u6709\u5212\u5206\u4e0e\u590d\u5236\u56e0\u5b50\u7ec4\u5408\uff1b\u8be5\u4efb\u52a1\u5217\u8868\u53ef\u76f4\u63a5\u6267\u884c\u6216\u4f18\u5316\u8c03\u5ea6\u540e\u6267\u884c\u3002\u7b97\u6cd5\u5728\u57fa\u4e8eC++\u7684PGAS\u6846\u67b6\u4e2d\u5b9e\u73b0\uff0c\u652f\u6301GPU\u95f4\u76f4\u63a5\u901a\u4fe1\u3002", "result": "\u5728\u591a\u79cd\u5212\u5206\u548c\u590d\u5236\u56e0\u5b50\u914d\u7f6e\u4e0b\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u6027\u80fd\u4e0e\u9ad8\u5ea6\u4f18\u5316\u7684PyTorch DTensor\u76f8\u5f53\u3002", "conclusion": "\u8be5\u901a\u7528\u7b97\u6cd5\u6709\u6548\u6d88\u9664\u4e86\u5bf9\u591a\u79cd\u4e13\u7528\u5b9e\u73b0\u7684\u9700\u6c42\uff0c\u51cf\u5c11\u4e86\u901a\u4fe1\u5f00\u9500\uff0c\u5e76\u5728\u5b9e\u9645\u6027\u80fd\u4e0a\u5177\u6709\u7ade\u4e89\u529b\uff0c\u9002\u7528\u4e8e\u79d1\u5b66\u8ba1\u7b97\u3001\u6570\u636e\u5206\u6790\u548cAI\u7b49\u5e7f\u6cdb\u573a\u666f\u3002"}}
{"id": "2510.08940", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.08940", "abs": "https://arxiv.org/abs/2510.08940", "authors": ["Abel Beyene", "Zhongpan Wu", "Yunus Dawji", "Karim Hammad", "Ebrahim Ghafar-Zadeh", "Sebastian Magierowski"], "title": "A High-Efficiency SoC for Next-Generation Mobile DNA Sequencing", "comment": null, "summary": "Hand-sized Deoxyribonucleic acid (DNA) sequencing machines are of growing\nimportance in several life sciences fields as their small footprints enable a\nbroader range of use cases than their larger, stationary counterparts. However,\nas currently designed, they lack sufficient embedded computing to process the\nlarge volume of measurements generated by their internal sensory system. As a\nconsequence, they rely on external devices for additional processing\ncapability. This dependence on external processing places a significant\ncommunication burden on the sequencer's embedded electronics. Moreover, it also\nprevents a truly mobile solution for sequencing in real-time. Anticipating\nnext-generation machines that include suitably advanced processing, we present\na System-on-Chip (SoC) fabricated in 22-nm complementary metal-oxide\nsemiconductor (CMOS). Our design, based on a general-purpose reduced\ninstruction set computing (RISC-V) core, also includes accelerators for DNA\ndetection that allow our system to demonstrate a 13X performance improvement\nover commercial embedded multicore processors combined with a near 3000X boost\nin energy efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e22\u7eb3\u7c73CMOS\u5de5\u827a\u7684\u7247\u4e0a\u7cfb\u7edf\uff08SoC\uff09\uff0c\u96c6\u6210\u4e86RISC-V\u901a\u7528\u5904\u7406\u5668\u548c\u4e13\u7528DNA\u68c0\u6d4b\u52a0\u901f\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fbf\u643a\u5f0fDNA\u6d4b\u5e8f\u4eea\u7684\u6027\u80fd\u4e0e\u80fd\u6548\u3002", "motivation": "\u5f53\u524d\u624b\u6301\u5f0fDNA\u6d4b\u5e8f\u4eea\u56e0\u5d4c\u5165\u5f0f\u8ba1\u7b97\u80fd\u529b\u4e0d\u8db3\uff0c\u9700\u4f9d\u8d56\u5916\u90e8\u8bbe\u5907\u5904\u7406\u5927\u91cf\u4f20\u611f\u6570\u636e\uff0c\u5bfc\u81f4\u901a\u4fe1\u8d1f\u62c5\u91cd\u4e14\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u79fb\u52a8\u6d4b\u5e8f\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8eRISC-V\u6838\u5fc3\u7684SoC\uff0c\u91c7\u752822\u7eb3\u7c73CMOS\u5de5\u827a\uff0c\u5e76\u96c6\u6210\u4e13\u7528DNA\u68c0\u6d4b\u786c\u4ef6\u52a0\u901f\u5668\u3002", "result": "\u8be5\u7cfb\u7edf\u76f8\u6bd4\u5546\u7528\u5d4c\u5165\u5f0f\u591a\u6838\u5904\u7406\u5668\u5b9e\u73b0\u4e8613\u500d\u7684\u6027\u80fd\u63d0\u5347\u548c\u8fd13000\u500d\u7684\u80fd\u6548\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684SoC\u67b6\u6784\u4e3a\u4e0b\u4e00\u4ee3\u4fbf\u643a\u5f0fDNA\u6d4b\u5e8f\u8bbe\u5907\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u3001\u9ad8\u80fd\u6548\u7684\u5d4c\u5165\u5f0f\u5904\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u671b\u5b9e\u73b0\u771f\u6b63\u7684\u5b9e\u65f6\u79fb\u52a8\u6d4b\u5e8f\u3002"}}
{"id": "2510.08609", "categories": ["cs.SE", "cs.CR", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.08609", "abs": "https://arxiv.org/abs/2510.08609", "authors": ["Imranur Rahman", "Jill Marley", "William Enck", "Laurie Williams"], "title": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?", "comment": "Accepted to ASE 2025", "summary": "Developers consistently use version constraints to specify acceptable\nversions of the dependencies for their project. \\emph{Pinning} dependencies can\nreduce the likelihood of breaking changes, but comes with a cost of manually\nmanaging the replacement of outdated and vulnerable dependencies. On the other\nhand, \\emph{floating} can be used to automatically get bug fixes and security\nfixes, but comes with the risk of breaking changes. Security practitioners\nadvocate \\emph{pinning} dependencies to prevent against software supply chain\nattacks, e.g., malicious package updates. However, since \\emph{pinning} is the\ntightest version constraint, \\emph{pinning} is the most likely to result in\noutdated dependencies. Nevertheless, how the likelihood of becoming outdated or\nvulnerable dependencies changes across version constraint types is unknown. The\ngoal of this study is to aid developers in making an informed dependency\nversion constraint choice by empirically evaluating the likelihood of\ndependencies becoming outdated or vulnerable across version constraint types at\nscale. In this study, we first identify the trends in dependency version\nconstraint usage and the patterns of version constraint type changes made by\ndevelopers in the npm, PyPI, and Cargo ecosystems. We then modeled the\ndependency state transitions using survival analysis and estimated how the\nlikelihood of becoming outdated or vulnerable changes when using \\emph{pinning}\nas opposed to the rest of the version constraint types. We observe that among\noutdated and vulnerable dependencies, the most commonly used version constraint\ntype is \\emph{floating-minor}, with \\emph{pinning} being the next most common.\nWe also find that \\emph{floating-major} is the least likely to result in\noutdated and \\emph{floating-minor} is the least likely to result in vulnerable\ndependencies.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u4f9d\u8d56\u7248\u672c\u7ea6\u675f\u7c7b\u578b\uff08\u5982\u56fa\u5b9a\u7248\u672c pinning \u4e0e\u6d6e\u52a8\u7248\u672c floating\uff09\u5bf9\u4f9d\u8d56\u9879\u8fc7\u65f6\u6216\u5b58\u5728\u6f0f\u6d1e\u53ef\u80fd\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0 floating-minor \u6700\u5e38\u7528\u4e14\u6700\u4e0d\u6613\u4ea7\u751f\u6f0f\u6d1e\uff0c\u800c floating-major \u6700\u4e0d\u6613\u5bfc\u81f4\u4f9d\u8d56\u8fc7\u65f6\u3002", "motivation": "\u5f00\u53d1\u8005\u5728\u4f9d\u8d56\u7ba1\u7406\u4e2d\u9700\u5728\u9632\u6b62\u7834\u574f\u6027\u53d8\u66f4\uff08\u901a\u8fc7 pinning\uff09\u4e0e\u81ea\u52a8\u83b7\u53d6\u4fee\u590d\uff08\u901a\u8fc7 floating\uff09\u4e4b\u95f4\u6743\u8861\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u4e0d\u540c\u7248\u672c\u7ea6\u675f\u7c7b\u578b\u5982\u4f55\u5f71\u54cd\u4f9d\u8d56\u8fc7\u65f6\u6216\u6f0f\u6d1e\u7684\u98ce\u9669\uff0c\u56e0\u6b64\u9700\u8981\u5b9e\u8bc1\u6307\u5bfc\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86 npm\u3001PyPI \u548c Cargo \u751f\u6001\u4e2d\u7248\u672c\u7ea6\u675f\u7684\u4f7f\u7528\u8d8b\u52bf\u53ca\u53d8\u66f4\u6a21\u5f0f\uff0c\u5e76\u91c7\u7528\u751f\u5b58\u5206\u6790\u5efa\u6a21\u4f9d\u8d56\u72b6\u6001\u8f6c\u6362\uff0c\u6bd4\u8f83 pinning \u4e0e\u5176\u4ed6\u7ea6\u675f\u7c7b\u578b\u5728\u5bfc\u81f4\u8fc7\u65f6\u6216\u6f0f\u6d1e\u65b9\u9762\u7684\u5dee\u5f02\u3002", "result": "\u5728\u8fc7\u65f6\u548c\u5b58\u5728\u6f0f\u6d1e\u7684\u4f9d\u8d56\u4e2d\uff0c\u6700\u5e38\u7528\u7684\u7ea6\u675f\u7c7b\u578b\u662f floating-minor\uff0c\u5176\u6b21\u4e3a pinning\uff1bfloating-major \u6700\u4e0d\u6613\u5bfc\u81f4\u4f9d\u8d56\u8fc7\u65f6\uff0c\u800c floating-minor \u6700\u4e0d\u6613\u5bfc\u81f4\u6f0f\u6d1e\u3002", "conclusion": "\u5f00\u53d1\u8005\u5e94\u6839\u636e\u5b89\u5168\u4e0e\u7ef4\u62a4\u76ee\u6807\u8c28\u614e\u9009\u62e9\u7248\u672c\u7ea6\u675f\u7c7b\u578b\uff0cfloating-minor \u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u540c\u65f6\u517c\u987e\u66f4\u65b0\uff0c\u53ef\u80fd\u662f\u8f83\u4f18\u9009\u62e9\u3002"}}
{"id": "2510.09163", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.09163", "abs": "https://arxiv.org/abs/2510.09163", "authors": ["Alessandro Ottaviano", "Andrino Meli", "Paul Scheffler", "Giovanni Bambini", "Robert Balas", "Davide Rossi", "Andrea Bartolini", "Luca Benini"], "title": "Co-designing a Programmable RISC-V Accelerator for MPC-based Energy and Thermal Management of Many-Core HPC Processors", "comment": "18 pages, 16 figures, 1 table", "summary": "Managing energy and thermal profiles is critical for many-core HPC processors\nwith hundreds of application-class processing elements (PEs). Advanced model\npredictive control (MPC) delivers state-of-the-art performance but requires\nsolving an online optimization problem over a thousand times per second (1 kHz\ncontrol bandwidth), with computational and memory demands scaling with PE\ncount. Traditional MPC approaches execute the controller on the PEs, but\noperating system overheads create jitter and limit control bandwidth. Running\nMPC on dedicated on-chip controllers enables fast, deterministic control but\nraises concerns about area and power overhead. In this work, we tackle these\nchallenges by proposing a hardware-software codesign of a lightweight MPC\ncontroller, based on an operator-splitting quadratic programming solver and an\nembedded multi-core RISC-V controller. Key innovations include pruning weak\nthermal couplings to reduce model memory and ahead-of-time scheduling for\nefficient parallel execution of sparse triangular systems arising from the\noptimization problem. The proposed controller achieves sub-millisecond latency\nwhen controlling 144 PEs at 500 MHz, delivering 33x lower latency and 7.9x\nhigher energy efficiency than a single-core baseline. Operating within a\ncompact less than 1 MiB memory footprint, it consumes as little as 325 mW while\noccupying less than 1.5% of a typical HPC processor's die area.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5668\uff08MPC\uff09\uff0c\u7528\u4e8e\u9ad8\u6548\u7ba1\u7406\u4f17\u6838\u9ad8\u6027\u80fd\u8ba1\u7b97\u5904\u7406\u5668\u7684\u80fd\u8017\u4e0e\u70ed\u5206\u5e03\uff0c\u5728\u63a7\u5236144\u4e2a\u5904\u7406\u5355\u5143\u65f6\u5b9e\u73b0\u4e9a\u6beb\u79d2\u7ea7\u5ef6\u8fdf\u30017.9\u500d\u80fd\u6548\u63d0\u5347\uff0c\u4e14\u4ec5\u5360\u7528\u5c0f\u4e8e1.5%\u82af\u7247\u9762\u79ef\u548c1 MiB\u5185\u5b58\u3002", "motivation": "\u4f20\u7edfMPC\u63a7\u5236\u5668\u5728\u5904\u7406\u5355\u5143\uff08PE\uff09\u4e0a\u8fd0\u884c\u53d7\u64cd\u4f5c\u7cfb\u7edf\u5f00\u9500\u5f71\u54cd\uff0c\u5bfc\u81f4\u6296\u52a8\u5e76\u9650\u5236\u63a7\u5236\u5e26\u5bbd\uff1b\u800c\u4e13\u7528\u7247\u4e0a\u63a7\u5236\u5668\u867d\u53ef\u5b9e\u73b0\u5feb\u901f\u786e\u5b9a\u6027\u63a7\u5236\uff0c\u5374\u9762\u4e34\u9762\u79ef\u4e0e\u529f\u8017\u5f00\u9500\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u517c\u987e\u6027\u80fd\u3001\u80fd\u6548\u4e0e\u8d44\u6e90\u5f00\u9500\u7684\u65b0\u578bMPC\u5b9e\u73b0\u65b9\u6848\u3002", "method": "\u91c7\u7528\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u57fa\u4e8e\u7b97\u5b50\u5206\u88c2\u4e8c\u6b21\u89c4\u5212\u6c42\u89e3\u5668\u548c\u5d4c\u5165\u5f0f\u591a\u6838RISC-V\u63a7\u5236\u5668\u6784\u5efa\u8f7b\u91cf\u7ea7MPC\uff1b\u901a\u8fc7\u526a\u679d\u5f31\u70ed\u8026\u5408\u4ee5\u51cf\u5c11\u6a21\u578b\u5185\u5b58\uff0c\u5e76\u5229\u7528\u63d0\u524d\u8c03\u5ea6\u7b56\u7565\u9ad8\u6548\u5e76\u884c\u6267\u884c\u4f18\u5316\u95ee\u9898\u4e2d\u4ea7\u751f\u7684\u7a00\u758f\u4e09\u89d2\u7cfb\u7edf\u3002", "result": "\u6240\u63d0\u63a7\u5236\u5668\u5728500 MHz\u4e0b\u63a7\u5236144\u4e2aPE\u65f6\u5b9e\u73b0\u4e9a\u6beb\u79d2\u5ef6\u8fdf\uff0c\u76f8\u6bd4\u5355\u6838\u57fa\u7ebf\u5ef6\u8fdf\u964d\u4f4e33\u500d\u3001\u80fd\u6548\u63d0\u53477.9\u500d\uff1b\u5185\u5b58\u5360\u7528\u5c0f\u4e8e1 MiB\uff0c\u529f\u8017\u4f4e\u81f3325 mW\uff0c\u82af\u7247\u9762\u79ef\u5360\u7528\u4e0d\u8db3\u5178\u578bHPC\u5904\u7406\u5668\u76841.5%\u3002", "conclusion": "\u8be5\u8f7b\u91cf\u7ea7MPC\u63a7\u5236\u5668\u5728\u6ee1\u8db3\u9ad8\u63a7\u5236\u5e26\u5bbd\u9700\u6c42\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3001\u529f\u8017\u4e0e\u9762\u79ef\u5f00\u9500\uff0c\u4e3a\u4f17\u6838HPC\u5904\u7406\u5668\u7684\u80fd\u6548\u4e0e\u70ed\u7ba1\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.09010", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.09010", "abs": "https://arxiv.org/abs/2510.09010", "authors": ["Yipu Zhang", "Chaofang Ma", "Jinming Ge", "Lin Jiang", "Jiang Xu", "Wei Zhang"], "title": "HERO: Hardware-Efficient RL-based Optimization Framework for NeRF Quantization", "comment": "Accepted by ASPDAC 2026", "summary": "Neural Radiance Field (NeRF) has emerged as a promising 3D reconstruction\nmethod, delivering high-quality results for AR/VR applications. While\nquantization methods and hardware accelerators have been proposed to enhance\nNeRF's computational efficiency, existing approaches face crucial limitations.\nCurrent quantization methods operate without considering hardware architecture,\nresulting in sub-optimal solutions within the vast design space encompassing\naccuracy, latency, and model size. Additionally, existing NeRF accelerators\nheavily rely on human experts to explore this design space, making the\noptimization process time-consuming, inefficient, and unlikely to discover\noptimal solutions. To address these challenges, we introduce HERO, a\nreinforcement learning framework performing hardware-aware quantization for\nNeRF. Our framework integrates a NeRF accelerator simulator to generate\nreal-time hardware feedback, enabling fully automated adaptation to hardware\nconstraints. Experimental results demonstrate that HERO achieves 1.31-1.33\n$\\times$ better latency, 1.29-1.33 $\\times$ improved cost efficiency, and a\nmore compact model size compared to CAQ, a previous state-of-the-art NeRF\nquantization framework. These results validate our framework's capability to\neffectively navigate the complex design space between hardware and algorithm\nrequirements, discovering superior quantization policies for NeRF\nimplementation. Code is available at https://github.com/ypzhng/HERO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HERO\uff0c\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u786c\u4ef6\u611f\u77e5NeRF\u91cf\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210NeRF\u52a0\u901f\u5668\u6a21\u62df\u5668\u5b9e\u73b0\u81ea\u52a8\u5316\u4f18\u5316\uff0c\u5728\u5ef6\u8fdf\u3001\u6210\u672c\u6548\u7387\u548c\u6a21\u578b\u5927\u5c0f\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709NeRF\u91cf\u5316\u65b9\u6cd5\u672a\u8003\u8651\u786c\u4ef6\u67b6\u6784\uff0c\u5bfc\u81f4\u5728\u7cbe\u5ea6\u3001\u5ef6\u8fdf\u548c\u6a21\u578b\u5927\u5c0f\u4e4b\u95f4\u7684\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u8868\u73b0\u6b21\u4f18\uff1b\u540c\u65f6\uff0c\u73b0\u6709\u52a0\u901f\u5668\u4f9d\u8d56\u4eba\u5de5\u63a2\u7d22\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u96be\u4ee5\u627e\u5230\u6700\u4f18\u89e3\u3002", "method": "\u63d0\u51faHERO\u6846\u67b6\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u786c\u4ef6\u611f\u77e5\u7684NeRF\u91cf\u5316\uff0c\u5e76\u96c6\u6210NeRF\u52a0\u901f\u5668\u6a21\u62df\u5668\u4ee5\u63d0\u4f9b\u5b9e\u65f6\u786c\u4ef6\u53cd\u9988\uff0c\u5b9e\u73b0\u5168\u81ea\u52a8\u9002\u914d\u786c\u4ef6\u7ea6\u675f\u3002", "result": "HERO\u76f8\u6bd4\u5148\u524d\u6700\u5148\u8fdb\u7684CAQ\u6846\u67b6\uff0c\u5728\u5ef6\u8fdf\u4e0a\u63d0\u53471.31\u20131.33\u500d\uff0c\u6210\u672c\u6548\u7387\u63d0\u53471.29\u20131.33\u500d\uff0c\u5e76\u83b7\u5f97\u66f4\u7d27\u51d1\u7684\u6a21\u578b\u3002", "conclusion": "HERO\u80fd\u6709\u6548\u5728\u786c\u4ef6\u4e0e\u7b97\u6cd5\u9700\u6c42\u4e4b\u95f4\u590d\u6742\u7684\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u5bfc\u822a\uff0c\u81ea\u52a8\u53d1\u73b0\u66f4\u4f18\u7684NeRF\u91cf\u5316\u7b56\u7565\u3002"}}
{"id": "2510.08610", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.08610", "abs": "https://arxiv.org/abs/2510.08610", "authors": ["Imranur Rahman", "Md Rayhanur Rahman"], "title": "Relative Positioning Based Code Chunking Method For Rich Context Retrieval In Repository Level Code Completion Task With Code Language Model", "comment": "Accepted to Context Collection Workshop co-located with ASE 2025", "summary": "Code completion can help developers improve efficiency and ease the\ndevelopment lifecycle. Although code completion is available in modern\nintegrated development environments (IDEs), research lacks in determining what\nmakes a good context for code completion based on the information available to\nthe IDEs for the large language models (LLMs) to perform better. In this paper,\nwe describe an effective context collection strategy to assist the LLMs in\nperforming better at code completion tasks. The key idea of our strategy is to\npreprocess the repository into smaller code chunks and later use syntactic and\nsemantic similarity-based code chunk retrieval with relative positioning. We\nfound that code chunking and relative positioning of the chunks in the final\ncontext improve the performance of code completion tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u6536\u96c6\u7b56\u7565\uff0c\u901a\u8fc7\u5c06\u4ee3\u7801\u5e93\u9884\u5904\u7406\u4e3a\u5c0f\u4ee3\u7801\u5757\uff0c\u5e76\u7ed3\u5408\u8bed\u6cd5\u4e0e\u8bed\u4e49\u76f8\u4f3c\u6027\u68c0\u7d22\u53ca\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u5982\u4f55\u6784\u5efa\u9002\u5408\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u8865\u5168\u7684\u6709\u6548\u4e0a\u4e0b\u6587\u7684\u6df1\u5165\u7406\u89e3\uff0c\u5c3d\u7ba1\u73b0\u4ee3IDE\u5df2\u63d0\u4f9b\u4ee3\u7801\u8865\u5168\u529f\u80fd\u3002", "method": "\u5c06\u4ee3\u7801\u4ed3\u5e93\u9884\u5904\u7406\u4e3a\u8f83\u5c0f\u7684\u4ee3\u7801\u5757\uff0c\u5229\u7528\u57fa\u4e8e\u8bed\u6cd5\u548c\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u68c0\u7d22\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u4ee3\u7801\u5757\u7684\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u6784\u5efa\u4e0a\u4e0b\u6587\u3002", "result": "\u4ee3\u7801\u5206\u5757\u4e0e\u4ee3\u7801\u5757\u5728\u6700\u7ec8\u4e0a\u4e0b\u6587\u4e2d\u7684\u76f8\u5bf9\u4f4d\u7f6e\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u6784\u5efa\u7b56\u7565\uff0c\u7279\u522b\u662f\u7ed3\u5408\u4ee3\u7801\u5206\u5757\u4e0e\u76f8\u5bf9\u4f4d\u7f6e\u4fe1\u606f\uff0c\u80fd\u591f\u663e\u8457\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u8865\u5168\u4e2d\u7684\u6548\u679c\u3002"}}
{"id": "2510.09339", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.09339", "abs": "https://arxiv.org/abs/2510.09339", "authors": ["Sebastian Magierowski", "Zhongpan Wu", "Abel Beyene", "Karim Hammad"], "title": "Sequencing on Silicon: AI SoC Design for Mobile Genomics at the Edge", "comment": null, "summary": "Miniature DNA sequencing hardware has begun to succeed in mobile contexts,\ndriving demand for efficient machine learning at the edge. This domain\nleverages deep learning techniques familiar from speech and time-series\nanalysis for both low-level signal processing and high-level genomic\ninterpretation. Unlike audio, however, nanopore sequencing presents raw data\nrates over 100X higher, requiring more aggressive compute and memory handling.\nIn this paper, we present a CMOS system-on-chip (SoC) designed for mobile\ngenetic analysis. Our approach combines a multi-core RISC-V processor with\ntightly coupled accelerators for deep learning and bioinformatics. A\nhardware/software co-design strategy enables energy-efficient operation across\na heterogeneous compute fabric, targeting real-time, on-device genome analysis.\nThis work exemplifies the integration of deep learning, edge computing, and\ndomain-specific hardware to advance next-generation mobile genomics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u79fb\u52a8\u57fa\u56e0\u7ec4\u5206\u6790\u7684CMOS\u7247\u4e0a\u7cfb\u7edf\uff08SoC\uff09\uff0c\u7ed3\u5408\u591a\u6838RISC-V\u5904\u7406\u5668\u4e0e\u6df1\u5ea6\u5b66\u4e60\u53ca\u751f\u7269\u4fe1\u606f\u5b66\u4e13\u7528\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u5b9e\u73b0\u9ad8\u6548\u80fd\u3001\u4f4e\u529f\u8017\u7684\u5b9e\u65f6\u7247\u4e0a\u57fa\u56e0\u7ec4\u5206\u6790\u3002", "motivation": "\u7eb3\u7c73\u5b54DNA\u6d4b\u5e8f\u5728\u79fb\u52a8\u573a\u666f\u4e2d\u4ea7\u751f\u6781\u9ad8\u7684\u539f\u59cb\u6570\u636e\u901f\u7387\uff08\u6bd4\u97f3\u9891\u9ad8100\u500d\u4ee5\u4e0a\uff09\uff0c\u5bf9\u8fb9\u7f18\u7aef\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u5904\u7406\u80fd\u529b\u63d0\u51fa\u4e25\u5cfb\u6311\u6218\uff0c\u4e9f\u9700\u9ad8\u6548\u3001\u4f4e\u529f\u8017\u7684\u673a\u5668\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e00\u79cd\u96c6\u6210\u591a\u6838RISC-V\u5904\u7406\u5668\u4e0e\u7d27\u8026\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u751f\u7269\u4fe1\u606f\u5b66\u52a0\u901f\u5668\u7684CMOS SoC\uff0c\u91c7\u7528\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u7b56\u7565\uff0c\u5728\u5f02\u6784\u8ba1\u7b97\u67b6\u6784\u4e0a\u5b9e\u73b0\u80fd\u6548\u4f18\u5316\u3002", "result": "\u8be5SoC\u652f\u6301\u5b9e\u65f6\u3001\u8bbe\u5907\u7aef\u7684\u57fa\u56e0\u7ec4\u5206\u6790\uff0c\u6709\u6548\u5e94\u5bf9\u7eb3\u7c73\u5b54\u6d4b\u5e8f\u5e26\u6765\u7684\u9ad8\u6570\u636e\u7387\u6311\u6218\uff0c\u5c55\u793a\u4e86\u6df1\u5ea6\u5b66\u4e60\u3001\u8fb9\u7f18\u8ba1\u7b97\u4e0e\u9886\u57df\u4e13\u7528\u786c\u4ef6\u878d\u5408\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6df1\u5ea6\u5b66\u4e60\u3001\u8fb9\u7f18\u8ba1\u7b97\u4e0e\u4e13\u7528\u786c\u4ef6\u96c6\u6210\uff0c\u8be5\u5de5\u4f5c\u63a8\u52a8\u4e86\u4e0b\u4e00\u4ee3\u79fb\u52a8\u57fa\u56e0\u7ec4\u5b66\u7684\u53d1\u5c55\uff0c\u4e3a\u9ad8\u901a\u91cf\u751f\u7269\u6570\u636e\u7684\u5b9e\u65f6\u5904\u7406\u63d0\u4f9b\u4e86\u9ad8\u6548\u80fd\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08664", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08664", "abs": "https://arxiv.org/abs/2510.08664", "authors": ["Jianan Mu", "Mingyu Shi", "Yining Wang", "Tianmeng Yang", "Bin Sun", "Xing Hu", "Jing Ye", "Huawei Li"], "title": "Faver: Boosting LLM-based RTL Generation with Function Abstracted Verifiable Middleware", "comment": null, "summary": "LLM-based RTL generation is an interesting research direction, as it holds\nthe potential to liberate the least automated stage in the current chip design.\nHowever, due to the substantial semantic gap between high-level specifications\nand RTL, coupled with limited training data, existing models struggle with\ngeneration accuracy. Drawing on human experience, design with verification\nhelps improving accuracy. However, as the RTL testbench data are even more\nscarce, it is not friendly for LLMs. Although LLMs excel at higher-level\nlanguages like Python/C, they have a huge semantic gap from RTL. When\nimplementing the same functionality, Python/C code and hardware code differ\nsignificantly in the spatiotemporal granularity, requiring the LLM not only to\nconsider high-level functional semantics but also to ensure the low-level\ndetails align with the circuit code. It is not an easy task. In this paper, we\npropose a function abstracted verifiable middleware (Faver) that streamlines\nRTL verification in LLM-based workflows. By mixing LLM-friendly code structures\nwith a rule-based template, Faver decouples the details of circuit\nverification, allowing the LLM to focus on the functionality itself. In our\nexperiments on the SFT model and open-source models, Faver improved the model's\ngeneration accuracy by up to 14%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFaver\u7684\u51fd\u6570\u62bd\u8c61\u53ef\u9a8c\u8bc1\u4e2d\u95f4\u4ef6\uff0c\u901a\u8fc7\u7ed3\u5408LLM\u53cb\u597d\u7684\u4ee3\u7801\u7ed3\u6784\u4e0e\u57fa\u4e8e\u89c4\u5219\u7684\u6a21\u677f\uff0c\u89e3\u8026\u7535\u8def\u9a8c\u8bc1\u7ec6\u8282\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u4e13\u6ce8\u4e8e\u529f\u80fd\u5b9e\u73b0\uff0c\u4ece\u800c\u5728RTL\u751f\u6210\u4efb\u52a1\u4e2d\u5c06\u51c6\u786e\u7387\u63d0\u5347\u6700\u591a14%\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684RTL\u751f\u6210\u9762\u4e34\u9ad8\u9636\u89c4\u8303\u4e0eRTL\u4e4b\u95f4\u8bed\u4e49\u9e3f\u6c9f\u5927\u3001\u8bad\u7ec3\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u751f\u6210\u51c6\u786e\u6027\u4e0d\u8db3\uff1b\u540c\u65f6RTL\u6d4b\u8bd5\u5e73\u53f0\u6570\u636e\u66f4\u52a0\u7a00\u7f3a\uff0c\u4e0d\u5229\u4e8eLLM\u5b66\u4e60\uff0c\u4e14Python/C\u7b49\u9ad8\u5c42\u8bed\u8a00\u4e0e\u786c\u4ef6\u4ee3\u7801\u5728\u65f6\u7a7a\u7c92\u5ea6\u4e0a\u5dee\u5f02\u663e\u8457\uff0c\u589e\u52a0\u4e86LLM\u5efa\u6a21\u96be\u5ea6\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u51fd\u6570\u62bd\u8c61\u53ef\u9a8c\u8bc1\u4e2d\u95f4\u4ef6\uff08Faver\uff09\uff0c\u878d\u5408LLM\u53cb\u597d\u7684\u4ee3\u7801\u7ed3\u6784\u4e0e\u57fa\u4e8e\u89c4\u5219\u7684\u6a21\u677f\uff0c\u5c06\u7535\u8def\u9a8c\u8bc1\u7ec6\u8282\u89e3\u8026\uff0c\u4f7fLLM\u4e13\u6ce8\u4e8e\u529f\u80fd\u8bed\u4e49\uff0c\u7b80\u5316RTL\u9a8c\u8bc1\u6d41\u7a0b\u3002", "result": "\u5728SFT\u6a21\u578b\u548c\u5f00\u6e90\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFaver\u6700\u591a\u53ef\u5c06\u6a21\u578b\u7684RTL\u751f\u6210\u51c6\u786e\u7387\u63d0\u534714%\u3002", "conclusion": "Faver\u6709\u6548\u7f13\u89e3\u4e86LLM\u5728RTL\u751f\u6210\u4e2d\u56e0\u8bed\u4e49\u9e3f\u6c9f\u548c\u6570\u636e\u7a00\u7f3a\u5bfc\u81f4\u7684\u51c6\u786e\u6027\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u5316\u82af\u7247\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u65b0\u8def\u5f84\u3002"}}
{"id": "2510.08665", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08665", "abs": "https://arxiv.org/abs/2510.08665", "authors": ["Aofan Liu", "Haoxuan Li", "Bin Wang", "Ao Yang", "Hui Li"], "title": "RA-Gen: A Controllable Code Generation Framework Using ReAct for Multi-Agent Task Execution", "comment": null, "summary": "Code generation models based on large language models (LLMs) have gained wide\nadoption, but challenges remain in ensuring safety, accuracy, and\ncontrollability, especially for complex tasks. Existing methods often lack\ndynamic integration of external tools, transparent reasoning, and user control\nover safety. To address these issues, we propose a controllable code generation\nframework utilizing the ReAct paradigm for multi-agent task execution. This\nframework is a multi-agent system designed to enable efficient, precise, and\ninterpretable code generation through dynamic interactions between LLMs and\nexternal resources. The framework adopts a collaborative architecture\ncomprising four specialized agents: a Planner for task decomposition, a\nSearcher that leverages the ReAct framework for reasoning and tool integration,\na CodeGen agent for accurate code generation, and an Extractor for structured\ndata retrieval. The ReAct-based Searcher alternates between generating\nreasoning traces and executing actions, facilitating seamless integration of\ninternal knowledge with external tools (such as search engines) to enhance\naccuracy and user control. Experimental results show the framework's\neffectiveness across multiple languages, achieving a 94.8% security rate on the\nSVEN dataset with CodeQL, outperforming existing approaches. Its transparent\nreasoning process fosters user trust and improves controllability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eReAct\u8303\u5f0f\u7684\u591a\u667a\u80fd\u4f53\u53ef\u63a7\u4ee3\u7801\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u89c4\u5212\u5668\u3001\u641c\u7d22\u5668\u3001\u4ee3\u7801\u751f\u6210\u5668\u548c\u63d0\u53d6\u5668\u56db\u4e2a\u4e13\u7528\u667a\u80fd\u4f53\u534f\u540c\u5de5\u4f5c\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u7cbe\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u4ee3\u7801\u751f\u6210\uff0c\u5e76\u5728\u5b89\u5168\u6027\u548c\u53ef\u63a7\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u5728\u5b89\u5168\u6027\u3001\u51c6\u786e\u6027\u548c\u53ef\u63a7\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5c24\u5176\u7f3a\u4e4f\u5bf9\u5916\u90e8\u5de5\u5177\u7684\u52a8\u6001\u96c6\u6210\u3001\u900f\u660e\u63a8\u7406\u8fc7\u7a0b\u4ee5\u53ca\u7528\u6237\u5bf9\u5b89\u5168\u6027\u7684\u63a7\u5236\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8eReAct\u8303\u5f0f\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u56db\u4e2a\u4e13\u7528\u667a\u80fd\u4f53\uff1a\u8d1f\u8d23\u4efb\u52a1\u5206\u89e3\u7684Planner\u3001\u57fa\u4e8eReAct\u8fdb\u884c\u63a8\u7406\u4e0e\u5de5\u5177\u8c03\u7528\u7684Searcher\u3001\u8d1f\u8d23\u4ee3\u7801\u751f\u6210\u7684CodeGen\uff0c\u4ee5\u53ca\u7528\u4e8e\u7ed3\u6784\u5316\u6570\u636e\u63d0\u53d6\u7684Extractor\uff1b\u5176\u4e2dSearcher\u901a\u8fc7\u4ea4\u66ff\u751f\u6210\u63a8\u7406\u8f68\u8ff9\u4e0e\u6267\u884c\u52a8\u4f5c\uff0c\u52a8\u6001\u7ed3\u5408\u5185\u90e8\u77e5\u8bc6\u4e0e\u5916\u90e8\u5de5\u5177\uff08\u5982\u641c\u7d22\u5f15\u64ce\uff09\u3002", "result": "\u8be5\u6846\u67b6\u5728\u591a\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5728SVEN\u6570\u636e\u96c6\u4e0a\u4f7f\u7528CodeQL\u8bc4\u4f30\u8fbe\u523094.8%\u7684\u5b89\u5168\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u5176\u900f\u660e\u63a8\u7406\u8fc7\u7a0b\u589e\u5f3a\u4e86\u7528\u6237\u4fe1\u4efb\u4e0e\u53ef\u63a7\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53ReAct\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u7684\u5b89\u5168\u6027\u3001\u51c6\u786e\u6027\u4e0e\u53ef\u63a7\u6027\uff0c\u4e3a\u590d\u6742\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u4e14\u7528\u6237\u53ef\u63a7\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08667", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08667", "abs": "https://arxiv.org/abs/2510.08667", "authors": ["Mohammad Baqar"], "title": "RAG4Tickets: AI-Powered Ticket Resolution via Retrieval-Augmented Generation on JIRA and GitHub Data", "comment": "13 Pages", "summary": "Modern software teams frequently encounter delays in resolving recurring or\nrelated issues due to fragmented knowledge scattered across JIRA tickets,\ndeveloper discussions, and GitHub pull requests (PRs). To address this\nchallenge, we propose a Retrieval-Augmented Generation (RAG) framework that\nintegrates Sentence-Transformers for semantic embeddings with FAISS-based\nvector search to deliver context-aware ticket resolution recommendations. The\napproach embeds historical JIRA tickets, user comments, and linked PR metadata\nto retrieve semantically similar past cases, which are then synthesized by a\nLarge Language Model (LLM) into grounded and explainable resolution\nsuggestions. The framework contributes a unified pipeline linking JIRA and\nGitHub data, an embedding and FAISS indexing strategy for heterogeneous\nsoftware artifacts, and a resolution generation module guided by retrieved\nevidence. Experimental evaluation using precision, recall, resolution time\nreduction, and developer acceptance metrics shows that the proposed system\nsignificantly improves resolution accuracy, fix quality, and knowledge reuse in\nmodern DevOps environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408Sentence-Transformers\u4e0eFAISS\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u6574\u5408JIRA\u548cGitHub\u4e2d\u7684\u5f02\u6784\u6570\u636e\uff0c\u901a\u8fc7\u8bed\u4e49\u68c0\u7d22\u5386\u53f2\u5de5\u5355\u4e0ePR\u4fe1\u606f\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53ef\u89e3\u91ca\u7684\u95ee\u9898\u89e3\u51b3\u5efa\u8bae\uff0c\u663e\u8457\u63d0\u5347DevOps\u73af\u5883\u4e2d\u95ee\u9898\u89e3\u51b3\u7684\u51c6\u786e\u6027\u4e0e\u77e5\u8bc6\u590d\u7528\u6548\u7387\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u56e2\u961f\u5728\u89e3\u51b3\u91cd\u590d\u6216\u76f8\u5173\u95ee\u9898\u65f6\u5e38\u5e38\u56e0\u77e5\u8bc6\u788e\u7247\u5316\uff08\u5206\u6563\u5728JIRA\u5de5\u5355\u3001\u5f00\u53d1\u8005\u8ba8\u8bba\u548cGitHub PR\u4e2d\uff09\u800c\u5ef6\u8bef\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u6574\u5408\u5e76\u667a\u80fd\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u4f7f\u7528Sentence-Transformers\u751f\u6210\u8bed\u4e49\u5d4c\u5165\uff0c\u901a\u8fc7FAISS\u8fdb\u884c\u5411\u91cf\u68c0\u7d22\uff0c\u6574\u5408\u5386\u53f2JIRA\u5de5\u5355\u3001\u7528\u6237\u8bc4\u8bba\u548c\u5173\u8054PR\u5143\u6570\u636e\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u68c0\u7d22\u5230\u7684\u76f8\u4f3c\u6848\u4f8b\u751f\u6210\u89e3\u91ca\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u5728\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u3001\u95ee\u9898\u89e3\u51b3\u65f6\u95f4\u7f29\u77ed\u548c\u5f00\u53d1\u8005\u63a5\u53d7\u5ea6\u7b49\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u63d0\u5347\u4e86\u95ee\u9898\u89e3\u51b3\u51c6\u786e\u7387\u3001\u4fee\u590d\u8d28\u91cf\u548c\u77e5\u8bc6\u590d\u7528\u6548\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684RAG\u6846\u67b6\u6709\u6548\u6574\u5408\u4e86JIRA\u4e0eGitHub\u4e2d\u7684\u5f02\u6784\u8f6f\u4ef6\u5f00\u53d1\u6570\u636e\uff0c\u901a\u8fc7\u8bed\u4e49\u68c0\u7d22\u4e0e\u751f\u6210\u673a\u5236\uff0c\u4e3aDevOps\u73af\u5883\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u4e14\u5b9e\u7528\u7684\u95ee\u9898\u89e3\u51b3\u652f\u6301\u3002"}}
{"id": "2510.08697", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.08697", "abs": "https://arxiv.org/abs/2510.08697", "authors": ["Terry Yue Zhuo", "Xiaolong Jin", "Hange Liu", "Juyong Jiang", "Tianyang Liu", "Chen Gong", "Bhupesh Bishnoi", "Vaisakhi Mishra", "Marek Suppa", "Noah Ziems", "Saiteja Utpala", "Ming Xu", "Guangyu Song", "Kaixin Li", "Yuhan Cao", "Bo Liu", "Zheng Liu", "Sabina Abdurakhmanova", "Wenhao Yu", "Mengzhao Jia", "Jihan Yao", "Kenneth Hamilton", "Kumar Shridhar", "Minh Chien Vu", "Dingmin Wang", "Jiawei Liu", "Zijian Wang", "Qian Liu", "Binyuan Hui", "Meg Risdal", "Ahsen Khaliq", "Atin Sood", "Zhenchang Xing", "Wasi Uddin Ahmad", "John Grundy", "David Lo", "Banghua Zhu", "Xiaoning Du", "Torsten Scholak", "Leandro von Werra"], "title": "BigCodeArena: Unveiling More Reliable Human Preferences in Code Generation via Execution", "comment": "Built with love by the BigCode community :)", "summary": "Crowdsourced model evaluation platforms, such as Chatbot Arena, enable\nreal-time evaluation from human perspectives to assess the quality of model\nresponses. In the coding domain, manually examining the quality of\nLLM-generated content is extremely challenging, as it requires understanding\nlong chunks of raw code and deliberately simulating code execution. To this\nend, we introduce BigCodeArena, an open human evaluation platform for code\ngeneration backed by a comprehensive and on-the-fly execution environment.\nBuilt on top of Chatbot Arena, BigCodeArena enables the execution of\nLLM-generated code and allows humans to interact with the execution process and\noutcomes. We collected over 14,000 raw code-centric conversation sessions\nacross 10 widely used LLMs, spanning 10 languages and 8 types of execution\nenvironments. Among these conversations, we identified more than 4,700\nmulti-turn samples with pairwise human preferences. Further analysis uncovers\nunderexplored preferences of LLMs in fine-grained domains characterized by\ntasks, languages, and frameworks. To systematically examine code understanding\nand generation capabilities of frontier LLMs, we curated two benchmarks based\non the collected data, namely BigCodeReward and AutoCodeArena. For\nBigCodeReward, we post-processed the 4,700 conversations and evaluated the\nconsistency between reward models and human preferences. The evaluation shows\nthat most LLMs have superior performance in judging coding preferences when the\nexecution results are available. Inspired by these findings, we propose\nAutoCodeArena, an automatic Elo rating benchmark designed to assess the coding\nquality of LLMs without human involvement. We find that proprietary LLMs like\nGPT-5, Claude-Sonnet-4, and Claude-Opus-4 still lead in code generation\nperformance among recent emerging models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BigCodeArena\uff0c\u4e00\u4e2a\u652f\u6301\u5b9e\u65f6\u4ee3\u7801\u6267\u884c\u4e0e\u4ea4\u4e92\u7684\u5f00\u6e90\u4eba\u5de5\u8bc4\u4f30\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u57fa\u4e8e\u6536\u96c6\u7684\u6570\u636e\u6784\u5efa\u4e86\u4e24\u4e2a\u65b0\u57fa\u51c6\uff1aBigCodeReward\uff08\u7528\u4e8e\u8bc4\u4f30\u5956\u52b1\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u4e00\u81f4\u6027\uff09\u548cAutoCodeArena\uff08\u65e0\u9700\u4eba\u5de5\u53c2\u4e0e\u7684\u81ea\u52a8Elo\u8bc4\u5206\u57fa\u51c6\uff09\u3002", "motivation": "\u5728\u4ee3\u7801\u9886\u57df\uff0c\u4eba\u5de5\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u6781\u5177\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u9700\u8981\u7406\u89e3\u5927\u91cf\u539f\u59cb\u4ee3\u7801\u5e76\u6a21\u62df\u6267\u884c\u8fc7\u7a0b\u3002\u73b0\u6709\u5e73\u53f0\u7f3a\u4e4f\u5bf9\u4ee3\u7801\u6267\u884c\u7684\u652f\u6301\uff0c\u96be\u4ee5\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "method": "\u57fa\u4e8eChatbot Arena\u6784\u5efaBigCodeArena\u5e73\u53f0\uff0c\u96c6\u6210\u5373\u65f6\u4ee3\u7801\u6267\u884c\u73af\u5883\uff0c\u652f\u6301\u4eba\u7c7b\u8bc4\u4f30\u8005\u4e0e\u4ee3\u7801\u6267\u884c\u8fc7\u7a0b\u4ea4\u4e92\uff1b\u6536\u96c6\u4e8614,000\u591a\u4e2a\u6db5\u76d610\u79cd\u8bed\u8a00\u548c8\u7c7b\u6267\u884c\u73af\u5883\u7684\u5bf9\u8bdd\u4f1a\u8bdd\uff0c\u4ece\u4e2d\u63d0\u53d64,700\u591a\u4e2a\u591a\u8f6e\u5bf9\u8bdd\u6837\u672c\u53ca\u4eba\u7c7b\u504f\u597d\u6570\u636e\uff1b\u57fa\u4e8e\u6b64\u6784\u5efaBigCodeReward\u548cAutoCodeArena\u4e24\u4e2a\u57fa\u51c6\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u3001\u8bed\u8a00\u548c\u6846\u67b6\u4e0b\u7684\u7ec6\u7c92\u5ea6\u504f\u597d\uff1bBigCodeReward\u8bc4\u4f30\u663e\u793a\uff0c\u5f53\u6709\u6267\u884c\u7ed3\u679c\u65f6\uff0c\u5927\u591a\u6570\u6a21\u578b\u5728\u5224\u65ad\u4ee3\u7801\u504f\u597d\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff1bAutoCodeArena\u81ea\u52a8\u8bc4\u4f30\u8868\u660e\uff0cGPT-5\u3001Claude-Sonnet-4\u548cClaude-Opus-4\u7b49\u95ed\u6e90\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u4ecd\u5904\u4e8e\u9886\u5148\u5730\u4f4d\u3002", "conclusion": "BigCodeArena\u4e3a\u4ee3\u7801\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u3001\u53ef\u4ea4\u4e92\u7684\u4eba\u7c7b\u8bc4\u4f30\u73af\u5883\uff0c\u6240\u6784\u5efa\u7684\u4e24\u4e2a\u57fa\u51c6\u6709\u52a9\u4e8e\u7cfb\u7edf\u6027\u8bc4\u4f30\u6a21\u578b\u7684\u4ee3\u7801\u7406\u89e3\u4e0e\u751f\u6210\u80fd\u529b\uff0c\u4e14\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5\u5728\u51cf\u5c11\u4eba\u5de5\u4f9d\u8d56\u7684\u540c\u65f6\u4ecd\u80fd\u6709\u6548\u53cd\u6620\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2510.08716", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.08716", "abs": "https://arxiv.org/abs/2510.08716", "authors": ["Stephan Lukasczyk", "Gordon Fraser"], "title": "Search-based Hyperparameter Tuning for Python Unit Test Generation", "comment": "Accepted to the 17th Symposium on Search-Based Software Engineering\n  2025 (SSBSE 2025)", "summary": "Search-based test-generation algorithms have countless configuration options.\nUsers rarely adjust these options and usually stick to the default values,\nwhich may not lead to the best possible results. Tuning an algorithm's\nhyperparameters is a method to find better hyperparameter values, but it\ntypically comes with a high demand of resources. Meta-heuristic search\nalgorithms -- that effectively solve the test-generation problem -- have been\nproposed as a solution to also efficiently tune parameters. In this work we\nexplore the use of differential evolution as a means for tuning the\nhyperparameters of the DynaMOSA and MIO many-objective search algorithms as\nimplemented in the Pynguin framework. Our results show that significant\nimprovement of the resulting test suite's coverage is possible with the tuned\nDynaMOSA algorithm and that differential evolution is more efficient than basic\ngrid search.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4f7f\u7528\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u5bf9DynaMOSA\u548cMIO\u591a\u76ee\u6807\u641c\u7d22\u7b97\u6cd5\u7684\u8d85\u53c2\u6570\u8fdb\u884c\u8c03\u4f18\uff0c\u7ed3\u679c\u8868\u660e\u8c03\u4f18\u540e\u7684DynaMOSA\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u5957\u4ef6\u7684\u8986\u76d6\u7387\uff0c\u4e14\u5dee\u5206\u8fdb\u5316\u6bd4\u7f51\u683c\u641c\u7d22\u66f4\u9ad8\u6548\u3002", "motivation": "\u641c\u7d22\u5f0f\u6d4b\u8bd5\u751f\u6210\u7b97\u6cd5\u6709\u5927\u91cf\u914d\u7f6e\u9009\u9879\uff0c\u4f46\u7528\u6237\u901a\u5e38\u4f7f\u7528\u9ed8\u8ba4\u503c\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6b21\u4f18\u7ed3\u679c\uff1b\u800c\u4f20\u7edf\u8d85\u53c2\u6570\u8c03\u4f18\u65b9\u6cd5\u8d44\u6e90\u6d88\u8017\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u8c03\u4f18\u7b56\u7565\u3002", "method": "\u91c7\u7528\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u5bf9Pynguin\u6846\u67b6\u4e2dDynaMOSA\u548cMIO\u7b97\u6cd5\u7684\u8d85\u53c2\u6570\u8fdb\u884c\u81ea\u52a8\u8c03\u4f18\uff0c\u5e76\u4e0e\u7f51\u683c\u641c\u7d22\u8fdb\u884c\u6548\u7387\u5bf9\u6bd4\u3002", "result": "\u8c03\u4f18\u540e\u7684DynaMOSA\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u5957\u4ef6\u7684\u8986\u76d6\u7387\uff0c\u4e14\u5dee\u5206\u8fdb\u5316\u5728\u8c03\u4f18\u6548\u7387\u4e0a\u4f18\u4e8e\u57fa\u672c\u7684\u7f51\u683c\u641c\u7d22\u3002", "conclusion": "\u5dee\u5206\u8fdb\u5316\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u6709\u6548\u7684\u8d85\u53c2\u6570\u8c03\u4f18\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u63d0\u5347\u641c\u7d22\u5f0f\u6d4b\u8bd5\u751f\u6210\u7b97\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2510.08810", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.08810", "abs": "https://arxiv.org/abs/2510.08810", "authors": ["Mohayeminul Islam", "Ajay Kumar Jha", "May Mahmoud", "Sarah Nadi"], "title": "PyMigTool: a tool for end-to-end Python library migration", "comment": "arXiv admin note: text overlap with arXiv:2504.13272", "summary": "Library migration is the process of replacing a library with a similar one in\na software project. Manual library migration is time consuming and error prone,\nas it requires developers to understand the Application Programming Interfaces\n(API) of both libraries, map equivalent APIs, and perform the necessary code\ntransformations. Due to the difficulty of the library migration process, most\nof the existing automated techniques and tooling stop at the API mapping stage\nor support a limited set of libraries and code transformations. In this paper,\nwe develop an end-to-end solution that can automatically migrate code between\nany arbitrary pair of Python libraries that provide similar functionality. Due\nto the promising capabilities of Large Language Models (LLMs) in code\ngeneration and transformation, we use LLMs as the primary engine for migration.\nBefore building the tool, we first study the capabilities of LLMs for library\nmigration on a benchmark of 321 real-world library migrations. We find that\nLLMs can effectively perform library migration, but some post-processing steps\ncan further improve the performance. Based on this, we develop PyMigTool, a\ncommand line application that combines the power of LLMs, static analysis, and\ndynamic analysis to provide accurate library migration. We evaluate PyMigTool\non 717 real-world Python applications that are not from our benchmark. We find\nthat PyMigTool can migrate 32% of the migrations with complete correctness. Of\nthe remaining migrations, only 14% of the migration-related changes are left\nfor developers to fix for more than half of the projects.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7aef\u5230\u7aefPython\u5e93\u8fc1\u79fb\u5de5\u5177PyMigTool\uff0c\u7ed3\u5408\u9759\u6001\u4e0e\u52a8\u6001\u5206\u6790\uff0c\u5728717\u4e2a\u771f\u5b9e\u9879\u76ee\u4e2d\u5b9e\u73b0\u4e8632%\u5b8c\u5168\u6b63\u786e\u7684\u81ea\u52a8\u8fc1\u79fb\u3002", "motivation": "\u624b\u52a8\u5e93\u8fc1\u79fb\u8017\u65f6\u4e14\u6613\u9519\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u5927\u591a\u4ec5\u652f\u6301\u6709\u9650\u5e93\u6216\u505c\u7559\u5728API\u6620\u5c04\u9636\u6bb5\uff0c\u7f3a\u4e4f\u901a\u7528\u6027\u548c\u7aef\u5230\u7aef\u80fd\u529b\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u6838\u5fc3\u5f15\u64ce\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u52a8\u6001\u5206\u6790\uff0c\u6784\u5efa\u547d\u4ee4\u884c\u5de5\u5177PyMigTool\uff0c\u5e76\u5728\u5305\u542b321\u4e2a\u771f\u5b9e\u8fc1\u79fb\u6848\u4f8b\u7684\u57fa\u51c6\u4e0a\u8bc4\u4f30LLM\u80fd\u529b\u540e\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5728717\u4e2a\u975e\u57fa\u51c6\u771f\u5b9ePython\u9879\u76ee\u4e2d\uff0cPyMigTool\u5b9e\u73b0\u4e8632%\u5b8c\u5168\u6b63\u786e\u7684\u8fc1\u79fb\uff1b\u5176\u4f59\u9879\u76ee\u4e2d\uff0c\u8d85\u8fc7\u4e00\u534a\u53ea\u9700\u5f00\u53d1\u8005\u4fee\u590d\u4e0d\u523014%\u7684\u8fc1\u79fb\u76f8\u5173\u4ee3\u7801\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e93\u8fc1\u79fb\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u7ed3\u5408\u540e\u5904\u7406\u4e0e\u7a0b\u5e8f\u5206\u6790\u6280\u672f\u53ef\u663e\u8457\u63d0\u5347\u8fc1\u79fb\u51c6\u786e\u7387\uff0cPyMigTool\u4e3a\u901a\u7528\u5e93\u8fc1\u79fb\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.08827", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.08827", "abs": "https://arxiv.org/abs/2510.08827", "authors": ["Erfan Al-Hossami", "Razvan Bunescu"], "title": "McMining: Automated Discovery of Misconceptions in Student Code", "comment": "16 pages, 8 figures", "summary": "When learning to code, students often develop misconceptions about various\nprogramming language concepts. These can not only lead to bugs or inefficient\ncode, but also slow down the learning of related concepts. In this paper, we\nintroduce McMining, the task of mining programming misconceptions from samples\nof code from a student. To enable the training and evaluation of McMining\nsystems, we develop an extensible benchmark dataset of misconceptions together\nwith a large set of code samples where these misconceptions are manifested. We\nthen introduce two LLM-based McMiner approaches and through extensive\nevaluations show that models from the Gemini, Claude, and GPT families are\neffective at discovering misconceptions in student code.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMcMining\u4efb\u52a1\uff0c\u7528\u4e8e\u4ece\u5b66\u751f\u4ee3\u7801\u4e2d\u6316\u6398\u7f16\u7a0b\u8bef\u89e3\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8bef\u89e3\u6807\u6ce8\u548c\u4ee3\u7801\u6837\u672c\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff1b\u5b9e\u9a8c\u8868\u660eGemini\u3001Claude\u548cGPT\u7cfb\u5217\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u6709\u6548\u8bc6\u522b\u8fd9\u4e9b\u8bef\u89e3\u3002", "motivation": "\u5b66\u751f\u5728\u5b66\u4e60\u7f16\u7a0b\u65f6\u5e38\u5bf9\u8bed\u8a00\u6982\u5ff5\u4ea7\u751f\u8bef\u89e3\uff0c\u8fd9\u4e0d\u4ec5\u5bfc\u81f4\u4ee3\u7801\u9519\u8bef\u6216\u4f4e\u6548\uff0c\u8fd8\u963b\u788d\u76f8\u5173\u6982\u5ff5\u7684\u5b66\u4e60\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u5316\u65b9\u6cd5\u6765\u8bc6\u522b\u548c\u5206\u6790\u8fd9\u4e9b\u8bef\u89e3\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86McMining\u4efb\u52a1\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u8bef\u89e3\u57fa\u51c6\u6570\u636e\u96c6\u53ca\u914d\u5957\u7684\u5b66\u751f\u4ee3\u7801\u6837\u672c\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684McMiner\u65b9\u6cd5\u8fdb\u884c\u8bef\u89e3\u6316\u6398\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u53d1\u73b0Gemini\u3001Claude\u548cGPT\u7cfb\u5217\u6a21\u578b\u5728\u8bc6\u522b\u5b66\u751f\u4ee3\u7801\u4e2d\u7684\u7f16\u7a0b\u8bef\u89e3\u65b9\u9762\u8868\u73b0\u6709\u6548\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u7528\u4e8e\u6709\u6548\u6316\u6398\u5b66\u751f\u4ee3\u7801\u4e2d\u7684\u7f16\u7a0b\u8bef\u89e3\uff0c\u6240\u63d0\u51fa\u7684McMining\u4efb\u52a1\u548c\u6570\u636e\u96c6\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.08834", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.08834", "abs": "https://arxiv.org/abs/2510.08834", "authors": ["Carlos Pinto Gomez", "Fabio Petrillo"], "title": "Identifying Video Game Debugging Bottlenecks: An Industry Perspective", "comment": "8 pages, 3 figures, 4 tables, gas 2026 conference submission", "summary": "Conventional debugging techniques used in traditional software are similarly\nused when debugging video games. However, the reality of video games require\nits own set of unique debugging techniques such as On-Screen Console, Debug\nDraws, Debug Camera, Cheats and In-Game Menus, and Data Scrubbing. In this\narticle, we provide insights from a video game studio on how 20 seasoned\nindustry game developers debug during the production of a game. Our experiments\nrely on the recordings of debugging sessions for the most critical bugs\ncategorized as Crashes, Object Behaviors, and Object Persistence. In this\npaper, we focus on identifying the debugging activities that bottleneck bug\nresolution. We also identify the debugging tools used to perform debugging\ntechniques. Lastly, we present how different disciplines collaborate during\ndebugging and how technical roles are at the core of debugging. Our thematic\nanalysis has identified game developers spend 36.6\\% of their time inspecting\ngame artifacts and 35.1\\% of their time reproducing the bug locally.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u89c6\u9891\u6e38\u620f\u5f00\u53d1\u4e2d\u7279\u6709\u7684\u8c03\u8bd5\u6280\u672f\uff0c\u5206\u6790\u4e8620\u4f4d\u8d44\u6df1\u5f00\u53d1\u8005\u5728\u5904\u7406\u5173\u952e\u6f0f\u6d1e\uff08\u5982\u5d29\u6e83\u3001\u5bf9\u8c61\u884c\u4e3a\u548c\u5bf9\u8c61\u6301\u4e45\u6027\uff09\u65f6\u7684\u8c03\u8bd5\u6d3b\u52a8\u3001\u5de5\u5177\u4f7f\u7528\u53ca\u8de8\u804c\u80fd\u534f\u4f5c\uff0c\u53d1\u73b0\u5f00\u53d1\u800536.6%\u7684\u65f6\u95f4\u7528\u4e8e\u68c0\u67e5\u6e38\u620f\u4ea7\u7269\uff0c35.1%\u7528\u4e8e\u672c\u5730\u590d\u73b0\u6f0f\u6d1e\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u8c03\u8bd5\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u5e94\u5bf9\u89c6\u9891\u6e38\u620f\u7684\u72ec\u7279\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u9002\u7528\u4e8e\u6e38\u620f\u5f00\u53d1\u7684\u4e13\u5c5e\u8c03\u8bd5\u6280\u672f\u4e0e\u5b9e\u8df5\u3002", "method": "\u901a\u8fc7\u8bb0\u5f55\u6e38\u620f\u5de5\u4f5c\u5ba4\u4e2d20\u4f4d\u8d44\u6df1\u5f00\u53d1\u8005\u5728\u5904\u7406\u5173\u952e\u6f0f\u6d1e\u65f6\u7684\u8c03\u8bd5\u4f1a\u8bdd\uff0c\u8fdb\u884c\u4e3b\u9898\u5206\u6790\uff0c\u8bc6\u522b\u8c03\u8bd5\u6d3b\u52a8\u3001\u5de5\u5177\u4f7f\u7528\u53ca\u56e2\u961f\u534f\u4f5c\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u5f00\u53d1\u8005\u5728\u8c03\u8bd5\u4e2d\u6700\u8017\u65f6\u7684\u6d3b\u52a8\u662f\u68c0\u67e5\u6e38\u620f\u4ea7\u7269\uff0836.6%\uff09\u548c\u672c\u5730\u590d\u73b0\u6f0f\u6d1e\uff0835.1%\uff09\uff0c\u5e76\u8bc6\u522b\u51fa\u5e38\u7528\u8c03\u8bd5\u5de5\u5177\u53ca\u6280\u672f\u89d2\u8272\u5728\u534f\u4f5c\u4e2d\u7684\u6838\u5fc3\u5730\u4f4d\u3002", "conclusion": "\u89c6\u9891\u6e38\u620f\u8c03\u8bd5\u4f9d\u8d56\u4e8e\u7279\u5b9a\u6280\u672f\u548c\u8de8\u5b66\u79d1\u534f\u4f5c\uff0c\u5176\u4e2d\u6280\u672f\u89d2\u8272\u8d77\u5173\u952e\u4f5c\u7528\uff1b\u4f18\u5316\u8c03\u8bd5\u6d41\u7a0b\u5e94\u805a\u7126\u4e8e\u51cf\u5c11\u68c0\u67e5\u4e0e\u590d\u73b0\u6f0f\u6d1e\u6240\u9700\u65f6\u95f4\u3002"}}
{"id": "2510.08850", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08850", "abs": "https://arxiv.org/abs/2510.08850", "authors": ["Vasudha Yanuganti", "Ishaan Puri", "Swapnil Chhatre", "Mantinder Singh", "Ashok Jallepalli", "Hritvik Shrivastava", "Pradeep Kumar Sharma"], "title": "Repository-Aware File Path Retrieval via Fine-Tuned LLMs", "comment": null, "summary": "Modern codebases make it hard for developers and AI coding assistants to find\nthe right source files when answering questions like \"How does this feature\nwork?\" or \"Where was the bug introduced?\" Traditional code search (keyword or\nIR based) often misses semantic context and cross file links, while large\nlanguage models (LLMs) understand natural language but lack repository specific\ndetail. We present a method for file path retrieval that fine tunes a strong\nLLM (Qwen3-8B) with QLoRA and Unsloth optimizations to predict relevant file\npaths directly from a natural language query. To build training data, we\nintroduce six code aware strategies that use abstract syntax tree (AST)\nstructure and repository content to generate realistic question-answer pairs,\nwhere answers are sets of file paths. The strategies range from single file\nprompts to hierarchical repository summaries, providing broad coverage. We fine\ntune on Python projects including Flask, Click, Jinja, FastAPI, and PyTorch,\nand obtain high retrieval accuracy: up to 91\\% exact match and 93\\% recall on\nheld out queries, clearly beating single strategy training. On a large codebase\nlike PyTorch (about 4,000 Python files), the model reaches 59\\% recall, showing\nscalability. We analyze how multi level code signals help the LLM reason over\ncross file context and discuss dataset design, limits (for example, context\nlength in very large repos), and future integration of retrieval with LLM based\ncode intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff08Qwen3-8B\uff09\u76f4\u63a5\u4ece\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u4e2d\u9884\u6d4b\u76f8\u5173\u6587\u4ef6\u8def\u5f84\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u516d\u79cd\u57fa\u4e8e\u4ee3\u7801\u7ed3\u6784\u7684\u8bad\u7ec3\u6570\u636e\u751f\u6210\u7b56\u7565\uff0c\u5728\u591a\u4e2aPython\u9879\u76ee\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe91%\u7684\u7cbe\u786e\u5339\u914d\u548c93%\u7684\u53ec\u56de\u7387\u3002", "motivation": "\u73b0\u4ee3\u4ee3\u7801\u5e93\u4f7f\u5f97\u5f00\u53d1\u8005\u548cAI\u7f16\u7a0b\u52a9\u624b\u96be\u4ee5\u5728\u56de\u7b54\u201c\u8be5\u529f\u80fd\u5982\u4f55\u5de5\u4f5c\uff1f\u201d\u6216\u201c\u9519\u8bef\u662f\u5728\u54ea\u91cc\u5f15\u5165\u7684\uff1f\u201d\u7b49\u95ee\u9898\u65f6\u51c6\u786e\u5b9a\u4f4d\u76f8\u5173\u6e90\u6587\u4ef6\u3002\u4f20\u7edf\u4ee3\u7801\u641c\u7d22\u65b9\u6cd5\u7f3a\u4e4f\u8bed\u4e49\u4e0a\u4e0b\u6587\u548c\u8de8\u6587\u4ef6\u94fe\u63a5\u4fe1\u606f\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7406\u89e3\u81ea\u7136\u8bed\u8a00\u4f46\u7f3a\u5c11\u4ee3\u7801\u5e93\u7279\u5b9a\u7ec6\u8282\u3002", "method": "\u4f7f\u7528QLoRA\u548cUnsloth\u4f18\u5316\u5bf9Qwen3-8B\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u4f7f\u5176\u80fd\u76f4\u63a5\u4ece\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u9884\u6d4b\u76f8\u5173\u6587\u4ef6\u8def\u5f84\uff1b\u901a\u8fc7\u516d\u79cd\u57fa\u4e8e\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u548c\u4ee3\u7801\u5e93\u5185\u5bb9\u7684\u7b56\u7565\u751f\u6210\u5305\u542b\u6587\u4ef6\u8def\u5f84\u4f5c\u4e3a\u7b54\u6848\u7684\u95ee\u7b54\u5bf9\u7528\u4e8e\u8bad\u7ec3\u3002", "result": "\u5728Flask\u3001Click\u3001Jinja\u3001FastAPI\u548cPyTorch\u7b49Python\u9879\u76ee\u4e0a\u5fae\u8c03\u540e\uff0c\u6a21\u578b\u5728\u4fdd\u7559\u67e5\u8be2\u4e0a\u8fbe\u5230\u6700\u9ad891%\u7684\u7cbe\u786e\u5339\u914d\u7387\u548c93%\u7684\u53ec\u56de\u7387\uff1b\u5728\u7ea64000\u4e2aPython\u6587\u4ef6\u7684PyTorch\u5927\u578b\u4ee3\u7801\u5e93\u4e2d\uff0c\u53ec\u56de\u7387\u8fbe59%\uff0c\u5c55\u73b0\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u591a\u5c42\u7ea7\u4ee3\u7801\u4fe1\u53f7\u6709\u52a9\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u8de8\u6587\u4ef6\u4e0a\u4e0b\u6587\uff1b\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u7b56\u7565\u8bad\u7ec3\uff0c\u4f46\u5728\u8d85\u5927\u4ee3\u7801\u5e93\u4e2d\u4ecd\u53d7\u9650\u4e8e\u4e0a\u4e0b\u6587\u957f\u5ea6\u7b49\u95ee\u9898\uff0c\u672a\u6765\u53ef\u7ed3\u5408\u68c0\u7d22\u4e0e\u5927\u6a21\u578b\u4ee3\u7801\u667a\u80fd\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2510.08876", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08876", "abs": "https://arxiv.org/abs/2510.08876", "authors": ["Kostiantyn Bevziuk", "Andrii Fatula", "Svetozar Lashin Yaroslav Opanasenko", "Anna Tukhtarova", "Ashok Jallepalli Pradeepkumar Sharma", "Hritvik Shrivastava"], "title": "Vector Graph-Based Repository Understanding for Issue-Driven File Retrieval", "comment": null, "summary": "We present a repository decomposition system that converts large software\nrepositories into a vectorized knowledge graph which mirrors project\narchitectural and semantic structure, capturing semantic relationships and\nallowing a significant level of automatization of further repository\ndevelopment. The graph encodes syntactic relations such as containment,\nimplementation, references, calls, and inheritance, and augments nodes with\nLLM-derived summaries and vector embeddings. A hybrid retrieval pipeline\ncombines semantic retrieval with graph-aware expansion, and an LLM-based\nassistant formulates constrained, read-only graph requests and produces\nhuman-oriented explanations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5927\u578b\u8f6f\u4ef6\u4ed3\u5e93\u8f6c\u5316\u4e3a\u5411\u91cf\u5316\u77e5\u8bc6\u56fe\u8c31\u7684\u7cfb\u7edf\uff0c\u8be5\u56fe\u8c31\u53cd\u6620\u9879\u76ee\u7684\u67b6\u6784\u4e0e\u8bed\u4e49\u7ed3\u6784\uff0c\u652f\u6301\u540e\u7eed\u5f00\u53d1\u7684\u9ad8\u5ea6\u81ea\u52a8\u5316\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5927\u578b\u8f6f\u4ef6\u4ed3\u5e93\u5728\u7406\u89e3\u548c\u81ea\u52a8\u5316\u5f00\u53d1\u65b9\u9762\u7684\u6311\u6218\uff0c\u4f5c\u8005\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u80fd\u540c\u65f6\u6355\u6349\u8bed\u6cd5\u5173\u7cfb\u548c\u8bed\u4e49\u4fe1\u606f\u7684\u77e5\u8bc6\u8868\u793a\u7cfb\u7edf\u3002", "method": "\u8be5\u7cfb\u7edf\u6784\u5efa\u4e00\u4e2a\u77e5\u8bc6\u56fe\u8c31\uff0c\u7f16\u7801\u5305\u542b\u3001\u5b9e\u73b0\u3001\u5f15\u7528\u3001\u8c03\u7528\u548c\u7ee7\u627f\u7b49\u8bed\u6cd5\u5173\u7cfb\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e3a\u8282\u70b9\u751f\u6210\u6458\u8981\u548c\u5411\u91cf\u5d4c\u5165\uff1b\u901a\u8fc7\u7ed3\u5408\u8bed\u4e49\u68c0\u7d22\u4e0e\u56fe\u611f\u77e5\u6269\u5c55\u7684\u6df7\u5408\u68c0\u7d22\u6d41\u7a0b\uff0c\u4ee5\u53ca\u57fa\u4e8eLLM\u7684\u52a9\u624b\u751f\u6210\u53ea\u8bfb\u56fe\u67e5\u8be2\u548c\u9762\u5411\u4eba\u7c7b\u7684\u89e3\u91ca\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u5c06\u8f6f\u4ef6\u4ed3\u5e93\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u3001\u8bed\u4e49\u4e30\u5bcc\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ed3\u5e93\u7406\u89e3\u4e0e\u81ea\u52a8\u5316\u5f00\u53d1\u7684\u80fd\u529b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7cfb\u7edf\u6709\u6548\u878d\u5408\u4e86\u8f6f\u4ef6\u7ed3\u6784\u4e0e\u8bed\u4e49\u4fe1\u606f\uff0c\u4e3a\u8f6f\u4ef6\u4ed3\u5e93\u7684\u81ea\u52a8\u5316\u5206\u6790\u4e0e\u5f00\u53d1\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.08981", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08981", "abs": "https://arxiv.org/abs/2510.08981", "authors": ["Mandira Roy", "Novarun Deb", "Nabendu Chaki", "Agostino Cortesi"], "title": "SEER: Sustainability Enhanced Engineering of Software Requirements", "comment": "Main Paper: 32 pages, References: 3 pages, Appendix: 13 pages.\n  Submitted to the Journal of Systems and Software, Elsevier", "summary": "The rapid expansion of software development has significant environmental,\ntechnical, social, and economic impacts. Achieving the United Nations\nSustainable Development Goals by 2030 compels developers to adopt sustainable\npractices. Existing methods mostly offer high-level guidelines, which are\ntime-consuming to implement and rely on team adaptability. Moreover, they focus\non design or implementation, while sustainability assessment should start at\nthe requirements engineering phase. In this paper, we introduce SEER, a\nframework which addresses sustainability concerns in the early software\ndevelopment phase. The framework operates in three stages: (i) it identifies\nsustainability requirements (SRs) relevant to a specific software product from\na general taxonomy; (ii) it evaluates how sustainable system requirements are\nbased on the identified SRs; and (iii) it optimizes system requirements that\nfail to satisfy any SR. The framework is implemented using the reasoning\ncapabilities of large language models and the agentic RAG (Retrieval Augmented\nGeneration) approach. SEER has been experimented on four software projects from\ndifferent domains. Results generated using Gemini 2.5 reasoning model\ndemonstrate the effectiveness of the proposed approach in accurately\nidentifying a broad range of sustainability concerns across diverse domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSEER\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548cRAG\u6280\u672f\uff0c\u5728\u8f6f\u4ef6\u5f00\u53d1\u65e9\u671f\u9636\u6bb5\u8bc6\u522b\u3001\u8bc4\u4f30\u5e76\u4f18\u5316\u53ef\u6301\u7eed\u6027\u9700\u6c42\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u6709\u6548\u8bc6\u522b\u5e7f\u6cdb\u7684\u53ef\u6301\u7eed\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u53ef\u6301\u7eed\u8f6f\u4ef6\u5f00\u53d1\u65b9\u6cd5\u591a\u4e3a\u9ad8\u5c42\u6307\u5bfc\uff0c\u5b9e\u65bd\u8017\u65f6\u4e14\u4f9d\u8d56\u56e2\u961f\u9002\u5e94\u6027\uff0c\u4e14\u901a\u5e38\u805a\u7126\u4e8e\u8bbe\u8ba1\u6216\u5b9e\u73b0\u9636\u6bb5\uff0c\u800c\u5ffd\u89c6\u4e86\u5728\u9700\u6c42\u5de5\u7a0b\u9636\u6bb5\u5c31\u8fdb\u884c\u53ef\u6301\u7eed\u6027\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002", "method": "SEER\u6846\u67b6\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1a(i) \u4ece\u901a\u7528\u5206\u7c7b\u6cd5\u4e2d\u8bc6\u522b\u7279\u5b9a\u8f6f\u4ef6\u4ea7\u54c1\u7684\u53ef\u6301\u7eed\u6027\u9700\u6c42\uff08SRs\uff09\uff1b(ii) \u57fa\u4e8eSRs\u8bc4\u4f30\u7cfb\u7edf\u9700\u6c42\u7684\u53ef\u6301\u7eed\u6027\uff1b(iii) \u5bf9\u672a\u6ee1\u8db3SRs\u7684\u7cfb\u7edf\u9700\u6c42\u8fdb\u884c\u4f18\u5316\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548cRAG\uff08\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff09\u65b9\u6cd5\u5b9e\u73b0\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u8f6f\u4ef6\u9879\u76ee\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528Gemini 2.5\u63a8\u7406\u6a21\u578b\u751f\u6210\u7684\u7ed3\u679c\u8868\u660e\uff0cSEER\u80fd\u51c6\u786e\u8bc6\u522b\u8de8\u9886\u57df\u7684\u5e7f\u6cdb\u53ef\u6301\u7eed\u6027\u95ee\u9898\u3002", "conclusion": "SEER\u6846\u67b6\u6709\u6548\u652f\u6301\u5728\u8f6f\u4ef6\u5f00\u53d1\u65e9\u671f\u9636\u6bb5\u7cfb\u7edf\u5316\u5730\u5904\u7406\u53ef\u6301\u7eed\u6027\u9700\u6c42\uff0c\u4e3a\u5b9e\u73b0\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2510.08990", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.08990", "abs": "https://arxiv.org/abs/2510.08990", "authors": ["Mandira Roy", "Novarun Deb", "Nabendu Chaki", "Agostino Cortesi"], "title": "Towards a Taxonomy of Sustainability Requirements for Software Design", "comment": "Paper: 7 pages", "summary": "Software systems are a significant contributor to global sustainability\nconcerns, demanding that environmental, social, technical, and economic factors\nbe systematically addressed from the initial requirements engineering phase.\nAlthough existing research provides various sustainability requirements (SRs),\nthese contributions are often fragmented, specific to certain dimensions, or\nlimited to particular application domains, resulting in a critical lack of a\nunified, comprehensive taxonomy for the software engineering community. To\naddress this gap, this research conducts a Systematic Literature Review (SLR)\nto extract and organize sustainability requirements from the state-of-the-art.\nThe primary contribution is a comprehensive taxonomy of SRs across the four\ndimensions of sustainability (environmental, technical, social, and economic).\nFor each identified category, we provide clear definitions, associated metrics,\nand measures. Furthermore, we depict a correlation matrix that projects the\npositive and negative influences (synergies and conflicts) among categories\nacross different dimensions. This systematized reference assists both software\ndevelopers and researchers in effectively formulating, managing, and\nreconciling trade-offs within sustainable software development.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u6784\u5efa\u4e86\u4e00\u4e2a\u6db5\u76d6\u73af\u5883\u3001\u6280\u672f\u3001\u793e\u4f1a\u548c\u7ecf\u6d4e\u56db\u4e2a\u7ef4\u5ea6\u7684\u53ef\u6301\u7eed\u6027\u9700\u6c42\u7efc\u5408\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u63d0\u4f9b\u4e86\u5404\u7c7b\u522b\u7684\u5b9a\u4e49\u3001\u5ea6\u91cf\u6307\u6807\u53ca\u7ef4\u5ea6\u95f4\u7684\u534f\u540c\u4e0e\u51b2\u7a81\u5173\u7cfb\u77e9\u9635\uff0c\u4ee5\u652f\u6301\u53ef\u6301\u7eed\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u9700\u6c42\u5236\u5b9a\u4e0e\u6743\u8861\u7ba1\u7406\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e2d\u7684\u53ef\u6301\u7eed\u6027\u9700\u6c42\u5f80\u5f80\u788e\u7247\u5316\u3001\u5c40\u9650\u4e8e\u7279\u5b9a\u7ef4\u5ea6\u6216\u5e94\u7528\u9886\u57df\uff0c\u7f3a\u4e4f\u7edf\u4e00\u5168\u9762\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u963b\u788d\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u5728\u9700\u6c42\u5de5\u7a0b\u9636\u6bb5\u7cfb\u7edf\u6027\u5730\u5e94\u5bf9\u53ef\u6301\u7eed\u6027\u6311\u6218\u3002", "method": "\u5f00\u5c55\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff08SLR\uff09\uff0c\u4ece\u73b0\u6709\u7814\u7a76\u4e2d\u63d0\u53d6\u5e76\u6574\u53ef\u6301\u7eed\u6027\u9700\u6c42\uff0c\u6784\u5efa\u6db5\u76d6\u56db\u4e2a\u53ef\u6301\u7eed\u6027\u7ef4\u5ea6\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u7c7b\u522b\u63d0\u4f9b\u5b9a\u4e49\u3001\u5ea6\u91cf\u6307\u6807\uff0c\u540c\u65f6\u5efa\u7acb\u8de8\u7ef4\u5ea6\u7c7b\u522b\u95f4\u7684\u534f\u540c\u4e0e\u51b2\u7a81\u5173\u7cfb\u77e9\u9635\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u53ef\u6301\u7eed\u6027\u9700\u6c42\u5206\u7c7b\u6cd5\uff0c\u5305\u542b\u6e05\u6670\u7684\u7c7b\u522b\u5b9a\u4e49\u3001\u76f8\u5173\u5ea6\u91cf\u6307\u6807\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u7ef4\u5ea6\u95f4\u7c7b\u522b\u7684\u6b63\u8d1f\u5f71\u54cd\u5173\u7cfb\uff08\u534f\u540c\u4e0e\u51b2\u7a81\uff09\u3002", "conclusion": "\u8be5\u5206\u7c7b\u4f53\u7cfb\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u53c2\u8003\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u5728\u53ef\u6301\u7eed\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u6709\u6548\u5236\u5b9a\u3001\u7ba1\u7406\u53ef\u6301\u7eed\u6027\u9700\u6c42\u5e76\u534f\u8c03\u5176\u4e2d\u7684\u6743\u8861\u5173\u7cfb\u3002"}}
{"id": "2510.08996", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.08996", "abs": "https://arxiv.org/abs/2510.08996", "authors": ["Spandan Garg", "Ben Steenhoek", "Yufan Huang"], "title": "Saving SWE-Bench: A Benchmark Mutation Approach for Realistic Agent Evaluation", "comment": null, "summary": "Current benchmarks for evaluating software engineering agents, such as\nSWE-Bench Verified, are predominantly derived from GitHub issues and fail to\naccurately reflect how developers interact with chat-based coding assistants in\nintegrated development environments (IDEs). We posit that this mismatch leads\nto a systematic overestimation of agent's capabilities in real-world scenarios,\nespecially bug fixing. We introduce a novel benchmarking framework that\ntransforms existing formal benchmarks into realistic user queries through\nsystematic analysis of developer interaction patterns with chat-based agents.\nOur methodology is flexible and can be easily extended to existing benchmarks.\nIn this paper, we apply our testing framework to SWE-Bench Verified, the\nTypeScript subset of Multi-SWE-Bench and a private benchmark, SWE-Bench C# and\ntransform formal GitHub issue descriptions into realistic user-style queries\nbased on telemetry analysis of a popular chat-based agent interactions. Our\nfindings reveal that existing benchmarks significantly overestimate agent\ncapabilities for some models by >50% over baseline performance for public\nbenchmarks and ~10-16% for our internal benchmark. This work establishes a new\nparadigm for evaluating interactive chat-based software engineering agents\nthrough benchmark mutation techniques.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u5f00\u53d1\u8005\u4e0e\u804a\u5929\u5f0f\u7f16\u7801\u52a9\u624b\u7684\u771f\u5b9e\u4ea4\u4e92\u6a21\u5f0f\uff0c\u5c06\u73b0\u6709\u6b63\u5f0f\u57fa\u51c6\uff08\u5982SWE-Bench Verified\uff09\u8f6c\u5316\u4e3a\u66f4\u8d34\u8fd1\u5b9e\u9645\u7684\u7528\u6237\u67e5\u8be2\uff0c\u53d1\u73b0\u5f53\u524d\u57fa\u51c6\u663e\u8457\u9ad8\u4f30\u4e86\u667a\u80fd\u4f53\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u7684\u8bc4\u4f30\u57fa\u51c6\uff08\u5982SWE-Bench Verified\uff09\u4e3b\u8981\u57fa\u4e8eGitHub\u95ee\u9898\uff0c\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u5f00\u53d1\u8005\u5728IDE\u4e2d\u4e0e\u804a\u5929\u5f0f\u7f16\u7801\u52a9\u624b\u7684\u771f\u5b9e\u4ea4\u4e92\u65b9\u5f0f\uff0c\u5bfc\u81f4\u5bf9\u667a\u80fd\u4f53\u80fd\u529b\u7684\u7cfb\u7edf\u6027\u9ad8\u4f30\uff0c\u5c24\u5176\u662f\u5728\u4fee\u590dbug\u4efb\u52a1\u4e2d\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5206\u6790\u6d41\u884c\u804a\u5929\u5f0f\u667a\u80fd\u4f53\u7684\u9065\u6d4b\u6570\u636e\uff0c\u7cfb\u7edf\u6027\u5730\u5c06\u6b63\u5f0f\u7684GitHub\u95ee\u9898\u63cf\u8ff0\u8f6c\u5316\u4e3a\u8d34\u8fd1\u771f\u5b9e\u7528\u6237\u884c\u4e3a\u7684\u67e5\u8be2\uff0c\u5e76\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8eSWE-Bench Verified\u3001Multi-SWE-Bench\u7684TypeScript\u5b50\u96c6\u4ee5\u53ca\u79c1\u6709\u7684SWE-Bench C#\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u73b0\u6709\u57fa\u51c6\u5bf9\u67d0\u4e9b\u6a21\u578b\u7684\u80fd\u529b\u9ad8\u4f30\u8d85\u8fc750%\uff08\u516c\u5f00\u57fa\u51c6\uff09\u548c\u7ea610\u201316%\uff08\u5185\u90e8\u57fa\u51c6\uff09\uff0c\u8868\u660e\u5f53\u524d\u8bc4\u4f30\u65b9\u5f0f\u4e0e\u771f\u5b9e\u4f7f\u7528\u573a\u666f\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u57fa\u51c6\u53d8\u5f02\u6280\u672f\u8bc4\u4f30\u4ea4\u4e92\u5f0f\u804a\u5929\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u7684\u65b0\u8303\u5f0f\uff0c\u5f3a\u8c03\u4e86\u6784\u5efa\u66f4\u8d34\u8fd1\u771f\u5b9e\u7528\u6237\u4ea4\u4e92\u7684\u8bc4\u4f30\u4f53\u7cfb\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.09045", "categories": ["cs.SE", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09045", "abs": "https://arxiv.org/abs/2510.09045", "authors": ["Manojit Chakraborty", "Madhusudan Ghosh", "Rishabh Gupta"], "title": "Cost-Efficient Long Code Translation using LLMs while Leveraging Identifier Replacements", "comment": null, "summary": "In the domain of software development, LLMs have been utilized to automate\ntasks such as code translation, where source code from one programming language\nis translated to another while preserving its functionality. However, LLMs\noften struggle with long source codes that don't fit into the context window,\nwhich produces inaccurate translations. To address this, we propose a novel\nzero-shot code translation method that incorporates identifier replacement. By\nsubstituting user-given long identifiers with generalized placeholders during\ntranslation, our method allows the LLM to focus on the logical structure of the\ncode, by reducing token count and memory usage, which improves the efficiency\nand cost-effectiveness of long code translation. Our empirical results\ndemonstrate that our approach preserves syntactical and hierarchical\ninformation and produces translation results with reduced tokens.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u96f6\u6837\u672c\u4ee3\u7801\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u901a\u8fc7\u66ff\u6362\u957f\u6807\u8bc6\u7b26\u4e3a\u901a\u7528\u5360\u4f4d\u7b26\uff0c\u51cf\u5c11\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u957f\u4ee3\u7801\u7684\u7ffb\u8bd1\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u8d85\u51fa\u4e0a\u4e0b\u6587\u7a97\u53e3\u7684\u957f\u4ee3\u7801\u65f6\uff0c\u96be\u4ee5\u51c6\u786e\u5b8c\u6210\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u3002", "method": "\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\uff0c\u5c06\u7528\u6237\u63d0\u4f9b\u7684\u957f\u6807\u8bc6\u7b26\u66ff\u6362\u4e3a\u901a\u7528\u5360\u4f4d\u7b26\uff0c\u4ee5\u964d\u4f4e\u8f93\u5165\u957f\u5ea6\u548c\u5185\u5b58\u5360\u7528\uff0c\u4f7f\u6a21\u578b\u66f4\u4e13\u6ce8\u4e8e\u4ee3\u7801\u903b\u8f91\u7ed3\u6784\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u4ee3\u7801\u8bed\u6cd5\u548c\u5c42\u6b21\u7ed3\u6784\u4fe1\u606f\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u7ffb\u8bd1\u6240\u9700\u7684token\u6570\u91cf\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u957f\u4ee3\u7801\u7ffb\u8bd1\u7684\u6548\u7387\u3001\u51c6\u786e\u6027\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2510.09058", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.09058", "abs": "https://arxiv.org/abs/2510.09058", "authors": ["Italo Santos", "Cleyton Magalhaes", "Ronnie de Souza Santos"], "title": "Model-Assisted and Human-Guided: Perceptions and Practices of Software Professionals Using LLMs for Coding", "comment": null, "summary": "Large Language Models have quickly become a central component of modern\nsoftware development workflows, and software practitioners are increasingly\nintegrating LLMs into various stages of the software development lifecycle.\nDespite the growing presence of LLMs, there is still a limited understanding of\nhow these tools are actually used in practice and how professionals perceive\ntheir benefits and limitations. This paper presents preliminary findings from a\nglobal survey of 131 software practitioners. Our results reveal how LLMs are\nutilized for various coding-specific tasks. Software professionals report\nbenefits such as increased productivity, reduced cognitive load, and faster\nlearning, but also raise concerns about LLMs' inaccurate outputs, limited\ncontext awareness, and associated ethical risks. Most developers treat LLMs as\nassistive tools rather than standalone solutions, reflecting a cautious yet\npractical approach to their integration. Our findings provide an early,\npractitioner-focused perspective on LLM adoption, highlighting key\nconsiderations for future research and responsible use in software engineering.", "AI": {"tldr": "\u4e00\u9879\u9488\u5bf9131\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u7684\u5168\u7403\u8c03\u67e5\u663e\u793a\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u88ab\u5e7f\u6cdb\u7528\u4f5c\u8f85\u52a9\u5de5\u5177\uff0c\u80fd\u63d0\u5347\u751f\u4ea7\u529b\u5e76\u964d\u4f4e\u8ba4\u77e5\u8d1f\u62c5\uff0c\u4f46\u4e5f\u5b58\u5728\u8f93\u51fa\u4e0d\u51c6\u786e\u3001\u4e0a\u4e0b\u6587\u7406\u89e3\u6709\u9650\u548c\u4f26\u7406\u98ce\u9669\u7b49\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u5bf9\u5176\u5728\u5b9e\u9645\u4e2d\u7684\u4f7f\u7528\u65b9\u5f0f\u53ca\u4ece\u4e1a\u8005\u5bf9\u5176\u4f18\u7f3a\u70b9\u7684\u770b\u6cd5\u4ecd\u7f3a\u4e4f\u6df1\u5165\u7406\u89e3\u3002", "method": "\u901a\u8fc7\u5168\u7403\u95ee\u5377\u8c03\u67e5\u6536\u96c6131\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u7684\u53cd\u9988\uff0c\u5206\u6790LLMs\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3001\u611f\u77e5\u4f18\u52bf\u4e0e\u5c40\u9650\u6027\u3002", "result": "\u4ece\u4e1a\u8005\u4e3b\u8981\u5c06LLMs\u7528\u4e8e\u7f16\u7801\u76f8\u5173\u4efb\u52a1\uff0c\u8ba4\u4e3a\u5176\u63d0\u9ad8\u4e86\u751f\u4ea7\u529b\u3001\u51cf\u8f7b\u4e86\u8ba4\u77e5\u8d1f\u62c5\u5e76\u52a0\u901f\u5b66\u4e60\uff0c\u4f46\u4e5f\u62c5\u5fe7\u5176\u8f93\u51fa\u4e0d\u51c6\u786e\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u6709\u9650\u53ca\u4f26\u7406\u98ce\u9669\uff1b\u591a\u6570\u4eba\u5c06\u5176\u89c6\u4e3a\u8f85\u52a9\u5de5\u5177\u800c\u975e\u72ec\u7acb\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u65e9\u671f\u3001\u4ee5\u4ece\u4e1a\u8005\u4e3a\u4e2d\u5fc3\u7684LLM\u5e94\u7528\u89c6\u89d2\uff0c\u5f3a\u8c03\u4e86\u672a\u6765\u7814\u7a76\u548c\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u8d1f\u8d23\u4efb\u4f7f\u7528LLM\u7684\u5173\u952e\u8003\u91cf\u3002"}}
{"id": "2510.09073", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.09073", "abs": "https://arxiv.org/abs/2510.09073", "authors": ["Matthew Sotoudeh"], "title": "Literate Tracing", "comment": "examples at https://lair.masot.net/trex . SPLASH Onward 2025", "summary": "As computer systems grow ever larger and more complex, a crucial task in\nsoftware development is for one person (the system expert) to communicate to\nanother (the system novice) how a certain program works. This paper reports on\nthe author's experiences with a paradigm for program documentation that we call\nliterate tracing. A literate trace explains a software system using annotated,\nconcrete execution traces of the system. Literate traces complement both\nin-code comments (which often lack global context) and out-of-band design docs\n(which often lack a concrete connection to the code). We also describe TReX,\nour tool for making literate traces that are interactive, visual, and\nguaranteed by construction to be faithful to the program semantics. We have\nused TReX to write literate traces explaining components of large systems\nsoftware including the Linux kernel, Git source control system, and GCC\ncompiler.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u201c\u6587\u5b66\u5316\u8ffd\u8e2a\u201d\uff08literate tracing\uff09\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u7a0b\u5e8f\u6587\u6863\u8303\u5f0f\uff0c\u901a\u8fc7\u5e26\u6ce8\u91ca\u7684\u5177\u4f53\u6267\u884c\u8f68\u8ff9\u6765\u89e3\u91ca\u8f6f\u4ef6\u7cfb\u7edf\uff0c\u5e76\u4ecb\u7ecd\u4e86\u652f\u6301\u8be5\u8303\u5f0f\u7684\u5de5\u5177TReX\uff0c\u8be5\u5de5\u5177\u80fd\u751f\u6210\u4ea4\u4e92\u5f0f\u3001\u53ef\u89c6\u5316\u4e14\u8bed\u4e49\u5fe0\u5b9e\u7684\u6587\u6863\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u673a\u7cfb\u7edf\u65e5\u76ca\u5e9e\u5927\u590d\u6742\uff0c\u7cfb\u7edf\u4e13\u5bb6\u5411\u65b0\u624b\u6e05\u6670\u4f20\u8fbe\u7a0b\u5e8f\u5de5\u4f5c\u539f\u7406\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u6587\u6863\u65b9\u5f0f\uff08\u5982\u4ee3\u7801\u6ce8\u91ca\u548c\u8bbe\u8ba1\u6587\u6863\uff09\u5206\u522b\u7f3a\u4e4f\u5168\u5c40\u4e0a\u4e0b\u6587\u6216\u4e0e\u4ee3\u7801\u7684\u5177\u4f53\u8054\u7cfb\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u201c\u6587\u5b66\u5316\u8ffd\u8e2a\u201d\u65b9\u6cd5\uff0c\u7ed3\u5408\u5177\u4f53\u6267\u884c\u8f68\u8ff9\u4e0e\u6ce8\u91ca\u6765\u89e3\u91ca\u7cfb\u7edf\uff0c\u5e76\u5f00\u53d1\u4e86\u540d\u4e3aTReX\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u751f\u6210\u4ea4\u4e92\u5f0f\u3001\u53ef\u89c6\u5316\u4e14\u8bed\u4e49\u4fdd\u771f\u7684\u6587\u5b66\u5316\u8ffd\u8e2a\u6587\u6863\u3002", "result": "TReX\u5df2\u88ab\u7528\u4e8e\u4e3aLinux\u5185\u6838\u3001Git\u7248\u672c\u63a7\u5236\u7cfb\u7edf\u548cGCC\u7f16\u8bd1\u5668\u7b49\u5927\u578b\u7cfb\u7edf\u8f6f\u4ef6\u7684\u5173\u952e\u7ec4\u4ef6\u7f16\u5199\u6587\u5b66\u5316\u8ffd\u8e2a\u6587\u6863\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u5b9e\u7528\u6027\u4e0e\u6709\u6548\u6027\u3002", "conclusion": "\u6587\u5b66\u5316\u8ffd\u8e2a\u6709\u6548\u5f25\u8865\u4e86\u4f20\u7edf\u6587\u6863\u65b9\u5f0f\u7684\u4e0d\u8db3\uff0cTReX\u5de5\u5177\u652f\u6301\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u53ef\u4fe1\u8d56\u7684\u7a0b\u5e8f\u89e3\u91ca\u6587\u6863\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u8f6f\u4ef6\u7cfb\u7edf\u7684\u53ef\u7406\u89e3\u6027\u4e0e\u53ef\u7ef4\u62a4\u6027\u3002"}}
{"id": "2510.09108", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.09108", "abs": "https://arxiv.org/abs/2510.09108", "authors": ["Lukas Krodinger", "Altin Hajdari", "Stephan Lukasczyk", "Gordon Fraser"], "title": "Constraint-Guided Unit Test Generation for Machine Learning Libraries", "comment": "Accepted for SSBSE 2025", "summary": "Machine learning (ML) libraries such as PyTorch and TensorFlow are essential\nfor a wide range of modern applications. Ensuring the correctness of ML\nlibraries through testing is crucial. However, ML APIs often impose strict\ninput constraints involving complex data structures such as tensors. Automated\ntest generation tools such as Pynguin are not aware of these constraints and\noften create non-compliant inputs. This leads to early test failures and\nlimited code coverage. Prior work has investigated extracting constraints from\nofficial API documentation. In this paper, we present PynguinML, an approach\nthat improves the Pynguin test generator to leverage these constraints to\ngenerate compliant inputs for ML APIs, enabling more thorough testing and\nhigher code coverage. Our evaluation is based on 165 modules from PyTorch and\nTensorFlow, comparing PynguinML against Pynguin. The results show that\nPynguinML significantly improves test effectiveness, achieving up to 63.9 %\nhigher code coverage.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPynguinML\uff0c\u901a\u8fc7\u5229\u7528\u673a\u5668\u5b66\u4e60API\u7684\u8f93\u5165\u7ea6\u675f\u6539\u8fdbPynguin\u6d4b\u8bd5\u751f\u6210\u5668\uff0c\u663e\u8457\u63d0\u5347\u5bf9PyTorch\u548cTensorFlow\u5e93\u7684\u6d4b\u8bd5\u8986\u76d6\u7387\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u6d4b\u8bd5\u5de5\u5177\uff08\u5982Pynguin\uff09\u4e0d\u4e86\u89e3\u673a\u5668\u5b66\u4e60API\u7684\u590d\u6742\u8f93\u5165\u7ea6\u675f\uff0c\u5bfc\u81f4\u751f\u6210\u65e0\u6548\u8f93\u5165\u3001\u6d4b\u8bd5\u63d0\u524d\u5931\u8d25\u53ca\u4ee3\u7801\u8986\u76d6\u7387\u4f4e\u3002", "method": "PynguinML\u6539\u8fdb\u4e86Pynguin\u6d4b\u8bd5\u751f\u6210\u5668\uff0c\u4f7f\u5176\u80fd\u591f\u5229\u7528\u4ece\u5b98\u65b9API\u6587\u6863\u4e2d\u63d0\u53d6\u7684\u8f93\u5165\u7ea6\u675f\uff0c\u751f\u6210\u7b26\u5408\u8981\u6c42\u7684\u6d4b\u8bd5\u8f93\u5165\u3002", "result": "\u5728165\u4e2aPyTorch\u548cTensorFlow\u6a21\u5757\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPynguinML\u76f8\u6bd4\u539f\u59cbPynguin\u6700\u591a\u53ef\u63d0\u534763.9%\u7684\u4ee3\u7801\u8986\u76d6\u7387\u3002", "conclusion": "\u5c06API\u8f93\u5165\u7ea6\u675f\u6574\u5408\u5230\u6d4b\u8bd5\u751f\u6210\u8fc7\u7a0b\u4e2d\uff0c\u80fd\u6709\u6548\u63d0\u5347\u673a\u5668\u5b66\u4e60\u5e93\u7684\u6d4b\u8bd5\u8d28\u91cf\u548c\u8986\u76d6\u8303\u56f4\u3002"}}
{"id": "2510.09134", "categories": ["cs.SE", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.09134", "abs": "https://arxiv.org/abs/2510.09134", "authors": ["Amal Elgammal", "Bernd J. Kr\u00e4mer", "Michael P. Papazoglou", "Mira Raheem"], "title": "A Semantic Framework for Patient Digital Twins in Chronic Care", "comment": "This manuscript is currently under review at Software and Systems\n  Modeling (SoSyM)", "summary": "Personalized chronic care requires the integration of multimodal health data\nto enable precise, adaptive, and preventive decision-making. Yet most current\ndigital twin (DT) applications remain organ-specific or tied to isolated data\ntypes, lacking a unified and privacy-preserving foundation. This paper\nintroduces the Patient Medical Digital Twin (PMDT), an ontology-driven in\nsilico patient framework that integrates physiological, psychosocial,\nbehavioral, and genomic information into a coherent, extensible model.\nImplemented in OWL 2.0, the PMDT ensures semantic interoperability, supports\nautomated reasoning, and enables reuse across diverse clinical contexts. Its\nontology is structured around modular Blueprints (patient, disease and\ndiagnosis, treatment and follow-up, trajectories, safety, pathways, and adverse\nevents), formalized through dedicated conceptual views. These were iteratively\nrefined and validated through expert workshops, questionnaires, and a pilot\nstudy in the EU H2020 QUALITOP project with real-world immunotherapy patients.\nEvaluation confirmed ontology coverage, reasoning correctness, usability, and\nGDPR compliance. Results demonstrate the PMDT's ability to unify heterogeneous\ndata, operationalize competency questions, and support descriptive, predictive,\nand prescriptive analytics in a federated, privacy-preserving manner. By\nbridging gaps in data fragmentation and semantic standardization, the PMDT\nprovides a validated foundation for next-generation digital health ecosystems,\ntransforming chronic care toward proactive, continuously optimized, and\nequitable management.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u60a3\u8005\u533b\u7597\u6570\u5b57\u5b6a\u751f\uff08PMDT\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u672c\u4f53\u9a71\u52a8\u7684\u65b9\u5f0f\u6574\u5408\u591a\u6a21\u6001\u5065\u5eb7\u6570\u636e\uff0c\u5728\u4fdd\u969c\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u652f\u6301\u6162\u6027\u75c5\u7684\u7cbe\u51c6\u3001\u4e3b\u52a8\u548c\u4e2a\u6027\u5316\u7ba1\u7406\u3002", "motivation": "\u5f53\u524d\u6570\u5b57\u5b6a\u751f\u5e94\u7528\u591a\u5c40\u9650\u4e8e\u5355\u4e00\u5668\u5b98\u6216\u5b64\u7acb\u6570\u636e\u7c7b\u578b\uff0c\u7f3a\u4e4f\u7edf\u4e00\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u6574\u5408\u6846\u67b6\uff0c\u96be\u4ee5\u652f\u6301\u4e2a\u6027\u5316\u6162\u6027\u75c5\u7ba1\u7406\u6240\u9700\u7684\u591a\u7ef4\u5ea6\u6570\u636e\u878d\u5408\u4e0e\u667a\u80fd\u51b3\u7b56\u3002", "method": "\u6784\u5efa\u57fa\u4e8eOWL 2.0\u7684\u672c\u4f53\u9a71\u52a8\u6570\u5b57\u5b6a\u751f\u6a21\u578bPMDT\uff0c\u56f4\u7ed5\u60a3\u8005\u3001\u75be\u75c5\u3001\u6cbb\u7597\u7b49\u4e03\u4e2a\u6a21\u5757\u5316\u84dd\u56fe\u8bbe\u8ba1\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u7814\u8ba8\u3001\u95ee\u5377\u53ca\u6b27\u76dfQUALITOP\u9879\u76ee\u4e2d\u7684\u514d\u75ab\u6cbb\u7597\u60a3\u8005\u8bd5\u70b9\u8fdb\u884c\u8fed\u4ee3\u9a8c\u8bc1\u3002", "result": "\u8bc4\u4f30\u8868\u660ePMDT\u5728\u672c\u4f53\u8986\u76d6\u5ea6\u3001\u63a8\u7406\u6b63\u786e\u6027\u3001\u53ef\u7528\u6027\u53caGDPR\u5408\u89c4\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u80fd\u6709\u6548\u6574\u5408\u5f02\u6784\u6570\u636e\uff0c\u652f\u6301\u63cf\u8ff0\u6027\u3001\u9884\u6d4b\u6027\u548c\u89c4\u8303\u6027\u5206\u6790\uff0c\u5e76\u5728\u8054\u90a6\u67b6\u6784\u4e0b\u4fdd\u969c\u9690\u79c1\u3002", "conclusion": "PMDT\u4e3a\u4e0b\u4e00\u4ee3\u6570\u5b57\u5065\u5eb7\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u6162\u6027\u75c5\u7ba1\u7406\u5411\u4e3b\u52a8\u3001\u6301\u7eed\u4f18\u5316\u548c\u516c\u5e73\u65b9\u5411\u7684\u8f6c\u578b\u3002"}}
{"id": "2510.09308", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09308", "abs": "https://arxiv.org/abs/2510.09308", "authors": ["Mira Raheem", "Amal Elgammal", "Michael Papazoglou", "Bernd Kr\u00e4mer", "Neamat El-Tazi"], "title": "A Model-Driven Engineering Approach to AI-Powered Healthcare Platforms", "comment": "Disclaimer: This manuscript is currently under review at * MDPI\n  Informatics*", "summary": "Artificial intelligence (AI) has the potential to transform healthcare by\nsupporting more accurate diagnoses and personalized treatments. However, its\nadoption in practice remains constrained by fragmented data sources, strict\nprivacy rules, and the technical complexity of building reliable clinical\nsystems. To address these challenges, we introduce a model driven engineering\n(MDE) framework designed specifically for healthcare AI. The framework relies\non formal metamodels, domain-specific languages (DSLs), and automated\ntransformations to move from high level specifications to running software. At\nits core is the Medical Interoperability Language (MILA), a graphical DSL that\nenables clinicians and data scientists to define queries and machine learning\npipelines using shared ontologies. When combined with a federated learning\narchitecture, MILA allows institutions to collaborate without exchanging raw\npatient data, ensuring semantic consistency across sites while preserving\nprivacy. We evaluate this approach in a multi center cancer immunotherapy\nstudy. The generated pipelines delivered strong predictive performance, with\nsupport vector machines achieving up to 98.5 percent and 98.3 percent accuracy\nin key tasks, while substantially reducing manual coding effort. These findings\nsuggest that MDE principles metamodeling, semantic integration, and automated\ncode generation can provide a practical path toward interoperable,\nreproducible, and trustworthy digital health platforms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u533b\u7597AI\u7684\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\uff08MDE\uff09\u6846\u67b6\uff0c\u7ed3\u5408\u56fe\u5f62\u5316\u9886\u57df\u7279\u5b9a\u8bed\u8a00MILA\u4e0e\u8054\u90a6\u5b66\u4e60\u67b6\u6784\uff0c\u5728\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\u7684\u540c\u65f6\u5b9e\u73b0\u8de8\u673a\u6784\u8bed\u4e49\u4e00\u81f4\u7684\u534f\u4f5c\u5efa\u6a21\uff0c\u5e76\u5728\u764c\u75c7\u514d\u75ab\u6cbb\u7597\u7814\u7a76\u4e2d\u9a8c\u8bc1\u4e86\u5176\u9ad8\u9884\u6d4b\u51c6\u786e\u7387\u548c\u5f00\u53d1\u6548\u7387\u3002", "motivation": "\u533b\u7597AI\u7684\u5b9e\u9645\u5e94\u7528\u53d7\u9650\u4e8e\u6570\u636e\u5b64\u5c9b\u3001\u9690\u79c1\u6cd5\u89c4\u548c\u6280\u672f\u590d\u6742\u6027\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u517c\u987e\u8bed\u4e49\u4e00\u81f4\u6027\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u5de5\u7a0b\u6548\u7387\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u7684\u6846\u67b6\uff0c\u5229\u7528\u5f62\u5f0f\u5316\u5143\u6a21\u578b\u3001\u9886\u57df\u7279\u5b9a\u8bed\u8a00MILA\u548c\u81ea\u52a8\u5316\u8f6c\u6362\u6280\u672f\uff0c\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u67b6\u6784\uff0c\u652f\u6301\u4e34\u5e8a\u4eba\u5458\u4e0e\u6570\u636e\u79d1\u5b66\u5bb6\u534f\u4f5c\u5b9a\u4e49\u67e5\u8be2\u4e0e\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\u3002", "result": "\u5728\u591a\u4e2d\u5fc3\u764c\u75c7\u514d\u75ab\u6cbb\u7597\u7814\u7a76\u4e2d\uff0c\u751f\u6210\u7684\u7ba1\u9053\u5728\u5173\u952e\u4efb\u52a1\u4e0a\u8fbe\u523098.5%\u548c98.3%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u624b\u52a8\u7f16\u7801\u5de5\u4f5c\u91cf\u3002", "conclusion": "\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u7684\u6838\u5fc3\u539f\u5219\uff08\u5143\u5efa\u6a21\u3001\u8bed\u4e49\u96c6\u6210\u548c\u81ea\u52a8\u4ee3\u7801\u751f\u6210\uff09\u4e3a\u6784\u5efa\u53ef\u4e92\u64cd\u4f5c\u3001\u53ef\u590d\u73b0\u4e14\u53ef\u4fe1\u7684\u6570\u5b57\u5065\u5eb7\u5e73\u53f0\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.09400", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.09400", "abs": "https://arxiv.org/abs/2510.09400", "authors": ["He Jiang", "Yufu Wang", "Hao Lin", "Peiyu Zou", "Zhide Zhou", "Ang Jia", "Xiaochen Li", "Zhilei Ren"], "title": "TIT: A Tree-Structured Instruction Tuning Approach for LLM-Based Code Translation", "comment": null, "summary": "Large Language Models (LLMs) have shown strong performance in automated\nsource-to-target code translation through pretraining on extensive code\ncorpora. However, mainstream LLM-based code translation methods suffer from two\ncritical limitations. First, they are highly sensitive to language-specific\nfeatures, which often introduce source-language syntax or lexicon into the\noutput, leading to syntactic confusion. Second, they lack fine-grained semantic\nalignment due to an over-reliance on function-level parallel datasets,\nresulting in semantic misalignment between the translated code and the original\nsource. To overcome these limitations, we propose TIT, a Tree-structured\nInstruction Tuning paradigm for LLM-based code translation. Specifically, TIT\nconsists of three modules. First, to mitigate syntactic confusion, the\nsyntactic information representation module integrates language-agnostic\nsyntactic features via structured parsing. Then, to generate high-quality\nfine-grained parallel data, the fine-grained parallel dataset augmentation\nmodule aligns nodes with code segments through statement-level segmentation and\ncontrastive matching. Finally, we leverage the dual-stage tree instruction\ntuning module to alleviate the contextual processing burden on the LLM caused\nby the introduction of syntactic information. The first stage employs\nsyntax-aware fine-tuning to enable the LLM to autonomously comprehend\nstructured syntactic information, while the second stage utilizes code\ngeneration fine-tuning to guide the model in generating accurate target code\nbased on function-level syntactic dependencies. The experimental results\ndemonstrate that the proposed method significantly outperforms existing\napproaches in multiple LLMs, achieving a success rate 1.22x-1.75x higher in\ncode translation while markedly reducing syntactic confusion.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTIT\uff08Tree-structured Instruction Tuning\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u89e3\u6790\u548c\u7ec6\u7c92\u5ea6\u5bf9\u9f50\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u7684\u8bed\u6cd5\u6b63\u786e\u6027\u4e0e\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u5b58\u5728\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u4e00\u662f\u5bf9\u8bed\u8a00\u7279\u5f02\u6027\u7279\u5f81\u654f\u611f\uff0c\u5bfc\u81f4\u8f93\u51fa\u6df7\u5165\u6e90\u8bed\u8a00\u8bed\u6cd5\u6216\u8bcd\u6c47\uff0c\u5f15\u53d1\u8bed\u6cd5\u6df7\u6dc6\uff1b\u4e8c\u662f\u8fc7\u5ea6\u4f9d\u8d56\u51fd\u6570\u7ea7\u5e73\u884c\u6570\u636e\uff0c\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5bf9\u9f50\uff0c\u9020\u6210\u7ffb\u8bd1\u7ed3\u679c\u4e0e\u6e90\u4ee3\u7801\u8bed\u4e49\u4e0d\u4e00\u81f4\u3002", "method": "TIT\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a1\uff09\u8bed\u6cd5\u4fe1\u606f\u8868\u793a\u6a21\u5757\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u89e3\u6790\u5f15\u5165\u8bed\u8a00\u65e0\u5173\u7684\u8bed\u6cd5\u7279\u5f81\u4ee5\u7f13\u89e3\u8bed\u6cd5\u6df7\u6dc6\uff1b2\uff09\u7ec6\u7c92\u5ea6\u5e73\u884c\u6570\u636e\u589e\u5f3a\u6a21\u5757\uff0c\u901a\u8fc7\u8bed\u53e5\u7ea7\u5206\u5272\u4e0e\u5bf9\u6bd4\u5339\u914d\u5bf9\u9f50\u4ee3\u7801\u7247\u6bb5\uff1b3\uff09\u53cc\u9636\u6bb5\u6811\u7ed3\u6784\u6307\u4ee4\u5fae\u8c03\u6a21\u5757\uff0c\u7b2c\u4e00\u9636\u6bb5\u8fdb\u884c\u8bed\u6cd5\u611f\u77e5\u5fae\u8c03\u4ee5\u7406\u89e3\u7ed3\u6784\u5316\u8bed\u6cd5\u4fe1\u606f\uff0c\u7b2c\u4e8c\u9636\u6bb5\u8fdb\u884c\u4ee3\u7801\u751f\u6210\u5fae\u8c03\u4ee5\u57fa\u4e8e\u51fd\u6570\u7ea7\u8bed\u6cd5\u4f9d\u8d56\u751f\u6210\u51c6\u786e\u76ee\u6807\u4ee3\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTIT\u5728\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4ee3\u7801\u7ffb\u8bd1\u6210\u529f\u7387\u63d0\u53471.22\u81f31.75\u500d\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u8bed\u6cd5\u6df7\u6dc6\u3002", "conclusion": "TIT\u901a\u8fc7\u878d\u5408\u8bed\u8a00\u65e0\u5173\u7684\u8bed\u6cd5\u7ed3\u6784\u4e0e\u7ec6\u7c92\u5ea6\u8bed\u4e49\u5bf9\u9f50\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u7684\u8bed\u6cd5\u6df7\u6dc6\u4e0e\u8bed\u4e49\u9519\u4f4d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ffb\u8bd1\u8d28\u91cf\u3002"}}
