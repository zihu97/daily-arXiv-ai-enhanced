<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 2]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.AR](#cs.AR) [Total: 3]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Marionette: Data Structure Description and Management for Heterogeneous Computing](https://arxiv.org/abs/2511.04853)
*Nuno dos Santos Fernandes,Pedro Tomás,Nuno Roma,Frank Winklmeier,Patricia Conde-Muíño*

Main category: cs.DC

TL;DR: Marionette 是一个 C++17 库，通过在编译时解耦数据布局与接口描述，支持多种内存管理策略和高效跨设备数据传输，从而简化面向对象 C++ 代码在异构硬件（如 GPU）上的加速。


<details>
  <summary>Details</summary>
Motivation: 将大型面向对象的 C++ 代码库适配到异构硬件（如 GPU）进行加速极具挑战性，主要难点在于数据布局、内存管理和跨设备数据传输的复杂性。

Method: Marionette 利用 C++17 的编译期抽象机制，将数据结构的布局与接口定义分离，支持灵活的内存管理策略，并允许通过任意函数扩展接口，同时保持与现有代码的兼容性。

Result: 通过一个基于 CUDA 的案例研究，展示了 Marionette 在性能、灵活性和易用性方面的优势，实现了高效的跨设备数据转换且运行时开销极小。

Conclusion: Marionette 为在异构平台上高效加速 C++ 代码提供了一种灵活、可移植且低开销的解决方案，适用于从简单到复杂的多种应用场景。

Abstract: Adapting large, object-oriented C++ codebases for hardware acceleration might
be extremely challenging, particularly when targeting heterogeneous platforms
such as GPUs. Marionette is a C++17 library designed to address this by
enabling flexible, efficient, and portable data structure definitions. It
decouples data layout from the description of the interface, supports multiple
memory management strategies, and provides efficient data transfers and
conversions across devices, all of this with minimal runtime overhead due to
the compile-time nature of its abstractions. By allowing interfaces to be
augmented with arbitrary functions, Marionette maintains compatibility with
existing code and offers a streamlined interface that supports both
straightforward and advanced use cases. This paper outlines its design, usage,
and performance, including a CUDA-based case study demonstrating its efficiency
and flexibility.

</details>


### [2] [GPU Under Pressure: Estimating Application's Stress via Telemetry and Performance Counters](https://arxiv.org/abs/2511.05067)
*Giuseppe Esposito,Juan-David Guerrero-Balaguera,Josie Esteban Rodriguez Condia,Matteo Sonza Reorda,Marco Barbiero,Rossella Fortuna*

Main category: cs.DC

TL;DR: 本文提出一种结合在线遥测参数与硬件性能计数器的方法，用于评估GPU在不同应用负载下的应力水平，从而预测其可靠性（尤其关注老化效应）。


<details>
  <summary>Details</summary>
Motivation: 持续高负载工作会显著增加GPU组件的应力，可能导致中间计算结果出错，影响可靠性；因此需要有效方法来估计应用引起的应力以预测可靠性。

Method: 结合GPU的在线遥测数据和硬件性能计数器（重点关注吞吐量、指令发射数量和停顿事件）来评估不同并行工作负载对GPU造成的应力。

Result: 实验结果表明，通过融合遥测数据与反映资源使用效率的性能计数器，可以有效估计并行工作负载对GPU造成的应力。

Conclusion: 利用遥测参数与特定性能计数器的组合，能够有效评估GPU在运行不同应用时所承受的应力，为可靠性预测（尤其是老化效应）提供支持。

Abstract: Graphics Processing Units (GPUs) are specialized accelerators in data centers
and high-performance computing (HPC) systems, enabling the fast execution of
compute-intensive applications, such as Convolutional Neural Networks (CNNs).
However, sustained workloads can impose significant stress on GPU components,
raising reliability concerns due to potential faults that corrupt the
intermediate application computations, leading to incorrect results. Estimating
the stress induced by an application is thus crucial to predict reliability
(with\,special\,emphasis\,on\,aging\,effects). In this work, we combine online
telemetry parameters and hardware performance counters to assess GPU stress
induced by different applications. The experimental results indicate the stress
induced by a parallel workload can be estimated by combining telemetry data and
Performance Counters that reveal the efficiency in the resource usage of the
target workload. For this purpose the selected performance counters focus on
measuring the i) throughput, ii) amount of issued instructions and iii) stall
events.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [3] [EPFL-REMNet: Efficient Personalized Federated Digital Twin Towards 6G Heterogeneous Radio Environme](https://arxiv.org/abs/2511.05238)
*Peide Li,Liu Cao,Lyutianyang Zhang,Dongyu Wei,Ye Hu,Qipeng Xie*

Main category: cs.NI

TL;DR: 本文提出EPFL-REMNet，一种高效个性化联邦学习框架，用于在6G异构无线环境中构建高保真数字孪生。该方法通过“共享主干+轻量级个性化头部”结构，在降低通信开销的同时提升非独立同分布（Non-IID）场景下的建图精度与公平性。


<details>
  <summary>Details</summary>
Motivation: 标准联邦学习在6G异构无线环境下面临Non-IID数据导致的精度下降和通信效率低的问题，难以有效构建高保真无线电环境地图（REM）数字孪生。

Method: EPFL-REMNet采用“共享主干+轻量级个性化头部”的模型架构，仅在服务器与客户端间传输压缩后的共享主干，个性化头部则保留在本地；并在90个地理分区客户端上构建轻、中、重三种Non-IID场景进行验证。

Result: 实验表明，EPFL-REMNet在所有Non-IID设置下均优于FedAvg及最新方法，同时实现了更高精度和更低上行开销，并显著缩小了不同客户端间的性能差距，提升了长尾客户端的本地地图准确性。

Conclusion: EPFL-REMNet有效解决了6G异构环境下联邦学习构建REM时的Non-IID挑战，在保证通信效率的同时提高了数字孪生的整体保真度与公平性。

Abstract: Radio Environment Map (REM) is transitioning from 5G homogeneous environments
to B5G/6G heterogeneous landscapes. However, standard Federated Learning (FL),
a natural fit for this distributed task, struggles with performance degradation
in accuracy and communication efficiency under the non-independent and
identically distributed (Non-IID) data conditions inherent to these new
environments. This paper proposes EPFL-REMNet, an efficient personalized
federated framework for constructing a high-fidelity digital twin of the 6G
heterogeneous radio environment. The proposed EPFL-REMNet employs a"shared
backbone + lightweight personalized head" model, where only the compressed
shared backbone is transmitted between the server and clients, while each
client's personalized head is maintained locally. We tested EPFL-REMNet by
constructing three distinct Non-IID scenarios (light, medium, and heavy) based
on radio environment complexity, with data geographically partitioned across 90
clients. Experimental results demonstrate that EPFL-REMNet simultaneously
achieves higher digital twin fidelity (accuracy) and lower uplink overhead
across all Non-IID settings compared to standard FedAvg and recent
state-of-the-art methods. Particularly, it significantly reduces performance
disparities across datasets and improves local map accuracy for long-tail
clients, enhancing the overall integrity of digital twin.

</details>


### [4] [A Formal Model for Path Set Attribute Calculation in Network Systems](https://arxiv.org/abs/2511.05334)
*Giovanni Fiaschi,Carlo Vitucci,Thomas Westerbäck,Daniel Sundmark,Thomas Nolte*

Main category: cs.NI

TL;DR: 本文提出了一种用于刻画路径集合的泛化函数模型，强调在多路径选择中基于属性进行刻画的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有研究对单条路径的评估较为充分，但缺乏对路径集合的细致刻画；而路径集合的特性高度依赖于所考虑的属性，因此需要一种通用的数学方法来系统描述路径集合。

Method: 提出一个函数模型，用于在一般形式下对路径集合进行数学刻画，并展示该模型如何结合具体属性进行上下文化分析。

Result: 该函数模型能够有效整合和表达路径集合的不同属性，为多路径选择提供理论支持。

Conclusion: 路径集合的刻画必须考虑其依赖的属性，所提出的函数模型为此提供了灵活且通用的数学框架。

Abstract: In graph theory and its practical networking applications, e.g.,
telecommunications and transportation, the problem of finding paths has
particular importance. Selecting paths requires giving scores to the
alternative solutions to drive a choice. While previous studies have provided
comprehensive evaluation of single-path solutions, the same level of detail is
lacking when considering sets of paths. This paper emphasizes that the path
characterization strongly depends on the properties under consideration. While
property-based characterization is also valid for single paths, it becomes
crucial to analyse multiple path sets. From the above consideration, this paper
proposes a mathematical approach, defining a functional model that lends itself
well to characterizing the path set in its general formulation. The paper shows
how the functional model contextualizes specific attributes.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Software Defined Vehicle Code Generation: A Few-Shot Prompting Approach](https://arxiv.org/abs/2511.04849)
*Quang-Dung Nguyen,Tri-Dung Tran,Thanh-Hieu Chu,Hoang-Loc Tran,Xiangwei Cheng,Dirk Slama*

Main category: cs.SE

TL;DR: 本文研究了如何通过提示工程（特别是少样本提示）引导大语言模型（LLMs）生成面向软件定义车辆（SDV）的代码，而无需对模型进行训练或访问其底层架构，并在专门构建的基准上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 软件定义车辆（SDV）的发展要求高效开发专用应用，但通用大语言模型因架构封闭难以适配SDV代码生成任务，因此需要一种无需训练即可引导模型的方法。

Method: 采用系统提示结合先进的提示工程技术（如少样本提示），在不修改或训练模型的前提下引导LLM生成SDV代码，并在专门构建的基准上对多种提示策略进行实验评估。

Result: 实验结果表明，采用少样本提示策略的模型在定量指标上显著优于其他提示方式，能更准确地生成符合预期的SDV代码。

Conclusion: 通过精心设计的提示结构，尤其是少样本提示，可以在无需访问模型内部结构或重新训练的情况下有效提升大语言模型在SDV代码生成任务中的表现。

Abstract: The emergence of Software-Defined Vehicles (SDVs) marks a paradigm shift in
the automotive industry, where software now plays a pivotal role in defining
vehicle functionality, enabling rapid innovation of modern vehicles. Developing
SDV-specific applications demands advanced tools to streamline code generation
and improve development efficiency. In recent years, general-purpose large
language models (LLMs) have demonstrated transformative potential across
domains. Still, restricted access to proprietary model architectures hinders
their adaption to specific tasks like SDV code generation. In this study, we
propose using prompts, a common and basic strategy to interact with LLMs and
redirect their responses. Using only system prompts with an appropriate and
efficient prompt structure designed using advanced prompt engineering
techniques, LLMs can be crafted without requiring a training session or access
to their base design. This research investigates the extensive experiments on
different models by applying various prompting techniques, including bare
models, using a benchmark specifically created to evaluate LLMs' performance in
generating SDV code. The results reveal that the model with a few-shot
prompting strategy outperforms the others in adjusting the LLM answers to match
the expected outcomes based on quantitative metrics.

</details>


### [6] [What About Our Bug? A Study on the Responsiveness of NPM Package Maintainers](https://arxiv.org/abs/2511.04986)
*Mohammadreza Saeidi,Ethan Thoma,Raula Gaikovina Kula,Gema Rodríguez-Pérez*

Main category: cs.SE

TL;DR: 该研究调查了npm生态系统中500个最常被依赖的包对30,340份缺陷报告的响应情况，发现维护者整体响应率较高（项目级中位数为70%），并通过定性分析提出了未修复缺陷的分类原因。


<details>
  <summary>Details</summary>
Motivation: 第三方库的广泛使用使npm等生态系统对现代软件开发至关重要，但依赖链中的缺陷可能向下传播。作者假设维护者未必总会修复缺陷，尤其当他们认为问题不在自身责任范围内时，因此希望验证这一假设。

Method: 采用混合方法：挖掘仓库问题数据，并通过开放式编码进行定性分析，以探究未处理缺陷报告背后的原因。

Result: 维护者总体响应积极，项目级中位响应率为70%（四分位距：55%-89%）；同时归纳出未修复缺陷的若干原因。

Conclusion: 提出了一个关于缺陷未被修复原因的分类体系，涵盖贡献实践、依赖约束和库特定标准等因素；理解维护者行为有助于构建更稳健、响应更快的开源生态。

Abstract: Background: Widespread use of third-party libraries makes ecosystems like
Node Package Manager (npm) critical to modern software development. However,
this interconnected chain of dependencies also creates challenges: bugs in one
library can propagate downstream, potentially impacting many other libraries
that rely on it. We hypothesize that maintainers may not always decide to fix a
bug, especially if the maintainer decides it falls out of their responsibility
within the chain of dependencies. Aims: To confirm this hypothesis, we
investigate the responsiveness of 30,340 bug reports across 500 of the most
depended-upon npm packages. Method: We adopt a mixed-method approach to mine
repository issue data and perform qualitative open coding to analyze reasons
behind unaddressed bug reports. Results: Our findings show that maintainers are
generally responsive, with a median project-level responsiveness of 70% (IQR:
55%-89%), reflecting their commitment to support downstream developers.
Conclusions: We present a taxonomy of the reasons some bugs remain unresolved.
The taxonomy includes contribution practices, dependency constraints, and
library-specific standards as reasons for not being responsive. Understanding
maintainer behavior can inform practices that promote a more robust and
responsive open-source ecosystem that benefits the entire community.

</details>


### [7] [Generating Software Architecture Description from Source Code using Reverse Engineering and Large Language Model](https://arxiv.org/abs/2511.05165)
*Ahmad Hatahet,Christoph Knieke,Andreas Rausch*

Main category: cs.SE

TL;DR: 本文提出一种结合逆向工程与大语言模型（LLM）的半自动化方法，从源代码生成软件架构描述（SAD），包括静态组件图和行为状态机图，以减轻人工负担并提升系统可维护性。


<details>
  <summary>Details</summary>
Motivation: 实践中软件架构描述常缺失、过时或与实现不一致，迫使开发者从源码中手动推导架构信息，过程耗时且增加认知负担，影响新成员上手和系统长期可理解性。

Method: 结合逆向工程技术与大语言模型（LLM），通过提示工程提取核心组件生成组件图，并利用少样本提示从代码逻辑中生成状态机图，从而构建静态与行为架构视图。

Result: 该方法在C++示例中成功展示了LLM能有效抽象组件结构并准确建模复杂行为，尤其在结合领域知识的少样本提示下表现更佳。

Conclusion: 所提方法为自动生成可扩展、易维护的软件架构文档提供了可行路径，显著减少人工干预，同时提升对系统的理解与长期可维护性。

Abstract: Software Architecture Descriptions (SADs) are essential for managing the
inherent complexity of modern software systems. They enable high-level
architectural reasoning, guide design decisions, and facilitate effective
communication among diverse stakeholders. However, in practice, SADs are often
missing, outdated, or poorly aligned with the system's actual implementation.
Consequently, developers are compelled to derive architectural insights
directly from source code-a time-intensive process that increases cognitive
load, slows new developer onboarding, and contributes to the gradual
degradation of clarity over the system's lifetime. To address these issues, we
propose a semi-automated generation of SADs from source code by integrating
reverse engineering (RE) techniques with a Large Language Model (LLM). Our
approach recovers both static and behavioral architectural views by extracting
a comprehensive component diagram, filtering architecturally significant
elements (core components) via prompt engineering, and generating state machine
diagrams to model component behavior based on underlying code logic with
few-shots prompting. This resulting views representation offer a scalable and
maintainable alternative to traditional manual architectural documentation.
This methodology, demonstrated using C++ examples, highlights the potent
capability of LLMs to: 1) abstract the component diagram, thereby reducing the
reliance on human expert involvement, and 2) accurately represent complex
software behaviors, especially when enriched with domain-specific knowledge
through few-shot prompting. These findings suggest a viable path toward
significantly reducing manual effort while enhancing system understanding and
long-term maintainability.

</details>


### [8] [CodeMapper: A Language-Agnostic Approach to Mapping Code Regions Across Commits](https://arxiv.org/abs/2511.05205)
*Huimin Hu,Michael Pradel*

Main category: cs.SE

TL;DR: 本文提出了CodeMapper，一种与编程语言和程序元素无关的代码映射方法，用于在不同提交之间定位开发者指定代码区域的对应位置，在多个数据集上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 在软件演化过程中，开发者常需将某一提交中的特定代码区域映射到另一提交中，但现有工具（如git diff）无法聚焦于用户指定区域，而其他技术又受限于特定语言或代码元素，缺乏通用性。

Method: CodeMapper包含两个阶段：(i) 通过分析diff、检测代码移动和搜索特定代码片段生成候选区域；(ii) 基于相似度计算选择最可能的目标区域。

Result: 在四个数据集（包括两个涵盖十种流行语言的手动标注数据集）上的实验表明，CodeMapper在71.0%–94.5%的案例中能正确识别目标区域，比最佳基线方法高出1.5–58.8个百分点。

Conclusion: CodeMapper有效解决了跨提交的代码区域映射问题，具有良好的语言无关性和实用性，显著优于现有方法。

Abstract: During software evolution, developers commonly face the problem of mapping a
specific code region from one commit to another. For example, they may want to
determine how the condition of an if-statement, a specific line in a
configuration file, or the definition of a function changes. We call this the
code mapping problem. Existing techniques, such as git diff, address this
problem only insufficiently because they show all changes made to a file
instead of focusing on a code region of the developer's choice. Other
techniques focus on specific code elements and programming languages (e.g.,
methods in Java), limiting their applicability. This paper introduces
CodeMapper, an approach to address the code mapping problem in a way that is
independent of specific program elements and programming languages. Given a
code region in one commit, CodeMapper finds the corresponding region in another
commit. The approach consists of two phases: (i) computing candidate regions by
analyzing diffs, detecting code movements, and searching for specific code
fragments, and (ii) selecting the most likely target region by calculating
similarities. Our evaluation applies CodeMapper to four datasets, including two
new hand-annotated datasets containing code region pairs in ten popular
programming languages. CodeMapper correctly identifies the expected target
region in 71.0%--94.5% of all cases, improving over the best available
baselines by 1.5--58.8 absolute percent points.

</details>


### [9] [Building Specialized Software-Assistant ChatBot with Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2511.05297)
*Mohammed Hilel,Yannis Karmim,Jean De Bodinat,Reda Sarehane,Antoine Gillon*

Main category: cs.SE

TL;DR: 本文提出了一种基于图的检索增强生成框架，将企业级Web应用自动转化为状态-动作知识图谱，以提升大语言模型在数字采用平台中的可靠性和上下文感知能力。


<details>
  <summary>Details</summary>
Motivation: 当前数字采用平台（DAP）依赖大量人工构建交互式引导，而直接使用大语言模型（LLM）作为虚拟助手容易产生幻觉，且由于多数生产级LLM为黑盒API，难以微调，因此需要一种无需访问模型权重即可提升LLM可靠性的方法。

Method: 构建一个图结构的检索增强生成（Graph-based RAG）框架，自动将企业Web应用界面提取并构建成状态-动作知识图谱，并将其集成到DAP工作流中，为LLM提供结构化上下文信息。

Result: 该框架成功应用于与RAKAM和Lemon Learning合作的工业场景，展示了在实际DAP系统中提升LLM辅助准确性和可用性的能力，并总结了可扩展性、鲁棒性及部署经验。

Conclusion: 通过将企业软件界面转化为结构化知识图谱，该方法有效缓解了LLM在DAP场景中的幻觉问题，在不依赖模型微调的前提下实现了可靠、上下文感知的用户引导。

Abstract: Digital Adoption Platforms (DAPs) have become essential tools for helping
employees navigate complex enterprise software such as CRM, ERP, or HRMS
systems. Companies like LemonLearning have shown how digital guidance can
reduce training costs and accelerate onboarding. However, building and
maintaining these interactive guides still requires extensive manual effort.
Leveraging Large Language Models as virtual assistants is an appealing
alternative, yet without a structured understanding of the target software,
LLMs often hallucinate and produce unreliable answers. Moreover, most
production-grade LLMs are black-box APIs, making fine-tuning impractical due to
the lack of access to model weights. In this work, we introduce a Graph-based
Retrieval-Augmented Generation framework that automatically converts enterprise
web applications into state-action knowledge graphs, enabling LLMs to generate
grounded and context-aware assistance. The framework was co-developed with the
AI enterprise RAKAM, in collaboration with Lemon Learning. We detail the
engineering pipeline that extracts and structures software interfaces, the
design of the graph-based retrieval process, and the integration of our
approach into production DAP workflows. Finally, we discuss scalability,
robustness, and deployment lessons learned from industrial use cases.

</details>


### [10] [Code Review Automation using Retrieval Augmented Generation](https://arxiv.org/abs/2511.05302)
*Qianru Meng,Xiao Zhang,Zhaochen Ren,Joost Visser*

Main category: cs.SE

TL;DR: 本文提出了一种名为RARe（Retrieval-Augmented Reviewer）的新方法，结合检索与生成技术，通过引入外部领域知识提升自动代码审查的质量，在两个基准数据集上优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 自动代码审查虽已有进展，但生成的评论仍存在偏离主题或过于泛化的问题，亟需更精准、实用的解决方案。

Method: RARe利用检索增强生成（RAG）框架，通过稠密检索器从代码库中选取最相关的已有评论，将其作为上下文输入大型语言模型，增强生成器的领域知识和上下文理解能力。

Result: 在两个基准数据集上分别取得12.32和12.96的BLEU-4分数，并通过人工评估和可解释性案例研究验证了其有效性和可靠性。

Conclusion: RARe通过融合检索与生成方法，显著提升了自动代码审查的相关性和实用性，为软件质量保障提供了有力支持。

Abstract: Code review is essential for maintaining software quality but is
labor-intensive. Automated code review generation offers a promising solution
to this challenge. Both deep learning-based generative techniques and
retrieval-based methods have demonstrated strong performance in this task.
However, despite these advancements, there are still some limitations where
generated reviews can be either off-point or overly general. To address these
issues, we introduce Retrieval-Augmented Reviewer (RARe), which leverages
Retrieval-Augmented Generation (RAG) to combine retrieval-based and generative
methods, explicitly incorporating external domain knowledge into the code
review process. RARe uses a dense retriever to select the most relevant reviews
from the codebase, which then enrich the input for a neural generator,
utilizing the contextual learning capacity of large language models (LLMs), to
produce the final review. RARe outperforms state-of-the-art methods on two
benchmark datasets, achieving BLEU-4 scores of 12.32 and 12.96, respectively.
Its effectiveness is further validated through a detailed human evaluation and
a case study using an interpretability tool, demonstrating its practical
utility and reliability.

</details>


### [11] [SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for Large Language Models](https://arxiv.org/abs/2511.05459)
*Jingxuan Xu,Ken Deng,Weihao Li,Songwei Yu,Huaixi Tang,Haoyang Huang,Zhiyi Lai,Zizheng Zhan,Yanan Wu,Chenchen Zhang,Kepeng Lei,Yifan Yao,Xinping Lei,Wenqiang Zhu,Zongxian Feng,Han Li,Junqi Xiong,Dailin Li,Zuchen Gao,Kun Wu,Wen Xiang,Ziqi Zhan,Yuanxing Zhang,Wuxuan Gong,Ziyuan Gao,Guanxiang Wang,Yirong Xue,Xiaojiang Zhang,Jinghui Wang,Huiming Wang,Wenhao Zhuang,Zhaoxiang Zhang,Yuqun Zhang,Haotian Zhang,Bin Chen,Jiaheng Liu*

Main category: cs.SE

TL;DR: 本文提出了SWE-Compass，一个覆盖8类任务、8种编程场景和10种编程语言的综合性软件工程评测基准，基于2000个来自真实GitHub PR的高质量实例，用于评估大语言模型在贴近实际开发流程中的编码能力。


<details>
  <summary>Details</summary>
Motivation: 现有针对大语言模型在软件工程领域的评测存在任务覆盖狭窄、语言偏向性强以及与真实开发者工作流对齐不足的问题，尤其缺乏对非Python语言和多样化开发场景的评估。

Method: 构建SWE-Compass基准，整合异构代码相关任务，涵盖8类任务、8种场景和10种语言；数据源自真实GitHub拉取请求，并经过系统性筛选与验证；在SWE-Agent和Claude Code两个智能体框架下评测十个前沿大语言模型。

Result: 评测揭示了不同任务类型、编程语言和场景之间的难度层级，证明SWE-Compass能有效反映模型在真实开发环境中的表现。

Conclusion: SWE-Compass为评估和提升大语言模型在软件工程中的智能体编码能力提供了严谨、可复现且与实际开发实践对齐的评测基础。

Abstract: Evaluating large language models (LLMs) for software engineering has been
limited by narrow task coverage, language bias, and insufficient alignment with
real-world developer workflows. Existing benchmarks often focus on algorithmic
problems or Python-centric bug fixing, leaving critical dimensions of software
engineering underexplored. To address these gaps, we introduce SWE-Compass1, a
comprehensive benchmark that unifies heterogeneous code-related evaluations
into a structured and production-aligned framework. SWE-Compass spans 8 task
types, 8 programming scenarios, and 10 programming languages, with 2000
high-quality instances curated from authentic GitHub pull requests and refined
through systematic filtering and validation. We benchmark ten state-of-the-art
LLMs under two agentic frameworks, SWE-Agent and Claude Code, revealing a clear
hierarchy of difficulty across task types, languages, and scenarios. Moreover,
by aligning evaluation with real-world developer practices, SWE-Compass
provides a rigorous and reproducible foundation for diagnosing and advancing
agentic coding capabilities in large language models.

</details>


### [12] [A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?](https://arxiv.org/abs/2511.05476)
*Md. Abdul Awal,Mrigank Rochan,Chanchal K. Roy*

Main category: cs.SE

TL;DR: 本文提出MetaCompress，一种用于评估代码语言模型知识蒸馏过程中学生模型对教师模型行为保真度的变形测试框架，揭示了传统准确率指标无法捕捉的行为差异。


<details>
  <summary>Details</summary>
Motivation: 当前基于准确率的评估方法仅能表面衡量压缩模型性能，无法反映学生模型在预测行为和内部表示上对教师模型的深层模仿程度，尤其在面对对抗攻击时表现差距显著。

Method: 提出MetaCompress框架，通过一组保持行为不变的变形关系，系统比较教师模型与学生模型的输出，以评估其行为保真度。

Result: 在两种常见任务和三种蒸馏方法（Compressor、AVATAR、MORPH）下，MetaCompress最多检测到62%的行为不一致，并发现学生模型在对抗攻击下性能下降最多达285%。

Conclusion: 传统准确率评估不足以衡量知识蒸馏后模型的行为一致性，MetaCompress为压缩代码语言模型提供了实用的行为保真度测试手段，应在蒸馏流程中引入此类评估。

Abstract: Transformer-based language models of code have achieved state-of-the-art
performance across a wide range of software analytics tasks, but their
practical deployment remains limited due to high computational costs, slow
inference speeds, and significant environmental impact. To address these
challenges, recent research has increasingly explored knowledge distillation as
a method for compressing a large language model of code (the teacher) into a
smaller model (the student) while maintaining performance. However, the degree
to which a student model deeply mimics the predictive behavior and internal
representations of its teacher remains largely unexplored, as current
accuracy-based evaluation provides only a surface-level view of model quality
and often fails to capture more profound discrepancies in behavioral fidelity
between the teacher and student models. To address this gap, we empirically
show that the student model often fails to deeply mimic the teacher model,
resulting in up to 285% greater performance drop under adversarial attacks,
which is not captured by traditional accuracy-based evaluation. Therefore, we
propose MetaCompress, a metamorphic testing framework that systematically
evaluates behavioral fidelity by comparing the outputs of teacher and student
models under a set of behavior-preserving metamorphic relations. We evaluate
MetaCompress on two widely studied tasks, using compressed versions of popular
language models of code, obtained via three different knowledge distillation
techniques: Compressor, AVATAR, and MORPH. The results show that MetaCompress
identifies up to 62% behavioral discrepancies in student models, underscoring
the need for behavioral fidelity evaluation within the knowledge distillation
pipeline and establishing MetaCompress as a practical framework for testing
compressed language models of code derived through knowledge distillation.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [13] [RAS: A Bit-Exact rANS Accelerator For High-Performance Neural Lossless Compression](https://arxiv.org/abs/2511.04684)
*Yuchao Qin,Anjunyi Fan,Bonan Yan*

Main category: cs.AR

TL;DR: 本文提出了RAS（Range Asymmetric Numeral System Acceleration System），一种用于加速基于rANS算法的神经无损压缩的硬件架构。通过将概率模型与rANS核心集成、采用BF16格式存储分布、两阶段更新机制、预测引导解码路径及多通道设计，RAS显著提升了压缩/解压速度，在图像任务中相比Python基线分别实现121.2倍编码和70.9倍解码加速，并保持高压缩率。


<details>
  <summary>Details</summary>
Motivation: 现有基于概率模型的无损压缩方法计算开销大、速度慢，难以满足数据中心对高效压缩的需求。因此，亟需一种能兼顾高压缩率与高性能的硬件加速方案。

Method: 提出RAS硬件架构：1）将rANS算法与概率生成器耦合，使用BF16格式存储分布并一次性转换为定点表示；2）采用两阶段rANS更新与字节级重归一化以降低逻辑开销和内存流量；3）引入预测引导的解码路径，通过缩小CDF搜索窗口加速解码，同时保证比特精确性；4）采用多通道结构提升吞吐量并支持细粒度时钟门控。

Result: RTL仿真原型在图像工作负载上相较Python rANS基线实现121.2倍编码加速和70.9倍解码加速；平均解码二分查找步数从7.00降至3.15（减少约55%）；在搭配神经概率模型时，压缩率优于传统编解码器，并超越CPU/GPU上的rANS实现。

Conclusion: RAS提供了一种实用且高效的神经无损压缩硬件加速方案，在保持高压缩率的同时大幅提升了处理速度，适用于数据中心等对性能敏感的场景。

Abstract: Data centers handle vast volumes of data that require efficient lossless
compression, yet emerging probabilistic models based methods are often
computationally slow. To address this, we introduce RAS, the Range Asymmetric
Numeral System Acceleration System, a hardware architecture that integrates the
rANS algorithm into a lossless compression pipeline and eliminates key
bottlenecks. RAS couples an rANS core with a probabilistic generator, storing
distributions in BF16 format and converting them once into a fixed-point domain
shared by a unified division/modulo datapath. A two-stage rANS update with
byte-level re-normalization reduces logic cost and memory traffic, while a
prediction-guided decoding path speculatively narrows the cumulative
distribution function (CDF) search window and safely falls back to maintain
bit-exactness. A multi-lane organization scales throughput and enables
fine-grained clock gating for efficient scheduling. On image workloads, our
RTL-simulated prototype achieves 121.2x encode and 70.9x decode speedups over a
Python rANS baseline, reducing average decoder binary-search steps from 7.00 to
3.15 (approximately 55% fewer). When paired with neural probability models, RAS
sustains higher compression ratios than classical codecs and outperforms
CPU/GPU rANS implementations, offering a practical approach to fast neural
lossless compression.

</details>


### [14] [Eliminating the Hidden Cost of Zone Management in ZNS SSDs](https://arxiv.org/abs/2511.04687)
*Teona Bagashvili,Tarikul Islam Papon,Subhadeep Sarkar,Manos Athanassoulis*

Main category: cs.AR

TL;DR: SilentZNS 是一种新型 ZNS SSD 区映射与管理方法，通过动态分配物理资源、避免全区域操作和减少无用写入，显著降低设备级写放大（最高减少86%）、磨损（最多76.9%）并提升工作负载执行速度（最高3.7倍）。


<details>
  <summary>Details</summary>
Motivation: 当前 Zoned Namespace (ZNS) SSD 实现存在设备级写放大、磨损加剧以及因区域映射和管理导致的主机 I/O 干扰等问题，主要源于固定物理区域和全区域操作的设计缺陷。

Method: 提出 SilentZNS 方法，摒弃传统的逻辑到物理区域映射，采用灵活的块级区域分配机制，在运行时动态分配可用资源给区域，并加入磨损均衡和读取性能保障约束，仅使用必要块以避免区域重置时的填充写入。

Result: 在 ConfZNS++ 模拟器上实现 SilentZNS，实验表明其可将无用填充写入减少最多20倍，在10%区域占用率下设备级写放大降低86%，整体磨损减少最多76.9%，工作负载执行速度提升最高达3.7倍。

Conclusion: SilentZNS 有效解决了现有 ZNS SSD 在写放大、磨损和 I/O 干扰方面的关键问题，为高效、低开销的 ZNS 存储系统提供了可行的新设计路径。

Abstract: Zoned Namespace (ZNS) SSDs offer a promising interface for stable throughput
and low-latency storage by eliminating device-side garbage collection. They
expose storage as append-only zones that give the host applications direct
control over data placement. However, current ZNS implementations suffer from
(a) device-level write amplification (DLWA), (b) increased wear, and (c)
interference with host I/O due to zone mapping and management. We identify two
primary design decisions as the main cause: (i) fixed physical zones and (ii)
full-zone operations that lead to excessive physical writes. We propose
SilentZNS, a new zone mapping and management approach that addresses the
aforementioned limitations by on-the-fly allocating available resources to
zones, while minimizing wear, maintaining parallelism, and avoiding unnecessary
writes at the device-level. SilentZNS is a flexible zone allocation scheme that
departs from the traditional logical-to-physical zone mapping and allows for
arbitrary collections of blocks to be assigned to a zone. We add the necessary
constraints to ensure wear-leveling and state-of-the-art read performance, and
use only the required blocks to avoid dummy writes during zone reset. We
implement SilentZNS using the state-of-the-art ConfZNS++ emulator and show that
it eliminates the undue burden of dummy writes by up to 20x, leading to lower
DLWA (86% less at 10% zone occupancy), less overall wear (up to 76.9%), and up
to 3.7x faster workload execution.

</details>


### [15] [MDM: Manhattan Distance Mapping of DNN Weights for Parasitic-Resistance-Resilient Memristive Crossbars](https://arxiv.org/abs/2511.04798)
*Matheus Farias,Wanghley Martins,H. T. Kung*

Main category: cs.AR

TL;DR: Manhattan Distance Mapping (MDM) 是一种用于忆阻器位切片存内计算（CIM）交叉阵列的后训练权重映射技术，通过优化活跃忆阻器的位置来减轻寄生电阻（PR）非理想性，从而提升模型精度和交叉阵列效率。


<details>
  <summary>Details</summary>
Motivation: 寄生电阻（PR）限制了CIM交叉阵列的效率，迫使DNN矩阵被划分为小块，导致模拟-数字转换增多、延迟增加、I/O压力增大及芯片面积上升。现有方法难以在保持性能的同时有效缓解PR影响。

Method: MDM利用位级结构稀疏性，将激活值从低阶密集侧输入，并根据曼哈顿距离对行进行重排序，将活跃单元移至受PR影响较小的区域，从而降低非理想性因子（NF）。

Result: 在ImageNet-1k上的DNN模型实验表明，MDM最多可将NF降低46%，并在ResNet中平均提升3.6%的模拟失真下的准确率。

Conclusion: MDM提供了一种轻量且空间感知的映射方法，有助于扩展CIM DNN加速器的规模并提升其鲁棒性。

Abstract: Manhattan Distance Mapping (MDM) is a post-training deep neural network (DNN)
weight mapping technique for memristive bit-sliced compute-in-memory (CIM)
crossbars that reduces parasitic resistance (PR) nonidealities.
  PR limits crossbar efficiency by mapping DNN matrices into small crossbar
tiles, reducing CIM-based speedup. Each crossbar executes one tile, requiring
digital synchronization before the next layer. At this granularity, designers
either deploy many small crossbars in parallel or reuse a few sequentially-both
increasing analog-to-digital conversions, latency, I/O pressure, and chip area.
  MDM alleviates PR effects by optimizing active-memristor placement.
Exploiting bit-level structured sparsity, it feeds activations from the denser
low-order side and reorders rows according to the Manhattan distance,
relocating active cells toward regions less affected by PR and thus lowering
the nonideality factor (NF).
  Applied to DNN models on ImageNet-1k, MDM reduces NF by up to 46% and
improves accuracy under analog distortion by an average of 3.6% in ResNets.
Overall, it provides a lightweight, spatially informed method for scaling CIM
DNN accelerators.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [16] [TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems](https://arxiv.org/abs/2511.05269)
*Ishan Kavathekar,Hemang Jain,Ameya Rathod,Ponnurangam Kumaraguru,Tanuja Ganu*

Main category: cs.MA

TL;DR: 本文提出了 TAMAS 基准，用于评估多智能体大语言模型系统在面对对抗攻击时的安全性与鲁棒性，发现当前系统极易受到攻击，并引入有效鲁棒性评分（ERS）来衡量安全性与任务效能之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂度提升，多智能体大语言模型系统被广泛用于协作解决问题，但其安全性和鲁棒性尚未得到充分研究，现有基准主要针对单智能体场景，无法反映多智能体协作中的独特漏洞。

Method: 作者构建了 TAMAS 基准，包含五个场景、300 个对抗实例（涵盖六种攻击类型和 211 个工具）以及 100 个无害任务；在十个基础大语言模型和三种来自 Autogen 与 CrewAI 框架的智能体交互配置上进行评估，并提出有效鲁棒性评分（ERS）。

Result: 实验表明，当前多智能体系统在面对对抗攻击时表现出高度脆弱性，揭示了部署中存在的关键挑战和失效模式。

Conclusion: TAMAS 为系统性研究和提升多智能体大语言模型系统的安全性提供了重要基础，强调亟需开发更强的防御机制。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities as
autonomous agents through tool use, planning, and decision-making abilities,
leading to their widespread adoption across diverse tasks. As task complexity
grows, multi-agent LLM systems are increasingly used to solve problems
collaboratively. However, safety and security of these systems remains largely
under-explored. Existing benchmarks and datasets predominantly focus on
single-agent settings, failing to capture the unique vulnerabilities of
multi-agent dynamics and co-ordination. To address this gap, we introduce
$\textbf{T}$hreats and $\textbf{A}$ttacks in $\textbf{M}$ulti-$\textbf{A}$gent
$\textbf{S}$ystems ($\textbf{TAMAS}$), a benchmark designed to evaluate the
robustness and safety of multi-agent LLM systems. TAMAS includes five distinct
scenarios comprising 300 adversarial instances across six attack types and 211
tools, along with 100 harmless tasks. We assess system performance across ten
backbone LLMs and three agent interaction configurations from Autogen and
CrewAI frameworks, highlighting critical challenges and failure modes in
current multi-agent deployments. Furthermore, we introduce Effective Robustness
Score (ERS) to assess the tradeoff between safety and task effectiveness of
these frameworks. Our findings show that multi-agent systems are highly
vulnerable to adversarial attacks, underscoring the urgent need for stronger
defenses. TAMAS provides a foundation for systematically studying and improving
the safety of multi-agent LLM systems.

</details>
