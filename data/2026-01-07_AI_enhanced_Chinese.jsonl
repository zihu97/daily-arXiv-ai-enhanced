{"id": "2601.02449", "categories": ["cs.MA", "cs.DM"], "pdf": "https://arxiv.org/pdf/2601.02449", "abs": "https://arxiv.org/abs/2601.02449", "authors": ["H. Van Dyke Parunak"], "title": "Stigmergic Swarming Agents for Fast Subgraph Isomorphism", "comment": "Accepted as full paper for AAMAS 2026 (May 2026)", "summary": "Maximum partial subgraph isomorphism compares two graphs (nodes joined by edges) to find a largest common subgraph. A common use case, for graphs with labeled nodes, seeks to find instances of a \\textit{query} graph with $q$ nodes in a (typically larger) \\textit{data} graph with $d$ nodes. The problem is NP-complete, and na\u00efve solutions are exponential in $q + d$. The fastest current heuristic has complexity $O(d^2)$. This paper outlines ASSIST (Approximate Swarming Subgraph Isomorphism through Stigmergy), inspired by the ant colony optimization approach to the traveling salesperson. After peering (identifying matching individual nodes in query and data) in time $O(q\\cdot log(d))$, the time required for ASSIST's iterative subgraph search, the combinatorially complex part of the problem, is linear in query size and constant in data size. ASSIST can be extended to support matching problems (such as temporally ordered edges, inexact matches, and missing nodes or edges in the data graph) that frustrate other heuristics.", "AI": {"tldr": "ASSIST\u662f\u4e00\u79cd\u53d7\u8681\u7fa4\u4f18\u5316\u542f\u53d1\u7684\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u6700\u5927\u90e8\u5206\u5b50\u56fe\u540c\u6784\u95ee\u9898\uff0c\u5176\u65f6\u95f4\u590d\u6742\u5ea6\u5728\u67e5\u8be2\u56fe\u89c4\u6a21\u4e0a\u7ebf\u6027\u3001\u6570\u636e\u56fe\u89c4\u6a21\u4e0a\u6052\u5b9a\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u6700\u5927\u90e8\u5206\u5b50\u56fe\u540c\u6784\u95ee\u9898\u65f6\u8ba1\u7b97\u590d\u6742\u5ea6\u8fc7\u9ad8\uff0c\u5c24\u5176\u5f53\u56fe\u89c4\u6a21\u589e\u5927\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "method": "\u63d0\u51faASSIST\u7b97\u6cd5\uff0c\u5148\u901a\u8fc7\u8282\u70b9\u5339\u914d\uff08peering\uff09\u9884\u5904\u7406\uff0c\u518d\u5229\u7528\u7c7b\u4f3c\u8681\u7fa4\u4f18\u5316\u7684\u8fed\u4ee3\u673a\u5236\u8fdb\u884c\u5b50\u56fe\u641c\u7d22\uff0c\u652f\u6301\u7075\u6d3b\u5339\u914d\u573a\u666f\u3002", "result": "ASSIST\u5728\u67e5\u8be2\u9636\u6bb5\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(q\u00b7log(d))\uff0c\u4e3b\u641c\u7d22\u9636\u6bb5\u590d\u6742\u5ea6\u4e3a\u7ebf\u6027\u4e8e\u67e5\u8be2\u56fe\u5927\u5c0f\u3001\u4e0e\u6570\u636e\u56fe\u5927\u5c0f\u65e0\u5173\uff0c\u4f18\u4e8e\u73b0\u6709O(d\u00b2)\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "conclusion": "ASSIST\u4e0d\u4ec5\u6548\u7387\u66f4\u9ad8\uff0c\u8fd8\u53ef\u6269\u5c55\u652f\u6301\u65f6\u5e8f\u8fb9\u3001\u6a21\u7cca\u5339\u914d\u548c\u7f3a\u5931\u8282\u70b9/\u8fb9\u7b49\u590d\u6742\u5339\u914d\u9700\u6c42\uff0c\u5177\u6709\u8f83\u5f3a\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.02526", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.02526", "abs": "https://arxiv.org/abs/2601.02526", "authors": ["P\u00e9ter Moln\u00e1r"], "title": "Modellierung und Simulation der Dynamik von Fussg\u00e4ngerstr\u00f6men", "comment": "In german language. Submitted as doctoral dissertation at the University of Stuttgart", "summary": "This work presents a microscopic model to describe pedestrian flows based on the social force theory. The aim of this study is twofold: (1) developing a realistic model that can be used as a tool for designing pedestrian-friendly infrastructure, and (2) verifying a social science theory using a model with sufficient data. The investigation of the pedestrian model shows that despite simple individual behavior patterns, complex spatial and temporal structures emerge through the interactions in pedestrian flows. Collective behavior emerges from individuals following two basic rules: (1) moving directly towards their goal at a certain speed, and (2) maintaining a distance to other pedestrians and obstacles. This self-organized collective behavior manifests itself as trails that are formed by pedestrians moving in one direction. Furthermore, strong dependencies of the properties of pedestrian flows on geometric forms of buildings are shown, and the influence of geometric changes on performance characteristics is investigated. An example demonstrates how efficiency can be increased by reducing walkable areas. This work also presents an evolutionary algorithm for optimizing building layouts based on the social force model. Additionally, a decision-making model is integrated to describe alternative goal selection, and adaptation and learning capabilities are included to improve pedestrian avoidance behavior and decision strategies based on accumulated experience. A method for determining load distributions in individual sections of a path system considering subjective selection criteria is also developed. Finally, a model that describes the self-organization of path systems with minimal detours is presented, similar to natural transport networks where total length and material costs are optimized.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u793e\u4f1a\u529b\u7406\u8bba\u6784\u5efa\u884c\u4eba\u6d41\u5fae\u89c2\u6a21\u578b\uff0c\u7528\u4e8e\u57fa\u7840\u8bbe\u65bd\u8bbe\u8ba1\u4e0e\u793e\u4f1a\u5b66\u7406\u8bba\u9a8c\u8bc1\uff0c\u63ed\u793a\u4e86\u4e2a\u4f53\u7b80\u5355\u884c\u4e3a\u5982\u4f55\u81ea\u7ec4\u7ec7\u5f62\u6210\u590d\u6742\u96c6\u4f53\u6a21\u5f0f\uff0c\u5e76\u63d0\u51fa\u4f18\u5316\u5efa\u7b51\u5e03\u5c40\u7684\u8fdb\u5316\u7b97\u6cd5\u3002", "motivation": "\u5f00\u53d1\u73b0\u5b9e\u53ef\u884c\u7684\u884c\u4eba\u6d41\u6a21\u578b\u4ee5\u8f85\u52a9\u884c\u4eba\u53cb\u597d\u578b\u57fa\u7840\u8bbe\u65bd\u8bbe\u8ba1\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u9a8c\u8bc1\u793e\u4f1a\u5b66\u7406\u8bba\u3002", "method": "\u91c7\u7528\u793e\u4f1a\u529b\u6a21\u578b\u63cf\u8ff0\u884c\u4eba\u884c\u4e3a\uff0c\u7ed3\u5408\u8fdb\u5316\u7b97\u6cd5\u4f18\u5316\u5efa\u7b51\u5e03\u5c40\uff0c\u96c6\u6210\u51b3\u7b56\u6a21\u578b\u4e0e\u5b66\u4e60\u673a\u5236\u6539\u8fdb\u907f\u969c\u4e0e\u8def\u5f84\u9009\u62e9\uff0c\u5e76\u5206\u6790\u8def\u5f84\u7cfb\u7edf\u8d1f\u8f7d\u5206\u5e03\u3002", "result": "\u6a21\u578b\u6210\u529f\u518d\u73b0\u81ea\u7ec4\u7ec7\u8def\u5f84\u7ed3\u6784\uff0c\u63ed\u793a\u5efa\u7b51\u51e0\u4f55\u5f62\u6001\u5bf9\u884c\u4eba\u6d41\u6027\u80fd\u7684\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u901a\u8fc7\u51cf\u5c11\u53ef\u884c\u8d70\u533a\u57df\u53cd\u800c\u63d0\u5347\u6548\u7387\uff1b\u540c\u65f6\u5b9e\u73b0\u8def\u5f84\u7cfb\u7edf\u6700\u5c0f\u7ed5\u884c\u4e0e\u6210\u672c\u4f18\u5316\u3002", "conclusion": "\u4e2a\u4f53\u9075\u5faa\u7b80\u5355\u89c4\u5219\u5373\u53ef\u6d8c\u73b0\u51fa\u590d\u6742\u7684\u96c6\u4f53\u884c\u4e3a\uff0c\u8be5\u6a21\u578b\u4e3a\u884c\u4eba\u8bbe\u65bd\u8bbe\u8ba1\u4e0e\u793e\u4f1a\u52a8\u529b\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2601.02369", "categories": ["cs.NI", "cs.CY", "cs.SI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2601.02369", "abs": "https://arxiv.org/abs/2601.02369", "authors": ["Ashlesha Hota", "Shashwat Kumar", "Daman Deep Singh", "Abolfazl Asudeh", "Palash Dey", "Abhijnan Chakraborty"], "title": "Fair Distribution of Digital Payments: Balancing Transaction Flows for Regulatory Compliance", "comment": null, "summary": "The concentration of digital payment transactions in just two UPI apps like PhonePe and Google Pay has raised concerns of duopoly in India s digital financial ecosystem. To address this, the National Payments Corporation of India (NPCI) has mandated that no single UPI app should exceed 30 percent of total transaction volume. Enforcing this cap, however, poses a significant computational challenge: how to redistribute user transactions across apps without causing widespread user inconvenience while maintaining capacity limits? In this paper, we formalize this problem as the Minimum Edge Activation Flow (MEAF) problem on a bipartite network of users and apps, where activating an edge corresponds to a new app installation. The objective is to ensure a feasible flow respecting app capacities while minimizing additional activations. We further prove that Minimum Edge Activation Flow is NP-Complete. To address the computational challenge, we propose scalable heuristics, named Decoupled Two-Stage Allocation Strategy (DTAS), that exploit flow structure and capacity reuse. Experiments on large semi-synthetic transaction network data show that DTAS finds solutions close to the optimal ILP within seconds, offering a fast and practical way to enforce transaction caps fairly and efficiently.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u7b97\u6cd5DTAS\uff0c\u7528\u4e8e\u5728\u5370\u5ea6UPI\u652f\u4ed8\u7cfb\u7edf\u4e2d\u516c\u5e73\u5206\u914d\u4ea4\u6613\u91cf\uff0c\u4ee5\u907f\u514d\u53cc\u5934\u5784\u65ad\u5e76\u6ee1\u8db330%\u4ea4\u6613\u4e0a\u9650\u8981\u6c42\u3002", "motivation": "\u89e3\u51b3\u5370\u5ea6\u6570\u5b57\u652f\u4ed8\u5e02\u573a\u7531PhonePe\u548cGoogle Pay\u4e3b\u5bfc\u6240\u5f15\u53d1\u7684\u53cc\u5934\u5784\u65ad\u95ee\u9898\uff0c\u786e\u4fdd\u5355\u4e00\u5e94\u7528\u4e0d\u8d85\u8fc730%\u4ea4\u6613\u91cf\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u4e8c\u5206\u56fe\u4e0a\u7684\u6700\u5c0f\u8fb9\u6fc0\u6d3b\u6d41\uff08MEAF\uff09\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u53ef\u6269\u5c55\u542f\u53d1\u5f0f\u7b97\u6cd5DTAS\uff0c\u5229\u7528\u6d41\u91cf\u7ed3\u6784\u4e0e\u5bb9\u91cf\u590d\u7528\u673a\u5236\u6c42\u89e3\u3002", "result": "\u5728\u5927\u89c4\u6a21\u534a\u5408\u6210\u6570\u636e\u4e0a\uff0cDTAS\u80fd\u5728\u6570\u79d2\u5185\u903c\u8fd1\u6700\u4f18ILP\u89e3\uff0c\u5b9e\u73b0\u5feb\u901f\u3001\u516c\u5e73\u3001\u9ad8\u6548\u7684\u4ea4\u6613\u5206\u914d\u3002", "conclusion": "DTAS\u4e3a\u76d1\u7ba1\u673a\u6784\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u5de5\u5177\uff0c\u53ef\u5728\u6700\u5c0f\u7528\u6237\u5e72\u6270\u4e0b\u5f3a\u5236\u6267\u884c\u4ea4\u6613\u4e0a\u9650\uff0c\u4fc3\u8fdb\u652f\u4ed8\u751f\u6001\u591a\u6837\u6027\u3002"}}
{"id": "2601.02898", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.02898", "abs": "https://arxiv.org/abs/2601.02898", "authors": ["Wim Vanderbauwhede", "Lauritz Thamsen", "Jos\u00e9 Cano"], "title": "Proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024)", "comment": "arXiv overlay proceedings for LOCO 2024. Living index of papers submitted individually", "summary": "This is the proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024).", "AI": {"tldr": "\u8fd9\u662f\u9996\u5c4a\u4f4e\u78b3\u8ba1\u7b97\u56fd\u9645\u7814\u8ba8\u4f1a\uff08LOCO 2024\uff09\u7684\u4f1a\u8bae\u8bba\u6587\u96c6\u3002", "motivation": "\u63a8\u52a8\u4f4e\u78b3\u8ba1\u7b97\u9886\u57df\u7684\u7814\u7a76\u4e0e\u4ea4\u6d41\u3002", "method": "\u901a\u8fc7\u4e3e\u529e\u56fd\u9645\u7814\u8ba8\u4f1a\u6c47\u96c6\u76f8\u5173\u7814\u7a76\u6210\u679c\u3002", "result": "\u5448\u73b0\u4e86\u4f4e\u78b3\u8ba1\u7b97\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\u4e0e\u8ba8\u8bba\u3002", "conclusion": "\u4e3a\u672a\u6765\u4f4e\u78b3\u8ba1\u7b97\u6280\u672f\u53d1\u5c55\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2601.02399", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02399", "abs": "https://arxiv.org/abs/2601.02399", "authors": ["Jiaxin Ai", "Yukang Feng", "Fanrui Zhang", "Jianwen Sun", "Zizhen Li", "Chuanhao Li", "Yifan Chang", "Wenxiao Wu", "Ruoxi Wang", "Mingliang Zhai", "Kaipeng Zhang"], "title": "ProSoftArena: Benchmarking Hierarchical Capabilities of Multimodal Agents in Professional Software Environments", "comment": null, "summary": "Multimodal agents are making rapid progress on general computer-use tasks, yet existing benchmarks remain largely confined to browsers and basic desktop applications, falling short in professional software workflows that dominate real-world scientific and industrial practice. To close this gap, we introduce ProSoftArena, a benchmark and platform specifically for evaluating multimodal agents in professional software environments. We establish the first capability hierarchy tailored to agent use of professional software and construct a benchmark of 436 realistic work and research tasks spanning 6 disciplines and 13 core professional applications. To ensure reliable and reproducible assessment, we build an executable real-computer environment with an execution-based evaluation framework and uniquely incorporate a human-in-the-loop evaluation paradigm. Extensive experiments show that even the best-performing agent attains only a 24.4\\% success rate on L2 tasks and completely fails on L3 multi-software workflow. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents in professional software settings. This project is available at: https://prosoftarena.github.io.", "AI": {"tldr": "ProSoftArena\u662f\u4e00\u4e2a\u4e13\u4e3a\u8bc4\u4f30\u591a\u6a21\u6001\u667a\u80fd\u4f53\u5728\u4e13\u4e1a\u8f6f\u4ef6\u73af\u5883\u4e2d\u8868\u73b0\u800c\u8bbe\u8ba1\u7684\u57fa\u51c6\u548c\u5e73\u53f0\uff0c\u6db5\u76d66\u4e2a\u5b66\u79d1\u300113\u4e2a\u6838\u5fc3\u5e94\u7528\u7684436\u9879\u771f\u5b9e\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u4eba\u673a\u534f\u540c\u8bc4\u4f30\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5c40\u9650\u4e8e\u6d4f\u89c8\u5668\u548c\u57fa\u7840\u684c\u9762\u5e94\u7528\uff0c\u65e0\u6cd5\u8986\u76d6\u79d1\u7814\u4e0e\u5de5\u4e1a\u4e2d\u4e3b\u6d41\u7684\u4e13\u4e1a\u8f6f\u4ef6\u5de5\u4f5c\u6d41\uff0c\u4e9f\u9700\u66f4\u8d34\u8fd1\u5b9e\u9645\u573a\u666f\u7684\u8bc4\u4f30\u4f53\u7cfb\u3002", "method": "\u6784\u5efa\u9996\u4e2a\u9762\u5411\u4e13\u4e1a\u8f6f\u4ef6\u4f7f\u7528\u7684\u667a\u80fd\u4f53\u80fd\u529b\u5c42\u7ea7\uff0c\u642d\u5efa\u53ef\u6267\u884c\u7684\u771f\u5b9e\u8ba1\u7b97\u673a\u73af\u5883\u4e0e\u57fa\u4e8e\u6267\u884c\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u7ed3\u5408\u4eba\u5de5\u53c2\u4e0e\u8bc4\u4f30\u3002", "result": "\u5f53\u524d\u6700\u4f18\u667a\u80fd\u4f53\u5728L2\u4efb\u52a1\u4e0a\u4ec5\u8fbe24.4%\u6210\u529f\u7387\uff0c\u5728L3\u591a\u8f6f\u4ef6\u5de5\u4f5c\u6d41\u4efb\u52a1\u4e2d\u5b8c\u5168\u5931\u8d25\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u591a\u6a21\u6001\u667a\u80fd\u4f53\u5728\u4e13\u4e1a\u8f6f\u4ef6\u73af\u5883\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u66f4\u9ad8\u6548\u7684\u8bbe\u8ba1\u539f\u5219\u4e0e\u80fd\u529b\u63d0\u5347\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2601.02410", "categories": ["cs.SE", "cs.AI", "cs.CY", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.02410", "abs": "https://arxiv.org/abs/2601.02410", "authors": ["Aizierjiang Aiersilan"], "title": "The Vibe-Check Protocol: Quantifying Cognitive Offloading in AI Programming", "comment": null, "summary": "The integration of Large Language Models (LLMs) into software engineering education has driven the emergence of ``Vibe Coding,'' a paradigm where developers articulate high-level intent through natural language and delegate implementation to AI agents. While proponents argue this approach modernizes pedagogy by emphasizing conceptual design over syntactic memorization, accumulating empirical evidence raises concerns regarding skill retention and deep conceptual understanding. This paper proposes a theoretical framework to investigate the research question: \\textit{Is Vibe Coding a better way to learn software engineering?} We posit a divergence in student outcomes between those leveraging AI for acceleration versus those using it for cognitive offloading. To evaluate these educational trade-offs, we propose the \\textbf{Vibe-Check Protocol (VCP)}, a systematic benchmarking framework incorporating three quantitative metrics: the \\textit{Cold Start Refactor} ($M_{CSR}$) for modeling skill decay; \\textit{Hallucination Trap Detection} ($M_{HT}$) based on signal detection theory to evaluate error identification; and the \\textit{Explainability Gap} ($E_{gap}$) for quantifying the divergence between code complexity and conceptual comprehension. Through controlled comparisons, VCP aims to provide a quantitative basis for educators to determine the optimal pedagogical boundary: identifying contexts where Vibe Coding fosters genuine mastery and contexts where it introduces hidden technical debt and superficial competence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVibe-Check Protocol\u6846\u67b6\uff0c\u7528\u4ee5\u8bc4\u4f30\u2018Vibe Coding\u2019\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u4e2d\u7684\u6210\u6548\u4e0e\u98ce\u9669\u3002", "motivation": "\u63a2\u8ba8AI\u8f85\u52a9\u7f16\u7a0b\u6559\u5b66\u662f\u5426\u771f\u6b63\u63d0\u5347\u5b66\u751f\u80fd\u529b\uff0c\u6216\u4ec5\u5bfc\u81f4\u8868\u9762\u638c\u63e1\u4e0e\u6280\u80fd\u9000\u5316\u3002", "method": "\u8bbe\u8ba1\u5305\u542b\u4e09\u9879\u91cf\u5316\u6307\u6807\u7684\u57fa\u51c6\u6846\u67b6\uff1a\u51b7\u542f\u52a8\u91cd\u6784\u3001\u5e7b\u89c9\u9677\u9631\u68c0\u6d4b\u3001\u53ef\u89e3\u91ca\u6027\u5dee\u8ddd\u3002", "result": "\u8be5\u6846\u67b6\u53ef\u5e2e\u52a9\u6559\u80b2\u8005\u533a\u5206AI\u52a0\u901f\u5b66\u4e60\u4e0e\u8ba4\u77e5\u5916\u5305\u7684\u4e0d\u540c\u5f71\u54cd\uff0c\u4ece\u800c\u8bbe\u5b9a\u5408\u7406\u6559\u5b66\u8fb9\u754c\u3002", "conclusion": "Vibe Coding\u5728\u7279\u5b9a\u60c5\u5883\u4e0b\u6709\u76ca\uff0c\u4f46\u9700\u8b66\u60d5\u5176\u53ef\u80fd\u5e26\u6765\u7684\u6280\u672f\u503a\u4e0e\u6d45\u5c42\u80fd\u529b\u5047\u8c61\u3002"}}
{"id": "2601.02421", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02421", "abs": "https://arxiv.org/abs/2601.02421", "authors": ["Nyan Lin Zaw"], "title": "Talks that Builds: Exploring Communication factors for the Success of Emerging Professional in Product Teams", "comment": "26 pages, 0 figure. Mixed-methods study examining factors contributing to successful product design teams with emerging professionals. Submitted to Southern States Communication Association", "summary": "This paper recognizes that most organizational communication study focuses on established professionals aged above 27 with more than five years of experience. In contrast, this study examines product teams with younger emerging professionals aged 18-27 and explores which factors influence their success. While some established factors still apply, others become less relevant, and new ones such as curiosity, locational proximity, documentation, access to resources were identified in the study. Overall, this study fills a gap in the literature on how these newer factors shape team productivity and project outcomes based on the success rate of the product the team developed.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u5f71\u54cd18-27\u5c81\u65b0\u5174\u804c\u573a\u4eba\u58eb\u4ea7\u54c1\u56e2\u961f\u6210\u529f\u7684\u5173\u952e\u56e0\u7d20\uff0c\u586b\u8865\u73b0\u6709\u6587\u732e\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u7ec4\u7ec7\u6c9f\u901a\u7814\u7a76\u591a\u805a\u7126\u8d44\u6df1\u4e13\u4e1a\u4eba\u58eb\uff0c\u5ffd\u7565\u5e74\u8f7b\u7fa4\u4f53\u7684\u7279\u6b8a\u6027\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u8bc6\u522b\u5bf9\u5e74\u8f7b\u56e2\u961f\u66f4\u5177\u5f71\u54cd\u529b\u7684\u65b0\u56e0\u7d20\uff0c\u5982\u597d\u5947\u5fc3\u3001\u5730\u7406\u4f4d\u7f6e\u90bb\u8fd1\u6027\u3001\u6587\u6863\u548c\u8d44\u6e90\u83b7\u53d6\u7b49\u3002", "result": "\u53d1\u73b0\u90e8\u5206\u4f20\u7edf\u56e0\u7d20\u76f8\u5173\u6027\u964d\u4f4e\uff0c\u800c\u65b0\u56e0\u7d20\u663e\u8457\u5f71\u54cd\u56e2\u961f\u751f\u4ea7\u529b\u4e0e\u9879\u76ee\u6210\u679c\u6210\u529f\u7387\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u65b0\u5174\u804c\u573a\u4eba\u7fa4\u56e2\u961f\u6210\u529f\u7684\u72ec\u7279\u9a71\u52a8\u56e0\u7d20\uff0c\u4e3a\u7ba1\u7406\u5b9e\u8df5\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002"}}
{"id": "2601.02382", "categories": ["cs.NI", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.02382", "abs": "https://arxiv.org/abs/2601.02382", "authors": ["Nathan Conger", "Nathan Scollar", "Kemal Davaslioglu", "Yalin E. Sagduyu", "Sastry Kompella"], "title": "How to Discover Knowledge for FutureG: Contextual RAG and LLM Prompting for O-RAN", "comment": null, "summary": "We present a retrieval-augmented question answering framework for 5G/6G networks, where the Open Radio Access Network (O-RAN) has become central to disaggregated, virtualized, and AI-driven wireless systems. While O-RAN enables multi-vendor interoperability and cloud-native deployments, its fast-changing specifications and interfaces pose major challenges for researchers and practitioners. Manual navigation of these complex documents is labor-intensive and error-prone, slowing system design, integration, and deployment. To address this challenge, we adopt Contextual Retrieval-Augmented Generation (Contextual RAG), a strategy in which candidate answer choices guide document retrieval and chunk-specific context to improve large language model (LLM) performance. This improvement over traditional RAG achieves more targeted and context-aware retrieval, which improves the relevance of documents passed to the LLM, particularly when the query alone lacks sufficient context for accurate grounding. Our framework is designed for dynamic domains where data evolves rapidly and models must be continuously updated or redeployed, all without requiring LLM fine-tuning. We evaluate this framework using the ORANBenchmark-13K dataset, and compare three LLMs, namely, Llama3.2, Qwen2.5-7B, and Qwen3.0-4B, across both Direct Question Answering (Direct Q&A) and Chain-of-Thought (CoT) prompting strategies. We show that Contextual RAG consistently improves accuracy over standard RAG and base prompting, while maintaining competitive runtime and CO2 emissions. These results highlight the potential of Contextual RAG to serve as a scalable and effective solution for domain-specific Q&A in ORAN and broader 5G/6G environments, enabling more accurate interpretation of evolving standards while preserving efficiency and sustainability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e0a\u4e0b\u6587\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08Contextual RAG\uff09\u7684\u95ee\u7b54\u6846\u67b6\uff0c\u7528\u4e8e\u5e94\u5bf9O-RAN\u6807\u51c6\u5feb\u901f\u6f14\u8fdb\u5e26\u6765\u7684\u4fe1\u606f\u68c0\u7d22\u6311\u6218\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u57285G/6G\u9886\u57df\u95ee\u7b54\u51c6\u786e\u7387\u3002", "motivation": "O-RAN\u89c4\u8303\u590d\u6742\u4e14\u9891\u7e41\u66f4\u65b0\uff0c\u4eba\u5de5\u67e5\u9605\u6548\u7387\u4f4e\u3001\u6613\u51fa\u9519\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u3001\u7cbe\u51c6\u5316\u7684\u95ee\u7b54\u652f\u6301\u5de5\u5177\u3002", "method": "\u91c7\u7528Contextual RAG\u65b9\u6cd5\uff0c\u5229\u7528\u5019\u9009\u7b54\u6848\u5f15\u5bfc\u6587\u6863\u68c0\u7d22\u4e0e\u4e0a\u4e0b\u6587\u5207\u7247\uff0c\u589e\u5f3aLLM\u5bf9\u67e5\u8be2\u7684\u7406\u89e3\u4e0e\u7b54\u6848\u751f\u6210\u80fd\u529b\uff0c\u65e0\u9700\u5fae\u8c03\u6a21\u578b\u3002", "result": "\u5728ORANBenchmark-13K\u6570\u636e\u96c6\u4e0a\uff0cContextual RAG\u76f8\u6bd4\u4f20\u7edfRAG\u548c\u57fa\u7840\u63d0\u793a\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u8fd0\u884c\u6548\u7387\u4e0e\u4f4e\u78b3\u6392\u653e\u3002", "conclusion": "Contextual RAG\u662f\u9762\u5411\u52a8\u6001\u6f14\u8fdb\u9886\u57df\u7684\u9ad8\u6548\u3001\u53ef\u6301\u7eed\u95ee\u7b54\u65b9\u6848\uff0c\u9002\u7528\u4e8eO-RAN\u53ca\u66f4\u5e7f\u6cdb\u76845G/6G\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2601.02430", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02430", "abs": "https://arxiv.org/abs/2601.02430", "authors": ["Chenxu Liu", "Yingjie Fu", "Wei Yang", "Ying Zhang", "Tao Xie"], "title": "WebCoderBench: Benchmarking Web Application Generation with Comprehensive and Interpretable Evaluation Metrics", "comment": null, "summary": "Web applications (web apps) have become a key arena for large language models (LLMs) to demonstrate their code generation capabilities and commercial potential. However, building a benchmark for LLM-generated web apps remains challenging due to the need for real-world user requirements, generalizable evaluation metrics without relying on ground-truth implementations or test cases, and interpretable evaluation results. To address these challenges, we introduce WebCoderBench, the first real-world-collected, generalizable, and interpretable benchmark for web app generation. WebCoderBench comprises 1,572 real user requirements, covering diverse modalities and expression styles that reflect realistic user intentions. WebCoderBench provides 24 fine-grained evaluation metrics across 9 perspectives, combining rule-based and LLM-as-a-judge paradigm for fully automated, objective, and general evaluation. Moreover, WebCoderBench adopts human-preference-aligned weights over metrics to yield interpretable overall scores. Experiments across 12 representative LLMs and 2 LLM-based agents show that there exists no dominant model across all evaluation metrics, offering an opportunity for LLM developers to optimize their models in a targeted manner for a more powerful version.", "AI": {"tldr": "WebCoderBench\u662f\u9996\u4e2a\u9762\u5411\u771f\u5b9e\u7528\u6237\u9700\u6c42\u3001\u53ef\u6cdb\u5316\u4e14\u53ef\u89e3\u91ca\u7684\u7f51\u9875\u5e94\u7528\u751f\u6210\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5305\u542b1572\u4e2a\u771f\u5b9e\u9700\u6c42\u4e0e24\u9879\u7ec6\u7c92\u5ea6\u6307\u6807\uff0c\u652f\u6301\u81ea\u52a8\u5316\u8bc4\u4f30\u5e76\u6307\u5bfcLLM\u9488\u5bf9\u6027\u4f18\u5316\u3002", "motivation": "\u73b0\u6709LLM\u751f\u6210\u7f51\u9875\u5e94\u7528\u7f3a\u4e4f\u771f\u5b9e\u9700\u6c42\u9a71\u52a8\u3001\u65e0\u9700\u4f9d\u8d56\u53c2\u8003\u5b9e\u73b0\u7684\u901a\u7528\u8bc4\u4f30\u4f53\u7cfb\uff0c\u4e9f\u9700\u6784\u5efa\u66f4\u8d34\u8fd1\u73b0\u5b9e\u3001\u53ef\u89e3\u91ca\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u5305\u542b1572\u6761\u771f\u5b9e\u7528\u6237\u9700\u6c42\u7684\u6570\u636e\u96c6\uff0c\u8bbe\u8ba19\u7ef4\u5ea624\u9879\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6307\u6807\uff0c\u7ed3\u5408\u89c4\u5219\u4e0eLLM-as-judge\u65b9\u6cd5\u5b9e\u73b0\u81ea\u52a8\u5316\u8bc4\u4f30\uff0c\u5e76\u91c7\u7528\u4eba\u7c7b\u504f\u597d\u52a0\u6743\u5f97\u51fa\u7efc\u5408\u8bc4\u5206\u3002", "result": "\u572812\u4e2a\u4e3b\u6d41LLM\u548c2\u4e2a\u667a\u80fd\u4f53\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5c1a\u65e0\u6a21\u578b\u5728\u6240\u6709\u6307\u6807\u4e0a\u5360\u4f18\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u9488\u5bf9\u6027\u4f18\u5316\u7a7a\u95f4\u3002", "conclusion": "WebCoderBench\u586b\u8865\u4e86LLM\u7f51\u9875\u751f\u6210\u9886\u57df\u8bc4\u6d4b\u7a7a\u767d\uff0c\u63a8\u52a8\u6a21\u578b\u5411\u66f4\u5b9e\u7528\u3001\u66f4\u53ef\u63a7\u65b9\u5411\u6f14\u8fdb\u3002"}}
{"id": "2601.02438", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02438", "abs": "https://arxiv.org/abs/2601.02438", "authors": ["Yun Bian", "Yi Chen", "HaiQuan Wang", "ShiHao Li", "Zhe Cui"], "title": "Focus on What Matters: Fisher-Guided Adaptive Multimodal Fusion for Vulnerability Detection", "comment": null, "summary": "Software vulnerability detection is a critical task for securing software systems and can be formulated as a binary classification problem: given a code snippet, determine whether it contains a vulnerability. Existing multimodal approaches typically fuse Natural Code Sequence (NCS) representations from pretrained language models with Code Property Graph (CPG) representations from graph neural networks, often under the implicit assumption that adding a modality necessarily yields extra information. In practice, sequence and graph representations can be redundant, and fluctuations in the quality of the graph modality can dilute the discriminative signal of the dominant modality. To address this, we propose TaCCS-DFA, a framework that introduces Fisher information as a geometric measure of how sensitive feature directions are to the classification decision, enabling task-oriented complementary fusion. TaCCS-DFA online estimates a low-rank principal Fisher subspace and restricts cross-modal attention to task-sensitive directions, thereby retrieving structural features from CPG that complement the sequence modality; meanwhile, an adaptive gating mechanism dynamically adjusts the contribution of the graph modality for each sample to suppress noise propagation. Our analysis shows that, under an isotropic perturbation assumption, the proposed mechanism admits a tighter risk bound than conventional full-spectrum attention. Experiments on BigVul, Devign, and ReVeal show that TaCCS-DFA achieves strong performance across multiple backbones. With CodeT5 as the backbone, TaCCS-DFA reaches an F1 score of 87.80\\% on the highly imbalanced BigVul dataset, improving over a strong baseline Vul-LMGNNs by 6.3 percentage points while maintaining low calibration error and computational overhead.", "AI": {"tldr": "TaCCS-DFA \u63d0\u51fa\u57fa\u4e8e Fisher \u4fe1\u606f\u7684\u4e92\u8865\u878d\u5408\u6846\u67b6\uff0c\u4f18\u5316\u591a\u6a21\u6001\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u591a\u6a21\u6001\u5fc5\u7136\u589e\u76ca\uff0c\u4f46\u5e8f\u5217\u4e0e\u56fe\u8868\u793a\u5e38\u5197\u4f59\uff0c\u56fe\u8d28\u91cf\u6ce2\u52a8\u4f1a\u524a\u5f31\u4e3b\u6a21\u6001\u5224\u522b\u529b\u3002", "method": "\u5728\u7ebf\u4f30\u8ba1\u4f4e\u79e9 Fisher \u5b50\u7a7a\u95f4\uff0c\u9650\u5236\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u81f3\u4efb\u52a1\u654f\u611f\u65b9\u5411\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u95e8\u63a7\u6291\u5236\u566a\u58f0\u4f20\u64ad\u3002", "result": "\u5728 BigVul\u3001Devign \u548c ReVeal \u4e0a\u8868\u73b0\u4f18\u5f02\uff0cCodeT5 \u9aa8\u5e72\u4e0b F1 \u8fbe 87.80%\uff0c\u8f83\u57fa\u7ebf\u63d0\u5347 6.3%\u3002", "conclusion": "TaCCS-DFA \u5b9e\u73b0\u66f4\u7d27\u98ce\u9669\u754c\uff0c\u5728\u4fdd\u6301\u4f4e\u6821\u51c6\u8bef\u5dee\u4e0e\u8ba1\u7b97\u5f00\u9500\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u7cbe\u5ea6\u3002"}}
{"id": "2601.02454", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02454", "abs": "https://arxiv.org/abs/2601.02454", "authors": ["Saba Naqvi", "Mohammad Baqar", "Nawaz Ali Mohammad"], "title": "The Rise of Agentic Testing: Multi-Agent Systems for Robust Software Quality Assurance", "comment": "11 Pages", "summary": "Software testing has progressed toward intelligent automation, yet current AI-based test generators still suffer from static, single-shot outputs that frequently produce invalid, redundant, or non-executable tests due to the lack of execution aware feedback. This paper introduces an agentic multi-model testing framework a closed-loop, self-correcting system in which a Test Generation Agent, an Execution and Analysis Agent, and a Review and Optimization Agent collaboratively generate, execute, analyze, and refine tests until convergence. By using sandboxed execution, detailed failure reporting, and iterative regeneration or patching of failing tests, the framework autonomously improves test quality and expands coverage. Integrated into a CI/CD-compatible pipeline, it leverages reinforcement signals from coverage metrics and execution outcomes to guide refinement. Empirical evaluations on microservice based applications show up to a 60% reduction in invalid tests, 30% coverage improvement, and significantly reduced human effort compared to single-model baselines demonstrating that multi-agent, feedback-driven loops can evolve software testing into an autonomous, continuously learning quality assurance ecosystem for self-healing, high-reliability codebases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u95ed\u73af\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u6267\u884c\u53cd\u9988\u81ea\u4e3b\u4f18\u5316\u6d4b\u8bd5\u7528\u4f8b\uff0c\u663e\u8457\u63d0\u5347\u8986\u76d6\u7387\u5e76\u51cf\u5c11\u65e0\u6548\u6d4b\u8bd5\u3002", "motivation": "\u5f53\u524dAI\u6d4b\u8bd5\u751f\u6210\u5668\u7f3a\u4e4f\u6267\u884c\u53cd\u9988\uff0c\u5bfc\u81f4\u6d4b\u8bd5\u65e0\u6548\u6216\u5197\u4f59\uff0c\u9700\u6784\u5efa\u81ea\u4fee\u6b63\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u7cfb\u7edf\u3002", "method": "\u8bbe\u8ba1\u4e09\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff08\u751f\u6210\u3001\u6267\u884c\u5206\u6790\u3001\u8bc4\u5ba1\u4f18\u5316\uff09\uff0c\u7ed3\u5408\u6c99\u7bb1\u6267\u884c\u3001\u5931\u8d25\u62a5\u544a\u4e0e\u8fed\u4ee3\u4fee\u590d\u673a\u5236\uff0c\u96c6\u6210CI/CD\u7ba1\u9053\u5e76\u5229\u7528\u8986\u76d6\u7387\u6307\u6807\u5f3a\u5316\u5b66\u4e60\u5f15\u5bfc\u4f18\u5316\u3002", "result": "\u5728\u5fae\u670d\u52a1\u5e94\u7528\u4e2d\u5b9e\u73b0\u65e0\u6548\u6d4b\u8bd5\u51cf\u5c1160%\u3001\u8986\u76d6\u7387\u63d0\u534730%\uff0c\u5927\u5e45\u964d\u4f4e\u4eba\u5de5\u5e72\u9884\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u53cd\u9988\u9a71\u52a8\u673a\u5236\u53ef\u63a8\u52a8\u8f6f\u4ef6\u6d4b\u8bd5\u5411\u81ea\u4e3b\u6301\u7eed\u5b66\u4e60\u7684\u8d28\u91cf\u4fdd\u969c\u751f\u6001\u6f14\u8fdb\uff0c\u652f\u6491\u9ad8\u53ef\u9760\u4ee3\u7801\u5e93\u3002"}}
{"id": "2601.02504", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.02504", "abs": "https://arxiv.org/abs/2601.02504", "authors": ["Elizaveta Artser", "Daniil Karol", "Anna Potriasaeva", "Aleksei Rostovskii", "Katsiaryna Dzialets", "Ekaterina Koshchenko", "Xiaotian Su", "April Yi Wang", "Anastasiia Birillo"], "title": "Enhancing Debugging Skills with AI-Powered Assistance: A Real-Time Tool for Debugging Support", "comment": "Accepted at ICSE SEET 2026, 6 pages, 2 figures", "summary": "Debugging is a crucial skill in programming education and software development, yet it is often overlooked in CS curricula. To address this, we introduce an AI-powered debugging assistant integrated into an IDE. It offers real-time support by analyzing code, suggesting breakpoints, and providing contextual hints. Using RAG with LLMs, program slicing, and custom heuristics, it enhances efficiency by minimizing LLM calls and improving accuracy. A three-level evaluation - technical analysis, UX study, and classroom tests - highlights its potential for teaching debugging.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u96c6\u6210\u4e8eIDE\u7684AI\u8c03\u8bd5\u52a9\u624b\uff0c\u901a\u8fc7RAG\u3001\u7a0b\u5e8f\u5207\u7247\u4e0e\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u5347\u8c03\u8bd5\u6559\u5b66\u6548\u7387\u3002", "motivation": "\u8c03\u8bd5\u6280\u80fd\u5728\u7f16\u7a0b\u6559\u80b2\u4e2d\u5e38\u88ab\u5ffd\u89c6\uff0c\u9700\u501f\u52a9AI\u5de5\u5177\u589e\u5f3a\u5b66\u4e60\u4f53\u9a8c\u3002", "method": "\u7ed3\u5408RAG\u3001\u5927\u8bed\u8a00\u6a21\u578b\u3001\u7a0b\u5e8f\u5207\u7247\u4e0e\u81ea\u5b9a\u4e49\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u51cf\u5c11LLM\u8c03\u7528\u5e76\u63d0\u9ad8\u51c6\u786e\u6027\u3002", "result": "\u4e09\u5c42\u6b21\u8bc4\u4f30\uff08\u6280\u672f\u5206\u6790\u3001\u7528\u6237\u4f53\u9a8c\u3001\u8bfe\u5802\u6d4b\u8bd5\uff09\u9a8c\u8bc1\u5176\u6559\u5b66\u6f5c\u529b\u3002", "conclusion": "\u8be5\u5de5\u5177\u80fd\u6709\u6548\u8f85\u52a9\u8c03\u8bd5\u6559\u5b66\uff0c\u503c\u5f97\u5728\u7f16\u7a0b\u8bfe\u7a0b\u4e2d\u63a8\u5e7f\u3002"}}
{"id": "2601.02512", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02512", "abs": "https://arxiv.org/abs/2601.02512", "authors": ["Pelin Rabia Kuran", "Rumbidzai Chitakunye", "Vincenzo Stoico", "Ilja Heitlager", "Justus Bogner"], "title": "Green LLM Techniques in Action: How Effective Are Existing Techniques for Improving the Energy Efficiency of LLM-Based Applications in Industry?", "comment": "Accepted for publication at the 2026 International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP'26)", "summary": "The rapid adoption of large language models (LLMs) has raised concerns about their substantial energy consumption, especially when deployed at industry scale. While several techniques have been proposed to address this, limited empirical evidence exists regarding the effectiveness of applying them to LLM-based industry applications. To fill this gap, we analyzed a chatbot application in an industrial context at Schuberg Philis, a Dutch IT services company. We then selected four techniques, namely Small and Large Model Collaboration, Prompt Optimization, Quantization, and Batching, applied them to the application in eight variations, and then conducted experiments to study their impact on energy consumption, accuracy, and response time compared to the unoptimized baseline.\n  Our results show that several techniques, such as Prompt Optimization and 2-bit Quantization, managed to reduce energy use significantly, sometimes by up to 90%. However, these techniques especially impacted accuracy negatively, to a degree that is not acceptable in practice. The only technique that achieved significant and strong energy reductions without harming the other qualities substantially was Small and Large Model Collaboration via Nvidia's Prompt Task and Complexity Classifier (NPCC) with prompt complexity thresholds. This highlights that reducing the energy consumption of LLM-based applications is not difficult in practice. However, improving their energy efficiency, i.e., reducing energy use without harming other qualities, remains challenging. Our study provides practical insights to move towards this goal.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5728\u5de5\u4e1a\u804a\u5929\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u6d4b\u8bd5\u56db\u79cd\u4f18\u5316\u6280\u672f\uff0c\u53d1\u73b0\u90e8\u5206\u65b9\u6cd5\u53ef\u5927\u5e45\u964d\u4f4e\u80fd\u8017\uff0c\u4f46\u5e38\u4ee5\u727a\u7272\u51c6\u786e\u6027\u4e3a\u4ee3\u4ef7\uff1b\u552f\u6709\u5c0f\u5927\u6a21\u578b\u534f\u4f5c\uff08NPCC\uff09\u5728\u663e\u8457\u8282\u80fd\u7684\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u7a33\u5b9a\u3002", "motivation": "\u5e94\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u5e26\u6765\u7684\u9ad8\u80fd\u8017\u95ee\u9898\uff0c\u586b\u8865\u5de5\u4e1a\u573a\u666f\u4e0b\u8282\u80fd\u6280\u672f\u5b9e\u8bc1\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u9009\u53d6Prompt\u4f18\u5316\u3001\u91cf\u5316\u3001\u6279\u5904\u7406\u548c\u5c0f\u5927\u6a21\u578b\u534f\u4f5c\u56db\u79cd\u6280\u672f\uff0c\u5728Schuberg Philis\u516c\u53f8\u7684\u804a\u5929\u673a\u5668\u4eba\u4e0a\u5b9e\u65bd\u516b\u79cd\u53d8\u4f53\u5b9e\u9a8c\uff0c\u5bf9\u6bd4\u57fa\u7ebf\u8bc4\u4f30\u80fd\u8017\u3001\u51c6\u786e\u7387\u4e0e\u54cd\u5e94\u65f6\u95f4\u3002", "result": "Prompt\u4f18\u5316\u4e0e2\u6bd4\u7279\u91cf\u5316\u6700\u9ad8\u8282\u80fd90%\uff0c\u4f46\u4e25\u91cd\u635f\u5bb3\u51c6\u786e\u7387\uff1b\u4ec5NPCC\u534f\u4f5c\u65b9\u6848\u5b9e\u73b0\u663e\u8457\u8282\u80fd\u4e14\u4e0d\u5f71\u54cd\u5176\u4ed6\u6307\u6807\u3002", "conclusion": "\u964d\u4f4eLLM\u5e94\u7528\u80fd\u8017\u4e0d\u96be\uff0c\u4f46\u517c\u987e\u80fd\u6548\u4e0e\u6027\u80fd\u4ecd\u5177\u6311\u6218\uff0c\u672c\u7814\u7a76\u4e3a\u5b9e\u9645\u4f18\u5316\u63d0\u4f9b\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2601.02522", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02522", "abs": "https://arxiv.org/abs/2601.02522", "authors": ["Zhinuan", "Guo", "Chushu Gao", "Justus Bogner"], "title": "On the Effectiveness of Proposed Techniques to Reduce Energy Consumption in RAG Systems: A Controlled Experiment", "comment": "Accepted for publication at the 2026 International Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS'26)", "summary": "The rising energy demands of machine learning (ML), e.g., implemented in popular variants like retrieval-augmented generation (RAG) systems, have raised significant concerns about their environmental sustainability. While previous research has proposed green tactics for ML-enabled systems, their empirical evaluation within RAG systems remains largely unexplored. This study presents a controlled experiment investigating five practical techniques aimed at reducing energy consumption in RAG systems. Using a production-like RAG system developed at our collaboration partner, the Software Improvement Group, we evaluated the impact of these techniques on energy consumption, latency, and accuracy.\n  Through a total of 9 configurations spanning over 200 hours of trials using the CRAG dataset, we reveal that techniques such as increasing similarity retrieval thresholds, reducing embedding sizes, applying vector indexing, and using a BM25S reranker can significantly reduce energy usage, up to 60% in some cases. However, several techniques also led to unacceptable accuracy decreases, e.g., by up to 30% for the indexing strategies. Notably, finding an optimal retrieval threshold and reducing embedding size substantially reduced energy consumption and latency with no loss in accuracy, making these two techniques truly energy-efficient. We present the first comprehensive, empirical study on energy-efficient design techniques for RAG systems, providing guidance for developers and researchers aiming to build sustainable RAG applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u4e94\u79cd\u964d\u4f4eRAG\u7cfb\u7edf\u80fd\u8017\u7684\u6280\u672f\uff0c\u53d1\u73b0\u8c03\u6574\u76f8\u4f3c\u5ea6\u9608\u503c\u548c\u51cf\u5c0f\u5d4c\u5165\u5c3a\u5bf8\u53ef\u5728\u4e0d\u5f71\u54cd\u51c6\u786e\u7387\u7684\u524d\u63d0\u4e0b\u663e\u8457\u8282\u80fd\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u65e5\u76ca\u589e\u957f\u7684\u80fd\u8017\u5f15\u53d1\u73af\u5883\u53ef\u6301\u7eed\u6027\u62c5\u5fe7\uff0c\u5c24\u5176\u5728RAG\u7cfb\u7edf\u4e2d\u7f3a\u4e4f\u5b9e\u8bc1\u7814\u7a76\u3002", "method": "\u5728\u5408\u4f5c\u65b9\u6784\u5efa\u7684\u7c7b\u751f\u4ea7RAG\u7cfb\u7edf\u4e0a\uff0c\u4f7f\u7528CRAG\u6570\u636e\u96c6\u8fdb\u884c200\u591a\u5c0f\u65f6\u30019\u79cd\u914d\u7f6e\u7684\u5bf9\u7167\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u6280\u672f\u5bf9\u80fd\u8017\u3001\u5ef6\u8fdf\u4e0e\u51c6\u786e\u7387\u7684\u5f71\u54cd\u3002", "result": "\u90e8\u5206\u6280\u672f\u5982\u63d0\u9ad8\u68c0\u7d22\u9608\u503c\u3001\u51cf\u5c0f\u5d4c\u5165\u5c3a\u5bf8\u3001\u5411\u91cf\u7d22\u5f15\u548cBM25S\u91cd\u6392\u5e8f\u5668\u53ef\u8282\u80fd\u9ad8\u8fbe60%\uff0c\u4f46\u67d0\u4e9b\u65b9\u6cd5\uff08\u5982\u7d22\u5f15\u7b56\u7565\uff09\u5bfc\u81f4\u51c6\u786e\u7387\u4e0b\u964d30%\uff1b\u524d\u4e24\u79cd\u6280\u672f\u5b9e\u73b0\u96f6\u7cbe\u5ea6\u635f\u5931\u4e0b\u7684\u9ad8\u6548\u8282\u80fd\u3002", "conclusion": "\u9996\u6b21\u63d0\u4f9bRAG\u7cfb\u7edf\u8282\u80fd\u8bbe\u8ba1\u7684\u5b9e\u8bc1\u6307\u5357\uff0c\u4e3a\u5f00\u53d1\u8005\u6784\u5efa\u53ef\u6301\u7eed\u5e94\u7528\u63d0\u4f9b\u5b9e\u8df5\u4f9d\u636e\u3002"}}
{"id": "2601.02559", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.02559", "abs": "https://arxiv.org/abs/2601.02559", "authors": ["Lauren Olson", "Emitz\u00e1 Guzm\u00e1n", "Florian Kunneman"], "title": "PerspectiveCoach: Exploring LLMs for Developer Reflection", "comment": "48th International Conference of Software Engineering", "summary": "Despite growing awareness of ethical challenges in software development, practitioners still lack structured tools that help them critically engage with the lived experiences of marginalized users. This paper presents PerspectiveCoach, a large language model (LLM)-powered conversational tool designed to guide developers through structured perspective-taking exercises and deepen critical reflection on how software design decisions affect marginalized communities. Through a controlled study with 18 front-end developers (balanced by sex), who interacted with the tool using a real case of online gender-based harassment, we examine how PerspectiveCoach supports ethical reasoning and engagement with user perspectives. Qualitative analysis revealed increased self-awareness, broadened perspectives, and more nuanced ethical articulation, while a complementary human-human study contextualized these findings. Text similarity analyses demonstrated that participants in the human-PerspectiveCoach study improved the fidelity of their restatements over multiple attempts, capturing both surface-level and semantic aspects of user concerns. However, human-PerspectiveCoach's restatements had a lower baseline than the human-human conversations, highlighting contextual differences in impersonal and interpersonal perspective-taking. Across the study, participants rated the tool highly for usability and relevance. This work contributes an exploratory design for LLM-powered end-user perspective-taking that supports critical, ethical self-reflection and offers empirical insights (i.e., enhancing adaptivity, centering plurality) into how such tools can help practitioners build more inclusive and socially responsive technologies.", "AI": {"tldr": "PerspectiveCoach\u662f\u4e00\u4e2a\u7531\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u5bf9\u8bdd\u5de5\u5177\uff0c\u65e8\u5728\u5e2e\u52a9\u5f00\u53d1\u8005\u901a\u8fc7\u7ed3\u6784\u5316\u89c6\u89d2\u7ec3\u4e60\uff0c\u589e\u5f3a\u5bf9\u8fb9\u7f18\u5316\u7528\u6237\u7ecf\u5386\u7684\u7406\u89e3\u4e0e\u4f26\u7406\u53cd\u601d\u3002", "motivation": "\u8f6f\u4ef6\u5f00\u53d1\u8005\u7f3a\u4e4f\u6709\u6548\u5de5\u5177\u6765\u6df1\u5165\u7406\u89e3\u8fb9\u7f18\u7fa4\u4f53\u7528\u6237\u7684\u5b9e\u9645\u4f53\u9a8c\uff0c\u4ece\u800c\u5f71\u54cd\u5305\u5bb9\u6027\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc718\u540d\u524d\u7aef\u5f00\u53d1\u8005\u53c2\u4e0e\u7684\u5bf9\u7167\u5b9e\u9a8c\uff0c\u7ed3\u5408\u771f\u5b9e\u6027\u522b\u9a9a\u6270\u6848\u4f8b\uff0c\u8bc4\u4f30PerspectiveCoach\u5728\u4fc3\u8fdb\u4f26\u7406\u63a8\u7406\u548c\u7528\u6237\u89c6\u89d2\u7406\u89e3\u65b9\u9762\u7684\u4f5c\u7528\uff0c\u5e76\u8f85\u4ee5\u4eba\u4e0e\u4eba\u5bf9\u8bdd\u7814\u7a76\u53ca\u6587\u672c\u76f8\u4f3c\u5ea6\u5206\u6790\u3002", "result": "\u5b9a\u6027\u5206\u6790\u663e\u793a\u5f00\u53d1\u8005\u81ea\u6211\u610f\u8bc6\u63d0\u5347\u3001\u89c6\u89d2\u62d3\u5bbd\u3001\u4f26\u7406\u8868\u8fbe\u66f4\u7ec6\u81f4\uff1b\u6587\u672c\u5206\u6790\u8868\u660e\u591a\u6b21\u4e92\u52a8\u540e\u590d\u8ff0\u51c6\u786e\u6027\u63d0\u9ad8\uff0c\u4f46\u57fa\u7ebf\u4f4e\u4e8e\u4eba\u9645\u5bf9\u8bdd\uff1b\u5de5\u5177\u5728\u53ef\u7528\u6027\u548c\u76f8\u5173\u6027\u4e0a\u83b7\u9ad8\u8bc4\u5206\u3002", "conclusion": "\u8be5\u5de5\u5177\u4e3a\u652f\u6301\u5f00\u53d1\u8005\u8fdb\u884c\u4f26\u7406\u81ea\u7701\u63d0\u4f9b\u4e86\u63a2\u7d22\u6027\u8bbe\u8ba1\uff0c\u5e76\u63d0\u51fa\u589e\u5f3a\u9002\u5e94\u6027\u4e0e\u591a\u5143\u4e2d\u5fc3\u5316\u7684\u5b9e\u8df5\u6d1e\u89c1\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u5177\u793e\u4f1a\u54cd\u5e94\u6027\u7684\u6280\u672f\u3002"}}
{"id": "2601.02563", "categories": ["cs.SE", "cs.CL", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.02563", "abs": "https://arxiv.org/abs/2601.02563", "authors": ["Viacheslav Siniaev", "Iaroslav Chelombitko", "Aleksey Komissarov"], "title": "Compressed code: the hidden effects of quantization and distillation on programming tokens", "comment": "18 pages, 1 figure and 6 tables", "summary": "Large Language Models (LLMs) have demonstrated exceptional code generation capabilities, yet their token-level mechanisms remain underexplored, particularly in compressed models. Through systematic analysis of programming language token representations, we characterize how programming languages are encoded in LLM tokenizers by analyzing their vocabulary distribution and keyword coverage patterns. We introduce a novel cold-start probability analysis method that provides insights into model behavior without requiring explicit prompts. Additionally, we present a comprehensive evaluation of how different model optimization techniques - including quantization, distillation, model scaling, and task-specific fine-tuning - affect token-level representations and code generation quality. Our experiments, supported by comprehensive probability distribution analysis and evaluation metrics, reveal critical insights into token-level behavior and provide empirically-validated guidelines for maintaining code generation quality under various optimization constraints. These findings advance both theoretical understanding of LLM code generation and practical implementation of optimized models in production environments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5206\u8bcd\u673a\u5236\uff0c\u5206\u6790\u4e0d\u540c\u4f18\u5316\u6280\u672f\u5bf9\u5206\u8bcd\u8868\u793a\u548c\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u51b7\u542f\u52a8\u6982\u7387\u5206\u6790\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5bf9\u538b\u7f29\u6a21\u578b\u4e2d\u7f16\u7a0b\u8bed\u8a00\u5206\u8bcd\u673a\u5236\u7684\u7406\u89e3\u5c1a\u4e0d\u5145\u5206\uff0c\u9700\u7cfb\u7edf\u6027\u63a2\u7d22\u4ee5\u6307\u5bfc\u5b9e\u9645\u4f18\u5316\u3002", "method": "\u901a\u8fc7\u8bcd\u6c47\u5206\u5e03\u4e0e\u5173\u952e\u8bcd\u8986\u76d6\u5206\u6790\u7f16\u7a0b\u8bed\u8a00\u7f16\u7801\u65b9\u5f0f\uff0c\u5f15\u5165\u51b7\u542f\u52a8\u6982\u7387\u5206\u6790\u6cd5\uff0c\u5e76\u8bc4\u4f30\u91cf\u5316\u3001\u84b8\u998f\u3001\u7f29\u653e\u4e0e\u5fae\u8c03\u7b49\u4f18\u5316\u6280\u672f\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u5206\u8bcd\u5c42\u7ea7\u884c\u4e3a\u7684\u5173\u952e\u89c4\u5f8b\uff0c\u63d0\u4f9b\u4e86\u5728\u591a\u79cd\u7ea6\u675f\u4e0b\u4fdd\u6301\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u5b9e\u8bc1\u6307\u5357\u3002", "conclusion": "\u672c\u7814\u7a76\u6df1\u5316\u4e86\u5bf9LLM\u4ee3\u7801\u751f\u6210\u673a\u7406\u7684\u7406\u8bba\u8ba4\u77e5\uff0c\u5e76\u4e3a\u751f\u4ea7\u73af\u5883\u4e2d\u4f18\u5316\u6a21\u578b\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2601.02601", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02601", "abs": "https://arxiv.org/abs/2601.02601", "authors": ["Nazanin Siavash", "Armin Moin"], "title": "State of the Quantum Software Engineering Ecosystem", "comment": null, "summary": "We study the current state of the Quantum Software Engineering (QSE) ecosystem, focusing on the achievements, activities, and engagements from academia and industry, with a special focus on successful entrepreneurial endeavors in this arena. Our research methodology is a novel one, featuring the state-of-the-art in Artificial Intelligence (AI), namely Large Language Models (LLMs), especially Generative Pretrained Transformers (GPT). We use one of such models, namely the OpenAI GPT-5 model, through the ChatGPT tool. The goal is to identify institutions and companies that are highly active and have achieved distinguished results in QSE, evidenced by peer-reviewed publications or raised capital in the venture capital market.", "AI": {"tldr": "\u672c\u6587\u5229\u7528GPT-5\u5206\u6790\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u5b66\u672f\u4e0e\u4ea7\u4e1a\u52a8\u6001\uff0c\u8bc6\u522b\u6d3b\u8dc3\u673a\u6784\u4e0e\u6210\u529f\u4f01\u4e1a\u3002", "motivation": "\u5398\u6e05\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u751f\u6001\u73b0\u72b6\uff0c\u805a\u7126\u5b66\u672f\u754c\u4e0e\u4ea7\u4e1a\u754c\u7684\u6210\u5c31\u4e0e\u521b\u4e1a\u6210\u679c\u3002", "method": "\u91c7\u7528GPT-5\u901a\u8fc7ChatGPT\u5de5\u5177\u5206\u6790\u673a\u6784\u4e0e\u4f01\u4e1a\u7684\u6d3b\u8dc3\u5ea6\u53ca\u6210\u679c\u8868\u73b0\u3002", "result": "\u8bc6\u522b\u51fa\u5728\u540c\u884c\u8bc4\u5ba1\u53d1\u8868\u6216\u98ce\u6295\u878d\u8d44\u65b9\u9762\u8868\u73b0\u7a81\u51fa\u7684\u673a\u6784\u4e0e\u516c\u53f8\u3002", "conclusion": "AI\u5927\u6a21\u578b\u53ef\u6709\u6548\u8f85\u52a9\u65b0\u5174\u79d1\u6280\u9886\u57df\u751f\u6001\u8c03\u7814\u4e0e\u8d8b\u52bf\u8bc6\u522b\u3002"}}
{"id": "2601.02632", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02632", "abs": "https://arxiv.org/abs/2601.02632", "authors": ["Alireza Ezaz", "Ghazal Khodabandeh", "Majid Babaei", "Naser Ezzati-Jivan"], "title": "TAAF: A Trace Abstraction and Analysis Framework Synergizing Knowledge Graphs and LLMs", "comment": "Accepted to ICSE 2026. DOI 10.1145/3744916.3787832", "summary": "Execution traces are a critical source of information for understanding, debugging, and optimizing complex software systems. However, traces from OS kernels or large-scale applications like Chrome or MySQL are massive and difficult to analyze. Existing tools rely on predefined analyses, and custom insights often require writing domain-specific scripts, which is an error-prone and time-consuming task. This paper introduces TAAF (Trace Abstraction and Analysis Framework), a novel approach that combines time-indexing, knowledge graphs (KGs), and large language models (LLMs) to transform raw trace data into actionable insights. TAAF constructs a time-indexed KG from trace events to capture relationships among entities such as threads, CPUs, and system resources. An LLM then interprets query-specific subgraphs to answer natural-language questions, reducing the need for manual inspection and deep system expertise. To evaluate TAAF, we introduce TraceQA-100, a benchmark of 100 questions grounded in real kernel traces. Experiments across three LLMs and multiple temporal settings show that TAAF improves answer accuracy by up to 31.2%, particularly in multi-hop and causal reasoning tasks. We further analyze where graph-grounded reasoning helps and where limitations remain, offering a foundation for next-generation trace analysis tools.", "AI": {"tldr": "TAAF\u6846\u67b6\u7ed3\u5408\u65f6\u95f4\u7d22\u5f15\u3001\u77e5\u8bc6\u56fe\u8c31\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u5bf9\u590d\u6742\u7cfb\u7edf\u6267\u884c\u8f68\u8ff9\u7684\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5206\u6790\uff0c\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u4f9d\u8d56\u9884\u5b9a\u4e49\u5206\u6790\u6216\u9700\u7f16\u5199\u811a\u672c\uff0c\u6548\u7387\u4f4e\u4e14\u6613\u51fa\u9519\uff0c\u4e9f\u9700\u66f4\u667a\u80fd\u7684\u8f68\u8ff9\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u65f6\u95f4\u7d22\u5f15\u77e5\u8bc6\u56fe\u8c31\u8868\u793a\u8f68\u8ff9\u5b9e\u4f53\u5173\u7cfb\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u6790\u5b50\u56fe\u5e76\u56de\u7b54\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u3002", "result": "\u5728TraceQA-100\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTAAF\u4f7f\u7b54\u6848\u51c6\u786e\u7387\u6700\u9ad8\u63d0\u534731.2%\uff0c\u5c24\u5176\u64c5\u957f\u591a\u8df3\u4e0e\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u3002", "conclusion": "TAAF\u4e3a\u4e0b\u4e00\u4ee3\u8f68\u8ff9\u5206\u6790\u5de5\u5177\u5960\u5b9a\u57fa\u7840\uff0c\u4f46\u4ecd\u5b58\u5728\u90e8\u5206\u5c40\u9650\u6027\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2601.03171", "categories": ["cs.NI", "cs.ET", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.03171", "abs": "https://arxiv.org/abs/2601.03171", "authors": ["Silvano Cortesi", "Lukas Schulthess", "Davide Plozza", "Christian Vogt", "Michele Magno"], "title": "Eco-WakeLoc: An Energy-Neutral and Cooperative UWB Real-Time Locating System", "comment": "This work has been accepted for publication in the IEEE Sensors Journal, specifically the Special Issue on \"Special Issue on Advances in Resource-Efficient Sensors and Interfaces Fostered by Artificial Intelligence\"", "summary": "Indoor localization systems face a fundamental trade-off between efficiency and responsiveness, which is especially important for emerging use cases such as mobile robots operating in GPS-denied environments. Traditional RTLS either require continuously powered infrastructure, limiting their scalability, or are limited by their responsiveness. This work presents Eco-WakeLoc, designed to achieve centimeter-level UWB localization while remaining energy-neutral by combining ultra-low power wake-up radios (WuRs) with solar energy harvesting. By activating anchor nodes only on demand, the proposed system eliminates constant energy consumption while achieving centimeter-level positioning accuracy. To reduce coordination overhead and improve scalability, Eco-WakeLoc employs cooperative localization where active tags initiate ranging exchanges (trilateration), while passive tags opportunistically reuse these messages for TDOA positioning. An additive-increase/multiplicative-decrease (AIMD)-based energy-aware scheduler adapts localization rates according to the harvested energy, thereby maximizing the overall performance of the sensor network while ensuring long-term energy neutrality. The measured energy consumption is only 3.22mJ per localization for active tags, 951uJ for passive tags, and 353uJ for anchors. Real-world deployment on a quadruped robot with nine anchors confirms the practical feasibility, achieving an average accuracy of 43cm in dynamic indoor environments. Year-long simulations show that tags achieve an average of 2031 localizations per day, retaining over 7% battery capacity after one year -- demonstrating that the RTLS achieves sustained energy-neutral operation. Eco-WakeLoc demonstrates that high-accuracy indoor localization can be achieved at scale without continuous infrastructure operation, combining energy neutrality, cooperative positioning, and adaptive scheduling.", "AI": {"tldr": "Eco-WakeLoc \u5b9e\u73b0\u4e86\u5398\u7c73\u7ea7 UWB \u5ba4\u5185\u5b9a\u4f4d\uff0c\u7ed3\u5408\u5524\u9192\u65e0\u7ebf\u7535\u4e0e\u592a\u9633\u80fd\u91c7\u96c6\uff0c\u5728\u4fdd\u8bc1\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u80fd\u91cf\u4e2d\u6027\u8fd0\u884c\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5ba4\u5185\u5b9a\u4f4d\u7cfb\u7edf\u5728\u6548\u7387\u4e0e\u54cd\u5e94\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u65e0 GPS \u73af\u5883\u4e0b\u7684\u79fb\u52a8\u673a\u5668\u4eba\u3002", "method": "\u91c7\u7528\u8d85\u4f4e\u529f\u8017\u5524\u9192\u65e0\u7ebf\u7535\u4e0e\u592a\u9633\u80fd\u91c7\u96c6\uff0c\u6309\u9700\u6fc0\u6d3b\u951a\u70b9\uff1b\u901a\u8fc7\u534f\u4f5c\u5b9a\u4f4d\u4e0e AIMD \u80fd\u91cf\u8c03\u5ea6\u4f18\u5316\u6027\u80fd\u3002", "result": "\u5b9e\u6d4b\u4e3b\u52a8\u6807\u7b7e\u80fd\u8017 3.22mJ/\u6b21\uff0c\u88ab\u52a8\u6807\u7b7e 951\u03bcJ/\u6b21\uff0c\u951a\u70b9 353\u03bcJ/\u6b21\uff1b\u5b9e\u9645\u90e8\u7f72\u5e73\u5747\u7cbe\u5ea6 43cm\uff0c\u5e74\u4eff\u771f\u663e\u793a\u6bcf\u65e5 2031 \u6b21\u5b9a\u4f4d\u4e14\u7535\u6c60\u4f59\u91cf >7%\u3002", "conclusion": "Eco-WakeLoc \u5728\u65e0\u9700\u6301\u7eed\u57fa\u7840\u8bbe\u65bd\u8fd0\u884c\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u3001\u53ef\u6269\u5c55\u3001\u80fd\u91cf\u4e2d\u6027\u7684\u5ba4\u5185\u5b9a\u4f4d\u3002"}}
{"id": "2601.02698", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.02698", "abs": "https://arxiv.org/abs/2601.02698", "authors": ["Manideep Reddy Chinthareddy"], "title": "Enterprise Identity Integration for AI-Assisted Developer Services: Architecture, Implementation, and Case Study", "comment": "11 pages, 3 Figures", "summary": "AI-assisted developer services are increasingly embedded in modern IDEs, yet enterprises must ensure these tools operate within existing identity, access control, and governance requirements. The Model Context Protocol (MCP) enables AI assistants to retrieve structured internal context, but its specification provides only a minimal authorization model and lacks guidance on integrating enterprise SSO. This article presents a practical architecture that incorporates OAuth 2.0 and OpenID Connect (OIDC) into MCP-enabled developer environments. It describes how IDE extensions obtain and present tokens, how MCP servers validate them through an identity provider, and how scopes and claims can enforce least-privilege access. A prototype implementation using Visual Studio Code, a Python-based MCP server, and an OIDC-compliant IdP demonstrates feasibility. A case study evaluates authentication latency, token-validation overhead, operational considerations, and AI-specific risks. The approach provides a deployable pattern for organizations adopting AI-assisted developer tools while maintaining identity assurance and auditability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408OAuth 2.0\u4e0eOIDC\u7684\u67b6\u6784\uff0c\u4f7fMCP\u652f\u6301\u4f01\u4e1a\u7ea7\u8eab\u4efd\u8ba4\u8bc1\uff0c\u786e\u4fddAI\u5f00\u53d1\u5de5\u5177\u5728\u5408\u89c4\u524d\u63d0\u4e0b\u5b89\u5168\u8fd0\u884c\u3002", "motivation": "\u4f01\u4e1a\u9700\u5728\u73b0\u6709\u8eab\u4efd\u6cbb\u7406\u6846\u67b6\u5185\u4f7f\u7528AI\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\uff0c\u800cMCP\u7f3a\u4e4f\u4f01\u4e1aSSO\u96c6\u6210\u65b9\u6848\u3002", "method": "\u901a\u8fc7VS Code\u6269\u5c55\u3001Python MCP\u670d\u52a1\u5668\u4e0eOIDC IdP\u6784\u5efa\u539f\u578b\uff0c\u5b9e\u73b0\u4ee4\u724c\u83b7\u53d6\u3001\u9a8c\u8bc1\u53ca\u6700\u5c0f\u6743\u9650\u63a7\u5236\u3002", "result": "\u5b9e\u8bc1\u663e\u793a\u8be5\u67b6\u6784\u53ef\u884c\uff0c\u8bc4\u4f30\u6db5\u76d6\u8ba4\u8bc1\u5ef6\u8fdf\u3001\u9a8c\u8bc1\u5f00\u9500\u3001\u8fd0\u7ef4\u8003\u91cf\u4e0eAI\u7279\u6709\u98ce\u9669\u3002", "conclusion": "\u672c\u65b9\u6848\u4e3a\u4f01\u4e1a\u90e8\u7f72AI\u5f00\u53d1\u52a9\u624b\u63d0\u4f9b\u53ef\u843d\u5730\u7684\u8eab\u4efd\u4fdd\u969c\u4e0e\u5ba1\u8ba1\u80fd\u529b\u6a21\u5f0f\u3002"}}
{"id": "2601.02732", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02732", "abs": "https://arxiv.org/abs/2601.02732", "authors": ["Lingzhe Zhang", "Tong Jia", "Yunpeng Zhai", "Leyi Pan", "Chiming Duan", "Minghua He", "Mengxi Jia", "Ying Li"], "title": "Agentic Memory Enhanced Recursive Reasoning for Root Cause Localization in Microservices", "comment": "accepted by ICSE-SEIP'26", "summary": "As contemporary microservice systems become increasingly popular and complex-often comprising hundreds or even thousands of fine-grained, interdependent subsystems-they are experiencing more frequent failures. Ensuring system reliability thus demands accurate root cause localization. While many traditional graph-based and deep learning approaches have been explored for this task, they often rely heavily on pre-defined schemas that struggle to adapt to evolving operational contexts. Consequently, a number of LLM-based methods have recently been proposed. However, these methods still face two major limitations: shallow, symptom-centric reasoning that undermines accuracy, and a lack of cross-alert reuse that leads to redundant reasoning and high latency. In this paper, we conduct a comprehensive study of how Site Reliability Engineers (SREs) localize the root causes of failures, drawing insights from professionals across multiple organizations. Our investigation reveals that expert root cause analysis exhibits three key characteristics: recursiveness, multi-dimensional expansion, and cross-modal reasoning. Motivated by these findings, we introduce AMER-RCL, an agentic memory enhanced recursive reasoning framework for root cause localization in microservices. AMER-RCL employs the Recursive Reasoning RCL engine, a multi-agent framework that performs recursive reasoning on each alert to progressively refine candidate causes, while Agentic Memory incrementally accumulates and reuses reasoning from prior alerts within a time window to reduce redundant exploration and lower inference latency. Experimental results demonstrate that AMER-RCL consistently outperforms state-of-the-art methods in both localization accuracy and inference efficiency.", "AI": {"tldr": "AMER-RCL\u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u8bb0\u5fc6\u589e\u5f3a\u7684\u9012\u5f52\u63a8\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u5fae\u670d\u52a1\u7cfb\u7edf\u4e2d\u7684\u6839\u56e0\u5b9a\u4f4d\uff0c\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\u4e0e\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u5728\u6839\u56e0\u5b9a\u4f4d\u4e2d\u5b58\u5728\u6d45\u5c42\u63a8\u7406\u548c\u7f3a\u4e4f\u8de8\u544a\u8b66\u590d\u7528\u7684\u95ee\u9898\uff0c\u53d7SRE\u4e13\u5bb6\u5206\u6790\u6a21\u5f0f\u542f\u53d1\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u3002", "method": "\u6784\u5efa\u9012\u5f52\u63a8\u7406\u5f15\u64ce\u4e0e\u667a\u80fd\u4f53\u8bb0\u5fc6\u673a\u5236\uff0c\u5b9e\u73b0\u5bf9\u544a\u8b66\u7684\u9012\u5f52\u7ec6\u5316\u4e0e\u5386\u53f2\u63a8\u7406\u590d\u7528\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAMER-RCL\u5728\u5b9a\u4f4d\u51c6\u786e\u7387\u548c\u63a8\u7406\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "AMER-RCL\u6709\u6548\u6a21\u62df\u4e13\u5bb6\u5206\u6790\u7279\u6027\uff0c\u4e3a\u590d\u6742\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u6839\u56e0\u5b9a\u4f4d\u63d0\u4f9b\u9ad8\u6548\u53ef\u9760\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2601.02736", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02736", "abs": "https://arxiv.org/abs/2601.02736", "authors": ["Lingzhe Zhang", "Tong Jia", "Yunpeng Zhai", "Leyi Pan", "Chiming Duan", "Minghua He", "Pei Xiao", "Ying Li"], "title": "Hypothesize-Then-Verify: Speculative Root Cause Analysis for Microservices with Pathwise Parallelism", "comment": "accepted by ICSE-NIER'26", "summary": "Microservice systems have become the backbone of cloud-native enterprise applications due to their resource elasticity, loosely coupled architecture, and lightweight deployment. Yet, the intrinsic complexity and dynamic runtime interactions of such systems inevitably give rise to anomalies. Ensuring system reliability therefore hinges on effective root cause analysis (RCA), which entails not only localizing the source of anomalies but also characterizing the underlying failures in a timely and interpretable manner. Recent advances in intelligent RCA techniques, particularly those powered by large language models (LLMs), have demonstrated promising capabilities, as LLMs reduce reliance on handcrafted features while offering cross-platform adaptability, task generalization, and flexibility. However, existing LLM-based methods still suffer from two critical limitations: (a) limited exploration diversity, which undermines accuracy, and (b) heavy dependence on large-scale LLMs, which results in slow inference. To overcome these challenges, we propose SpecRCA, a speculative root cause analysis framework for microservices that adopts a \\textit{hypothesize-then-verify} paradigm. SpecRCA first leverages a hypothesis drafting module to rapidly generate candidate root causes, and then employs a parallel root cause verifier to efficiently validate them. Preliminary experiments on the AIOps 2022 dataset demonstrate that SpecRCA achieves superior accuracy and efficiency compared to existing approaches, highlighting its potential as a practical solution for scalable and interpretable RCA in complex microservice environments.", "AI": {"tldr": "SpecRCA\u662f\u4e00\u79cd\u7528\u4e8e\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u63a8\u6d4b\u6027\u6839\u56e0\u5206\u6790\u6846\u67b6\uff0c\u91c7\u7528\u201c\u5047\u8bbe-\u9a8c\u8bc1\u201d\u8303\u5f0f\uff0c\u5728\u4fdd\u8bc1\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6839\u56e0\u5206\u6790\u65b9\u6cd5\u5b58\u5728\u63a2\u7d22\u591a\u6837\u6027\u4e0d\u8db3\u548c\u63a8\u7406\u901f\u5ea6\u6162\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u5fae\u670d\u52a1\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51faSpecRCA\u6846\u67b6\uff0c\u5305\u542b\u5feb\u901f\u751f\u6210\u5019\u9009\u6839\u56e0\u7684\u5047\u8bbe\u8d77\u8349\u6a21\u5757\u548c\u5e76\u884c\u9a8c\u8bc1\u8fd9\u4e9b\u5047\u8bbe\u7684\u6839\u56e0\u9a8c\u8bc1\u5668\u3002", "result": "\u5728AIOps 2022\u6570\u636e\u96c6\u4e0a\u7684\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0cSpecRCA\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SpecRCA\u4e3a\u590d\u6742\u5fae\u670d\u52a1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u9ad8\u6548\u6839\u56e0\u5206\u6790\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02868", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02868", "abs": "https://arxiv.org/abs/2601.02868", "authors": ["Peiding Wang", "Li Zhang", "Fang Liu", "Chongyang Tao", "Yinghao Zhu"], "title": "CodeMEM: AST-Guided Adaptive Memory for Repository-Level Iterative Code Generation", "comment": "preprint", "summary": "Large language models (LLMs) substantially enhance developer productivity in repository-level code generation through interactive collaboration. However, as interactions progress, repository context must be continuously preserved and updated to integrate newly validated information. Meanwhile, the expanding session history increases cognitive burden, often leading to forgetting and the reintroduction of previously resolved errors. Existing memory management approaches show promise but remain limited by natural language-centric representations. To overcome these limitations, we propose CodeMEM, an AST-guided dynamic memory management system tailored for repository-level iterative code generation. Specifically, CodeMEM introduces the Code Context Memory component that dynamically maintains and updates repository context through AST-guided LLM operations, along with the Code Session Memory that constructs a code-centric representation of interaction history and explicitly detects and mitigates forgetting through AST-based analysis. Experimental results on the instruction-following benchmark CodeIF-Bench and the code generation benchmark CoderEval demonstrate that CodeMEM achieves state-of-the-art performance, improving instruction following by 12.2% for the current turn and 11.5% for the session level, and reducing interaction rounds by 2-3, while maintaining competitive inference latency and token efficiency.", "AI": {"tldr": "CodeMEM\u662f\u4e00\u79cd\u57fa\u4e8eAST\u7684\u52a8\u6001\u5185\u5b58\u7ba1\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u63d0\u5347\u4ed3\u5e93\u7ea7\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u56e0\u81ea\u7136\u8bed\u8a00\u4e3a\u4e2d\u5fc3\u7684\u8868\u793a\u65b9\u5f0f\uff0c\u5728\u4fdd\u5b58\u548c\u66f4\u65b0\u4ed3\u5e93\u4e0a\u4e0b\u6587\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u5bfc\u81f4\u8ba4\u77e5\u8d1f\u62c5\u589e\u52a0\u548c\u9519\u8bef\u91cd\u73b0\u3002", "method": "CodeMEM\u5305\u542b\u4ee3\u7801\u4e0a\u4e0b\u6587\u5185\u5b58\u548c\u4ee3\u7801\u4f1a\u8bdd\u5185\u5b58\u4e24\u4e2a\u7ec4\u4ef6\uff0c\u524d\u8005\u901a\u8fc7AST\u5f15\u5bfc\u7684LLM\u64cd\u4f5c\u52a8\u6001\u7ef4\u62a4\u4ed3\u5e93\u4e0a\u4e0b\u6587\uff0c\u540e\u8005\u6784\u5efa\u4ee5\u4ee3\u7801\u4e3a\u4e2d\u5fc3\u7684\u4ea4\u4e92\u5386\u53f2\u8868\u793a\u5e76\u68c0\u6d4b\u7f13\u89e3\u9057\u5fd8\u3002", "result": "\u5728CodeIF-Bench\u548cCoderEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCodeMEM\u5728\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u5206\u522b\u63d0\u534712.2%\uff08\u5f53\u524d\u8f6e\u6b21\uff09\u548c11.5%\uff08\u4f1a\u8bdd\u7ea7\u522b\uff09\uff0c\u51cf\u5c112-3\u8f6e\u4ea4\u4e92\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u5ef6\u8fdf\u548c\u4ee4\u724c\u6548\u7387\u3002", "conclusion": "CodeMEM\u6709\u6548\u89e3\u51b3\u4e86\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u9057\u5fd8\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u51c6\u786e\u7684\u4ea4\u4e92\u5f0f\u534f\u4f5c\u3002"}}
{"id": "2601.02971", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02971", "abs": "https://arxiv.org/abs/2601.02971", "authors": ["Muhammad Laiq"], "title": "Few-shot learning for security bug report identification", "comment": null, "summary": "Security bug reports require prompt identification to minimize the window of vulnerability in software systems. Traditional machine learning (ML) techniques for classifying bug reports to identify security bug reports rely heavily on large amounts of labeled data. However, datasets for security bug reports are often scarce in practice, leading to poor model performance and limited applicability in real-world settings. In this study, we propose a few-shot learning-based technique to effectively identify security bug reports using limited labeled data. We employ SetFit, a state-of-the-art few-shot learning framework that combines sentence transformers with contrastive learning and parameter-efficient fine-tuning. The model is trained on a small labeled dataset of bug reports and is evaluated on its ability to classify these reports as either security-related or non-security-related. Our approach achieves an AUC of 0.865, at best, outperforming traditional ML techniques (baselines) for all of the evaluated datasets. This highlights the potential of SetFit to effectively identify security bug reports. SetFit-based few-shot learning offers a promising alternative to traditional ML techniques to identify security bug reports. The approach enables efficient model development with minimal annotation effort, making it highly suitable for scenarios where labeled data is scarce.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eSetFit\u7684\u5c11\u6837\u672c\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u9ad8\u6548\u8bc6\u522b\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u9700\u5feb\u901f\u8bc6\u522b\u4ee5\u964d\u4f4e\u98ce\u9669\uff0c\u4f46\u5b9e\u9645\u4e2d\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u5bfc\u81f4\u4f20\u7edf\u6a21\u578b\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u91c7\u7528SetFit\u6846\u67b6\uff0c\u7ed3\u5408\u53e5\u5b50\u53d8\u6362\u5668\u3001\u5bf9\u6bd4\u5b66\u4e60\u4e0e\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff0c\u5728\u5c0f\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u4e0a\u8bad\u7ec3\u5206\u7c7b\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0aAUC\u6700\u9ad8\u8fbe0.865\uff0c\u5168\u9762\u4f18\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "SetFit\u5c11\u6837\u672c\u5b66\u4e60\u662f\u8bc6\u522b\u5b89\u5168\u6f0f\u6d1e\u62a5\u544a\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u573a\u666f\u3002"}}
{"id": "2601.03009", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03009", "abs": "https://arxiv.org/abs/2601.03009", "authors": ["Nek Dil Khan", "Javed Ali Khan", "Darvesh Khan", "Jianqiang Li", "Mumrez Khan", "Shah Fahad Khan"], "title": "A Dataset of Low-Rated Applications from the Amazon Appstore for User Feedback Analysis", "comment": null, "summary": "In todays digital landscape, end-user feedback plays a crucial role in the evolution of software applications, particularly in addressing issues that hinder user experience. While much research has focused on high-rated applications, low-rated applications often remain unexplored, despite their potential to reveal valuable insights. This study introduces a novel dataset curated from 64 low-rated applications sourced from the Amazon Software Appstore (ASA), containing 79,821 user reviews. The dataset is designed to capture the most frequent issues identified by users, which are critical for improving software quality. To further enhance the dataset utility, a subset of 6000 reviews was manually annotated to classify them into six district issue categories: user interface (UI) and user experience (UX), functionality and features, compatibility and device specificity, performance and stability, customer support and responsiveness, and security and privacy issues. This annotated dataset is a valuable resource for developing machine learning-based approaches aiming to automate the classification of user feedback into various issue types. Making both the annotated and raw datasets publicly available provides researchers and developers with a crucial tool to understand common issues in low-rated apps and inform software improvements. The comprehensive analysis and availability of this dataset lay the groundwork for data-derived solutions to improve software quality based on user feedback. Additionally, the dataset can provide opportunities for software vendors and researchers to explore various software evolution-related activities, including frequently missing features, sarcasm, and associated emotions, which will help better understand the reasons for comparatively low app ratings.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u4ece\u4e9a\u9a6c\u900a\u5e94\u7528\u5546\u5e9764\u6b3e\u4f4e\u5206\u5e94\u7528\u4e2d\u63d0\u53d6\u7684\u5305\u542b79,821\u6761\u7528\u6237\u8bc4\u8bba\u7684\u65b0\u6570\u636e\u96c6\uff0c\u5176\u4e2d6000\u6761\u8bc4\u8bba\u7ecf\u4eba\u5de5\u6807\u6ce8\u5f52\u7c7b\u4e3a\u516d\u5927\u95ee\u9898\u7c7b\u522b\uff0c\u65e8\u5728\u652f\u6301\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7528\u6237\u53cd\u9988\u81ea\u52a8\u5206\u7c7b\uff0c\u52a9\u529b\u8f6f\u4ef6\u8d28\u91cf\u6539\u8fdb\u3002", "motivation": "\u4f4e\u5206\u5e94\u7528\u5e38\u88ab\u5ffd\u89c6\uff0c\u4f46\u5176\u7528\u6237\u53cd\u9988\u8574\u542b\u5b9d\u8d35\u6d1e\u5bdf\uff0c\u53ef\u7528\u4e8e\u63ed\u793a\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\u7684\u5173\u952e\u95ee\u9898\u5e76\u6307\u5bfc\u8f6f\u4ef6\u4f18\u5316\u3002", "method": "\u4ece\u4e9a\u9a6c\u900a\u5e94\u7528\u5546\u5e97\u6536\u96c6\u4f4e\u5206\u5e94\u7528\u7684\u7528\u6237\u8bc4\u8bba\uff0c\u6784\u5efa\u539f\u59cb\u6570\u636e\u96c6\uff0c\u5e76\u5bf9\u5176\u4e2d6000\u6761\u8bc4\u8bba\u8fdb\u884c\u4eba\u5de5\u6807\u6ce8\uff0c\u5212\u5206\u4e3a\u516d\u7c7b\u5e38\u89c1\u95ee\u9898\u3002", "result": "\u6210\u529f\u6784\u5efa\u5e76\u516c\u5f00\u53d1\u5e03\u6807\u6ce8\u4e0e\u539f\u59cb\u6570\u636e\u96c6\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5f00\u53d1\u8005\u63d0\u4f9b\u7406\u89e3\u4f4e\u5206\u5e94\u7528\u5e38\u89c1\u95ee\u9898\u3001\u5f00\u53d1\u81ea\u52a8\u5316\u5206\u7c7b\u6a21\u578b\u7684\u91cd\u8981\u8d44\u6e90\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u57fa\u4e8e\u7528\u6237\u53cd\u9988\u7684\u6570\u636e\u9a71\u52a8\u578b\u8f6f\u4ef6\u8d28\u91cf\u6539\u8fdb\u5960\u5b9a\u57fa\u7840\uff0c\u5e76\u652f\u6301\u63a2\u7d22\u7f3a\u5931\u529f\u80fd\u3001\u8bbd\u523a\u8bed\u6c14\u4e0e\u60c5\u7eea\u7b49\u6df1\u5c42\u6f14\u5316\u6d3b\u52a8\u3002"}}
{"id": "2601.03251", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.03251", "abs": "https://arxiv.org/abs/2601.03251", "authors": ["Xue Qin", "Matthew DiGiovanni"], "title": "NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments", "comment": null, "summary": "Navigation is one of the fundamental tasks for automated exploration in Virtual Reality (VR). Existing technologies primarily focus on path optimization in 360-degree image datasets and 3D simulators, which cannot be directly applied to immersive VR environments. To address this gap, we present NavAI, a generalizable large language model (LLM)-based navigation framework that supports both basic actions and complex goal-directed tasks across diverse VR applications. We evaluate NavAI in three distinct VR environments through goal-oriented and exploratory tasks. Results show that it achieves high accuracy, with an 89% success rate in goal-oriented tasks. Our analysis also highlights current limitations of relying entirely on LLMs, particularly in scenarios that require dynamic goal assessment. Finally, we discuss the limitations observed during the experiments and offer insights for future research directions.", "AI": {"tldr": "NavAI\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528\u5bfc\u822a\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u591a\u79cdVR\u73af\u5883\u4e2d\u7684\u76ee\u6807\u5bfc\u5411\u548c\u63a2\u7d22\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u6280\u672f\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u6c89\u6d78\u5f0fVR\u73af\u5883\u4e2d\u7684\u5bfc\u822a\u4efb\u52a1\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faNavAI\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u652f\u6301\u57fa\u7840\u52a8\u4f5c\u4e0e\u590d\u6742\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\uff0c\u5e76\u5728\u4e09\u79cdVR\u73af\u5883\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "NavAI\u5728\u76ee\u6807\u5bfc\u5411\u4efb\u52a1\u4e2d\u8fbe\u523089%\u7684\u6210\u529f\u7387\uff0c\u4f46\u5728\u52a8\u6001\u76ee\u6807\u8bc4\u4f30\u573a\u666f\u4e2d\u4ecd\u5b58\u5728\u5c40\u9650\u3002", "conclusion": "NavAI\u5c55\u793a\u4e86\u5728VR\u5bfc\u822a\u4e2d\u7684\u9ad8\u51c6\u786e\u6027\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u5b8c\u5168\u4f9d\u8d56LLM\u7684\u4e0d\u8db3\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
