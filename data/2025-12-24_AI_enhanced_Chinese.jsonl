{"id": "2512.19758", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.19758", "abs": "https://arxiv.org/abs/2512.19758", "authors": ["Wang Bin", "Ao Yang", "Kedan Li", "Aofan Liu", "Hui Li", "Guibo Luo", "Weixiang Huang", "Yan Zhuang"], "title": "Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models", "comment": "Accepted to ICSE 2026 Research Track", "summary": "In the domain of software security testing, Directed Grey-Box Fuzzing (DGF) has garnered widespread attention for its efficient target localization and excellent detection performance. However, existing approaches measure only the physical distance between seed execution paths and target locations, overlooking logical relationships among code segments. This omission can yield redundant or misleading guidance in complex binaries, weakening DGF's real-world effectiveness. To address this, we introduce \\textbf{attention distance}, a novel metric that leverages a large language model's contextual analysis to compute attention scores between code elements and reveal their intrinsic connections. Under the same AFLGo configuration -- without altering any fuzzing components other than the distance metric -- replacing physical distances with attention distances across 38 real vulnerability reproduction experiments delivers a \\textbf{3.43$\\times$} average increase in testing efficiency over the traditional method. Compared to state-of-the-art directed fuzzers DAFL and WindRanger, our approach achieves \\textbf{2.89$\\times$} and \\textbf{7.13$\\times$} improvements, respectively. To further validate the generalizability of attention distance, we integrate it into DAFL and WindRanger, where it also consistently enhances their original performance. All related code and datasets are publicly available at https://github.com/TheBinKing/Attention\\_Distance.git.", "AI": {"tldr": "\u63d0\u51fa\u6ce8\u610f\u529b\u8ddd\u79bb\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5b9a\u5411\u7070\u76d2\u6a21\u7cca\u6d4b\u8bd5\u4ec5\u4f9d\u8d56\u7269\u7406\u8def\u5f84\u8ddd\u79bb\uff0c\u5ffd\u7565\u4ee3\u7801\u903b\u8f91\u5173\u8054\uff0c\u5bfc\u81f4\u590d\u6742\u4e8c\u8fdb\u5236\u4e2d\u5f15\u5bfc\u5197\u4f59\u6216\u8bef\u5bfc\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u5206\u6790\u7684\u2018\u6ce8\u610f\u529b\u8ddd\u79bb\u2019\uff0c\u8ba1\u7b97\u4ee3\u7801\u5143\u7d20\u95f4\u5185\u5728\u5173\u8054\u5f97\u5206\uff0c\u66ff\u4ee3\u4f20\u7edf\u7269\u7406\u8ddd\u79bb\u3002", "result": "\u572838\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u590d\u73b0\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u8f83AFLGo\u63d0\u53473.43\u500d\u6548\u7387\uff0c\u4f18\u4e8eDAFL\u548cWindRanger\u8fbe2.89\u500d\u548c7.13\u500d\uff1b\u96c6\u6210\u81f3\u540e\u4e24\u8005\u4ea6\u6301\u7eed\u589e\u5f3a\u6027\u80fd\u3002", "conclusion": "\u6ce8\u610f\u529b\u8ddd\u79bb\u663e\u8457\u63d0\u5347\u5b9a\u5411\u6a21\u7cca\u6d4b\u8bd5\u6548\u679c\uff0c\u5177\u5907\u826f\u597d\u6cdb\u5316\u80fd\u529b\uff0c\u76f8\u5173\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2512.20073", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.20073", "abs": "https://arxiv.org/abs/2512.20073", "authors": ["Hongyang Shang", "Shuai Dong", "Ye Ke", "Arindam Basu"], "title": "3D Stack In-Sensor-Computing (3DS-ISC): Accelerating Time-Surface Construction for Neuromorphic Event Cameras", "comment": null, "summary": "This work proposes a 3D Stack In-Sensor-Computing (3DS-ISC) architecture for efficient event-based vision processing. A real-time normalization method using an exponential decay function is introduced to construct the time-surface, reducing hardware usage while preserving temporal information. The circuit design utilizes the leakage characterization of Dynamic Random Access Memory(DRAM) for timestamp normalization. Custom interdigitated metal-oxide-metal capacitor (MOMCAP) is used to store the charge and low leakage switch (LL switch) is used to extend the effective charge storage time. The 3DS-ISC architecture integrates sensing, memory, and computation to overcome the memory wall problem, reducing power, latency, and reducing area by 69x, 2.2x and 1.9x, respectively, compared with its 2D counterpart. Moreover, compared to works using a 16-bit SRAM to store timestamps, the ISC analog array can reduce power consumption by three orders of magnitude. In real computer vision (CV) tasks, we applied the spatial-temporal correlation filter (STCF) for denoise, and 3D-ISC achieved almost equivalent accuracy compared to the digital implementation using high precision timestamps. As for the image classification, time-surface constructed by 3D-ISC is used as the input of GoogleNet, achieving 99% on N-MNIST, 85% on N-Caltech101, 78% on CIFAR10-DVS, and 97% on DVS128 Gesture, comparable with state-of-the-art results on each dataset. Additionally, the 3D-ISC method is also applied to image reconstruction using the DAVIS240C dataset, achieving the highest average SSIM (0.62) among three methods. This work establishes a foundation for real-time, resource-efficient event-based processing and points to future integration of advanced computational circuits for broader applications.", "AI": {"tldr": "\u63d0\u51fa3D\u5806\u53e0\u611f\u5185\u8ba1\u7b97\u67b6\u6784\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e8b\u4ef6\u89c6\u89c9\u5904\u7406\uff0c\u663e\u8457\u964d\u4f4e\u529f\u8017\u4e0e\u9762\u79ef\u5e76\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf2D\u67b6\u6784\u5185\u5b58\u5899\u95ee\u9898\uff0c\u63d0\u5347\u4e8b\u4ef6\u76f8\u673a\u5b9e\u65f6\u5904\u7406\u6548\u7387\u4e0e\u80fd\u6548\u3002", "method": "\u5229\u7528DRAM\u6f0f\u7535\u7279\u6027\u8fdb\u884c\u65f6\u95f4\u6233\u5f52\u4e00\u5316\uff0c\u7ed3\u5408\u5b9a\u5236\u7535\u5bb9\u4e0e\u4f4e\u6f0f\u5f00\u5173\uff0c\u6784\u5efa3D\u611f\u5185\u8ba1\u7b97\u67b6\u6784\u3002", "result": "\u76f8\u6bd42D\u65b9\u6848\uff0c\u529f\u8017\u3001\u5ef6\u8fdf\u3001\u9762\u79ef\u5206\u522b\u964d\u4f4e69\u500d\u30012.2\u500d\u30011.9\u500d\uff1b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5206\u7c7b\u51c6\u786e\u7387\u63a5\u8fd1SOTA\uff0c\u56fe\u50cf\u91cd\u5efaSSIM\u8fbe0.62\u3002", "conclusion": "3D-ISC\u4e3a\u5b9e\u65f6\u4f4e\u529f\u8017\u4e8b\u4ef6\u89c6\u89c9\u5904\u7406\u5960\u5b9a\u57fa\u7840\uff0c\u672a\u6765\u53ef\u6269\u5c55\u81f3\u66f4\u5e7f\u6cdb\u8ba1\u7b97\u4efb\u52a1\u3002"}}
{"id": "2512.19841", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2512.19841", "abs": "https://arxiv.org/abs/2512.19841", "authors": ["Yousef Mehrdad Bibalan", "Behrouz Far", "Mohammad Moshirpour", "Bahareh Ghiyasian"], "title": "A Multi-Agent Retrieval-Augmented Framework for Work-in-Progress Predictio", "comment": "15th International Conference on Digital Image Processing and Pattern Recognition (DPPR 2025), December 20 ~ 21, 2025, Sydney, Australia", "summary": "Work-in-Progress (WiP) prediction is critical for predictive process monitoring, enabling accurate anticipation of workload fluctuations and optimized operational planning. This paper proposes a retrieval-augmented, multi-agent framework that combines retrieval-augmented generation (RAG) and collaborative multi-agent reasoning for WiP prediction. The narrative generation component transforms structured event logs into semantically rich natural language stories, which are embedded into a semantic vector-based process memory to facilitate dynamic retrieval of historical context during inference. The framework includes predictor agents that independently leverage retrieved historical contexts and a decision-making assistant agent that extracts high-level descriptive signals from recent events. A fusion agent then synthesizes predictions using ReAct-style reasoning over agent outputs and retrieved narratives. We evaluate our framework on two real-world benchmark datasets. Results show that the proposed retrieval-augmented multi-agent approach achieves competitive prediction accuracy, obtaining a Mean Absolute Percentage Error (MAPE) of 1.50\\% on one dataset, and surpassing Temporal Convolutional Networks (TCN), Long Short-Term Memory (LSTM), and persistence baselines. The results highlight improved robustness, demonstrating the effectiveness of integrating retrieval mechanisms and multi-agent reasoning in WiP prediction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e0e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u5de5\u4f5c\u8fdb\u5c55\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4e3a\u66f4\u7cbe\u51c6\u9884\u5224\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8\u5e76\u4f18\u5316\u8fd0\u8425\u89c4\u5212\uff0c\u9700\u6539\u8fdb\u73b0\u6709\u9884\u6d4b\u65b9\u6cd5\u7684\u4e0a\u4e0b\u6587\u5229\u7528\u4e0e\u63a8\u7406\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5c06\u4e8b\u4ef6\u65e5\u5fd7\u8f6c\u4e3a\u81ea\u7136\u8bed\u8a00\u6545\u4e8b\u5e76\u5d4c\u5165\u8bed\u4e49\u5411\u91cf\u8bb0\u5fc6\u5e93\uff0c\u7ed3\u5408\u591a\u4e2a\u9884\u6d4b\u667a\u80fd\u4f53\u4e0e\u51b3\u7b56\u8f85\u52a9\u667a\u80fd\u4f53\uff0c\u6700\u7ec8\u7531\u878d\u5408\u667a\u80fd\u4f53\u4ee5ReAct\u63a8\u7406\u6574\u5408\u7ed3\u679c\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cMAPE\u8fbe1.50%\uff0c\u4f18\u4e8eTCN\u3001LSTM\u548c\u6301\u7eed\u57fa\u7ebf\u6a21\u578b\uff0c\u5c55\u73b0\u66f4\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u96c6\u6210\u68c0\u7d22\u673a\u5236\u4e0e\u591a\u667a\u80fd\u4f53\u63a8\u7406\u80fd\u6709\u6548\u63d0\u5347\u5de5\u4f5c\u8fdb\u5c55\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2512.19698", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.19698", "abs": "https://arxiv.org/abs/2512.19698", "authors": ["Yejin Cho", "John Heidemann"], "title": "Smoothing Rough Edges of IPv6 in VPNs", "comment": null, "summary": "How do commercial VPNs interact with IPv6? We show two \"rough edges\" in how commercial VPNs handle IPv6. First, we show that many IPv4-only VPNs leak IPv6 traffic to the ISP. Individual use VPNs in part to conceal their local IP addresses, so such leaks reduce user privacy. While prior work has studied VPNs in testbeds, we use a new dataset of 129k VPN-using daily visitors to WhatIsMyIPAddress.com that quantifies these leaks and show 12 VPNs previously considered safe still leak for at least 5% of their users. We show native IPv6 addresses leak most commonly in VPNs that claim only IPv4 support, with 5% to 57% of visitors of v4-only VPNs having their native IPv6 address exposed. Second, we show that most dual-stack VPNs users actually select IPv4 instead of IPv6. We observe this problem in our visitor data, and we identify the root cause arises because when user's computer follows standard address-selection rules, VPN-assigned addresses are often de-preferenced. Testing six VPNs on Android, we show that five consistently de-prioritize IPv6. Finally, we suggest a solution to IPv6 de-preferencing: we define a new IPv6 address range for VPNs that is not de-preferenced by address selection. We prototype this solution on Linux. Our findings help identify and address rough edges in the addition of IPv6 support to VPNs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u5546\u4e1aVPN\u5728\u5904\u7406IPv6\u65f6\u7684\u4e24\u5927\u95ee\u9898\uff1aIPv4-only VPN\u6cc4\u9732IPv6\u6d41\u91cf\uff0c\u4ee5\u53ca\u53cc\u6808VPN\u7528\u6237\u5e38\u88ab\u8feb\u4f7f\u7528IPv4\u3002\u4f5c\u8005\u63d0\u51fa\u65b0IPv6\u5730\u5740\u8303\u56f4\u65b9\u6848\u4ee5\u89e3\u51b3\u4f18\u5148\u7ea7\u95ee\u9898\u3002", "motivation": "\u63d0\u5347\u7528\u6237\u9690\u79c1\u4fdd\u62a4\uff0c\u89e3\u51b3\u5546\u4e1aVPN\u5728IPv6\u652f\u6301\u4e2d\u7684\u5b9e\u9645\u7f3a\u9677\u3002", "method": "\u57fa\u4e8e12.9\u4e07\u771f\u5b9e\u7528\u6237\u8bbf\u95ee\u6570\u636e\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u5e76\u5728Android\u4e0eLinux\u5e73\u53f0\u6d4b\u8bd5\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b012\u6b3e\u6240\u8c13\u5b89\u5168\u7684VPN\u4ecd\u5b58\u5728\u81f3\u5c115%\u7528\u6237IPv6\u6cc4\u9732\uff1b57% IPv4-only\u7528\u6237\u66b4\u9732\u539f\u751fIPv6\u5730\u5740\uff1b\u591a\u6570\u53cc\u6808VPN\u56e0\u5730\u5740\u9009\u62e9\u89c4\u5219\u5bfc\u81f4IPv6\u88ab\u964d\u7ea7\u3002", "conclusion": "\u901a\u8fc7\u5b9a\u4e49\u4e13\u7528IPv6\u5730\u5740\u8303\u56f4\u5e76\u539f\u578b\u5b9e\u73b0\uff0c\u53ef\u6709\u6548\u89e3\u51b3VPN\u4e2dIPv6\u88ab\u7cfb\u7edf\u964d\u7ea7\u7684\u95ee\u9898\uff0c\u63a8\u52a8\u66f4\u5b8c\u5584\u7684IPv6\u652f\u6301\u3002"}}
{"id": "2512.20198", "categories": ["cs.AR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.20198", "abs": "https://arxiv.org/abs/2512.20198", "authors": ["Huizheng Wang", "Taiquan Wei", "Hongbin Wang", "Zichuan Wang", "Xinru Tang", "Zhiheng Yue", "Shaojun Wei", "Yang Hu", "Shouyi Yin"], "title": "Designing Spatial Architectures for Sparse Attention: STAR Accelerator via Cross-Stage Tiling", "comment": "Accepted for publication in IEEE Transactions on Computers", "summary": "Large language models (LLMs) rely on self-attention for contextual understanding, demanding high-throughput inference and large-scale token parallelism (LTPP). Existing dynamic sparsity accelerators falter under LTPP scenarios due to stage-isolated optimizations. Revisiting the end-to-end sparsity acceleration flow, we identify an overlooked opportunity: cross-stage coordination can substantially reduce redundant computation and memory access. We propose STAR, a cross-stage compute- and memory-efficient algorithm-hardware co-design tailored for Transformer inference under LTPP. STAR introduces a leading-zero-based sparsity prediction using log-domain add-only operations to minimize prediction overhead. It further employs distributed sorting and a sorted updating FlashAttention mechanism, guided by a coordinated tiling strategy that enables fine-grained stage interaction for improved memory efficiency and latency. These optimizations are supported by a dedicated STAR accelerator architecture, achieving up to 9.2$\\times$ speedup and 71.2$\\times$ energy efficiency over A100, and surpassing SOTA accelerators by up to 16.1$\\times$ energy and 27.1$\\times$ area efficiency gains. Further, we deploy STAR onto a multi-core spatial architecture, optimizing dataflow and execution orchestration for ultra-long sequence processing. Architectural evaluation shows that, compared to the baseline design, Spatial-STAR achieves a 20.1$\\times$ throughput improvement.", "AI": {"tldr": "STAR\u662f\u4e00\u79cd\u9762\u5411\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u8de8\u9636\u6bb5\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u901a\u8fc7\u96f6\u5f00\u9500\u7a00\u758f\u9884\u6d4b\u4e0e\u6392\u5e8f\u66f4\u65b0\u673a\u5236\u663e\u8457\u63d0\u5347\u80fd\u6548\u4e0e\u541e\u5410\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u7a00\u758f\u52a0\u901f\u5668\u5728\u5927\u89c4\u6a21\u4ee4\u724c\u5e76\u884c\u573a\u666f\u4e0b\u6548\u7387\u4f4e\u4e0b\uff0c\u7f3a\u4e4f\u8de8\u9636\u6bb5\u534f\u540c\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5bf9\u6570\u57df\u52a0\u6cd5\u7684\u524d\u5bfc\u96f6\u7a00\u758f\u9884\u6d4b\u3001\u5206\u5e03\u5f0f\u6392\u5e8f\u4e0e\u6392\u5e8f\u66f4\u65b0FlashAttention\u673a\u5236\uff0c\u5e76\u914d\u5408\u4e13\u7528\u786c\u4ef6\u67b6\u6784\u4e0e\u7a7a\u95f4\u591a\u6838\u6570\u636e\u6d41\u4f18\u5316\u3002", "result": "\u76f8\u6bd4A100\u5b9e\u73b0\u6700\u9ad89.2\u500d\u52a0\u901f\u4e0e71.2\u500d\u80fd\u6548\u63d0\u5347\uff0c\u8d85\u8d8aSOTA\u52a0\u901f\u5668\u8fbe16.1\u500d\u80fd\u6548\u4e0e27.1\u500d\u9762\u79ef\u6548\u7387\uff0cSpatial-STAR\u541e\u5410\u63d0\u534720.1\u500d\u3002", "conclusion": "STAR\u6709\u6548\u89e3\u51b3LLM\u63a8\u7406\u4e2d\u8de8\u9636\u6bb5\u5197\u4f59\u8ba1\u7b97\u4e0e\u8bbf\u5b58\u95ee\u9898\uff0c\u4e3a\u9ad8\u6548Transformer\u63a8\u7406\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2512.20457", "categories": ["cs.MA", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.20457", "abs": "https://arxiv.org/abs/2512.20457", "authors": ["Marco Aruta", "Francesco Improta", "Vadim Malvone", "Aniello Murano"], "title": "When Natural Strategies Meet Fuzziness and Resource-Bounded Actions (Extended Version)", "comment": null, "summary": "In formal strategic reasoning for Multi-Agent Systems (MAS), agents are typically assumed to (i) employ arbitrarily complex strategies, (ii) execute each move at zero cost, and (iii) operate over fully crisp game structures. These idealized assumptions stand in stark contrast with human decision making in real world environments. The natural strategies framework along with some of its recent variants, partially addresses this gap by restricting strategies to concise rules guarded by regular expressions. Yet, it still overlook both the cost of each action and the uncertainty that often characterizes human perception of facts over the time. In this work, we introduce HumanATLF, a logic that builds upon natural strategies employing both fuzzy semantics and resource bound actions: each action carries a real valued cost drawn from a non refillable budget, and atomic conditions and goals have degrees in [0,1]. We give a formal syntax and semantics, and prove that model checking is in P when both the strategy complexity k and resource budget b are fixed, NP complete if just one strategic operator over Boolean objectives is allowed, and Delta^P_2 complete when k and b vary. Moreover, we show that recall based strategies can be decided in PSPACE. We implement our algorithms in VITAMIN, an open source model checking tool for MAS and validate them on an adversarial resource aware drone rescue scenario.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHumanATLF\u903b\u8f91\uff0c\u7ed3\u5408\u6a21\u7cca\u8bed\u4e49\u4e0e\u8d44\u6e90\u7ea6\u675f\u52a8\u4f5c\uff0c\u7528\u4e8e\u66f4\u8d34\u8fd1\u4eba\u7c7b\u51b3\u7b56\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5f62\u5f0f\u5316\u5efa\u6a21\u4e0e\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709MAS\u5f62\u5f0f\u5316\u63a8\u7406\u5047\u8bbe\u8fc7\u4e8e\u7406\u60f3\u5316\uff0c\u5ffd\u7565\u4eba\u7c7b\u51b3\u7b56\u4e2d\u7684\u7b56\u7565\u7b80\u6d01\u6027\u3001\u884c\u52a8\u6210\u672c\u53ca\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u6269\u5c55\u81ea\u7136\u7b56\u7565\u6846\u67b6\uff0c\u5f15\u5165\u6a21\u7cca\u8bed\u4e49\u548c\u8d44\u6e90\u9884\u7b97\u7ea6\u675f\uff0c\u5b9a\u4e49HumanATLF\u903b\u8f91\u5e76\u5b9e\u73b0\u6a21\u578b\u68c0\u6d4b\u7b97\u6cd5\u3002", "result": "\u8bc1\u660e\u4e0d\u540c\u53c2\u6570\u4e0b\u6a21\u578b\u68c0\u6d4b\u590d\u6742\u5ea6\u5206\u522b\u4e3aP\u3001NP\u5b8c\u5168\u548cDelta^P_2\u5b8c\u5168\uff1b\u57fa\u4e8e\u8bb0\u5fc6\u7684\u7b56\u7565\u53ef\u5728PSPACE\u5185\u5224\u5b9a\uff0c\u5e76\u901a\u8fc7VITAMIN\u5de5\u5177\u5728\u65e0\u4eba\u673a\u6551\u63f4\u573a\u666f\u9a8c\u8bc1\u6709\u6548\u6027\u3002", "conclusion": "HumanATLF\u80fd\u66f4\u771f\u5b9e\u523b\u753b\u4eba\u7c7b\u51b3\u7b56\u884c\u4e3a\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u4e0e\u6a21\u7cca\u73af\u5883\u4e0b\u7684MAS\u63d0\u4f9b\u5b9e\u7528\u7684\u5f62\u5f0f\u5316\u5206\u6790\u5de5\u5177\u3002"}}
{"id": "2512.19883", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.19883", "abs": "https://arxiv.org/abs/2512.19883", "authors": ["Phong Nguyen", "Anh M. T. Bui", "Phuong T. Nguyen"], "title": "Larger Is Not Always Better: Leveraging Structured Code Diffs for Comment Inconsistency Detection", "comment": "This paper has been reviewed and accepted to the Short Papers and Posters Track of SANER 2026", "summary": "Ensuring semantic consistency between source code and its accompanying comments is crucial for program comprehension, effective debugging, and long-term maintainability. Comment inconsistency arises when developers modify code but neglect to update the corresponding comments, potentially misleading future maintainers and introducing errors. Recent approaches to code-comment inconsistency (CCI) detection leverage Large Language Models (LLMs) and rely on capturing the semantic relationship between code changes and outdated comments. However, they often ignore the structural complexity of code evolution, including historical change activities, and introduce privacy and resource challenges. In this paper, we propose a Just-In-Time CCI detection approach built upon the CodeT5+ backbone. Our method decomposes code changes into ordered sequences of modification activities such as replacing, deleting, and adding to more effectively capture the correlation between these changes and the corresponding outdated comments. Extensive experiments conducted on publicly available benchmark datasets-JITDATA and CCIBENCH--demonstrate that our proposed approach outperforms recent state-of-the-art models by up to 13.54% in F1-Score and achieves an improvement ranging from 4.18% to 10.94% over fine-tuned LLMs including DeepSeek-Coder, CodeLlama and Qwen2.5-Coder.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eCodeT5+\u7684\u5373\u65f6\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u89e3\u4ee3\u7801\u53d8\u66f4\u6d3b\u52a8\u63d0\u5347\u6ce8\u91ca\u4e00\u81f4\u6027\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4ee3\u7801\u6f14\u5316\u7684\u7ed3\u6784\u590d\u6742\u6027\u4e14\u5b58\u5728\u9690\u79c1\u4e0e\u8d44\u6e90\u95ee\u9898\uff0c\u9700\u66f4\u9ad8\u6548\u51c6\u786e\u7684\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u5c06\u4ee3\u7801\u53d8\u66f4\u5206\u89e3\u4e3a\u66ff\u6362\u3001\u5220\u9664\u3001\u6dfb\u52a0\u7b49\u6709\u5e8f\u6d3b\u52a8\u5e8f\u5217\uff0c\u5229\u7528CodeT5+\u5efa\u6a21\u5176\u4e0e\u6ce8\u91ca\u95f4\u7684\u8bed\u4e49\u5173\u8054\u3002", "result": "\u5728JITDATA\u548cCCIBENCH\u6570\u636e\u96c6\u4e0aF1\u5206\u6570\u6700\u9ad8\u63d0\u534713.54%\uff0c\u4f18\u4e8e\u591a\u4e2a\u5fae\u8c03LLM\u6a21\u578b4.18%-10.94%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u6355\u6349\u4ee3\u7801\u53d8\u66f4\u4e0e\u6ce8\u91ca\u95f4\u5173\u7cfb\uff0c\u663e\u8457\u63d0\u5347\u6ce8\u91ca\u4e0d\u4e00\u81f4\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2512.20495", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.20495", "abs": "https://arxiv.org/abs/2512.20495", "authors": ["He Zhu", "Zheng Liu", "Xingyang Li", "Anbang Wu", "Jieru Zhao", "Fangxin Liu", "Yiming Gan", "Jingwen Leng", "Yu Feng"], "title": "Nebula: Enable City-Scale 3D Gaussian Splatting in Virtual Reality via Collaborative Rendering and Accelerated Stereo Rasterization", "comment": null, "summary": "3D Gaussian splatting (3DGS) has drawn significant attention in the architectural community recently. However, current architectural designs often overlook the 3DGS scalability, making them fragile for extremely large-scale 3DGS. Meanwhile, the VR bandwidth requirement makes it impossible to deliver high-fidelity and smooth VR content from the cloud.\n  We present Nebula, a coherent acceleration framework for large-scale 3DGS collaborative rendering. Instead of streaming videos, Nebula streams intermediate results after the LoD search, reducing 1925% data communication between the cloud and the client. To further enhance the motion-to-photon experience, we introduce a temporal-aware LoD search in the cloud that tames the irregular memory access and reduces redundant data access by exploiting temporal coherence across frames. On the client side, we propose a novel stereo rasterization that enables two eyes to share most computations during the stereo rendering with bit-accurate quality. With minimal hardware augmentations, Nebula achieves 2.7$\\times$ motion-to-photon speedup and reduces 1925% bandwidth over lossy video streaming.", "AI": {"tldr": "Nebula\u662f\u4e00\u4e2a\u9488\u5bf9\u5927\u89c4\u6a213D\u9ad8\u65af\u70b9\u7ed8\u7684\u534f\u540c\u6e32\u67d3\u52a0\u901f\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u4e91-\u7aef\u6570\u636e\u4f20\u8f93\u4e0e\u8ba1\u7b97\u5171\u4eab\uff0c\u663e\u8457\u964d\u4f4e\u5e26\u5bbd\u5e76\u63d0\u5347VR\u4f53\u9a8c\u3002", "motivation": "\u5f53\u524d3D\u9ad8\u65af\u70b9\u7ed8\u5728\u5efa\u7b51\u9886\u57df\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\uff0c\u4e14\u4e91\u7aefVR\u5185\u5bb9\u4f20\u8f93\u53d7\u9650\u4e8e\u5e26\u5bbd\uff0c\u96be\u4ee5\u5b9e\u73b0\u9ad8\u4fdd\u771f\u6d41\u7545\u4f53\u9a8c\u3002", "method": "\u63d0\u51faNebula\u6846\u67b6\uff0c\u5305\u62ec\u4e91\u7aef\u65f6\u5e8f\u611f\u77e5LOD\u641c\u7d22\u51cf\u5c11\u5197\u4f59\u8bbf\u95ee\uff0c\u5ba2\u6237\u7aef\u7acb\u4f53\u5149\u6805\u5316\u5171\u4eab\u53cc\u76ee\u8ba1\u7b97\uff0c\u5e76\u4ee5\u4e2d\u95f4\u7ed3\u679c\u6d41\u66ff\u4ee3\u89c6\u9891\u6d41\u3002", "result": "\u76f8\u6bd4\u6709\u635f\u89c6\u9891\u6d41\uff0c\u5e26\u5bbd\u964d\u4f4e1925%\uff0c\u8fd0\u52a8\u5230\u5149\u5b50\u5ef6\u8fdf\u63d0\u901f2.7\u500d\uff0c\u4e14\u753b\u8d28\u65e0\u635f\u3002", "conclusion": "Nebula\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a213DGS\u5728VR\u573a\u666f\u4e0b\u7684\u5e26\u5bbd\u4e0e\u5ef6\u8fdf\u74f6\u9888\uff0c\u4e3a\u4e91\u534f\u540c\u6e32\u67d3\u63d0\u4f9b\u9ad8\u6548\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.19851", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.19851", "abs": "https://arxiv.org/abs/2512.19851", "authors": ["Aditya Bhosale", "Laxmikant Kale"], "title": "An Adaptive Distributed Stencil Abstraction for GPUs", "comment": null, "summary": "The scientific computing ecosystem in Python is largely confined to single-node parallelism, creating a gap between high-level prototyping in NumPy and high-performance execution on modern supercomputers. The increasing prevalence of hardware accelerators and the need for energy efficiency have made resource adaptivity a critical requirement, yet traditional HPC abstractions remain rigid. To address these challenges, we present an adaptive, distributed abstraction for stencil computations on multi-node GPUs. This abstraction is built using CharmTyles, a framework based on the adaptive Charm++ runtime, and features a familiar NumPy-like syntax to minimize the porting effort from prototype to production code. We showcase the resource elasticity of our abstraction by dynamically rescaling a running application across a different number of nodes and present a performance analysis of the associated overheads. Furthermore, we demonstrate that our abstraction achieves significant performance improvements over both a specialized, high-performance stencil DSL and a generalized NumPy replacement.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eCharmTyles\u7684\u81ea\u9002\u5e94\u5206\u5e03\u5f0f\u62bd\u8c61\uff0c\u652f\u6301\u591a\u8282\u70b9GPU\u4e0a\u7684Stencil\u8ba1\u7b97\uff0c\u5177\u5907NumPy\u8bed\u6cd5\u5e76\u5b9e\u73b0\u8d44\u6e90\u5f39\u6027\u4e0e\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3Python\u79d1\u5b66\u8ba1\u7b97\u751f\u6001\u5728\u73b0\u4ee3\u8d85\u7b97\u4e0a\u7f3a\u4e4f\u8d44\u6e90\u9002\u5e94\u6027\u4e0e\u9ad8\u6027\u80fd\u6267\u884c\u80fd\u529b\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u57fa\u4e8eCharm++\u8fd0\u884c\u65f6\u7684CharmTyles\u6846\u67b6\u6784\u5efa\u81ea\u9002\u5e94\u5206\u5e03\u5f0f\u62bd\u8c61\uff0c\u63d0\u4f9b\u7c7bNumPy\u63a5\u53e3\uff0c\u5e76\u652f\u6301\u52a8\u6001\u8282\u70b9\u6269\u5c55\u3002", "result": "\u76f8\u6bd4\u4e13\u7528Stencil DSL\u548c\u901a\u7528NumPy\u66ff\u4ee3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8fd0\u884c\u65f6\u8d44\u6e90\u4f38\u7f29\u7684\u5f00\u9500\u53ef\u63a7\u3002", "conclusion": "\u8be5\u62bd\u8c61\u5f25\u5408\u4e86\u539f\u578b\u5f00\u53d1\u4e0e\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u79d1\u5b66\u8ba1\u7b97\u63d0\u4f9b\u4e86\u7075\u6d3b\u9ad8\u6548\u7684\u591a\u8282\u70b9GPU\u6267\u884c\u65b9\u6848\u3002"}}
{"id": "2512.19980", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.19980", "abs": "https://arxiv.org/abs/2512.19980", "authors": ["Zhe Yin", "Xiaodong Gu", "Beijun Shen"], "title": "Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?", "comment": "Accepted by FSE2026", "summary": "Code language models excel on code intelligence tasks, yet their internal interpretability is underexplored. Existing neuron interpretability techniques from NLP are suboptimal for source code due to programming languages formal, hierarchical, and executable nature. We empirically investigate code LLMs at the neuron level, localizing language-specific neurons (selectively responsive to one language) and concept layers (feed-forward layers encoding language-agnostic code representations). We analyze Llama-3.1-8B and Qwen2.5-Coder-32B on multilingual inputs in C++, Java, Python, Go, and JavaScript, measuring neuron selectivity and layerwise contributions during generation. We find (1) neurons specialized for individual languages alongside a universal subset supporting general-purpose generation; and (2) lower layers mainly encode language-specific syntax, while middle layers capture semantic abstractions shared across languages, emerging as concept layers. We demonstrate utility on three tasks: neuron-guided fine-tuning for code generation, clone detection via concept-layer embeddings, and concept-layer-guided transfer for code summarization, each yielding consistent gains in multilingual settings.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u7684\u795e\u7ecf\u5143\u53ef\u89e3\u91ca\u6027\uff0c\u53d1\u73b0\u8bed\u8a00\u7279\u5b9a\u795e\u7ecf\u5143\u548c\u8de8\u8bed\u8a00\u6982\u5ff5\u5c42\uff0c\u5e76\u5728\u591a\u8bed\u8a00\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u5176\u6548\u7528\u3002", "motivation": "\u73b0\u6709\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u795e\u7ecf\u5143\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u7f16\u7a0b\u8bed\u8a00\uff0c\u9700\u9488\u5bf9\u4ee3\u7801\u7279\u6027\u8fdb\u884c\u4e13\u95e8\u5206\u6790\u3002", "method": "\u5206\u6790Llama-3.1-8B\u4e0eQwen2.5-Coder-32B\u5728C++\u3001Java\u3001Python\u3001Go\u548cJavaScript\u4e0a\u7684\u795e\u7ecf\u5143\u9009\u62e9\u6027\u53ca\u5c42\u6b21\u8d21\u732e\u3002", "result": "\u53d1\u73b0\u8bed\u8a00\u4e13\u7528\u795e\u7ecf\u5143\u4e0e\u901a\u7528\u795e\u7ecf\u5143\u5e76\u5b58\uff1b\u4f4e\u5c42\u7f16\u7801\u8bed\u6cd5\uff0c\u4e2d\u5c42\u5f62\u6210\u8de8\u8bed\u8a00\u8bed\u4e49\u62bd\u8c61\u7684\u6982\u5ff5\u5c42\uff0c\u5e76\u5728\u4e09\u9879\u4efb\u52a1\u4e2d\u53d6\u5f97\u7a33\u5b9a\u63d0\u5347\u3002", "conclusion": "\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u5b58\u5728\u7ed3\u6784\u5316\u53ef\u89e3\u91ca\u673a\u5236\uff0c\u6982\u5ff5\u5c42\u53ef\u7528\u4e8e\u6307\u5bfc\u5fae\u8c03\u3001\u514b\u9686\u68c0\u6d4b\u4e0e\u6458\u8981\u8fc1\u79fb\uff0c\u63d0\u5347\u591a\u8bed\u8a00\u6027\u80fd\u3002"}}
{"id": "2512.20571", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.20571", "abs": "https://arxiv.org/abs/2512.20571", "authors": ["Brennan Romero", "D. G. Perera"], "title": "Composing Mini Oscilloscope on Embedded Systems", "comment": "22 pages, 11 figures", "summary": "In this paper, our goal is to reproduce the basic functionalities of a regular oscilloscope, using the Nuvoton NUC-140 embedded systems development platform as the front-end and display method. A custom-built daughter board connects the NUC-140 to a variety of peripherals, including two BNC scope-probe connections, an external nine-button keypad, and a calibration signal. The LCD of the NUC-140 development board serves as the waveform display. From the experimental results, it is demonstrated that our proposed system became a very competent debugging tool. It implements 90% of the features we typically use on original oscilloscopes, including: automatic, edge-triggered, and single modes; waveform visualization using vertical and horizontal scaling; probe calibration.", "AI": {"tldr": "\u672c\u6587\u5229\u7528NUC-140\u5d4c\u5165\u5f0f\u5e73\u53f0\u5b9e\u73b0\u7c7b\u793a\u6ce2\u5668\u529f\u80fd\uff0c\u5177\u5907\u5e38\u7528\u8c03\u8bd5\u7279\u6027\u3002", "motivation": "\u5f00\u53d1\u4f4e\u6210\u672c\u3001\u4fbf\u643a\u7684\u5d4c\u5165\u5f0f\u793a\u6ce2\u5668\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u81ea\u5236\u5b50\u677f\u8fde\u63a5\u63a2\u5934\u4e0e\u6309\u952e\uff0c\u4ee5NUC-140\u6db2\u6676\u5c4f\u663e\u793a\u6ce2\u5f62\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b090%\u5e38\u7528\u793a\u6ce2\u5668\u529f\u80fd\uff0c\u5982\u81ea\u52a8/\u8fb9\u6cbf\u89e6\u53d1\u3001\u7f29\u653e\u3001\u6821\u51c6\u7b49\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u53ef\u4f5c\u4e3a\u9ad8\u6548\u5b9e\u7528\u7684\u5d4c\u5165\u5f0f\u8c03\u8bd5\u5de5\u5177\u3002"}}
{"id": "2512.20083", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.20083", "abs": "https://arxiv.org/abs/2512.20083", "authors": ["Wenzhao Wu", "Yahui Tang", "Mingfei Cheng", "Wenbing Tang", "Yuan Zhou", "Yang Liu"], "title": "Detecting Non-Optimal Decisions of Embodied Agents via Diversity-Guided Metamorphic Testing", "comment": null, "summary": "As embodied agents advance toward real-world deployment, ensuring optimal decisions becomes critical for resource-constrained applications. Current evaluation methods focus primarily on functional correctness, overlooking the non-functional optimality of generated plans. This gap can lead to significant performance degradation and resource waste. We identify and formalize the problem of Non-optimal Decisions (NoDs), where agents complete tasks successfully but inefficiently. We present NoD-DGMT, a systematic framework for detecting NoDs in embodied agent task planning via diversity-guided metamorphic testing. Our key insight is that optimal planners should exhibit invariant behavioral properties under specific transformations. We design four novel metamorphic relations capturing fundamental optimality properties: position detour suboptimality, action optimality completeness, condition refinement monotonicity, and scene perturbation invariance. To maximize detection efficiency, we introduce a diversity-guided selection strategy that actively selects test cases exploring different violation categories, avoiding redundant evaluations while ensuring comprehensive diversity coverage. Extensive experiments on the AI2-THOR simulator with four state-of-the-art planning models demonstrate that NoD-DGMT achieves violation detection rates of 31.9% on average, with our diversity-guided filter improving rates by 4.3% and diversity scores by 3.3 on average. NoD-DGMT significantly outperforms six baseline methods, with 16.8% relative improvement over the best baseline, and demonstrates consistent superiority across different model architectures and task complexities.", "AI": {"tldr": "\u63d0\u51faNoD-DGMT\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6837\u6027\u5f15\u5bfc\u7684\u8715\u53d8\u6d4b\u8bd5\u68c0\u6d4b\u5177\u8eab\u667a\u80fd\u4f53\u4efb\u52a1\u89c4\u5212\u4e2d\u7684\u975e\u6700\u4f18\u51b3\u7b56\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u7387\u4e0e\u8986\u76d6\u591a\u6837\u6027\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u5ffd\u89c6\u89c4\u5212\u65b9\u6848\u7684\u975e\u529f\u80fd\u6027\u6700\u4f18\u6027\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d6a\u8d39\u548c\u6027\u80fd\u4e0b\u964d\uff0c\u4e9f\u9700\u7cfb\u7edf\u5316\u68c0\u6d4b\u975e\u6700\u4f18\u51b3\u7b56\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u56db\u7c7b\u65b0\u9896\u8715\u53d8\u5173\u7cfb\u6355\u6349\u6700\u4f18\u6027\u5c5e\u6027\uff0c\u5e76\u7ed3\u5408\u591a\u6837\u6027\u5f15\u5bfc\u7b56\u7565\u4e3b\u52a8\u9009\u62e9\u6d4b\u8bd5\u7528\u4f8b\uff0c\u63d0\u5347\u68c0\u6d4b\u6548\u7387\u4e0e\u8986\u76d6\u7387\u3002", "result": "\u5728AI2-THOR\u4eff\u771f\u5668\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0cNoD-DGMT\u5e73\u5747\u68c0\u6d4b\u7387\u8fbe31.9%\uff0c\u8f83\u6700\u4f73\u57fa\u7ebf\u63d0\u534716.8%\uff0c\u591a\u6837\u6027\u8bc4\u5206\u63d0\u9ad83.3\u3002", "conclusion": "NoD-DGMT\u80fd\u6709\u6548\u8bc6\u522b\u5177\u8eab\u667a\u80fd\u4f53\u89c4\u5212\u4e2d\u7684\u4f4e\u6548\u884c\u4e3a\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u573a\u666f\u63d0\u4f9b\u53ef\u9760\u7684\u8d28\u91cf\u4fdd\u969c\u673a\u5236\u3002"}}
{"id": "2512.20017", "categories": ["cs.DC", "cs.GR"], "pdf": "https://arxiv.org/pdf/2512.20017", "abs": "https://arxiv.org/abs/2512.20017", "authors": ["Hexu Zhao", "Xiaoteng Liu", "Xiwen Min", "Jianhao Huang", "Youming Deng", "Yanfei Li", "Ang Li", "Jinyang Li", "Aurojit Panda"], "title": "Scaling Point-based Differentiable Rendering for Large-scale Reconstruction", "comment": "13 pages main text, plus appendix", "summary": "Point-based Differentiable Rendering (PBDR) enables high-fidelity 3D scene reconstruction, but scaling PBDR to high-resolution and large scenes requires efficient distributed training systems. Existing systems are tightly coupled to a specific PBDR method. And they suffer from severe communication overhead due to poor data locality. In this paper, we present Gaian, a general distributed training system for PBDR. Gaian provides a unified API expressive enough to support existing PBDR methods, while exposing rich data-access information, which Gaian leverages to optimize locality and reduce communication. We evaluated Gaian by implementing 4 PBDR algorithms. Our implementations achieve high performance and resource efficiency: across six datasets and up to 128 GPUs, it reduces communication by up to 91% and improves training throughput by 1.50x-3.71x.", "AI": {"tldr": "Gaian \u662f\u4e00\u4e2a\u901a\u7528\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u7cfb\u7edf\uff0c\u4e13\u4e3a\u70b9\u57fa\u53ef\u5fae\u6e32\u67d3\uff08PBDR\uff09\u8bbe\u8ba1\uff0c\u901a\u8fc7\u4f18\u5316\u6570\u636e\u5c40\u90e8\u6027\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u5e76\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\u3002", "motivation": "\u73b0\u6709 PBDR \u5206\u5e03\u5f0f\u7cfb\u7edf\u8026\u5408\u6027\u5f3a\u3001\u901a\u4fe1\u5f00\u9500\u5927\uff0c\u4e9f\u9700\u901a\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa Gaian \u7cfb\u7edf\uff0c\u63d0\u4f9b\u7edf\u4e00 API \u5e76\u5229\u7528\u6570\u636e\u8bbf\u95ee\u4fe1\u606f\u4f18\u5316\u5c40\u90e8\u6027\u4e0e\u901a\u4fe1\u6548\u7387\u3002", "result": "\u5728 4 \u79cd PBDR \u7b97\u6cd5\u548c 6 \u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u901a\u4fe1\u51cf\u5c11\u8fbe 91%\uff0c\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u5347 1.50x-3.71x\u3002", "conclusion": "Gaian \u5728\u4fdd\u6301\u901a\u7528\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86 PBDR \u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2512.20159", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20159", "abs": "https://arxiv.org/abs/2512.20159", "authors": ["Ruiqi Wang", "Xinchen Wang", "Cuiyun Gao", "Chun Yong Chong", "Xin Xia", "Qing Liao"], "title": "AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration", "comment": null, "summary": "Large language models (LLMs) have been increasingly deployed in real-world software engineering, fostering the development of code evaluation metrics to study the quality of LLM-generated code. Conventional rule-based metrics merely score programs based on their surface-level similarities with reference programs instead of analyzing functionality and code quality in depth. To address this limitation, researchers have developed LLM-as-a-judge metrics, prompting LLMs to evaluate and score code, and curated various code evaluation benchmarks to validate their effectiveness. However, these benchmarks suffer from critical limitations, hindering reliable assessments of evaluation capability: Some feature coarse-grained binary labels, which reduce rich code behavior to a single bit of information, obscuring subtle errors. Others propose fine-grained but subjective, vaguely-defined evaluation criteria, introducing unreliability in manually-annotated scores, which is the ground-truth they rely on. Furthermore, they often use uncontrolled data synthesis methods, leading to unbalanced score distributions that poorly represent real-world code generation scenarios.\n  To curate a diverse benchmark with programs of well-balanced distributions across various quality levels and streamline the manual annotation procedure, we propose AXIOM, a novel perturbation-based framework for synthesizing code evaluation benchmarks at scale. It reframes program scores as the refinement effort needed for deployment, consisting of two stages: (1) Rule-guided perturbation, which prompts LLMs to apply sequences of predefined perturbation rules to existing high-quality programs to modify their functionality and code quality, enabling us to precisely control each program's target score to achieve balanced score distributions. (2) Multisource quality calibration, which first selects a subset of...", "AI": {"tldr": "\u63d0\u51faAXIOM\u6846\u67b6\uff0c\u901a\u8fc7\u6270\u52a8\u548c\u591a\u6e90\u6821\u51c6\u6784\u5efa\u9ad8\u8d28\u91cf\u3001\u5e73\u8861\u5206\u5e03\u7684\u4ee3\u7801\u8bc4\u4f30\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u6807\u7b7e\u7c97\u7cd9\u3001\u4e3b\u89c2\u6027\u5f3a\u3001\u6570\u636e\u5206\u5e03\u4e0d\u5e73\u8861\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u53ef\u9760\u8bc4\u4f30LLM\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u89c4\u5219\u5f15\u5bfc\u6270\u52a8\u4e0e\u591a\u6e90\u8d28\u91cf\u6821\u51c6\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u5229\u7528LLM\u5bf9\u9ad8\u8d28\u91cf\u7a0b\u5e8f\u65bd\u52a0\u53ef\u63a7\u6270\u52a8\u751f\u6210\u4e0d\u540c\u8d28\u91cf\u7b49\u7ea7\u6837\u672c\uff0c\u5e76\u6821\u51c6\u8bc4\u5206\u4e00\u81f4\u6027\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u8986\u76d6\u591a\u79cd\u8d28\u91cf\u5c42\u7ea7\u3001\u5206\u5e03\u5747\u8861\u4e14\u6807\u6ce8\u53ef\u9760\u7684\u4ee3\u7801\u8bc4\u4f30\u57fa\u51c6\uff0c\u63d0\u5347\u8bc4\u4f30\u6307\u6807\u7684\u6709\u6548\u6027\u3002", "conclusion": "AXIOM\u4e3a\u5927\u89c4\u6a21\u5408\u6210\u9ad8\u8d28\u91cf\u4ee3\u7801\u8bc4\u4f30\u57fa\u51c6\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8LLM\u4ee3\u7801\u8bc4\u4f30\u7814\u7a76\u8fc8\u5411\u66f4\u53ef\u9760\u3001\u5b9e\u7528\u7684\u65b9\u5411\u3002"}}
{"id": "2512.20203", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.20203", "abs": "https://arxiv.org/abs/2512.20203", "authors": ["Zhenlei Ye", "Xiaobing Sun", "Sicong Cao", "Lili Bo", "Bin Li"], "title": "Well Begun is Half Done: Location-Aware and Trace-Guided Iterative Automated Vulnerability Repair", "comment": "Accepted by ICSE 2026", "summary": "The advances of large language models (LLMs) have paved the way for automated software vulnerability repair approaches, which iteratively refine the patch until it becomes plausible. Nevertheless, existing LLM-based vulnerability repair approaches face notable limitations: 1) they ignore the concern of locations that need to be patched and focus solely on the repair content. 2) they lack quality assessment for generated candidate patches in the iterative process.\n  To tackle the two limitations, we propose \\sysname, an LLM-based approach that provides information about where should be patched first. Furthermore, \\sysname improves the iterative repair strategy by assessing the quality of test-failing patches and selecting the best patch for the next iteration. We introduce two dimensions to assess the quality of patches: whether they introduce new vulnerabilities and the taint statement coverage. We evaluated \\sysname on a real-world C/C++ vulnerability repair dataset VulnLoc+, which contains 40 vulnerabilities and their Proofs-of-Vulnerability. The experimental results demonstrate that \\sysname exhibits substantial improvements compared with the Neural Machine Translation-based, Program Analysis-based, and LLM-based state-of-the-art vulnerability repair approaches. Specifically, \\sysname is able to generate 27 plausible patches, which is comparable to or even 8 to 22 more plausible patches than the baselines. In terms of correct patch generation, \\sysname repairs 8 to 13 additional vulnerabilities compared with existing approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6f0f\u6d1e\u4fee\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u4f4d\u4fee\u590d\u4f4d\u7f6e\u5e76\u8bc4\u4f30\u8865\u4e01\u8d28\u91cf\u63d0\u5347\u4fee\u590d\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u6f0f\u6d1e\u4fee\u590d\u65b9\u6cd5\u5ffd\u89c6\u4fee\u590d\u4f4d\u7f6e\u5b9a\u4f4d\u548c\u8865\u4e01\u8d28\u91cf\u8bc4\u4f30\u3002", "method": "\u5f15\u5165\u8865\u4e01\u4f4d\u7f6e\u63d0\u793a\u4e0e\u53cc\u7ef4\u5ea6\u8d28\u91cf\u8bc4\u4f30\uff08\u65b0\u6f0f\u6d1e\u5f15\u5165\u98ce\u9669\u3001\u6c61\u70b9\u8bed\u53e5\u8986\u76d6\u7387\uff09\uff0c\u8fed\u4ee3\u4f18\u5316\u4fee\u590d\u8fc7\u7a0b\u3002", "result": "\u5728VulnLoc+\u6570\u636e\u96c6\u4e0a\u751f\u621027\u4e2a\u5408\u7406\u8865\u4e01\uff0c\u6bd4\u57fa\u7ebf\u591a\u4fee\u590d8\u81f313\u4e2a\u6f0f\u6d1e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7ffb\u8bd1\u578b\u3001\u7a0b\u5e8f\u5206\u6790\u578b\u53caLLM\u578b\u6f0f\u6d1e\u4fee\u590d\u6280\u672f\u3002"}}
{"id": "2512.20163", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.20163", "abs": "https://arxiv.org/abs/2512.20163", "authors": ["Leszek G\u0105sieniec", "Tytus Grodzicki", "Tomasz Jurdzi\u0144ski", "Jakub Kowalski", "Grzegorz Stachowiak"], "title": "Population Protocols Revisited: Parity and Beyond", "comment": null, "summary": "For nearly two decades, population protocols have been extensively studied, yielding efficient solutions for central problems in distributed computing, including leader election, and majority computation, a predicate type in Presburger Arithmetic closely tied to population protocols. Surprisingly, no protocols have achieved both time- and space-efficiency for congruency predicates, such as parity computation, which are complementary in this arithmetic framework. This gap highlights a significant challenge in the field. To address this gap, we explore the parity problem, where agents are tasked with computing the parity of the given sub-population size. Then we extend the solution for parity to compute congruences modulo an arbitrary $m$.\n  Previous research on efficient population protocols has focused on protocols that minimise both stabilisation time and state utilisation for specific problems. In contrast, this work slightly relaxes this expectation, permitting protocols to place less emphasis on full optimisation and more on universality, robustness, and probabilistic guarantees. This allows us to propose a novel computing paradigm that integrates population weights (or simply weights), a robust clocking mechanism, and efficient anomaly detection coupled with a switching mechanism (which ensures slow but always correct solutions). This paradigm facilitates universal design of efficient multistage stable population protocols. Specifically, the first efficient parity and congruence protocols introduced here use both $O(\\log^3 n)$ states and achieve silent stabilisation in $O(\\log^3 n)$ time. We conclude by discussing the impact of implicit conversion between unary and binary representations enabled by the weight system, with applications to other problems, including the computation and representation of (sub-)population sizes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6743\u91cd\u548c\u65f6\u949f\u673a\u5236\u7684\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u7fa4\u4f53\u534f\u8bae\uff0c\u9996\u6b21\u5728\u65f6\u95f4\u548c\u7a7a\u95f4\u4e0a\u540c\u65f6\u9ad8\u6548\u89e3\u51b3\u5947\u5076\u6027\u548c\u6a21\u8fd0\u7b97\u95ee\u9898\u3002", "motivation": "\u586b\u8865\u7fa4\u4f53\u534f\u8bae\u4e2d\u5947\u5076\u6027\u53ca\u540c\u4f59\u8c13\u8bcd\u7f3a\u4e4f\u65f6\u7a7a\u9ad8\u6548\u89e3\u6cd5\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5f15\u5165\u6743\u91cd\u7cfb\u7edf\u3001\u9c81\u68d2\u65f6\u949f\u4e0e\u5f02\u5e38\u68c0\u6d4b\u5207\u6362\u673a\u5236\uff0c\u6784\u5efa\u591a\u9636\u6bb5\u7a33\u5b9a\u534f\u8bae\u6846\u67b6\u3002", "result": "\u9996\u4e2a\u5b9e\u73b0O(log\u00b3n)\u72b6\u6001\u6570\u4e0eO(log\u00b3n)\u9759\u9ed8\u7a33\u5b9a\u65f6\u95f4\u7684\u5947\u5076\u6027\u4e0e\u6a21m\u540c\u4f59\u534f\u8bae\u3002", "conclusion": "\u8be5\u8303\u5f0f\u652f\u6301\u9690\u5f0f\u4e00\u8fdb\u5236-\u4e8c\u8fdb\u5236\u8f6c\u6362\uff0c\u53ef\u63a8\u5e7f\u81f3\u5b50\u7fa4\u4f53\u89c4\u6a21\u8ba1\u7b97\u7b49\u5176\u4ed6\u95ee\u9898\uff0c\u63d0\u5347\u534f\u8bae\u901a\u7528\u6027\u4e0e\u5b9e\u7528\u6027\u3002"}}
{"id": "2512.20328", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.20328", "abs": "https://arxiv.org/abs/2512.20328", "authors": ["Antonio Vitale", "Khai-Nguyen Nguyen", "Denys Poshyvanyk", "Rocco Oliveto", "Simone Scalabrino", "Antonio Mastropaolo"], "title": "Toward Explaining Large Language Models in Software Engineering Tasks", "comment": null, "summary": "Recent progress in Large Language Models (LLMs) has substantially advanced the automation of software engineering (SE) tasks, enabling complex activities such as code generation and code summarization. However, the black-box nature of LLMs remains a major barrier to their adoption in high-stakes and safety-critical domains, where explainability and transparency are vital for trust, accountability, and effective human supervision. Despite increasing interest in explainable AI for software engineering, existing methods lack domain-specific explanations aligned with how practitioners reason about SE artifacts. To address this gap, we introduce FeatureSHAP, the first fully automated, model-agnostic explainability framework tailored to software engineering tasks. Based on Shapley values, FeatureSHAP attributes model outputs to high-level input features through systematic input perturbation and task-specific similarity comparisons, while remaining compatible with both open-source and proprietary LLMs. We evaluate FeatureSHAP on two bi-modal SE tasks: code generation and code summarization. The results show that FeatureSHAP assigns less importance to irrelevant input features and produces explanations with higher fidelity than baseline methods. A practitioner survey involving 37 participants shows that FeatureSHAP helps practitioners better interpret model outputs and make more informed decisions. Collectively, FeatureSHAP represents a meaningful step toward practical explainable AI in software engineering. FeatureSHAP is available at https://github.com/deviserlab/FeatureSHAP.", "AI": {"tldr": "FeatureSHAP \u662f\u9996\u4e2a\u9762\u5411\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684\u81ea\u52a8\u5316\u3001\u6a21\u578b\u65e0\u5173\u7684\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u57fa\u4e8e Shapley \u503c\u63d0\u4f9b\u9ad8\u4fdd\u771f\u89e3\u91ca\uff0c\u63d0\u5347\u5f00\u53d1\u8005\u5bf9 LLM \u8f93\u51fa\u7684\u7406\u89e3\u4e0e\u51b3\u7b56\u80fd\u529b\u3002", "motivation": "LLM \u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u9ed1\u76d2\u7279\u6027\u963b\u788d\u4e86\u5728\u5173\u952e\u9886\u57df\u7684\u53ef\u4fe1\u90e8\u7f72\uff0c\u4e9f\u9700\u5951\u5408\u5f00\u53d1\u8005\u601d\u7ef4\u7684\u9886\u57df\u4e13\u5c5e\u89e3\u91ca\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e Shapley \u503c\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u8f93\u5165\u6270\u52a8\u548c\u4efb\u52a1\u7279\u5b9a\u76f8\u4f3c\u5ea6\u6bd4\u8f83\uff0c\u5c06\u6a21\u578b\u8f93\u51fa\u5f52\u56e0\u4e8e\u9ad8\u5c42\u8f93\u5165\u7279\u5f81\uff0c\u517c\u5bb9\u5f00\u6e90\u4e0e\u95ed\u6e90 LLM\u3002", "result": "\u5728\u4ee3\u7801\u751f\u6210\u4e0e\u6458\u8981\u4efb\u52a1\u4e2d\uff0cFeatureSHAP \u80fd\u964d\u4f4e\u65e0\u5173\u7279\u5f81\u6743\u91cd\uff0c\u89e3\u91ca\u4fdd\u771f\u5ea6\u4f18\u4e8e\u57fa\u7ebf\uff1b37 \u540d\u4ece\u4e1a\u8005\u8c03\u67e5\u8868\u660e\u5176\u6709\u6548\u8f85\u52a9\u7406\u89e3\u4e0e\u51b3\u7b56\u3002", "conclusion": "FeatureSHAP \u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5b9e\u7528\u5316\u53ef\u89e3\u91ca AI \u63d0\u4f9b\u4e86\u91cd\u8981\u8fdb\u5c55\uff0c\u63a8\u52a8 LLM \u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e0b\u7684\u53ef\u4fe1\u5e94\u7528\u3002"}}
{"id": "2512.20334", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.20334", "abs": "https://arxiv.org/abs/2512.20334", "authors": ["Yuan Huang", "Yukang Zhou", "Xiangping Chen", "Zibin Zheng"], "title": "Comment Traps: How Defective Commented-out Code Augment Defects in AI-Assisted Code Generation", "comment": "This paper has been accepted by FSE 2026 (ACM International Conference on the Foundations of Software Engineering). This is a preprint version and may differ from the final published version", "summary": "With the rapid development of large language models in code generation, AI-powered editors such as GitHub Copilot and Cursor are revolutionizing software development practices. At the same time, studies have identified potential defects in the generated code. Previous research has predominantly examined how code context influences the generation of defective code, often overlooking the impact of defects within commented-out code (CO code). AI coding assistants' interpretation of CO code in prompts affects the code they generate.\n  This study evaluates how AI coding assistants, GitHub Copilot and Cursor, are influenced by defective CO code. The experimental results show that defective CO code in the context causes AI coding assistants to generate more defective code, reaching up to 58.17 percent. Our findings further demonstrate that the tools do not simply copy the defective code from the context. Instead, they actively reason to complete incomplete defect patterns and continue to produce defective code despite distractions such as incorrect indentation or tags. Even with explicit instructions to ignore the defective CO code, the reduction in defects does not exceed 21.84 percent. These findings underscore the need for improved robustness and security measures in AI coding assistants.", "AI": {"tldr": "\u7f3a\u9677\u6ce8\u91ca\u4ee3\u7801\u663e\u8457\u5f71\u54cdAI\u7f16\u7a0b\u52a9\u624b\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\uff0c\u5373\u4f7f\u660e\u786e\u6307\u793a\u5ffd\u7565\uff0c\u7f3a\u9677\u7387\u4ecd\u9ad8\u8fbe58.17%\uff0c\u51f8\u663e\u63d0\u5347\u5176\u9c81\u68d2\u6027\u4e0e\u5b89\u5168\u6027\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63ed\u793a\u6ce8\u91ca\u4ee3\u7801\u4e2d\u7684\u7f3a\u9677\u5982\u4f55\u5f71\u54cdAI\u7f16\u7a0b\u52a9\u624b\u7684\u4ee3\u7801\u751f\u6210\u884c\u4e3a\uff0c\u5f25\u8865\u73b0\u6709\u7814\u7a76\u5bf9\u6ce8\u91ca\u7f3a\u9677\u5f71\u54cd\u7684\u5ffd\u89c6\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30GitHub Copilot\u548cCursor\u5728\u5305\u542b\u7f3a\u9677\u6ce8\u91ca\u4ee3\u7801\u4e0a\u4e0b\u6587\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u6790\u5176\u751f\u6210\u4ee3\u7801\u7684\u7f3a\u9677\u7387\u53ca\u884c\u4e3a\u6a21\u5f0f\u3002", "result": "\u7f3a\u9677\u6ce8\u91ca\u4ee3\u7801\u4f7fAI\u52a9\u624b\u751f\u6210\u7f3a\u9677\u4ee3\u7801\u7684\u6bd4\u4f8b\u9ad8\u8fbe58.17%\uff1b\u5373\u4f7f\u7ed9\u4e88\u5ffd\u7565\u6307\u4ee4\uff0c\u7f3a\u9677\u51cf\u5c11\u4e0d\u8d85\u8fc721.84%\uff1b\u5de5\u5177\u4f1a\u4e3b\u52a8\u63a8\u7406\u8865\u5168\u7f3a\u9677\u6a21\u5f0f\u3002", "conclusion": "\u5f53\u524dAI\u7f16\u7a0b\u52a9\u624b\u5bf9\u6ce8\u91ca\u7f3a\u9677\u7f3a\u4e4f\u8db3\u591f\u9c81\u68d2\u6027\uff0c\u4e9f\u9700\u6539\u8fdb\u5176\u5b89\u5168\u6027\u4e0e\u6297\u5e72\u6270\u80fd\u529b\u4ee5\u4fdd\u969c\u4ee3\u7801\u8d28\u91cf\u3002"}}
{"id": "2512.20184", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.20184", "abs": "https://arxiv.org/abs/2512.20184", "authors": ["Chaoyi Ruan", "Yiliang Wang", "Ziji Shi", "Jialin Li"], "title": "Reaching Agreement Among Reasoning LLM Agents", "comment": null, "summary": "Multi-agent systems have extended the capability of agentic AI. Instead of single inference passes, multiple agents perform collective reasoning to derive high quality answers. However, existing multi-agent orchestration relies on static heuristic workflows such as fixed loop limits and barrier synchronization. These ad-hoc approaches waste computational resources, incur high latency due to stragglers, and risk finalizing transient agreements. We argue that reliable multi-agent reasoning requires a formal foundation analogous to classical distributed consensus problem.\n  To that end, we propose a formal model of the multi-agent refinement problem. The model includes definitions of the correctness guarantees and formal semantics of agent reasoning. We then introduce Aegean, a consensus protocol designed for stochastic reasoning agents that solves multi-agent refinement. We implement the protocol in Aegean-Serve, a consensus-aware serving engine that performs incremental quorum detection across concurrent agent executions, enabling early termination when sufficient agents converge. Evaluation using four mathematical reasoning benchmarks shows that Aegean provides provable safety and liveness guarantees while reducing latency by 1.2--20$\\times$ compared to state-of-the-art baselines, maintaining answer quality within 2.5%. Consistent gains across both local GPU deployments and commercial API providers validate that consensus-based orchestration eliminates straggler delays without sacrificing correctness.", "AI": {"tldr": "Aegean\u534f\u8bae\u901a\u8fc7\u5171\u8bc6\u673a\u5236\u4f18\u5316\u591a\u667a\u80fd\u4f53\u63a8\u7406\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u5e76\u4fdd\u8bc1\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u9759\u6001\u542f\u53d1\u5f0f\u5de5\u4f5c\u6d41\u6d6a\u8d39\u8d44\u6e90\u3001\u5ef6\u8fdf\u9ad8\u4e14\u6613\u53d7\u77ac\u6001\u534f\u8bae\u5f71\u54cd\uff0c\u9700\u5f62\u5f0f\u5316\u57fa\u7840\u63d0\u5347\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7cbe\u70bc\u95ee\u9898\u7684\u5f62\u5f0f\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u9002\u7528\u4e8e\u968f\u673a\u63a8\u7406\u667a\u80fd\u4f53\u7684Aegean\u5171\u8bc6\u534f\u8bae\u53ca\u914d\u5957\u5f15\u64ceAegean-Serve\u3002", "result": "\u5728\u56db\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\uff0cAegean\u5c06\u5ef6\u8fdf\u964d\u4f4e1.2-20\u500d\uff0c\u7b54\u6848\u8d28\u91cf\u635f\u5931\u4e0d\u8d85\u8fc72.5%\uff0c\u4e14\u5728\u672c\u5730GPU\u548c\u5546\u4e1aAPI\u4e2d\u5747\u6709\u6548\u3002", "conclusion": "\u57fa\u4e8e\u5171\u8bc6\u7684\u7f16\u6392\u80fd\u6d88\u9664\u62d6\u5c3e\u5ef6\u8fdf\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u6b63\u786e\u6027\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u53ef\u9760\u5f62\u5f0f\u5316\u57fa\u7840\u3002"}}
{"id": "2512.20345", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.20345", "abs": "https://arxiv.org/abs/2512.20345", "authors": ["Xiaoxue Ma", "Wanwei Zhan", "Jiale Chen", "Yishu Li", "Jacky Keung", "Federica Sarro"], "title": "A Comprehensive Study of Bugs in Modern Distributed Deep Learning Systems", "comment": null, "summary": "In today's data-driven era, deep learning is vital for processing massive datasets, yet single-device training is constrained by computational and memory limits. Distributed deep learning overcomes these challenges by leveraging multiple GPUs or machines in parallel. While general-purpose frameworks (e.g., TensorFlow and PyTorch) provide distributed capabilities, these are often add-on features that demand significant manual effort for advanced parallelism, underscoring the need for specialized frameworks. This study conducts the first large-scale empirical analysis of practitioner challenges in dedicated distributed frameworks. We examine 849 real-world issues from DeepSpeed, Megatron-LM, and Colossal-AI and construct a taxonomy of 34 bug symptoms, 28 root causes, and 6 fix patterns. Crucially, we establish explicit mappings between symptoms, causes, and fixes across distributed training stages, enabling a systematic understanding of how issues emerge and are resolved. Our results show that 45.1\\% of bug symptoms are unique to distributed frameworks, with setup failures, memory issues, and performance anomalies being the most prevalent. Moreover, 95\\% of issues in the communication setup stage occur exclusively in distributed contexts. We also find over 60\\% of cases can be resolved through version and dependency management, and distributed feature, API, and communication tuning. Based on these findings, we provide actionable implications.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u4e13\u7528\u5206\u5e03\u5f0f\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4e2d\u7684\u5b9e\u8df5\u8005\u6311\u6218\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u6784\u5efa\u4e86\u5305\u542b34\u79cd\u75c7\u72b6\u300128\u4e2a\u6839\u672c\u539f\u56e0\u548c6\u79cd\u4fee\u590d\u6a21\u5f0f\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u63d0\u51fa\u9488\u5bf9\u6027\u5efa\u8bae\u3002", "motivation": "\u901a\u7528\u6846\u67b6\u7684\u5206\u5e03\u5f0f\u529f\u80fd\u591a\u4e3a\u9644\u52a0\u7279\u6027\uff0c\u624b\u52a8\u5b9e\u73b0\u9ad8\u7ea7\u5e76\u884c\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4e9f\u9700\u6df1\u5165\u7406\u89e3\u4e13\u7528\u5206\u5e03\u5f0f\u6846\u67b6\u4e2d\u7684\u95ee\u9898\u4e0e\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5206\u6790\u6765\u81eaDeepSpeed\u3001Megatron-LM\u548cColossal-AI\u7684849\u4e2a\u771f\u5b9e\u95ee\u9898\uff0c\u6784\u5efa\u75c7\u72b6-\u539f\u56e0-\u4fee\u590d\u6620\u5c04\u5173\u7cfb\uff0c\u5e76\u6309\u8bad\u7ec3\u9636\u6bb5\u7cfb\u7edf\u5f52\u7c7b\u3002", "result": "45.1%\u7684\u75c7\u72b6\u4e3a\u5206\u5e03\u5f0f\u7279\u6709\uff0c\u901a\u4fe1\u8bbe\u7f6e\u9636\u6bb595%\u7684\u95ee\u9898\u4ec5\u51fa\u73b0\u5728\u5206\u5e03\u5f0f\u73af\u5883\uff1b\u8d8560%\u95ee\u9898\u53ef\u901a\u8fc7\u7248\u672c\u4f9d\u8d56\u7ba1\u7406\u53ca\u901a\u4fe1\u8c03\u4f18\u89e3\u51b3\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u5206\u5e03\u5f0f\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684\u6838\u5fc3\u75db\u70b9\uff0c\u4e3a\u5f00\u53d1\u8005\u4f18\u5316\u5de5\u5177\u94fe\u3001\u63d0\u5347\u7a33\u5b9a\u6027\u4e0e\u6613\u7528\u6027\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u548c\u884c\u52a8\u6307\u5357\u3002"}}
{"id": "2512.20210", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.20210", "abs": "https://arxiv.org/abs/2512.20210", "authors": ["Yinan Ni", "Xiao Yang", "Yuqi Tang", "Zhimin Qiu", "Chen Wang", "Tingzhou Yuan"], "title": "Predictive-LoRA: A Proactive and Fragmentation-Aware Serverless Inference System for LLMs", "comment": null, "summary": "The serverless computing paradigm offers compelling advantages for deploying Large Language Model (LLM) inference services, including elastic scaling and pay-per-use billing. However, serving multiple fine-tuned LLMs via Low-Rank Adaptation (LoRA) in serverless environments faces critical challenges: reactive adapter loading causes significant cold start latency, and frequent adapter swapping leads to severe GPU memory fragmentation. In this paper, we present Predictive-LoRA (P-LoRA), a proactive and fragmentation-aware serverless inference system for LoRA-based LLMs. P-LoRA introduces two key innovations: (1) a lightweight LSTM-based traffic predictor that forecasts adapter demand and proactively prefetches hot adapters from host memory to GPU, reducing cold start latency by up to 68%; and (2) a page-based adapter memory management mechanism inspired by operating system virtual memory, which keeps GPU memory utilization above 87% even under heterogeneous adapter ranks. We evaluate P-LoRA using production-like workloads derived from the Azure Functions trace. Experimental results demonstrate that P-LoRA achieves 1.52x higher throughput than S-LoRA while reducing the average Time-To-First-Token (TTFT) by 35% under high concurrency scenarios.", "AI": {"tldr": "P-LoRA \u662f\u4e00\u79cd\u9762\u5411 LoRA \u5fae\u8c03\u6a21\u578b\u7684\u65e0\u670d\u52a1\u5668\u63a8\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u9884\u6d4b\u9884\u52a0\u8f7d\u548c\u5206\u9875\u5185\u5b58\u7ba1\u7406\u663e\u8457\u964d\u4f4e\u51b7\u542f\u52a8\u5ef6\u8fdf\u5e76\u63d0\u5347 GPU \u5229\u7528\u7387\u3002", "motivation": "\u89e3\u51b3\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e0b\u591a LoRA \u6a21\u578b\u63a8\u7406\u65f6\u7684\u51b7\u542f\u52a8\u5ef6\u8fdf\u4e0e\u663e\u5b58\u788e\u7247\u95ee\u9898\u3002", "method": "\u5f15\u5165 LSTM \u6d41\u91cf\u9884\u6d4b\u5668\u4e3b\u52a8\u9884\u52a0\u8f7d\u9002\u914d\u5668\uff0c\u5e76\u91c7\u7528\u7c7b\u64cd\u4f5c\u7cfb\u7edf\u7684\u5206\u9875\u673a\u5236\u7ba1\u7406\u663e\u5b58\u3002", "result": "\u5728 Azure \u5de5\u4f5c\u8d1f\u8f7d\u4e0b\uff0c\u541e\u5410\u91cf\u63d0\u5347 1.52 \u500d\uff0cTTFT \u964d\u4f4e 35%\uff0cGPU \u5229\u7528\u7387\u7ef4\u6301\u5728 87% \u4ee5\u4e0a\u3002", "conclusion": "P-LoRA \u6709\u6548\u4f18\u5316\u4e86\u65e0\u670d\u52a1\u5668\u67b6\u6784\u4e2d LoRA \u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u4e0e\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2512.20381", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.20381", "abs": "https://arxiv.org/abs/2512.20381", "authors": ["Syeda Tasnim Fabiha", "Saad Shafiq", "Wesley Klewerton Guez Assun\u00e7\u00e3o", "Nenad Medvidovi\u0107"], "title": "Identifying Appropriately-Sized Services with Deep Reinforcement Learning", "comment": "22 pages, 6 figures", "summary": "Service-based architecture (SBA) has gained attention in industry and academia as a means to modernize legacy systems. It refers to a design style that enables systems to be developed as suites of small, loosely coupled, and autonomous components (services) that encapsulate functionality and communicate via language-agnostic APIs. However, defining appropriately sized services that capture cohesive subsets of system functionality remains challenging. Existing work often relies on the availability of documentation, access to project personnel, or a priori knowledge of the target number of services, assumptions that do not hold in many real-world scenarios. Our work addresses these limitations using a deep reinforcement learning-based approach to identify appropriately sized services directly from implementation artifacts. We present Rake, a reinforcement learning-based technique that leverages available system documentation and source code to guide service decomposition at the level of implementation methods. Rake does not require specific documentation or access to project personnel and is language-agnostic. It also supports a customizable objective function that balances modularization quality and business capability alignment, i.e., the degree to which a service covers the targeted business capability. We applied Rake to four open-source legacy projects and compared it with two state-of-the-art techniques. On average, Rake achieved 7-14 percent higher modularization quality and 18-22 percent stronger business capability alignment. Our results further show that optimizing solely for business context can degrade decomposition quality in tightly coupled systems, highlighting the need for balanced objectives.", "AI": {"tldr": "Rake\u662f\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u670d\u52a1\u5206\u89e3\u65b9\u6cd5\uff0c\u80fd\u4ece\u6e90\u4ee3\u7801\u548c\u6587\u6863\u4e2d\u81ea\u52a8\u8bc6\u522b\u5408\u9002\u5927\u5c0f\u7684\u670d\u52a1\uff0c\u65e0\u9700\u4f9d\u8d56\u9879\u76ee\u4eba\u5458\u6216\u7279\u5b9a\u6587\u6863\uff0c\u4e14\u652f\u6301\u81ea\u5b9a\u4e49\u76ee\u6807\u51fd\u6570\u5e73\u8861\u6a21\u5757\u5316\u8d28\u91cf\u548c\u4e1a\u52a1\u80fd\u529b\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u670d\u52a1\u5212\u5206\u65b9\u6cd5\u5e38\u4f9d\u8d56\u6587\u6863\u3001\u4eba\u5458\u77e5\u8bc6\u6216\u9884\u8bbe\u670d\u52a1\u6570\u91cf\uff0c\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u96be\u4ee5\u9002\u7528\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u3001\u8bed\u8a00\u65e0\u5173\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faRake\u65b9\u6cd5\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u4ece\u5b9e\u73b0\u6784\u4ef6\uff08\u5982\u6e90\u7801\uff09\u51fa\u53d1\uff0c\u5728\u65b9\u6cd5\u7ea7\u522b\u5f15\u5bfc\u670d\u52a1\u5206\u89e3\uff0c\u5e76\u652f\u6301\u5b9a\u5236\u76ee\u6807\u51fd\u6570\u4ee5\u517c\u987e\u6a21\u5757\u8d28\u91cf\u4e0e\u4e1a\u52a1\u80fd\u529b\u5339\u914d\u3002", "result": "\u5728\u56db\u4e2a\u5f00\u6e90\u9057\u7559\u9879\u76ee\u4e0a\u9a8c\u8bc1\uff0cRake\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5e73\u5747\u63d0\u5347\u6a21\u5757\u5316\u8d28\u91cf7-14%\uff0c\u4e1a\u52a1\u80fd\u529b\u5bf9\u9f50\u5ea618-22%\uff1b\u540c\u65f6\u53d1\u73b0\u4ec5\u4f18\u5316\u4e1a\u52a1\u4e0a\u4e0b\u6587\u4f1a\u635f\u5bb3\u7d27\u8026\u5408\u7cfb\u7edf\u7684\u5206\u89e3\u8d28\u91cf\u3002", "conclusion": "Rake\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u3001\u81ea\u52a8\u5316\u3001\u53ef\u5b9a\u5236\u7684\u670d\u52a1\u5212\u5206\u65b9\u6848\uff0c\u6709\u6548\u5e94\u5bf9\u73b0\u5b9e\u7ea6\u675f\uff0c\u5f3a\u8c03\u5e73\u8861\u6a21\u5757\u5316\u4e0e\u4e1a\u52a1\u76ee\u6807\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.20485", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.20485", "abs": "https://arxiv.org/abs/2512.20485", "authors": ["Tanisha Fonseca", "Gengrui Zhang"], "title": "WOC: Dual-Path Weighted Object Consensus Made Efficient", "comment": null, "summary": "Modern distributed systems face a critical challenge: existing consensus protocols optimize for either node heterogeneity or workload independence, but not both. For example, Cabinet leverages weighted quorums to handle node heterogeneity but serializes all operations through a global leader, limiting parallelism. EPaxos enables parallel execution for independent operations but treats all nodes uniformly, ignoring performance differences. To tackle this problem, we present WOC, a dual-path consensus protocol that dynamically routes operations into two paths based on their access patterns. Independent operations execute through a fast path that uses object-specific weighted quorums and completes in one network round-trip. Conflicting or shared objects route through a leader-coordinated slow path employing node-weighted consensus. Our evaluation demonstrates that WOC achieves up to 4X higher throughput than Cabinet for workloads with >70% independent objects, while maintaining equivalent performance under high contention.", "AI": {"tldr": "WOC\u662f\u4e00\u79cd\u53cc\u8def\u5f84\u5171\u8bc6\u534f\u8bae\uff0c\u901a\u8fc7\u52a8\u6001\u8def\u7531\u64cd\u4f5c\u63d0\u5347\u541e\u5410\u91cf\uff0c\u517c\u987e\u8282\u70b9\u5f02\u6784\u6027\u548c\u5de5\u4f5c\u8d1f\u8f7d\u72ec\u7acb\u6027\u3002", "motivation": "\u73b0\u6709\u5171\u8bc6\u534f\u8bae\u65e0\u6cd5\u540c\u65f6\u4f18\u5316\u8282\u70b9\u5f02\u6784\u6027\u548c\u5de5\u4f5c\u8d1f\u8f7d\u72ec\u7acb\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u74f6\u9888\u3002", "method": "\u8bbe\u8ba1\u53cc\u8def\u5f84\u673a\u5236\uff1a\u72ec\u7acb\u64cd\u4f5c\u8d70\u5feb\u901f\u8def\u5f84\uff08\u5bf9\u8c61\u52a0\u6743\u6cd5\u5b9a\u4eba\u6570\uff09\uff0c\u51b2\u7a81\u64cd\u4f5c\u8d70\u6162\u901f\u8def\u5f84\uff08\u8282\u70b9\u52a0\u6743\u5171\u8bc6\uff09\u3002", "result": "\u5728>70%\u72ec\u7acb\u5bf9\u8c61\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\uff0cWOC\u541e\u5410\u91cf\u6bd4Cabinet\u9ad84\u500d\uff0c\u9ad8\u4e89\u7528\u573a\u666f\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "WOC\u6709\u6548\u5e73\u8861\u4e86\u5e76\u884c\u6027\u548c\u8282\u70b9\u5f02\u6784\u6027\uff0c\u663e\u8457\u63d0\u5347\u5206\u5e03\u5f0f\u7cfb\u7edf\u6027\u80fd\u3002"}}
