{"id": "2511.00074", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00074", "abs": "https://arxiv.org/abs/2511.00074", "authors": ["Richard Osuagwu", "Thomas Cook", "Maraim Masoud", "Koustav Ghosal", "Riccardo Mattivi"], "title": "ScaleCall -- Agentic Tool Calling at Scale for Fintech: Challenges, Methods, and Deployment Insights", "comment": null, "summary": "While Large Language Models (LLMs) excel at tool calling, deploying these\ncapabilities in regulated enterprise environments such as fintech presents\nunique challenges due to on-premises constraints, regulatory compliance\nrequirements, and the need to disambiguate large, functionally overlapping\ntoolsets. In this paper, we present a comprehensive study of tool retrieval\nmethods for enterprise environments through the development and deployment of\nScaleCall, a prototype tool-calling framework within Mastercard designed for\norchestrating internal APIs and automating data engineering workflows. We\nsystematically evaluate embedding-based retrieval, prompt-based listwise\nranking, and hybrid approaches, revealing that method effectiveness depends\nheavily on domain-specific factors rather than inherent algorithmic\nsuperiority. Through empirical investigation on enterprise-derived benchmarks,\nwe find that embedding-based methods offer superior latency for large tool\nrepositories, while listwise ranking provides better disambiguation for\noverlapping functionalities, with hybrid approaches showing promise in specific\ncontexts. We integrate our findings into ScaleCall's flexible architecture and\nvalidate the framework through real-world deployment in Mastercard's regulated\nenvironment. Our work provides practical insights into the trade-offs between\nretrieval accuracy, computational efficiency, and operational requirements,\ncontributing to the understanding of tool-calling system design for enterprise\napplications in regulated industries.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u53d7\u76d1\u7ba1\u7684\u4f01\u4e1a\u73af\u5883\u4e2d\uff08\u5982\u91d1\u878d\u79d1\u6280\uff09\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u8c03\u7528\u80fd\u529b\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u540d\u4e3aScaleCall\u7684\u5de5\u5177\u8c03\u7528\u6846\u67b6\uff0c\u5e76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\u3001\u57fa\u4e8e\u63d0\u793a\u7684\u5217\u8868\u6392\u5e8f\u53ca\u6df7\u5408\u65b9\u6cd5\u5728\u4f01\u4e1a\u5185\u90e8API\u7f16\u6392\u548c\u6570\u636e\u5de5\u7a0b\u81ea\u52a8\u5316\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5728\u53d7\u76d1\u7ba1\u7684\u4f01\u4e1a\u73af\u5883\u4e2d\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u5177\u8c03\u7528\u80fd\u529b\u9762\u4e34\u672c\u5730\u90e8\u7f72\u9650\u5236\u3001\u5408\u89c4\u8981\u6c42\u4ee5\u53ca\u5927\u91cf\u529f\u80fd\u91cd\u53e0\u5de5\u5177\u96be\u4ee5\u533a\u5206\u7b49\u6311\u6218\uff0c\u4e9f\u9700\u9488\u5bf9\u4f01\u4e1a\u573a\u666f\u4f18\u5316\u5de5\u5177\u68c0\u7d22\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u5e76\u90e8\u7f72ScaleCall\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5d4c\u5165\u68c0\u7d22\u3001\u63d0\u793a\u9a71\u52a8\u7684\u5217\u8868\u6392\u5e8f\u548c\u6df7\u5408\u65b9\u6cd5\uff0c\u5728\u4f01\u4e1a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u96c6\u6210\u5230\u7075\u6d3b\u67b6\u6784\u4e2d\u8fdb\u884c\u5b9e\u9645\u9a8c\u8bc1\u3002", "result": "\u5d4c\u5165\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u5de5\u5177\u5e93\u4e2d\u5177\u6709\u66f4\u4f4e\u5ef6\u8fdf\uff0c\u5217\u8868\u6392\u5e8f\u5728\u529f\u80fd\u91cd\u53e0\u573a\u666f\u4e0b\u8868\u73b0\u66f4\u4f18\uff0c\u6df7\u5408\u65b9\u6cd5\u5728\u7279\u5b9a\u60c5\u5883\u4e0b\u5c55\u73b0\u51fa\u6f5c\u529b\uff1b\u65b9\u6cd5\u6548\u679c\u9ad8\u5ea6\u4f9d\u8d56\u9886\u57df\u7279\u6027\u800c\u975e\u7b97\u6cd5\u672c\u8eab\u4f18\u52a3\u3002", "conclusion": "\u5de5\u5177\u8c03\u7528\u7cfb\u7edf\u5728\u4f01\u4e1a\u5e94\u7528\u4e2d\u7684\u8bbe\u8ba1\u9700\u6743\u8861\u68c0\u7d22\u51c6\u786e\u6027\u3001\u8ba1\u7b97\u6548\u7387\u4e0e\u8fd0\u8425\u9700\u6c42\uff0c\u672c\u7814\u7a76\u4e3a\u53d7\u76d1\u7ba1\u884c\u4e1a\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bbe\u8ba1\u6d1e\u89c1\u548c\u53ef\u90e8\u7f72\u7684\u6846\u67b6\u53c2\u8003\u3002"}}
{"id": "2511.00087", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00087", "abs": "https://arxiv.org/abs/2511.00087", "authors": ["Anshu Dubey", "Akash Dhruv"], "title": "Adding New Capability in Existing Scientific Application with LLM Assistance", "comment": "8 pages, 4 figures, submitted to The 1st International Workshop on\n  Foundational large Language Models Advances for HPC in Asia", "summary": "With the emergence and rapid evolution of large language models (LLM),\nautomating coding tasks has become an important research topic. Many efforts\nare underway and literature abounds about the efficacy of models and their\nability to generate code. A less explored aspect of code generation is for new\nalgorithms, where the training dataset would not have included any previous\nexample of similar code. In this paper we propose a new methodology for writing\ncode from scratch for a new algorithm using LLM assistance, and describe\nenhancement of a previously developed code-translation tool, Code-Scribe, for\nnew code generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ece\u96f6\u5f00\u59cb\u4e3a\u5168\u65b0\u7b97\u6cd5\u751f\u6210\u4ee3\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u6539\u8fdb\u4e86\u5df2\u6709\u4ee3\u7801\u7ffb\u8bd1\u5de5\u5177Code-Scribe\u4ee5\u652f\u6301\u65b0\u4ee3\u7801\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8LLM\u5728\u5df2\u6709\u4ee3\u7801\u6a21\u5f0f\u4e0a\u7684\u751f\u6210\u80fd\u529b\uff0c\u800c\u5bf9\u8bad\u7ec3\u6570\u636e\u4e2d\u672a\u5305\u542b\u7c7b\u4f3c\u793a\u4f8b\u7684\u5168\u65b0\u7b97\u6cd5\u4ee3\u7801\u751f\u6210\u95ee\u9898\u63a2\u7d22\u8f83\u5c11\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408LLM\u8f85\u52a9\u4ece\u5934\u7f16\u5199\u65b0\u7b97\u6cd5\u4ee3\u7801\u7684\u65b9\u6cd5\uff0c\u5e76\u5bf9\u5df2\u6709\u7684Code-Scribe\u4ee3\u7801\u7ffb\u8bd1\u5de5\u5177\u8fdb\u884c\u589e\u5f3a\uff0c\u7528\u4e8e\u652f\u6301\u65b0\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u3002", "result": "\u6210\u529f\u5c06Code-Scribe\u5de5\u5177\u6269\u5c55\u81f3\u65b0\u7b97\u6cd5\u4ee3\u7801\u751f\u6210\u573a\u666f\uff0c\u5c55\u793a\u4e86LLM\u5728\u65e0\u5148\u9a8c\u793a\u4f8b\u60c5\u51b5\u4e0b\u7684\u4ee3\u7801\u521b\u4f5c\u6f5c\u529b\u3002", "conclusion": "LLM\u5728\u5168\u65b0\u7b97\u6cd5\u4ee3\u7801\u751f\u6210\u65b9\u9762\u5177\u6709\u5e94\u7528\u524d\u666f\uff0c\u901a\u8fc7\u9002\u5f53\u65b9\u6cd5\u548c\u5de5\u5177\u589e\u5f3a\uff0c\u53ef\u6709\u6548\u652f\u6301\u4ece\u96f6\u5f00\u59cb\u7684\u4ee3\u7801\u521b\u4f5c\u3002"}}
{"id": "2511.00125", "categories": ["cs.SE", "cs.AI", "cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.00125", "abs": "https://arxiv.org/abs/2511.00125", "authors": ["\u00c1lvaro Silva", "Alexandra Mendes", "Ruben Martins"], "title": "Inferring multiple helper Dafny assertions with LLMs", "comment": null, "summary": "The Dafny verifier provides strong correctness guarantees but often requires\nnumerous manual helper assertions, creating a significant barrier to adoption.\nWe investigate the use of Large Language Models (LLMs) to automatically infer\nmissing helper assertions in Dafny programs, with a primary focus on cases\ninvolving multiple missing assertions. To support this study, we extend the\nDafnyBench benchmark with curated datasets where one, two, or all assertions\nare removed, and we introduce a taxonomy of assertion types to analyze\ninference difficulty. Our approach refines fault localization through a hybrid\nmethod that combines LLM predictions with error-message heuristics. We\nimplement this approach in a new tool called DAISY (Dafny Assertion Inference\nSYstem). While our focus is on multiple missing assertions, we also evaluate\nDAISY on single-assertion cases. DAISY verifies 63.4% of programs with one\nmissing assertion and 31.7% with multiple missing assertions. Notably, many\nprograms can be verified with fewer assertions than originally present,\nhighlighting that proofs often admit multiple valid repair strategies and that\nrecovering every original assertion is unnecessary. These results demonstrate\nthat automated assertion inference can substantially reduce proof engineering\neffort and represent a step toward more scalable and accessible formal\nverification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDAISY\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u63a8\u65adDafny\u7a0b\u5e8f\u4e2d\u7f3a\u5931\u7684\u8f85\u52a9\u65ad\u8a00\uff0c\u5c24\u5176\u9488\u5bf9\u591a\u4e2a\u65ad\u8a00\u7f3a\u5931\u7684\u60c5\u51b5\u3002\u901a\u8fc7\u6269\u5c55DafnyBench\u57fa\u51c6\u5e76\u5f15\u5165\u65ad\u8a00\u7c7b\u578b\u5206\u7c7b\uff0c\u7ed3\u5408LLM\u9884\u6d4b\u4e0e\u9519\u8bef\u4fe1\u606f\u542f\u53d1\u5f0f\u65b9\u6cd5\u8fdb\u884c\u6545\u969c\u5b9a\u4f4d\u3002\u5b9e\u9a8c\u8868\u660e\uff0cDAISY\u5728\u5355\u65ad\u8a00\u7f3a\u5931\u65f6\u9a8c\u8bc1\u6210\u529f\u7387\u8fbe63.4%\uff0c\u591a\u65ad\u8a00\u7f3a\u5931\u65f6\u4e3a31.7%\uff0c\u4e14\u5e38\u53ef\u7528\u66f4\u5c11\u65ad\u8a00\u5b8c\u6210\u9a8c\u8bc1\uff0c\u663e\u8457\u964d\u4f4e\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u5de5\u7a0b\u8d1f\u62c5\u3002", "motivation": "Dafny\u9a8c\u8bc1\u5668\u867d\u80fd\u63d0\u4f9b\u5f3a\u6b63\u786e\u6027\u4fdd\u8bc1\uff0c\u4f46\u901a\u5e38\u9700\u8981\u5927\u91cf\u624b\u52a8\u6dfb\u52a0\u8f85\u52a9\u65ad\u8a00\uff0c\u963b\u788d\u5176\u5e7f\u6cdb\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u6765\u63a8\u65ad\u7f3a\u5931\u7684\u65ad\u8a00\uff0c\u5c24\u5176\u662f\u591a\u4e2a\u65ad\u8a00\u540c\u65f6\u7f3a\u5931\u7684\u590d\u6742\u573a\u666f\u3002", "method": "\u4f5c\u8005\u6269\u5c55\u4e86DafnyBench\u57fa\u51c6\uff0c\u6784\u5efa\u5305\u542b\u79fb\u9664\u4e00\u4e2a\u3001\u4e24\u4e2a\u6216\u5168\u90e8\u65ad\u8a00\u7684\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u65ad\u8a00\u7c7b\u578b\u5206\u7c7b\u4ee5\u5206\u6790\u63a8\u65ad\u96be\u5ea6\u3002\u5176\u65b9\u6cd5\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9884\u6d4b\u4e0e\u9519\u8bef\u4fe1\u606f\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u5b9e\u73b0\u6df7\u5408\u5f0f\u6545\u969c\u5b9a\u4f4d\uff0c\u5e76\u5728\u65b0\u5de5\u5177DAISY\u4e2d\u5b9e\u73b0\u8be5\u65b9\u6cd5\u3002", "result": "DAISY\u5728\u5355\u65ad\u8a00\u7f3a\u5931\u60c5\u51b5\u4e0b\u6210\u529f\u9a8c\u8bc163.4%\u7684\u7a0b\u5e8f\uff0c\u5728\u591a\u65ad\u8a00\u7f3a\u5931\u60c5\u51b5\u4e0b\u9a8c\u8bc1\u6210\u529f\u7387\u4e3a31.7%\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\uff0c\u8bb8\u591a\u7a0b\u5e8f\u53ef\u4f7f\u7528\u6bd4\u539f\u59cb\u66f4\u5c11\u7684\u65ad\u8a00\u5b8c\u6210\u9a8c\u8bc1\uff0c\u8bf4\u660e\u5b58\u5728\u591a\u79cd\u6709\u6548\u4fee\u590d\u7b56\u7565\uff0c\u65e0\u9700\u5b8c\u5168\u6062\u590d\u539f\u59cb\u65ad\u8a00\u3002", "conclusion": "\u81ea\u52a8\u5316\u65ad\u8a00\u63a8\u65ad\u80fd\u663e\u8457\u51cf\u5c11\u5f62\u5f0f\u5316\u9a8c\u8bc1\u4e2d\u7684\u8bc1\u660e\u5de5\u7a0b\u5de5\u4f5c\u91cf\uff0cDAISY\u5c55\u793a\u4e86LLM\u5728\u63d0\u5347\u9a8c\u8bc1\u53ef\u6269\u5c55\u6027\u548c\u6613\u7528\u6027\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u662f\u8fc8\u5411\u66f4\u9ad8\u6548\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2511.00160", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00160", "abs": "https://arxiv.org/abs/2511.00160", "authors": ["Katherine A. Rosenfeld", "Cliff C. Kerr", "Jessica Lundin"], "title": "What a diff makes: automating code migration with large language models", "comment": "10 pages, 8 figures", "summary": "Modern software programs are built on stacks that are often undergoing\nchanges that introduce updates and improvements, but may also break any project\nthat depends upon them. In this paper we explore the use of Large Language\nModels (LLMs) for code migration, specifically the problem of maintaining\ncompatibility with a dependency as it undergoes major and minor semantic\nversion changes. We demonstrate, using metrics such as test coverage and change\ncomparisons, that contexts containing diffs can significantly improve\nperformance against out of the box LLMs and, in some cases, perform better than\nusing code. We provide a dataset to assist in further development of this\nproblem area, as well as an open-source Python package, AIMigrate, that can be\nused to assist with migrating code bases. In a real-world migration of\nTYPHOIDSIM between STARSIM versions, AIMigrate correctly identified 65% of\nrequired changes in a single run, increasing to 80% with multiple runs, with\n47% of changes generated perfectly.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8f85\u52a9\u4ee3\u7801\u8fc1\u79fb\uff0c\u4ee5\u5e94\u5bf9\u4f9d\u8d56\u5e93\u7248\u672c\u66f4\u65b0\u5e26\u6765\u7684\u517c\u5bb9\u6027\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5165\u5305\u542b\u4ee3\u7801\u5dee\u5f02\uff08diffs\uff09\u7684\u4e0a\u4e0b\u6587\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u8fc1\u79fb\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u5f00\u6e90\u4e86\u6570\u636e\u96c6\u548cPython\u5de5\u5177\u5305AIMigrate\u3002\u5728\u771f\u5b9e\u9879\u76eeTYPHOIDSIM\u7684\u8fc1\u79fb\u5b9e\u9a8c\u4e2d\uff0cAIMigrate\u5355\u6b21\u8fd0\u884c\u53ef\u8bc6\u522b65%\u7684\u5fc5\u8981\u53d8\u66f4\uff0c\u591a\u6b21\u8fd0\u884c\u63d0\u5347\u81f380%\uff0c\u5176\u4e2d47%\u7684\u53d8\u66f4\u88ab\u5b8c\u7f8e\u751f\u6210\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u4f9d\u8d56\u7684\u5e93\u9891\u7e41\u66f4\u65b0\uff0c\u53ef\u80fd\u5bfc\u81f4\u9879\u76ee\u517c\u5bb9\u6027\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u5e94\u5bf9\u8bed\u4e49\u7248\u672c\u53d8\u66f4\uff0c\u56e0\u6b64\u63a2\u7d22\u5229\u7528LLMs\u81ea\u52a8\u5316\u4ee3\u7801\u8fc1\u79fb\u4ee5\u7ef4\u6301\u517c\u5bb9\u6027\u3002", "method": "\u4f7f\u7528\u5305\u542b\u4ee3\u7801\u5dee\u5f02\uff08diffs\uff09\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u589e\u5f3aLLM\u8f93\u5165\uff0c\u5bf9\u6bd4\u539f\u59cb\u4ee3\u7801\u8f93\u5165\u4e0ediff\u4e0a\u4e0b\u6587\u5bf9\u8fc1\u79fb\u6548\u679c\u7684\u5f71\u54cd\uff0c\u5e76\u5f00\u53d1\u5f00\u6e90\u5de5\u5177AIMigrate\u548c\u914d\u5957\u6570\u636e\u96c6\u652f\u6301\u4ee3\u7801\u8fc1\u79fb\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8ediff\u4e0a\u4e0b\u6587\u7684\u63d0\u793a\u663e\u8457\u4f18\u4e8e\u666e\u901aLLM\u8f93\u51fa\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u4f18\u4e8e\u4ec5\u4f7f\u7528\u4ee3\u7801\u7684\u65b9\u6cd5\u3002\u5728TYPHOIDSIM\u9879\u76ee\u8fc1\u79fb\u4e2d\uff0cAIMigrate\u5355\u6b21\u8bc6\u522b65%\u7684\u53d8\u66f4\uff0c\u591a\u6b21\u8fd0\u884c\u8fbe80%\uff0c47%\u7684\u53d8\u66f4\u5b8c\u5168\u6b63\u786e\u3002", "conclusion": "\u7ed3\u5408diff\u4e0a\u4e0b\u6587\u80fd\u6709\u6548\u63d0\u5347LLM\u5728\u4ee3\u7801\u8fc1\u79fb\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\uff0c\u6240\u63d0\u51fa\u7684AIMigrate\u5de5\u5177\u548c\u6570\u636e\u96c6\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u8d44\u6e90\u3002"}}
{"id": "2511.00034", "categories": ["cs.MA", "cs.LG", "68T05, 68T07, 91A10", "I.2.6; I.2.11; I.2.8"], "pdf": "https://arxiv.org/pdf/2511.00034", "abs": "https://arxiv.org/abs/2511.00034", "authors": ["Aditya Akella"], "title": "On the Fundamental Limitations of Decentralized Learnable Reward Shaping in Cooperative Multi-Agent Reinforcement Learning", "comment": "8 pages, 5 figures, 2 tables", "summary": "Recent advances in learnable reward shaping have shown promise in\nsingle-agent reinforcement learning by automatically discovering effective\nfeedback signals. However, the effectiveness of decentralized learnable reward\nshaping in cooperative multi-agent settings remains poorly understood. We\npropose DMARL-RSA, a fully decentralized system where each agent learns\nindividual reward shaping, and evaluate it on cooperative navigation tasks in\nthe simple_spread_v3 environment. Despite sophisticated reward learning,\nDMARL-RSA achieves only -24.20 +/- 0.09 average reward, compared to MAPPO with\ncentralized training at 1.92 +/- 0.87 -- a 26.12-point gap. DMARL-RSA performs\nsimilarly to simple independent learning (IPPO: -23.19 +/- 0.96), indicating\nthat advanced reward shaping cannot overcome fundamental decentralized\ncoordination limitations. Interestingly, decentralized methods achieve higher\nlandmark coverage (0.888 +/- 0.029 for DMARL-RSA, 0.960 +/- 0.045 for IPPO out\nof 3 total) but worse overall performance than centralized MAPPO (0.273 +/-\n0.008 landmark coverage) -- revealing a coordination paradox between local\noptimization and global performance. Analysis identifies three critical\nbarriers: (1) non-stationarity from concurrent policy updates, (2) exponential\ncredit assignment complexity, and (3) misalignment between individual reward\noptimization and global objectives. These results establish empirical limits\nfor decentralized reward learning and underscore the necessity of centralized\ncoordination for effective multi-agent cooperation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u53bb\u4e2d\u5fc3\u5316\u53ef\u5b66\u4e60\u5956\u52b1\u5851\u5f62\u7684\u6709\u6548\u6027\uff0c\u63d0\u51faDMARL-RSA\u65b9\u6cd5\uff0c\u53d1\u73b0\u5c3d\u7ba1\u5176\u80fd\u63d0\u9ad8\u5730\u6807\u8986\u76d6\u7387\uff0c\u4f46\u6574\u4f53\u6027\u80fd\u8fdc\u4f4e\u4e8e\u4e2d\u5fc3\u5316\u8bad\u7ec3\u65b9\u6cd5\uff08\u5982MAPPO\uff09\uff0c\u63ed\u793a\u4e86\u53bb\u4e2d\u5fc3\u5316\u534f\u8c03\u7684\u6839\u672c\u5c40\u9650\u3002", "motivation": "\u63a2\u7d22\u53bb\u4e2d\u5fc3\u5316\u53ef\u5b66\u4e60\u5956\u52b1\u5851\u5f62\u5728\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\uff0c\u586b\u8865\u8be5\u9886\u57df\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u63d0\u51faDMARL-RSA\uff0c\u4e00\u79cd\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u7684\u7cfb\u7edf\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u72ec\u7acb\u5b66\u4e60\u5956\u52b1\u5851\u5f62\uff0c\u5e76\u5728simple_spread_v3\u73af\u5883\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "DMARL-RSA\u5e73\u5747\u5956\u52b1\u4e3a-24.20\uff0c\u663e\u8457\u4f4e\u4e8e\u4e2d\u5fc3\u5316MAPPO\uff081.92\uff09\uff1b\u867d\u5730\u6807\u8986\u76d6\u7387\u66f4\u9ad8\uff0c\u4f46\u6574\u4f53\u6027\u80fd\u66f4\u5dee\uff0c\u63ed\u793a\u5c40\u90e8\u4f18\u5316\u4e0e\u5168\u5c40\u6027\u80fd\u4e4b\u95f4\u7684\u534f\u8c03\u6096\u8bba\u3002", "conclusion": "\u53bb\u4e2d\u5fc3\u5316\u5956\u52b1\u5b66\u4e60\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff0c\u6709\u6548\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4ecd\u9700\u4f9d\u8d56\u4e2d\u5fc3\u5316\u534f\u8c03\u673a\u5236\u3002"}}
{"id": "2511.00197", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00197", "abs": "https://arxiv.org/abs/2511.00197", "authors": ["Oorja Majgaonkar", "Zhiwei Fei", "Xiang Li", "Federica Sarro", "He Ye"], "title": "Understanding Code Agent Behaviour: An Empirical Study of Success and Failure Trajectories", "comment": null, "summary": "The increasing deployment of Large Language Model (LLM) agents for complex\nsoftware engineering tasks has created a need to understand their\nproblem-solving behaviours beyond simple success metrics. While these agents\ndemonstrate impressive capabilities in automated issue resolution, their\ndecision-making processes remain largely opaque. This paper presents an\nempirical study of agent trajectories, namely the execution traces capturing\nthe steps agents take when attempting to resolve software issues. We analyse\ntrajectories from three state-of-the-art code agents (OpenHands, SWE-agent, and\nPrometheus) on the SWE-Bench benchmark, examining both successful and failed\nattempts. Our investigation reveals several key insights into agent behaviour.\nFirst, we identify how distinct problem-solving strategies, such as defensive\nprogramming and context gathering, enable success in different scenarios.\nSecond, we find that failed trajectories are consistently longer and exhibit\nhigher variance than successful ones, with failure patterns differing\nsignificantly between agents. Third, our fault localisation analysis shows that\nwhile most trajectories correctly identify problematic files (72-81\\% even in\nfailures), success depends more on achieving approximate rather than exact code\nmodifications. These and other findings unveiled by our study, provide a\nfoundation for understanding agent behaviour through trajectory analysis,\ncontributing to the development of more robust and interpretable autonomous\nsoftware engineering systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9\u4e09\u4e2a\u5148\u8fdb\u4ee3\u7801\u667a\u80fd\u4f53\uff08OpenHands\u3001SWE-agent \u548c Prometheus\uff09\u5728 SWE-Bench \u57fa\u51c6\u4e0a\u7684\u6267\u884c\u8f68\u8ff9\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5176\u5728\u89e3\u51b3\u8f6f\u4ef6\u95ee\u9898\u65f6\u7684\u6210\u529f\u4e0e\u5931\u8d25\u884c\u4e3a\u6a21\u5f0f\uff0c\u53d1\u73b0\u6210\u529f\u66f4\u4f9d\u8d56\u4e8e\u8fd1\u4f3c\u800c\u975e\u7cbe\u786e\u7684\u4ee3\u7801\u4fee\u6539\uff0c\u5e76\u6307\u51fa\u8f68\u8ff9\u5206\u6790\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u81ea\u4e3b\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5728\u590d\u6742\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4ec5\u9760\u6210\u529f\u6307\u6807\u5df2\u4e0d\u8db3\u4ee5\u7406\u89e3\u5176\u95ee\u9898\u89e3\u51b3\u884c\u4e3a\uff0c\u4e9f\u9700\u6df1\u5165\u63a2\u7a76\u5176\u51b3\u7b56\u8fc7\u7a0b\u548c\u884c\u4e3a\u6a21\u5f0f\u3002", "method": "\u5bf9\u4e09\u4e2a\u5148\u8fdb\u4ee3\u7801\u667a\u80fd\u4f53\u5728 SWE-Bench \u57fa\u51c6\u4e0a\u7684\u6210\u529f\u4e0e\u5931\u8d25\u6267\u884c\u8f68\u8ff9\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u5305\u62ec\u95ee\u9898\u89e3\u51b3\u7b56\u7565\u3001\u8f68\u8ff9\u957f\u5ea6\u4e0e\u65b9\u5dee\u3001\u6545\u969c\u5b9a\u4f4d\u51c6\u786e\u6027\u7b49\u65b9\u9762\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\uff081\uff09\u4e0d\u540c\u7b56\u7565\uff08\u5982\u9632\u5fa1\u6027\u7f16\u7a0b\u3001\u4e0a\u4e0b\u6587\u6536\u96c6\uff09\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u4fc3\u6210\u6210\u529f\uff1b\uff082\uff09\u5931\u8d25\u8f68\u8ff9\u66f4\u957f\u4e14\u65b9\u5dee\u66f4\u5927\uff0c\u5931\u8d25\u6a21\u5f0f\u56e0\u667a\u80fd\u4f53\u800c\u5f02\uff1b\uff083\uff09\u591a\u6570\u8f68\u8ff9\u80fd\u6b63\u786e\u5b9a\u4f4d\u95ee\u9898\u6587\u4ef6\uff08\u5931\u8d25\u6848\u4f8b\u4e2d\u4e5f\u670972\u201381%\uff09\uff0c\u4f46\u6210\u529f\u66f4\u4f9d\u8d56\u8fd1\u4f3c\u800c\u975e\u7cbe\u786e\u7684\u4ee3\u7801\u4fee\u6539\u3002", "conclusion": "\u8f68\u8ff9\u5206\u6790\u4e3a\u7406\u89e3\u4ee3\u7801\u667a\u80fd\u4f53\u884c\u4e3a\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u7684\u81ea\u4e3b\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\u3002"}}
{"id": "2511.00295", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.00295", "abs": "https://arxiv.org/abs/2511.00295", "authors": ["Kosmas Alexandridis", "Giorgos Dimitrakopoulos"], "title": "H-FA: A Hybrid Floating-Point and Logarithmic Approach to Hardware Accelerated FlashAttention", "comment": "Accepted for publication at IEEE Transactions on Circuits and Systems\n  for Artificial Intelligence", "summary": "Transformers have significantly advanced AI and machine learning through\ntheir powerful attention mechanism. However, computing attention on long\nsequences can become a computational bottleneck. FlashAttention mitigates this\nby fusing the softmax and matrix operations into a tiled computation pattern\nthat decouples performance from sequence length. Though designed for GPUs, its\nsimplicity also makes it well suited for direct hardware acceleration. To\nimprove hardware implementation, we compute FlashAttention using a mixture of\nfloating-point and fixed-point logarithm domain representations. Floating-point\nis used to compute attention scores from query and key matrices, while\nlogarithmic computation simplifies the fused computation of softmax\nnormalization and the multiplication with the value matrix. This\ntransformation, called H-FA, replaces vector-wide floating-point multiplication\nand division operations by additions and subtractions implemented efficiently\nwith fixed-point arithmetic in the logarithm domain. Exponential function\nevaluations are effectively omitted and fused with the rest operations, and the\nfinal result is directly returned to floating-point arithmetic without any\nadditional hardware overhead. Hardware implementation results at 28nm\ndemonstrate that H-FA achieves a 26.5% reduction in area and a 23.4% reduction\nin power, on average, compared to FlashAttention parallel hardware\narchitectures built solely with floating-point datapaths, without hindering\nperformance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aH-FA\u7684\u786c\u4ef6\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u6d6e\u70b9\u4e0e\u5bf9\u6570\u57df\u5b9a\u70b9\u8868\u793a\u6765\u5b9e\u73b0FlashAttention\uff0c\u4ece\u800c\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u786c\u4ef6\u9762\u79ef\u548c\u529f\u8017\u3002", "motivation": "\u957f\u5e8f\u5217\u6ce8\u610f\u529b\u8ba1\u7b97\u5b58\u5728\u8ba1\u7b97\u74f6\u9888\uff0c\u5c3d\u7ba1FlashAttention\u901a\u8fc7\u878d\u5408softmax\u548c\u77e9\u9635\u8fd0\u7b97\u7f13\u89e3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u5176\u7eaf\u6d6e\u70b9\u786c\u4ef6\u5b9e\u73b0\u4ee3\u4ef7\u8f83\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u786c\u4ef6\u5b9e\u73b0\u65b9\u5f0f\u3002", "method": "\u5c06FlashAttention\u4e2d\u7684\u90e8\u5206\u8ba1\u7b97\u8f6c\u6362\u5230\u5bf9\u6570\u57df\uff0c\u4f7f\u7528\u6d6e\u70b9\u8ba1\u7b97\u67e5\u8be2\u548c\u952e\u7684\u6ce8\u610f\u529b\u5f97\u5206\uff0c\u800csoftmax\u5f52\u4e00\u5316\u4e0e\u503c\u77e9\u9635\u76f8\u4e58\u5219\u901a\u8fc7\u5bf9\u6570\u57df\u4e2d\u7684\u5b9a\u70b9\u52a0\u51cf\u6cd5\u9ad8\u6548\u5b8c\u6210\uff0c\u5e76\u7701\u7565\u663e\u5f0f\u7684\u6307\u6570\u51fd\u6570\u8ba1\u7b97\u3002", "result": "\u572828nm\u5de5\u827a\u4e0b\uff0cH-FA\u76f8\u6bd4\u7eaf\u6d6e\u70b9\u5b9e\u73b0\u7684FlashAttention\u786c\u4ef6\u67b6\u6784\u5e73\u5747\u51cf\u5c1126.5%\u9762\u79ef\u548c23.4%\u529f\u8017\uff0c\u4e14\u672a\u5f71\u54cd\u6027\u80fd\u3002", "conclusion": "H-FA\u901a\u8fc7\u6df7\u5408\u6d6e\u70b9\u4e0e\u5bf9\u6570\u57df\u5b9a\u70b9\u8868\u793a\uff0c\u5728\u4fdd\u6301FlashAttention\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u786c\u4ef6\u6548\u7387\uff0c\u4e3a\u6ce8\u610f\u529b\u673a\u5236\u7684\u786c\u4ef6\u52a0\u901f\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2511.00096", "categories": ["cs.MA", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.00096", "abs": "https://arxiv.org/abs/2511.00096", "authors": ["Shangyu Lou"], "title": "Urban-MAS: Human-Centered Urban Prediction with LLM-Based Multi-Agent System", "comment": "Accepted to The 3rd ACM SIGSPATIAL International Workshop on Advances\n  in Urban AI (UrbanAI'25)", "summary": "Urban Artificial Intelligence (Urban AI) has advanced human-centered urban\ntasks such as perception prediction and human dynamics. Large Language Models\n(LLMs) can integrate multimodal inputs to address heterogeneous data in complex\nurban systems but often underperform on domain-specific tasks. Urban-MAS, an\nLLM-based Multi-Agent System (MAS) framework, is introduced for human-centered\nurban prediction under zero-shot settings. It includes three agent types:\nPredictive Factor Guidance Agents, which prioritize key predictive factors to\nguide knowledge extraction and enhance the effectiveness of compressed urban\nknowledge in LLMs; Reliable UrbanInfo Extraction Agents, which improve\nrobustness by comparing multiple outputs, validating consistency, and\nre-extracting when conflicts occur; and Multi-UrbanInfo Inference Agents, which\nintegrate extracted multi-source information across dimensions for prediction.\nExperiments on running-amount prediction and urban perception across Tokyo,\nMilan, and Seattle demonstrate that Urban-MAS substantially reduces errors\ncompared to single-LLM baselines. Ablation studies indicate that Predictive\nFactor Guidance Agents are most critical for enhancing predictive performance,\npositioning Urban-MAS as a scalable paradigm for human-centered urban AI\nprediction. Code is available on the project\nwebsite:https://github.com/THETUREHOOHA/UrbanMAS", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Urban-MAS\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u57ce\u5e02\u9884\u6d4b\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e09\u79cd\u667a\u80fd\u4f53\uff1a\u9884\u6d4b\u56e0\u5b50\u5f15\u5bfc\u667a\u80fd\u4f53\u3001\u53ef\u9760\u57ce\u5e02\u4fe1\u606f\u63d0\u53d6\u667a\u80fd\u4f53\u548c\u591a\u6e90\u57ce\u5e02\u4fe1\u606f\u63a8\u7406\u667a\u80fd\u4f53\u3002\u5b9e\u9a8c\u8868\u660e\uff0cUrban-MAS\u5728\u4e1c\u4eac\u3001\u7c73\u5170\u548c\u897f\u96c5\u56fe\u7684\u8dd1\u6b65\u91cf\u9884\u6d4b\u548c\u57ce\u5e02\u611f\u77e5\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u5355LLM\u57fa\u7ebf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u6574\u5408\u591a\u6a21\u6001\u8f93\u5165\u4ee5\u5904\u7406\u590d\u6742\u57ce\u5e02\u7cfb\u7edf\u4e2d\u7684\u5f02\u6784\u6570\u636e\uff0c\u4f46\u5728\u7279\u5b9a\u9886\u57df\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u6846\u67b6\u6765\u63d0\u5347LLM\u5728\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u57ce\u5e02\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51faUrban-MAS\u6846\u67b6\uff0c\u5305\u542b\u4e09\u79cd\u667a\u80fd\u4f53\uff1a1\uff09\u9884\u6d4b\u56e0\u5b50\u5f15\u5bfc\u667a\u80fd\u4f53\uff0c\u7528\u4e8e\u8bc6\u522b\u5173\u952e\u9884\u6d4b\u56e0\u5b50\u5e76\u6307\u5bfc\u77e5\u8bc6\u63d0\u53d6\uff1b2\uff09\u53ef\u9760\u57ce\u5e02\u4fe1\u606f\u63d0\u53d6\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u591a\u8f93\u51fa\u6bd4\u5bf9\u548c\u4e00\u81f4\u6027\u9a8c\u8bc1\u63d0\u5347\u9c81\u68d2\u6027\uff1b3\uff09\u591a\u6e90\u57ce\u5e02\u4fe1\u606f\u63a8\u7406\u667a\u80fd\u4f53\uff0c\u878d\u5408\u591a\u7ef4\u4fe1\u606f\u8fdb\u884c\u9884\u6d4b\u3002", "result": "\u5728\u4e1c\u4eac\u3001\u7c73\u5170\u548c\u897f\u96c5\u56fe\u7684\u8dd1\u6b65\u91cf\u9884\u6d4b\u548c\u57ce\u5e02\u611f\u77e5\u4efb\u52a1\u4e2d\uff0cUrban-MAS\u76f8\u6bd4\u5355LLM\u57fa\u7ebf\u663e\u8457\u964d\u4f4e\u4e86\u9884\u6d4b\u8bef\u5dee\uff1b\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u9884\u6d4b\u56e0\u5b50\u5f15\u5bfc\u667a\u80fd\u4f53\u5bf9\u6027\u80fd\u63d0\u5347\u6700\u5173\u952e\u3002", "conclusion": "Urban-MAS\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u3001\u9002\u7528\u4e8e\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u57ce\u5e02AI\u9884\u6d4b\u7684\u6709\u6548\u8303\u5f0f\uff0c\u5c24\u5176\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.01001", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.01001", "abs": "https://arxiv.org/abs/2511.01001", "authors": ["Johansell Villalobos", "Daniel Caviedes-Voulli\u00e8me", "Silvio Rizzi", "Esteban Meneses"], "title": "Towards Portability at Scale: A Cross-Architecture Performance Evaluation of a GPU-enabled Shallow Water Solver", "comment": "Conference: SBAC-PAD 2025", "summary": "Current climate change has posed a grand challenge in the field of numerical\nmodeling due to its complex, multiscale dynamics. In hydrological modeling, the\nincreasing demand for high-resolution, real-time simulations has led to the\nadoption of GPU-accelerated platforms and performance portable programming\nframeworks such as Kokkos. In this work, we present a comprehensive performance\nstudy of the SERGHEI-SWE solver, a shallow water equations code, across four\nstate-of-the-art heterogeneous HPC systems: Frontier (AMD MI250X), JUWELS\nBooster (NVIDIA A100), JEDI (NVIDIA H100), and Aurora (Intel Max 1550). We\nassess strong scaling up to 1024 GPUs and weak scaling upwards of 2048 GPUs,\ndemonstrating consistent scalability with a speedup of 32 and an efficiency\nupwards of 90\\% for most almost all the test range. Roofline analysis reveals\nthat memory bandwidth is the dominant performance bottleneck, with key solver\nkernels residing in the memory-bound region. To evaluate performance\nportability, we apply both harmonic and arithmetic mean-based metrics while\nvarying problem size. Results indicate that while SERGHEI-SWE achieves\nportability across devices with tuned problem sizes (<70\\%), there is room for\nkernel optimization within the solver with more granular control of the\narchitecture specifically by using Kokkos teams and architecture specific\ntunable parameters. These findings position SERGHEI-SWE as a robust, scalable,\nand portable simulation tool for large-scale geophysical applications under\nevolving HPC architectures with potential to enhance its performance.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6d45\u6c34\u65b9\u7a0b\u6c42\u89e3\u5668SERGHEI-SWE\u5728\u56db\u79cd\u4e3b\u6d41\u5f02\u6784\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u4e0a\u7684\u6027\u80fd\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5176\u826f\u597d\u7684\u5f3a\u5f31\u6269\u5c55\u6027\uff08\u6700\u9ad8\u8fbe32\u500d\u52a0\u901f\u6bd4\u548c90%\u4ee5\u4e0a\u6548\u7387\uff09\uff0c\u5e76\u901a\u8fc7\u5c4b\u9876\u7ebf\u5206\u6790\u6307\u51fa\u5185\u5b58\u5e26\u5bbd\u662f\u4e3b\u8981\u6027\u80fd\u74f6\u9888\uff1b\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u901a\u8fc7Kokkos\u6846\u67b6\u7684\u7ec6\u7c92\u5ea6\u4f18\u5316\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u6027\u80fd\u53ef\u79fb\u690d\u6027\u3002", "motivation": "\u5e94\u5bf9\u6c14\u5019\u53d8\u5316\u5e26\u6765\u7684\u590d\u6742\u591a\u5c3a\u5ea6\u6570\u503c\u6a21\u62df\u6311\u6218\uff0c\u6ee1\u8db3\u6c34\u6587\u5efa\u6a21\u5bf9\u9ad8\u5206\u8fa8\u7387\u3001\u5b9e\u65f6\u4eff\u771f\u7684\u9700\u6c42\uff0c\u8bc4\u4f30\u5e76\u4f18\u5316GPU\u52a0\u901f\u5e73\u53f0\u4e0a\u7684\u6027\u80fd\u53ef\u79fb\u690d\u6027\u3002", "method": "\u5728Frontier\u3001JUWELS Booster\u3001JEDI\u548cAurora\u56db\u5957\u5f02\u6784HPC\u7cfb\u7edf\u4e0a\u5bf9SERGHEI-SWE\u6c42\u89e3\u5668\u8fdb\u884c\u5f3a\u5f31\u6269\u5c55\u6027\u6d4b\u8bd5\uff08\u6700\u591a\u8fbe2048\u5757GPU\uff09\uff0c\u7ed3\u5408\u5c4b\u9876\u7ebf\u6a21\u578b\u5206\u6790\u6027\u80fd\u74f6\u9888\uff0c\u5e76\u91c7\u7528\u8c03\u548c\u5e73\u5747\u4e0e\u7b97\u672f\u5e73\u5747\u6307\u6807\u8bc4\u4f30\u5176\u5728\u4e0d\u540c\u95ee\u9898\u89c4\u6a21\u4e0b\u7684\u6027\u80fd\u53ef\u79fb\u690d\u6027\u3002", "result": "SERGHEI-SWE\u5728\u591a\u6570\u6d4b\u8bd5\u8303\u56f4\u5185\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6269\u5c55\u6027\uff08\u52a0\u901f\u6bd4\u8fbe32\uff0c\u6548\u7387\u8d8590%\uff09\uff1b\u5c4b\u9876\u7ebf\u5206\u6790\u8868\u660e\u5176\u6838\u5fc3\u6838\u51fd\u6570\u53d7\u5185\u5b58\u5e26\u5bbd\u9650\u5236\uff1b\u5728\u8c03\u4f18\u95ee\u9898\u89c4\u6a21\u4e0b\u53ef\u5b9e\u73b0\u8de8\u67b6\u6784\u7684\u6027\u80fd\u53ef\u79fb\u690d\u6027\uff08<70%\uff09\uff0c\u4f46\u4ecd\u6709\u901a\u8fc7Kokkos\u56e2\u961f\u673a\u5236\u548c\u67b6\u6784\u7279\u5b9a\u53c2\u6570\u8fdb\u4e00\u6b65\u4f18\u5316\u7684\u7a7a\u95f4\u3002", "conclusion": "SERGHEI-SWE\u662f\u4e00\u4e2a\u5728\u4e0d\u65ad\u6f14\u8fdb\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\u67b6\u6784\u4e0a\u5177\u6709\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u826f\u597d\u6027\u80fd\u53ef\u79fb\u690d\u6027\u7684\u5927\u89c4\u6a21\u5730\u7403\u7269\u7406\u6a21\u62df\u5de5\u5177\uff0c\u5177\u5907\u901a\u8fc7\u7ec6\u7c92\u5ea6\u4f18\u5316\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.00202", "categories": ["cs.SE", "cs.LG", "cs.LO", "F.3.1; I.2.5"], "pdf": "https://arxiv.org/pdf/2511.00202", "abs": "https://arxiv.org/abs/2511.00202", "authors": ["Jacqueline Mitchell", "Yasser Shaaban"], "title": "Position: Vibe Coding Needs Vibe Reasoning: Improving Vibe Coding with Formal Verification", "comment": "7 pages, 3 figures, In Proceedings of the 1st ACM SIGPLAN\n  International Workshop on Language Models and Programming Languages\n  (LMPL'25), October 12-18, 2025, Singapore, Singapore. ACM, New York, NY, USA", "summary": "``Vibe coding'' -- the practice of developing software through iteratively\nconversing with a large language model (LLM) -- has exploded in popularity\nwithin the last year. However, developers report key limitations including the\naccumulation of technical debt, security issues, and code churn to achieve\nsatisfactory results. We argue that these pitfalls result from LLMs' inability\nto reconcile accumulating human-imposed constraints during vibe coding, with\ndevelopers inadvertently failing to resolve contradictions because LLMs\nprioritize user commands over code consistency. Given LLMs' receptiveness to\nverification-based feedback, we argue that formal methods can mitigate these\npitfalls, making vibe coding more reliable. However, we posit that integrating\nformal methods must transcend existing approaches that combine formal methods\nand LLMs. We advocate for a side-car system throughout the vibe coding process\nwhich: (1) \\emph{Autoformalizes} specifications (2) Validates against targets,\n(3) Delivers \\emph{actionable} feedback to the LLM, and (4) Allows intuitive\ndeveloper influence on specifications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u4f34\u968f\u5f0f\u5f62\u5f0f\u5316\u65b9\u6cd5\u7cfb\u7edf\uff08side-car system\uff09\u6765\u63d0\u5347\u201c\u6c1b\u56f4\u7f16\u7a0b\u201d\uff08vibe coding\uff09\u7684\u53ef\u9760\u6027\uff0c\u8be5\u7cfb\u7edf\u80fd\u81ea\u52a8\u5f62\u5f0f\u5316\u89c4\u8303\u3001\u9a8c\u8bc1\u76ee\u6807\u3001\u5411\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u53ef\u64cd\u4f5c\u53cd\u9988\uff0c\u5e76\u652f\u6301\u5f00\u53d1\u8005\u76f4\u89c2\u5730\u5f71\u54cd\u89c4\u8303\u3002", "motivation": "\u5f53\u524d\u6c1b\u56f4\u7f16\u7a0b\u5b58\u5728\u6280\u672f\u503a\u7d2f\u79ef\u3001\u5b89\u5168\u95ee\u9898\u548c\u4ee3\u7801\u9891\u7e41\u53d8\u66f4\u7b49\u95ee\u9898\uff0c\u6839\u6e90\u5728\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u534f\u8c03\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u79ef\u7d2f\u7684\u4eba\u4e3a\u7ea6\u675f\uff0c\u4e14\u4f18\u5148\u54cd\u5e94\u7528\u6237\u6307\u4ee4\u800c\u5ffd\u89c6\u4ee3\u7801\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u8d2f\u7a7f\u6c1b\u56f4\u7f16\u7a0b\u5168\u8fc7\u7a0b\u7684\u4f34\u968f\u5f0f\u7cfb\u7edf\uff0c\u5177\u5907\u81ea\u52a8\u5f62\u5f0f\u5316\u89c4\u8303\u3001\u76ee\u6807\u9a8c\u8bc1\u3001\u5411LLM\u63d0\u4f9b\u53ef\u64cd\u4f5c\u53cd\u9988\u4ee5\u53ca\u652f\u6301\u5f00\u53d1\u8005\u76f4\u89c2\u5e72\u9884\u89c4\u8303\u56db\u5927\u529f\u80fd\u3002", "result": "\u8be5\u65b9\u6cd5\u6709\u671b\u7f13\u89e3\u6c1b\u56f4\u7f16\u7a0b\u4e2d\u7684\u5173\u952e\u7f3a\u9677\uff0c\u63d0\u5347\u5176\u53ef\u9760\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u5c06\u5f62\u5f0f\u5316\u65b9\u6cd5\u4ee5\u65b0\u578b\u4f34\u968f\u5f0f\u7cfb\u7edf\u5f62\u5f0f\u878d\u5165\u6c1b\u56f4\u7f16\u7a0b\uff0c\u53ef\u6709\u6548\u514b\u670d\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u534f\u8c03\u7ea6\u675f\u4e0e\u4fdd\u6301\u4ee3\u7801\u4e00\u81f4\u6027\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2511.00271", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00271", "abs": "https://arxiv.org/abs/2511.00271", "authors": ["Saadat Izadi", "Shakib Komasi", "Ali Salimi", "Alireza Rezaei", "Mahmood Ahmadi"], "title": "Mist-Assisted Federated Learning for Intrusion Detection in Heterogeneous IoT Networks", "comment": null, "summary": "The rapid growth of the Internet of Things (IoT) offers new opportunities but\nalso expands the attack surface of distributed, resource-limited devices.\nIntrusion detection in such environments is difficult due to data heterogeneity\nfrom diverse sensing modalities and the non-IID distribution of samples across\nclients. Federated Learning (FL) provides a privacy-preserving alternative to\ncentralized training, yet conventional frameworks struggle under these\nconditions. To address this, we propose a Mist-assisted hierarchical framework\nfor IoT intrusion detection. The architecture spans four layers: (i) Mist,\nwhere raw data are abstracted into a unified feature space and lightweight\nmodels detect anomalies; (ii) Edge, which applies utility-based client\nselection; (iii) Fog, where multiple regional aggregators use FedProx to\nstabilize training; and (iv) Cloud, which consolidates and disseminates global\nmodels. Evaluations on the TON-IoT dataset show the framework achieves 98-99%\naccuracy, PR-AUC> 0.97, and stable convergence under heterogeneous and\nlarge-scale settings, while maintaining efficiency and preserving privacy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eMist\u8f85\u52a9\u7684\u5206\u5c42\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5f02\u6784\u3001\u5927\u89c4\u6a21\u7269\u8054\u7f51\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u5165\u4fb5\u68c0\u6d4b\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u7684\u5feb\u901f\u589e\u957f\u5e26\u6765\u4e86\u65b0\u7684\u5b89\u5168\u6311\u6218\uff0c\u4f20\u7edf\u96c6\u4e2d\u5f0f\u5165\u4fb5\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u6570\u636e\u5f02\u6784\u6027\u3001\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u4ee5\u53ca\u8d44\u6e90\u53d7\u9650\u7b49\u95ee\u9898\uff0c\u800c\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u5728\u8fd9\u4e9b\u6761\u4ef6\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u56db\u5c42\u67b6\u6784\uff1aMist\u5c42\u5c06\u539f\u59cb\u6570\u636e\u62bd\u8c61\u4e3a\u7edf\u4e00\u7279\u5f81\u7a7a\u95f4\u5e76\u8fdb\u884c\u8f7b\u91cf\u7ea7\u5f02\u5e38\u68c0\u6d4b\uff1bEdge\u5c42\u57fa\u4e8e\u6548\u7528\u9009\u62e9\u5ba2\u6237\u7aef\uff1bFog\u5c42\u4f7f\u7528FedProx\u8fdb\u884c\u533a\u57df\u805a\u5408\u4ee5\u7a33\u5b9a\u8bad\u7ec3\uff1bCloud\u5c42\u6574\u5408\u5e76\u5206\u53d1\u5168\u5c40\u6a21\u578b\u3002", "result": "\u5728TON-IoT\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u5f02\u6784\u548c\u5927\u89c4\u6a21\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u4e8698-99%\u7684\u51c6\u786e\u7387\u3001PR-AUC>0.97\uff0c\u5e76\u5177\u5907\u7a33\u5b9a\u7684\u6536\u655b\u6027\u3001\u9ad8\u6548\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684Mist\u8f85\u52a9\u5206\u5c42\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7269\u8054\u7f51\u73af\u5883\u4e2d\u5165\u4fb5\u68c0\u6d4b\u9762\u4e34\u7684\u5f02\u6784\u6027\u3001\u9690\u79c1\u548c\u6548\u7387\u6311\u6218\uff0c\u5177\u6709\u826f\u597d\u7684\u5b9e\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.00321", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00321", "abs": "https://arxiv.org/abs/2511.00321", "authors": ["Dowon Kim", "MinJae Lee", "Janghyeon Kim", "HyuckSung Kwon", "Hyeonggyu Jeong", "Sang-Soo Park", "Minyong Yoon", "Si-Dong Roh", "Yongsuk Kwon", "Jinin So", "Jungwook Choi"], "title": "Scalable Processing-Near-Memory for 1M-Token LLM Inference: CXL-Enabled KV-Cache Management Beyond GPU Limits", "comment": null, "summary": "The expansion of context windows in large language models (LLMs) to\nmulti-million tokens introduces severe memory and compute bottlenecks,\nparticularly in managing the growing Key-Value (KV) cache. While Compute\nExpress Link (CXL) enables non-eviction frameworks that offload the full\nKV-cache to scalable external memory, these frameworks still suffer from costly\ndata transfers when recalling non-resident KV tokens to limited GPU memory as\ncontext lengths increase. This work proposes scalable Processing-Near-Memory\n(PNM) for 1M-Token LLM Inference, a CXL-enabled KV-cache management system that\ncoordinates memory and computation beyond GPU limits. Our design offloads token\npage selection to a PNM accelerator within CXL memory, eliminating costly\nrecalls and enabling larger GPU batch sizes. We further introduce a hybrid\nparallelization strategy and a steady-token selection mechanism to enhance\ncompute efficiency and scalability. Implemented atop a state-of-the-art CXL-PNM\nsystem, our solution delivers consistent performance gains for LLMs with up to\n405B parameters and 1M-token contexts. Our PNM-only offloading scheme (PNM-KV)\nand GPU-PNM hybrid with steady-token execution (PnG-KV) achieve up to 21.9x\nthroughput improvement, up to 60x lower energy per token, and up to 7.3x better\ntotal cost efficiency than the baseline, demonstrating that CXL-enabled\nmulti-PNM architectures can serve as a scalable backbone for future\nlong-context LLM inference.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eCXL\u7684\u8fd1\u5185\u5b58\u8ba1\u7b97\uff08PNM\uff09\u7cfb\u7edf\uff0c\u7528\u4e8e\u9ad8\u6548\u7ba1\u7406\u767e\u4e07\u7ea7\u4e0a\u4e0b\u6587\u957f\u5ea6\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u7684KV\u7f13\u5b58\uff0c\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u3001\u80fd\u6548\u548c\u6210\u672c\u6548\u76ca\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u6269\u5c55\u81f3\u767e\u4e07\u7ea7token\uff0cKV\u7f13\u5b58\u5e26\u6765\u4e25\u91cd\u7684\u5185\u5b58\u4e0e\u8ba1\u7b97\u74f6\u9888\uff1b\u73b0\u6709\u57fa\u4e8eCXL\u7684\u975e\u9a71\u9010\u6846\u67b6\u867d\u53ef\u5c06KV\u7f13\u5b58\u5378\u8f7d\u81f3\u5916\u90e8\u5185\u5b58\uff0c\u4f46\u5728\u4e0a\u4e0b\u6587\u589e\u957f\u65f6\u4ecd\u9700\u9891\u7e41\u5c06\u975e\u9a7b\u7559KV token\u8c03\u56deGPU\u5185\u5b58\uff0c\u9020\u6210\u9ad8\u6602\u7684\u6570\u636e\u4f20\u8f93\u5f00\u9500\u3002", "method": "\u8bbe\u8ba1\u4e00\u79cdCXL\u652f\u6301\u7684PNM\u67b6\u6784\uff0c\u5c06token\u9875\u9009\u62e9\u4efb\u52a1\u5378\u8f7d\u81f3CXL\u5185\u5b58\u5185\u7684PNM\u52a0\u901f\u5668\uff0c\u907f\u514d\u6602\u8d35\u7684\u6570\u636e\u53ec\u56de\uff1b\u5f15\u5165\u6df7\u5408\u5e76\u884c\u7b56\u7565\u4e0e\u7a33\u6001token\u9009\u62e9\u673a\u5236\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u4e0e\u53ef\u6269\u5c55\u6027\u3002", "result": "\u5728\u9ad8\u8fbe405B\u53c2\u6570\u548c1M-token\u4e0a\u4e0b\u6587\u7684LLM\u4e0a\u5b9e\u73b0\u7a33\u5b9a\u6027\u80fd\u63d0\u5347\uff1aPNM-KV\u65b9\u6848\u548cPnG-KV\u65b9\u6848\u5206\u522b\u5b9e\u73b0\u6700\u9ad821.9\u500d\u541e\u5410\u91cf\u63d0\u5347\u300160\u500d\u6bcftoken\u80fd\u8017\u964d\u4f4e\u548c7.3\u500d\u603b\u6210\u672c\u6548\u7387\u63d0\u5347\u3002", "conclusion": "CXL\u652f\u6301\u7684\u591aPNM\u67b6\u6784\u53ef\u4f5c\u4e3a\u672a\u6765\u957f\u4e0a\u4e0b\u6587\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u53ef\u6269\u5c55\u57fa\u7840\u67b6\u6784\uff0c\u6709\u6548\u89e3\u51b3KV\u7f13\u5b58\u7ba1\u7406\u74f6\u9888\u3002"}}
{"id": "2511.00038", "categories": ["cs.DC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00038", "abs": "https://arxiv.org/abs/2511.00038", "authors": ["Suman Raj", "Radhika Mittal", "Rajiv Mayani", "Pawel Zuk", "Anirban Mandal", "Michael Zink", "Yogesh Simmhan", "Ewa Deelman"], "title": "AeroResQ: Edge-Accelerated UAV Framework for Scalable, Resilient and Collaborative Escape Route Planning in Wildfire Scenarios", "comment": "26 pages, 11 figures", "summary": "Drone fleets equipped with onboard cameras, computer vision, and Deep Neural\nNetwork (DNN) models present a powerful paradigm for real-time spatio-temporal\ndecision-making. In wildfire response, such drones play a pivotal role in\nmonitoring fire dynamics, supporting firefighter coordination, and facilitating\nsafe evacuation. In this paper, we introduce AeroResQ, an edge-accelerated UAV\nframework designed for scalable, resilient, and collaborative escape route\nplanning during wildfire scenarios. AeroResQ adopts a multi-layer orchestration\narchitecture comprising service drones (SDs) and coordinator drones (CDs), each\nperforming specialized roles. SDs survey fire-affected areas, detect stranded\nindividuals using onboard edge accelerators running fire detection and human\npose identification DNN models, and issue requests for assistance. CDs,\nequipped with lightweight data stores such as Apache IoTDB, dynamically\ngenerate optimal ground escape routes and monitor firefighter movements along\nthese routes. The framework proposes a collaborative path-planning approach\nbased on a weighted A* search algorithm, where CDs compute context-aware escape\npaths. AeroResQ further incorporates intelligent load-balancing and resilience\nmechanisms: CD failures trigger automated data redistribution across IoTDB\nreplicas, while SD failures initiate geo-fenced re-partitioning and\nreassignment of spatial workloads to operational SDs. We evaluate AeroResQ\nusing realistic wildfire emulated setup modeled on recent Southern California\nwildfires. Experimental results demonstrate that AeroResQ achieves a nominal\nend-to-end latency of <=500ms, much below the 2s request interval, while\nmaintaining over 98% successful task reassignment and completion, underscoring\nits feasibility for real-time, on-field deployment in emergency response and\nfirefighter safety operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AeroResQ\uff0c\u4e00\u79cd\u9762\u5411\u91ce\u706b\u5e94\u6025\u54cd\u5e94\u7684\u8fb9\u7f18\u52a0\u901f\u65e0\u4eba\u673a\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u670d\u52a1\u65e0\u4eba\u673a\u4e0e\u534f\u8c03\u65e0\u4eba\u673a\u7684\u5206\u5c42\u67b6\u6784\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u53ef\u9760\u6027\u7684\u5b9e\u65f6\u9003\u751f\u8def\u5f84\u89c4\u5212\u4e0e\u4efb\u52a1\u5206\u914d\u3002", "motivation": "\u91ce\u706b\u5e94\u6025\u54cd\u5e94\u9700\u8981\u5b9e\u65f6\u3001\u53ef\u9760\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u65e0\u4eba\u673a\u534f\u540c\u3001\u8def\u5f84\u89c4\u5212\u6548\u7387\u4e0e\u7cfb\u7edf\u97e7\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e9f\u9700\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u5177\u5907\u6545\u969c\u6062\u590d\u80fd\u529b\u7684\u8fb9\u7f18\u667a\u80fd\u6846\u67b6\u3002", "method": "AeroResQ\u91c7\u7528\u591a\u5c42\u7f16\u6392\u67b6\u6784\uff0c\u5305\u62ec\u6267\u884c\u706b\u60c5\u76d1\u6d4b\u4e0e\u4eba\u5458\u8bc6\u522b\u7684\u670d\u52a1\u65e0\u4eba\u673a\uff08SDs\uff09\u548c\u8d1f\u8d23\u8def\u5f84\u89c4\u5212\u4e0e\u6570\u636e\u7ba1\u7406\u7684\u534f\u8c03\u65e0\u4eba\u673a\uff08CDs\uff09\uff1b\u8def\u5f84\u89c4\u5212\u57fa\u4e8e\u52a0\u6743A*\u7b97\u6cd5\uff0c\u7cfb\u7edf\u96c6\u6210Apache IoTDB\u8f7b\u91cf\u5b58\u50a8\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9488\u5bf9CD\u548cSD\u6545\u969c\u7684\u8d1f\u8f7d\u5747\u8861\u4e0e\u5de5\u4f5c\u533a\u91cd\u5206\u914d\u673a\u5236\u3002", "result": "\u5728\u6a21\u62df\u5357\u52a0\u5dde\u91ce\u706b\u573a\u666f\u7684\u5b9e\u9a8c\u4e2d\uff0cAeroResQ\u7aef\u5230\u7aef\u5ef6\u8fdf\u2264500ms\uff08\u8fdc\u4f4e\u4e8e2\u79d2\u8bf7\u6c42\u95f4\u9694\uff09\uff0c\u4efb\u52a1\u91cd\u5206\u914d\u4e0e\u5b8c\u6210\u6210\u529f\u7387\u8d85\u8fc798%\u3002", "conclusion": "AeroResQ\u5177\u5907\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u53ef\u9760\u6027\u548c\u5f3a\u97e7\u6027\uff0c\u9002\u7528\u4e8e\u91ce\u706b\u7b49\u7d27\u6025\u573a\u666f\u4e0b\u7684\u5b9e\u65f6\u73b0\u573a\u90e8\u7f72\uff0c\u80fd\u6709\u6548\u63d0\u5347\u6d88\u9632\u5458\u5b89\u5168\u4e0e\u6551\u63f4\u6548\u7387\u3002"}}
{"id": "2511.00215", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00215", "abs": "https://arxiv.org/abs/2511.00215", "authors": ["Xiaomeng Xu", "Zahin Wahab", "Reid Holmes", "Caroline Lemieux"], "title": "DocPrism: Local Categorization and External Filtering to Identify Relevant Code-Documentation Inconsistencies", "comment": null, "summary": "Code-documentation inconsistencies are common and undesirable: they can lead\nto developer misunderstandings and software defects. This paper introduces\nDocPrism, a multi-language, code-documentation inconsistency detection tool.\nDocPrism uses a standard large language model (LLM) to analyze and explain\ninconsistencies. Plain use of LLMs for this task yield unacceptably high false\npositive rates: LLMs identify natural gaps between high-level documentation and\ndetailed code implementations as inconsistencies. We introduce and apply the\nLocal Categorization, External Filtering (LCEF) methodology to reduce false\npositives. LCEF relies on the LLM's local completion skills rather than its\nlong-term reasoning skills. In our ablation study, LCEF reduces DocPrism's\ninconsistency flag rate from 98% to 14%, and increases accuracy from 14% to\n94%. On a broad evaluation across Python, TypeScript, C++, and Java, DocPrism\nmaintains a low flag rate of 15%, and achieves a precision of 0.62 without\nperforming any fine-tuning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDocPrism\uff0c\u4e00\u79cd\u591a\u8bed\u8a00\u4ee3\u7801-\u6587\u6863\u4e0d\u4e00\u81f4\u6027\u68c0\u6d4b\u5de5\u5177\uff0c\u901a\u8fc7\u5f15\u5165LCEF\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6b64\u4efb\u52a1\u4e2d\u7684\u8bef\u62a5\u7387\uff0c\u5728\u672a\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u5728\u591a\u79cd\u8bed\u8a00\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u3002", "motivation": "\u4ee3\u7801\u4e0e\u6587\u6863\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u6027\u666e\u904d\u5b58\u5728\uff0c\u5bb9\u6613\u5bfc\u81f4\u5f00\u53d1\u8005\u8bef\u89e3\u548c\u8f6f\u4ef6\u7f3a\u9677\uff1b\u800c\u76f4\u63a5\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u68c0\u6d4b\u4f1a\u4ea7\u751f\u8fc7\u9ad8\u8bef\u62a5\u7387\uff0c\u56e0\u5176\u5c06\u9ad8\u5c42\u6b21\u6587\u6863\u4e0e\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\u4e4b\u95f4\u7684\u81ea\u7136\u5dee\u5f02\u8bef\u5224\u4e3a\u4e0d\u4e00\u81f4\u3002", "method": "\u63d0\u51faLocal Categorization, External Filtering\uff08LCEF\uff09\u65b9\u6cd5\uff0c\u5229\u7528LLM\u7684\u5c40\u90e8\u8865\u5168\u80fd\u529b\u800c\u975e\u957f\u671f\u63a8\u7406\u80fd\u529b\uff0c\u4ee5\u51cf\u5c11\u8bef\u62a5\uff1b\u8be5\u65b9\u6cd5\u96c6\u6210\u4e8e\u591a\u8bed\u8a00\u5de5\u5177DocPrism\u4e2d\u3002", "result": "\u5728\u6d88\u878d\u5b9e\u9a8c\u4e2d\uff0cLCEF\u5c06DocPrism\u7684\u4e0d\u4e00\u81f4\u6807\u8bb0\u7387\u4ece98%\u964d\u81f314%\uff0c\u51c6\u786e\u7387\u4ece14%\u63d0\u5347\u81f394%\uff1b\u5728Python\u3001TypeScript\u3001C++\u548cJava\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u4e2d\uff0cDocPrism\u4fdd\u630115%\u7684\u4f4e\u6807\u8bb0\u7387\u548c0.62\u7684\u7cbe\u786e\u7387\uff0c\u4e14\u65e0\u9700\u5fae\u8c03\u3002", "conclusion": "DocPrism\u7ed3\u5408LCEF\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLM\u5728\u4ee3\u7801-\u6587\u6863\u4e00\u81f4\u6027\u68c0\u6d4b\u4e2d\u7684\u9ad8\u8bef\u62a5\u95ee\u9898\uff0c\u4e3a\u591a\u8bed\u8a00\u8f6f\u4ef6\u7ef4\u62a4\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u51c6\u786e\u7684\u81ea\u52a8\u5316\u68c0\u6d4b\u65b9\u6848\u3002"}}
{"id": "2511.00262", "categories": ["cs.SE", "D.2; I.2"], "pdf": "https://arxiv.org/pdf/2511.00262", "abs": "https://arxiv.org/abs/2511.00262", "authors": ["Romina Etezadi", "Sallam Abualhaija", "Chetan Arora", "Lionel Briand"], "title": "LLM-Driven Cost-Effective Requirements Change Impact Analysis", "comment": "28 pages, 6 figures", "summary": "Requirements are inherently subject to changes throughout the software\ndevelopment lifecycle. Within the limited budget available to requirements\nengineers, manually identifying the impact of such changes on other\nrequirements is both error-prone and effort-intensive. That might lead to\noverlooked impacted requirements, which, if not properly managed, can cause\nserious issues in the downstream tasks. Inspired by the growing potential of\nlarge language models (LLMs) across diverse domains, we propose ProReFiCIA, an\nLLM-driven approach for automatically identifying the impacted requirements\nwhen changes occur. We conduct an extensive evaluation of ProReFiCIA using\nseveral LLMs and prompts variants tailored to this task. Using the best\ncombination of an LLM and a prompt variant, ProReFiCIA achieves a recall of\n93.3% on a benchmark dataset and 95.8% on a newly created industry dataset,\ndemonstrating its strong effectiveness in identifying impacted requirements.\nFurther, the cost of applying ProReFiCIA remains small, as the engineer only\nneeds to review the generated results, which represent between 2.1% and 8.5% of\nthe entire set of requirements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u52a8\u5316\u65b9\u6cd5 ProReFiCIA\uff0c\u7528\u4e8e\u5728\u9700\u6c42\u53d8\u66f4\u65f6\u9ad8\u6548\u8bc6\u522b\u53d7\u5f71\u54cd\u7684\u9700\u6c42\uff0c\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u5230\u4e8693.3%\u548c95.8%\u7684\u53ec\u56de\u7387\uff0c\u4e14\u5de5\u7a0b\u5e08\u53ea\u9700\u5ba1\u67e5\u5360\u603b\u9700\u6c422.1%\u20138.5%\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u6210\u672c\u8f83\u4f4e\u3002", "motivation": "\u9700\u6c42\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7ecf\u5e38\u53d1\u751f\u53d8\u5316\uff0c\u4eba\u5de5\u8bc6\u522b\u53d8\u66f4\u5bf9\u5176\u4ed6\u9700\u6c42\u7684\u5f71\u54cd\u65e2\u5bb9\u6613\u51fa\u9519\u53c8\u8017\u8d39\u5927\u91cf\u7cbe\u529b\uff0c\u53ef\u80fd\u5bfc\u81f4\u9057\u6f0f\u53d7\u5f71\u54cd\u9700\u6c42\uff0c\u4ece\u800c\u5f15\u53d1\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u4e25\u91cd\u95ee\u9898\u3002", "method": "\u63d0\u51fa ProReFiCIA \u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u8bc6\u522b\u9700\u6c42\u53d8\u66f4\u6240\u5f71\u54cd\u7684\u5176\u4ed6\u9700\u6c42\uff0c\u5e76\u901a\u8fc7\u591a\u79cd LLM \u4e0e\u63d0\u793a\u6a21\u677f\u7ec4\u5408\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u9009\u51fa\u6700\u4f18\u914d\u7f6e\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u548c\u65b0\u6784\u5efa\u7684\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\uff0cProReFiCIA \u5206\u522b\u5b9e\u73b0\u4e8693.3%\u548c95.8%\u7684\u53ec\u56de\u7387\uff1b\u5de5\u7a0b\u5e08\u4ec5\u9700\u5ba1\u67e5\u5360\u5168\u90e8\u9700\u6c422.1%\u81f38.5%\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u663e\u8457\u964d\u4f4e\u4eba\u5de5\u6210\u672c\u3002", "conclusion": "ProReFiCIA \u80fd\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u5730\u8bc6\u522b\u53d7\u53d8\u66f4\u5f71\u54cd\u7684\u9700\u6c42\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u4eba\u5de5\u65b9\u6cd5\uff0c\u5177\u6709\u826f\u597d\u7684\u5b9e\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.00628", "categories": ["cs.MA", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00628", "abs": "https://arxiv.org/abs/2511.00628", "authors": ["Yang Li", "Siqi Ping", "Xiyu Chen", "Xiaojian Qi", "Zigan Wang", "Ye Luo", "Xiaowei Zhang"], "title": "AgentGit: A Version Control Framework for Reliable and Scalable LLM-Powered Multi-Agent Systems", "comment": null, "summary": "With the rapid progress of large language models (LLMs), LLM-powered\nmulti-agent systems (MAS) are drawing increasing interest across academia and\nindustry. However, many current MAS frameworks struggle with reliability and\nscalability, especially on complex tasks. We present AgentGit, a framework that\nbrings Git-like rollback and branching to MAS workflows. Built as an\ninfrastructure layer on top of LangGraph, AgentGit supports state commit,\nrevert, and branching, allowing agents to traverse, compare, and explore\nmultiple trajectories efficiently. To evaluate AgentGit, we designed an\nexperiment that optimizes target agents by selecting better prompts. We ran a\nmulti-step A/B test against three baselines -- LangGraph, AutoGen, and Agno --\non a real-world task: retrieving and analyzing paper abstracts. Results show\nthat AgentGit significantly reduces redundant computation, lowers runtime and\ntoken usage, and supports parallel exploration across multiple branches,\nenhancing both reliability and scalability in MAS development. This work offers\na practical path to more robust MAS design and enables error recovery, safe\nexploration, iterative debugging, and A/B testing in collaborative AI systems.", "AI": {"tldr": "AgentGit \u662f\u4e00\u4e2a\u57fa\u4e8e LangGraph \u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u5f15\u5165\u7c7b\u4f3c Git \u7684\u56de\u6eda\u4e0e\u5206\u652f\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u9762\u4e34\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u652f\u6301\u72b6\u6001\u7ba1\u7406\u4e0e\u9519\u8bef\u6062\u590d\u7684\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u63d0\u51fa AgentGit \u6846\u67b6\uff0c\u901a\u8fc7\u5728 LangGraph \u4e0a\u6784\u5efa\u57fa\u7840\u8bbe\u65bd\u5c42\uff0c\u5b9e\u73b0\u72b6\u6001\u63d0\u4ea4\u3001\u56de\u6eda\u548c\u5206\u652f\u529f\u80fd\uff0c\u652f\u6301\u591a\u8f68\u8ff9\u5e76\u884c\u63a2\u7d22\u4e0e\u9ad8\u6548\u6bd4\u8f83\u3002", "result": "\u5728\u8bba\u6587\u6458\u8981\u68c0\u7d22\u4e0e\u5206\u6790\u4efb\u52a1\u4e2d\uff0cAgentGit \u76f8\u8f83 LangGraph\u3001AutoGen \u548c Agno \u4e09\u5927\u57fa\u7ebf\uff0c\u663e\u8457\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u3001\u964d\u4f4e\u8fd0\u884c\u65f6\u95f4\u548c token \u6d88\u8017\uff0c\u5e76\u652f\u6301\u591a\u5206\u652f\u5e76\u884c\u63a2\u7d22\u3002", "conclusion": "AgentGit \u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u9c81\u68d2\u8bbe\u8ba1\u8def\u5f84\uff0c\u652f\u6301\u9519\u8bef\u6062\u590d\u3001\u5b89\u5168\u63a2\u7d22\u3001\u8fed\u4ee3\u8c03\u8bd5\u548c A/B \u6d4b\u8bd5\uff0c\u6709\u6548\u63d0\u5347 MAS \u7684\u53ef\u9760\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.00294", "categories": ["cs.DC", "cs.NI", "68M14", "C.2.4"], "pdf": "https://arxiv.org/pdf/2511.00294", "abs": "https://arxiv.org/abs/2511.00294", "authors": ["Lucas Almeida", "Maycon Peixoto"], "title": "Tetris: An SLA-aware Application Placement Strategy in the Edge-Cloud Continuum", "comment": "10 pages, 7 sections, 12 figures, 9 tables", "summary": "An Edge-Cloud Continuum integrates edge and cloud resources to provide a\nflexible and scalable infrastructure. This paradigm can minimize latency by\nprocessing data closer to the source at the edge while leveraging the vast\ncomputational power of the cloud for more intensive tasks. In this context,\nmodule application placement requires strategic allocation plans that align\nuser demands with infrastructure constraints, aiming for efficient resource\nuse. Therefore, we propose Tetris, an application placement strategy that\nutilizes a heuristic algorithm to distribute computational services across edge\nand cloud resources efficiently. Tetris prioritizes services based on SLA\nurgencies and resource efficiency to avoid system overloading. Our results\ndemonstrate that Tetris reduces SLA violations by approximately 76% compared to\nthe baseline method, which serves as a reference point for benchmarking\nperformance in this scenario. Therefore, Tetris offers an effective placement\napproach for managing latency-sensitive applications in Edge-Cloud Continuum\nenvironments, enhancing Quality of Service (QoS) for users.", "AI": {"tldr": "Tetris \u662f\u4e00\u79cd\u9762\u5411 Edge-Cloud Continuum \u7684\u5e94\u7528\u653e\u7f6e\u7b56\u7565\uff0c\u901a\u8fc7\u542f\u53d1\u5f0f\u7b97\u6cd5\u6839\u636e SLA \u7d27\u8feb\u6027\u548c\u8d44\u6e90\u6548\u7387\u5206\u914d\u670d\u52a1\uff0c\u5728\u51cf\u5c11\u7cfb\u7edf\u8fc7\u8f7d\u7684\u540c\u65f6\u5c06 SLA \u8fdd\u89c4\u964d\u4f4e\u7ea6 76%\uff0c\u663e\u8457\u63d0\u5347\u670d\u52a1\u8d28\u91cf\u3002", "motivation": "\u5728 Edge-Cloud Continuum \u73af\u5883\u4e2d\uff0c\u9700\u5728\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u548c\u57fa\u7840\u8bbe\u65bd\u7ea6\u675f\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u8d44\u6e90\u5229\u7528\u5e76\u964d\u4f4e\u5ef6\u8fdf\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u667a\u80fd\u7684\u5e94\u7528\u6a21\u5757\u653e\u7f6e\u7b56\u7565\u3002", "method": "\u63d0\u51fa Tetris \u7b56\u7565\uff0c\u91c7\u7528\u542f\u53d1\u5f0f\u7b97\u6cd5\u5728\u8fb9\u7f18\u548c\u4e91\u8d44\u6e90\u95f4\u5206\u914d\u8ba1\u7b97\u670d\u52a1\uff0c\u4f18\u5148\u8003\u8651 SLA \u7d27\u8feb\u6027\u548c\u8d44\u6e90\u6548\u7387\uff0c\u907f\u514d\u7cfb\u7edf\u8fc7\u8f7d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cTetris \u5c06 SLA \u8fdd\u89c4\u51cf\u5c11\u4e86\u7ea6 76%\u3002", "conclusion": "Tetris \u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5e94\u7528\u653e\u7f6e\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u7ba1\u7406 Edge-Cloud Continuum \u4e2d\u5bf9\u5ef6\u8fdf\u654f\u611f\u7684\u5e94\u7528\uff0c\u80fd\u663e\u8457\u63d0\u5347\u7528\u6237\u7684\u670d\u52a1\u8d28\u91cf\u3002"}}
{"id": "2511.00417", "categories": ["cs.SE", "cs.AI", "cs.HC", "H.5.3; D.2.9; I.2.0"], "pdf": "https://arxiv.org/pdf/2511.00417", "abs": "https://arxiv.org/abs/2511.00417", "authors": ["Marcel Valovy"], "title": "Human-AI Programming Role Optimization: Developing a Personality-Driven Self-Determination Framework", "comment": "PhD Dissertation, Prague University of Economics and Business, 2025.\n  323 pages. ACM CCS 2012: Human-computer interaction, Collaborative\n  interaction, Human-AI collaborative systems, Pair programming, AI-assisted\n  software engineering", "summary": "As artificial intelligence transforms software development, a critical\nquestion emerges: how can developers and AI systems collaborate most\neffectively? This dissertation optimizes human-AI programming roles through\nself-determination theory and personality psychology, introducing the Role\nOptimization Motivation Alignment (ROMA) framework.\n  Through Design Science Research spanning five cycles, this work establishes\nempirically-validated connections between personality traits, programming role\npreferences, and collaborative outcomes, engaging 200 experimental participants\nand 46 interview respondents.\n  Key findings demonstrate that personality-driven role optimization\nsignificantly enhances self-determination and team dynamics, yielding 23%\naverage motivation increases among professionals and up to 65% among\nundergraduates. Five distinct personality archetypes emerge: The Explorer (high\nOpenness/low Agreeableness), The Orchestrator (high\nExtraversion/Agreeableness), The Craftsperson (high Neuroticism/low\nExtraversion), The Architect (high Conscientiousness), and The Adapter\n(balanced profile). Each exhibits distinct preferences for programming roles\n(Co-Pilot, Co-Navigator, Agent), with assignment modes proving crucial for\nsatisfaction.\n  The dissertation contributes: (1) an empirically-validated framework linking\npersonality traits to role preferences and self-determination outcomes; (2) a\ntaxonomy of AI collaboration modalities mapped to personality profiles while\npreserving human agency; and (3) an ISO/IEC 29110 extension enabling Very Small\nEntities to implement personality-driven role optimization within established\nstandards.\n  Keywords: artificial intelligence, human-computer interaction, behavioral\nsoftware engineering, self-determination theory, personality psychology,\nphenomenology, intrinsic motivation, pair programming, design science research,\nISO/IEC 29110", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u81ea\u6211\u51b3\u5b9a\u7406\u8bba\u548c\u4eba\u683c\u5fc3\u7406\u5b66\uff0c\u63d0\u51faROMA\u6846\u67b6\uff0c\u4f18\u5316\u4eba\u7c7b\u4e0eAI\u5728\u7f16\u7a0b\u4e2d\u7684\u534f\u4f5c\u89d2\u8272\uff0c\u53d1\u73b0\u4eba\u683c\u7279\u8d28\u4e0e\u89d2\u8272\u504f\u597d\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u5e76\u663e\u8457\u63d0\u5347\u5f00\u53d1\u8005\u7684\u52a8\u673a\u548c\u56e2\u961f\u534f\u4f5c\u6548\u679c\u3002", "motivation": "\u63a2\u7d22\u5728AI\u65e5\u76ca\u4ecb\u5165\u8f6f\u4ef6\u5f00\u53d1\u7684\u80cc\u666f\u4e0b\uff0c\u5982\u4f55\u57fa\u4e8e\u5f00\u53d1\u8005\u7684\u4eba\u683c\u7279\u8d28\u4f18\u5316\u5176\u4e0eAI\u7cfb\u7edf\u7684\u534f\u4f5c\u89d2\u8272\uff0c\u4ee5\u63d0\u5347\u5185\u5728\u52a8\u673a\u3001\u81ea\u4e3b\u6027\u548c\u56e2\u961f\u534f\u4f5c\u6548\u7387\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u5386\u7ecf\u4e94\u4e2a\u8fed\u4ee3\u5468\u671f\uff0c\u7ed3\u5408200\u540d\u5b9e\u9a8c\u53c2\u4e0e\u8005\u548c46\u540d\u8bbf\u8c08\u5bf9\u8c61\uff0c\u5b9e\u8bc1\u5206\u6790\u4eba\u683c\u7279\u8d28\u3001\u7f16\u7a0b\u89d2\u8272\u504f\u597d\u4e0e\u534f\u4f5c\u7ed3\u679c\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u8bc6\u522b\u51fa\u4e94\u79cd\u4eba\u683c\u539f\u578b\uff08\u63a2\u7d22\u8005\u3001\u534f\u8c03\u8005\u3001\u5de5\u5320\u3001\u67b6\u6784\u5e08\u3001\u9002\u5e94\u8005\uff09\uff0c\u6bcf\u79cd\u5bf9AI\u534f\u4f5c\u89d2\u8272\uff08\u5982Co-Pilot\u3001Co-Navigator\u3001Agent\uff09\u6709\u4e0d\u540c\u504f\u597d\uff1b\u57fa\u4e8e\u4eba\u683c\u7684\u89d2\u8272\u5206\u914d\u4f7f\u4e13\u4e1a\u4eba\u58eb\u5e73\u5747\u52a8\u673a\u63d0\u534723%\uff0c\u672c\u79d1\u751f\u6700\u9ad8\u8fbe65%\u3002", "conclusion": "\u8bba\u6587\u8d21\u732e\u4e86\u4e00\u4e2a\u4eba\u683c\u9a71\u52a8\u7684\u534f\u4f5c\u89d2\u8272\u4f18\u5316\u6846\u67b6\uff08ROMA\uff09\u3001AI\u534f\u4f5c\u6a21\u5f0f\u5206\u7c7b\u6cd5\uff0c\u5e76\u6269\u5c55\u4e86ISO/IEC 29110\u6807\u51c6\uff0c\u652f\u6301\u6781\u5c0f\u578b\u5b9e\u4f53\u5728\u6807\u51c6\u6846\u67b6\u5185\u5b9e\u65bd\u4e2a\u6027\u5316\u4eba\u673a\u534f\u4f5c\u7b56\u7565\u3002"}}
{"id": "2511.00502", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.00502", "abs": "https://arxiv.org/abs/2511.00502", "authors": ["Peng Zhang", "Vitaly Petrov", "Emil Bj\u00f6rnson"], "title": "Impact of Antenna Arrays Misalignment on the Near Field Distance in Terahertz Communications", "comment": "Accepted to IEEE Globecom, 2025. Copyright 2025 IEEE. Personal use of\n  this material is permitted. Permission from IEEE must be obtained for all\n  other uses, in any current or future media, including reprinting/republishing\n  this material, creating new works, for resale or redistribution to servers or\n  lists, or reuse of any copyrighted component of this work in other works", "summary": "The extremely short wavelength of terahertz (THz) communications leads to an\nextended radiative near-field region, in which some canonical far-field\nassumptions fail. Existing near-field boundary formulations (Fraunhofer\ndistance) for uniform linear/planar array (ULA/UPA) configurations assume ideal\nalignment between transceivers, overlooking practical misalignments caused by\nmobility or mechanical imperfections. This paper addresses this critical gap by\nanalyzing the impact of spatial misalignment on near-field distance\ncalculations in THz systems. We derive exact analytical expressions and\nsimplified approximations for the near-field boundary in both ULA--ULA and\nUPA--UPA configurations under arbitrary misalignment offsets. Through numerical\nsimulations, we validate our theoretical models and quantify how misalignment\nreshapes the near-field region. These findings provide essential guidelines for\noptimizing THz system deployment in realistic scenarios.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u592a\u8d6b\u5179\u901a\u4fe1\u4e2d\u7531\u4e8e\u6536\u53d1\u5668\u7a7a\u95f4\u9519\u4f4d\u5bf9\u8fd1\u573a\u8fb9\u754c\u8ba1\u7b97\u7684\u5f71\u54cd\uff0c\u63a8\u5bfc\u4e86\u5728\u4efb\u610f\u9519\u4f4d\u6761\u4ef6\u4e0b\u5747\u5300\u7ebf\u9635\u548c\u9762\u9635\u914d\u7f6e\u4e0b\u7684\u8fd1\u573a\u8fb9\u754c\u7684\u7cbe\u786e\u89e3\u6790\u8868\u8fbe\u5f0f\u4e0e\u7b80\u5316\u8fd1\u4f3c\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u592a\u8d6b\u5179\u901a\u4fe1\u7cfb\u7edf\u4e2d\u8fd1\u573a\u8fb9\u754c\u7684\u8ba1\u7b97\u901a\u5e38\u5047\u8bbe\u6536\u53d1\u5668\u7406\u60f3\u5bf9\u9f50\uff0c\u5ffd\u7565\u4e86\u5b9e\u9645\u56e0\u79fb\u52a8\u6027\u6216\u673a\u68b0\u8bef\u5dee\u5bfc\u81f4\u7684\u7a7a\u95f4\u9519\u4f4d\u95ee\u9898\uff0c\u8fd9\u5728\u6781\u77ed\u6ce2\u957f\u4e0b\u5c24\u4e3a\u5173\u952e\u3002", "method": "\u63a8\u5bfc\u4e86ULA\u2013ULA\u548cUPA\u2013UPA\u914d\u7f6e\u5728\u4efb\u610f\u9519\u4f4d\u504f\u79fb\u4e0b\u7684\u8fd1\u573a\u8fb9\u754c\u7684\u7cbe\u786e\u89e3\u6790\u8868\u8fbe\u5f0f\u548c\u7b80\u5316\u8fd1\u4f3c\u516c\u5f0f\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u7406\u8bba\u6a21\u578b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u7a7a\u95f4\u9519\u4f4d\u663e\u8457\u6539\u53d8\u4e86\u8fd1\u573a\u533a\u57df\u7684\u5f62\u72b6\u548c\u8303\u56f4\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u80fd\u51c6\u786e\u63cf\u8ff0\u8fd9\u4e00\u73b0\u8c61\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u592a\u8d6b\u5179\u7cfb\u7edf\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u8fd1\u573a\u5efa\u6a21\u4e0e\u4f18\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u4f9d\u636e\u548c\u8bbe\u8ba1\u6307\u5bfc\u3002"}}
{"id": "2511.01078", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.01078", "abs": "https://arxiv.org/abs/2511.01078", "authors": ["Qinwei Huang", "Stefan Wang", "Simon Khan", "Garrett Katz", "Qinru Qiu"], "title": "Predictive Auxiliary Learning for Belief-based Multi-Agent Systems", "comment": null, "summary": "The performance of multi-agent reinforcement learning (MARL) in partially\nobservable environments depends on effectively aggregating information from\nobservations, communications, and reward signals. While most existing\nmulti-agent systems primarily rely on rewards as the only feedback for policy\ntraining, our research shows that introducing auxiliary predictive tasks can\nsignificantly enhance learning efficiency and stability. We propose\nBelief-based Predictive Auxiliary Learning (BEPAL), a framework that\nincorporates auxiliary training objectives to support policy optimization.\nBEPAL follows the centralized training with decentralized execution paradigm.\nEach agent learns a belief model that predicts unobservable state information,\nsuch as other agents' rewards or motion directions, alongside its policy model.\nBy enriching hidden state representations with information that does not\ndirectly contribute to immediate reward maximization, this auxiliary learning\nprocess stabilizes MARL training and improves overall performance. We evaluate\nBEPAL in the predator-prey environment and Google Research Football, where it\nachieves an average improvement of about 16 percent in performance metrics and\ndemonstrates more stable convergence compared to baseline methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBEPAL\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u8f85\u52a9\u9884\u6d4b\u4efb\u52a1\uff08\u5982\u9884\u6d4b\u5176\u4ed6\u667a\u80fd\u4f53\u7684\u5956\u52b1\u6216\u8fd0\u52a8\u65b9\u5411\uff09\u6765\u589e\u5f3a\u7b56\u7565\u5b66\u4e60\u7684\u6548\u7387\u4e0e\u7a33\u5b9a\u6027\uff0c\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u7ea616%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5927\u591a\u6570\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4ec5\u4f9d\u8d56\u5956\u52b1\u4fe1\u53f7\u8fdb\u884c\u7b56\u7565\u8bad\u7ec3\uff0c\u5ffd\u7565\u4e86\u89c2\u6d4b\u548c\u901a\u4fe1\u4e2d\u8574\u542b\u7684\u4e30\u5bcc\u4fe1\u606f\uff1b\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u8f85\u52a9\u9884\u6d4b\u4efb\u52a1\u6765\u63d0\u5347\u5b66\u4e60\u6548\u7387\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51faBelief-based Predictive Auxiliary Learning\uff08BEPAL\uff09\u6846\u67b6\uff0c\u91c7\u7528\u96c6\u4e2d\u8bad\u7ec3\u3001\u5206\u6563\u6267\u884c\u8303\u5f0f\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u540c\u65f6\u5b66\u4e60\u4e00\u4e2a\u4fe1\u5ff5\u6a21\u578b\uff08\u7528\u4e8e\u9884\u6d4b\u4e0d\u53ef\u89c2\u6d4b\u72b6\u6001\uff09\u548c\u7b56\u7565\u6a21\u578b\uff0c\u5229\u7528\u8f85\u52a9\u4efb\u52a1\u4e30\u5bcc\u9690\u72b6\u6001\u8868\u793a\u3002", "result": "\u5728\u6355\u98df\u8005-\u730e\u7269\u73af\u5883\u548cGoogle Research Football\u4e2d\uff0cBEPAL\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5e73\u5747\u63d0\u5347\u7ea616%\u7684\u6027\u80fd\u6307\u6807\uff0c\u5e76\u5c55\u73b0\u51fa\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u6027\u3002", "conclusion": "\u5f15\u5165\u57fa\u4e8e\u4fe1\u5ff5\u7684\u8f85\u52a9\u9884\u6d4b\u4efb\u52a1\u80fd\u6709\u6548\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u7684\u6027\u80fd\u4e0e\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u9a8c\u8bc1\u4e86\u8f85\u52a9\u5b66\u4e60\u5728MARL\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2511.00603", "categories": ["cs.DC", "cs.AI", "cs.NI", "68T05", "I.2.11"], "pdf": "https://arxiv.org/pdf/2511.00603", "abs": "https://arxiv.org/abs/2511.00603", "authors": ["Yubo Wang", "Yubo Cui", "Tuo Shi", "Danyang Li", "Wenxin Li", "Lide Suo", "Tao Wang", "Xin Xie"], "title": "EPARA: Parallelizing Categorized AI Inference in Edge Clouds", "comment": "15 pages,20 figures", "summary": "With the increasing adoption of AI applications such as large language models\nand computer vision AI, the computational demands on AI inference systems are\ncontinuously rising, making the enhancement of task processing capacity using\nexisting hardware a primary objective in edge clouds. We propose EPARA, an\nend-to-end AI parallel inference framework in edge, aimed at enhancing the edge\nAI serving capability. Our key idea is to categorize tasks based on their\nsensitivity to latency/frequency and requirement for GPU resources, thereby\nachieving both request-level and service-level task-resource allocation. EPARA\nconsists of three core components: 1) a task-categorized parallelism allocator\nthat decides the parallel mode of each task, 2) a distributed request handler\nthat performs the calculation for the specific request, and 3) a state-aware\nscheduler that periodically updates service placement in edge clouds. We\nimplement a EPARA prototype and conduct a case study on the EPARA operation for\nLLMs and segmentation tasks. Evaluation through testbed experiments involving\nedge servers, embedded devices, and microcomputers shows that EPARA achieves up\nto 2.1$\\times$ higher goodput in production workloads compared to prior\nframeworks, while adapting to various edge AI inference tasks.", "AI": {"tldr": "EPARA \u662f\u4e00\u79cd\u9762\u5411\u8fb9\u7f18\u8ba1\u7b97\u7684\u7aef\u5230\u7aef AI \u5e76\u884c\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u7c7b\u4e0e\u8d44\u6e90\u5206\u914d\u7b56\u7565\uff0c\u5728\u4e0d\u589e\u52a0\u786c\u4ef6\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u8fb9\u7f18 AI \u63a8\u7406\u7cfb\u7edf\u7684\u541e\u5410\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u7b49 AI \u5e94\u7528\u7684\u666e\u53ca\uff0c\u8fb9\u7f18\u4e91\u4e2d AI \u63a8\u7406\u4efb\u52a1\u7684\u8ba1\u7b97\u9700\u6c42\u4e0d\u65ad\u589e\u957f\uff0c\u5982\u4f55\u5229\u7528\u73b0\u6709\u786c\u4ef6\u63d0\u5347\u4efb\u52a1\u5904\u7406\u80fd\u529b\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002", "method": "EPARA \u6846\u67b6\u6839\u636e\u4efb\u52a1\u5bf9\u5ef6\u8fdf/\u9891\u7387\u7684\u654f\u611f\u6027\u548c GPU \u8d44\u6e90\u9700\u6c42\u8fdb\u884c\u5206\u7c7b\uff0c\u5b9e\u73b0\u8bf7\u6c42\u7ea7\u548c\u670d\u52a1\u7ea7\u7684\u4efb\u52a1-\u8d44\u6e90\u5206\u914d\u3002\u5176\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u4efb\u52a1\u5206\u7c7b\u5e76\u884c\u5206\u914d\u5668\u3001\u5206\u5e03\u5f0f\u8bf7\u6c42\u5904\u7406\u5668\u548c\u72b6\u6001\u611f\u77e5\u8c03\u5ea6\u5668\u3002", "result": "\u5728\u5305\u542b\u8fb9\u7f18\u670d\u52a1\u5668\u3001\u5d4c\u5165\u5f0f\u8bbe\u5907\u548c\u5fae\u578b\u8ba1\u7b97\u673a\u7684\u6d4b\u8bd5\u5e73\u53f0\u4e0a\uff0cEPARA \u5728\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u76f8\u6bd4\u73b0\u6709\u6846\u67b6\u5b9e\u73b0\u4e86\u6700\u9ad8 2.1 \u500d\u7684 goodput \u63d0\u5347\uff0c\u5e76\u80fd\u9002\u5e94\u591a\u79cd\u8fb9\u7f18 AI \u63a8\u7406\u4efb\u52a1\u3002", "conclusion": "EPARA \u6709\u6548\u63d0\u5347\u4e86\u8fb9\u7f18 AI \u63a8\u7406\u7cfb\u7edf\u7684\u670d\u52a1\u80fd\u529b\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u73af\u5883\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u5e76\u884c\u63a8\u7406\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00796", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00796", "abs": "https://arxiv.org/abs/2511.00796", "authors": ["Ran Yan", "Youhe Jiang", "Tianyuan Wu", "Jiaxuan Gao", "Zhiyu Mei", "Wei Fu", "Haohui Mai", "Wei Wang", "Yi Wu", "Binhang Yuan"], "title": "AReaL-Hex: Accommodating Asynchronous RL Training over Heterogeneous GPUs", "comment": null, "summary": "Maximizing training throughput and cost-efficiency of RL for LLMs is\nessential to democratize this advanced technique. One promising but challenging\napproach is to deploy such a computational workflow over heterogeneous GPUs.\nUnlike conventional large-scale LLM pretraining, RL training generally\ndecomposes into three coupled stages, i.e., rollout generation, reward\ncomputation, and policy/value updates, which exhibit markedly different compute\nintensities, memory footprints, and communication patterns. Recent research\nshows that fully asynchronous RL training can disaggregate these stages across\ndisjoint hardware pools without sacrificing training stability, creating a\ngreat opportunity for real-world heterogeneous deployment. To this end, we\npresent AReaL-Hex, a heterogeneity-aware asynchronous RL training system that\neffectively schedules how to execute rollout generation and policy model\ntraining over heterogeneous GPUs while enforcing data staleness bounds.\nConcretely, we use a two-phase scheduler: (i) a constrained search with MILP to\nselect per-stage parallelization strategies and workload assignments given a\nresource budget, and (ii) a graph-partitioning step that allocates\nheterogeneous GPUs and interconnects to maximize end-to-end throughput. Built\natop a fully asynchronous RL architecture, AReaL-Hex maps HBM-I/O-bound\ngeneration and compute-bound optimization to more cost-efficient resources and\nbalances their producer-consumer interactions to avoid both idleness and stale\nrollout trajectories. On the mathematical reasoning task with various model\nscales (1.5B, 7B, and 14B), compared to homogeneous deployments of\nstate-of-the-art asynchronous RL systems: (i) When maintaining the same total\nbudgets, AReaL-Hex delivers up to 1.50x higher training throughput; (ii) When\nachieving the same training throughput, AReaL-Hex results in up to 1.46x\nreduction in training cost.", "AI": {"tldr": "AReaL-Hex \u662f\u4e00\u79cd\u9762\u5411\u5f02\u6784 GPU \u7684\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8bad\u7ec3\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8c03\u5ea6\u7b56\u7565\u4f18\u5316\u751f\u6210\u4e0e\u8bad\u7ec3\u9636\u6bb5\u7684\u8d44\u6e90\u5206\u914d\uff0c\u5728\u4fdd\u8bc1\u6570\u636e\u65b0\u9c9c\u5ea6\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\u5e76\u964d\u4f4e\u6210\u672c\u3002", "motivation": "\u4e3a\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u6210\u672c\u5e76\u63d0\u5347\u541e\u5410\u91cf\uff0c\u9700\u6709\u6548\u5229\u7528\u5f02\u6784 GPU \u8d44\u6e90\u3002\u4f20\u7edf\u540c\u6784\u90e8\u7f72\u96be\u4ee5\u5339\u914d RL \u4e09\u9636\u6bb5\uff08rollout \u751f\u6210\u3001\u5956\u52b1\u8ba1\u7b97\u3001\u7b56\u7565/\u4ef7\u503c\u66f4\u65b0\uff09\u5728\u8ba1\u7b97\u5f3a\u5ea6\u3001\u5185\u5b58\u5360\u7528\u548c\u901a\u4fe1\u6a21\u5f0f\u4e0a\u7684\u663e\u8457\u5dee\u5f02\u3002", "method": "\u63d0\u51fa AReaL-Hex \u7cfb\u7edf\uff0c\u57fa\u4e8e\u5b8c\u5168\u5f02\u6b65 RL \u67b6\u6784\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8c03\u5ea6\u5668\uff1a(i) \u4f7f\u7528\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08MILP\uff09\u5728\u8d44\u6e90\u9884\u7b97\u7ea6\u675f\u4e0b\u9009\u62e9\u5404\u9636\u6bb5\u7684\u5e76\u884c\u7b56\u7565\u4e0e\u5de5\u4f5c\u8d1f\u8f7d\u5206\u914d\uff1b(ii) \u901a\u8fc7\u56fe\u5212\u5206\u65b9\u6cd5\u5206\u914d\u5f02\u6784 GPU \u4e0e\u4e92\u8fde\u8d44\u6e90\u4ee5\u6700\u5927\u5316\u7aef\u5230\u7aef\u541e\u5410\u91cf\uff0c\u5e76\u63a7\u5236\u6570\u636e\u9648\u65e7\u6027\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e0a\uff08\u6a21\u578b\u89c4\u6a21 1.5B\u30017B\u300114B\uff09\uff0c\u76f8\u6bd4\u540c\u6784\u90e8\u7f72\u7684\u5148\u8fdb\u5f02\u6b65 RL \u7cfb\u7edf\uff1a(i) \u76f8\u540c\u9884\u7b97\u4e0b\uff0cAReaL-Hex \u541e\u5410\u91cf\u6700\u9ad8\u63d0\u5347 1.50 \u500d\uff1b(ii) \u76f8\u540c\u541e\u5410\u91cf\u4e0b\uff0c\u8bad\u7ec3\u6210\u672c\u6700\u591a\u964d\u4f4e 1.46 \u500d\u3002", "conclusion": "AReaL-Hex \u901a\u8fc7\u5f02\u6784\u611f\u77e5\u7684\u5f02\u6b65\u8c03\u5ea6\u673a\u5236\uff0c\u6709\u6548\u5e73\u8861\u4e86\u751f\u6210\u4e0e\u4f18\u5316\u9636\u6bb5\u7684\u8d44\u6e90\u9700\u6c42\uff0c\u5728\u771f\u5b9e\u5f02\u6784 GPU \u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u8bad\u7ec3\u6548\u7387\u4e0e\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2511.00467", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00467", "abs": "https://arxiv.org/abs/2511.00467", "authors": ["Liu Wang", "Dong Wang", "Shidong Pan", "Zheng Jiang", "Haoyu Wang", "Yi Wang"], "title": "A Big Step Forward? A User-Centric Examination of iOS App Privacy Report and Enhancements", "comment": "Accepted to S&P 2025", "summary": "The prevalent engagement with mobile apps underscores the importance of\nunderstanding their data practices. Transparency plays a crucial role in this\ncontext, ensuring users to be informed and give consent before any data access\noccurs. Apple introduced a new feature since iOS 15.2, App Privacy Report, to\ninform users about detailed insights into apps' data access and sharing. This\nfeature continues Apple's trend of privacy-focused innovations (following\nPrivacy Nutrition Labels), and has been marketed as a big step forward in user\nprivacy. However, its real-world impacts on user privacy and control remain\nunexamined. We thus proposed an end-to-end study involving systematic\nassessment of the App Privacy Report's real-world benefits and limitations,\nLLM-enabled and multi-technique synthesized enhancements, and comprehensive\nevaluation from both system and user perspectives. Through a structured focus\ngroup study with twelve everyday iOS users, we explored their experiences,\nunderstanding, and perceptions of the feature, suggesting its limited practical\nimpact resulting from missing important details. We identified two primary user\nconcerns: the clarity of data access purpose and domain description. In\nresponse, we proposed enhancements including a purpose inference framework and\ndomain clarification pipeline. We demonstrated the effectiveness and benefits\nof such enhancements for mobile app users. This work provides practical\ninsights that could help enhance user privacy transparency and discusses areas\nfor future research.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86iOS 15.2\u5f15\u5165\u7684\u201cApp\u9690\u79c1\u62a5\u544a\u201d\u529f\u80fd\u5728\u73b0\u5b9e\u4e2d\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5176\u5bf9\u7528\u6237\u9690\u79c1\u7684\u5b9e\u9645\u5e2e\u52a9\u6709\u9650\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6280\u672f\u878d\u5408\u7684\u6539\u8fdb\u65b9\u6848\uff0c\u4ee5\u63d0\u5347\u6570\u636e\u8bbf\u95ee\u76ee\u7684\u548c\u57df\u540d\u63cf\u8ff0\u7684\u6e05\u6670\u5ea6\u3002", "motivation": "\u5c3d\u7ba1\u82f9\u679c\u63a8\u51fa\u4e86App\u9690\u79c1\u62a5\u544a\u4ee5\u589e\u5f3a\u7528\u6237\u5bf9\u5e94\u7528\u6570\u636e\u884c\u4e3a\u7684\u4e86\u89e3\uff0c\u4f46\u5176\u5728\u771f\u5b9e\u4f7f\u7528\u573a\u666f\u4e2d\u5bf9\u7528\u6237\u9690\u79c1\u548c\u63a7\u5236\u7684\u5b9e\u9645\u5f71\u54cd\u5c1a\u672a\u88ab\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u7814\u7a76\u91c7\u7528\u7aef\u5230\u7aef\u65b9\u6cd5\uff0c\u5305\u62ec\u5bf912\u540d\u666e\u901aiOS\u7528\u6237\u7684\u7126\u70b9\u5c0f\u7ec4\u7814\u7a76\uff0c\u5206\u6790\u7528\u6237\u5bf9App\u9690\u79c1\u62a5\u544a\u7684\u7406\u89e3\u4e0e\u4f53\u9a8c\uff1b\u5e76\u63d0\u51fa\u5305\u542b\u76ee\u7684\u63a8\u65ad\u6846\u67b6\u548c\u57df\u540d\u6f84\u6e05\u7ba1\u9053\u7684\u589e\u5f3a\u65b9\u6848\uff0c\u4ece\u7cfb\u7edf\u548c\u7528\u6237\u53cc\u91cd\u89c6\u89d2\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0App\u9690\u79c1\u62a5\u544a\u56e0\u7f3a\u4e4f\u5173\u952e\u7ec6\u8282\uff08\u5982\u6570\u636e\u8bbf\u95ee\u76ee\u7684\u548c\u57df\u540d\u8bf4\u660e\uff09\u800c\u5b9e\u9645\u5f71\u54cd\u6709\u9650\uff1b\u6240\u63d0\u51fa\u7684\u589e\u5f3a\u65b9\u6848\u6709\u6548\u63d0\u5347\u4e86\u900f\u660e\u5ea6\u548c\u7528\u6237\u4f53\u9a8c\u3002", "conclusion": "App\u9690\u79c1\u62a5\u544a\u867d\u5177\u521b\u65b0\u6027\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u771f\u6b63\u8d4b\u80fd\u7528\u6237\uff1b\u672c\u7814\u7a76\u4e3a\u63d0\u5347\u79fb\u52a8\u5e94\u7528\u9690\u79c1\u900f\u660e\u5ea6\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.01310", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.01310", "abs": "https://arxiv.org/abs/2511.01310", "authors": ["Sureyya Akin", "Kavita Srivastava", "Prateek B. Kapoor", "Pradeep G. Sethi", "Sunita Q. Patel", "Rahu Srivastava"], "title": "From Pixels to Cooperation Multi Agent Reinforcement Learning based on Multimodal World Models", "comment": null, "summary": "Learning cooperative multi-agent policies directly from high-dimensional,\nmultimodal sensory inputs like pixels and audio (from pixels) is notoriously\nsample-inefficient. Model-free Multi-Agent Reinforcement Learning (MARL)\nalgorithms struggle with the joint challenge of representation learning,\npartial observability, and credit assignment. To address this, we propose a\nnovel framework based on a shared, generative Multimodal World Model (MWM). Our\nMWM is trained to learn a compressed latent representation of the environment's\ndynamics by fusing distributed, multimodal observations from all agents using a\nscalable attention-based mechanism. Subsequently, we leverage this learned MWM\nas a fast, \"imagined\" simulator to train cooperative MARL policies (e.g.,\nMAPPO) entirely within its latent space, decoupling representation learning\nfrom policy learning. We introduce a new set of challenging multimodal,\nmulti-agent benchmarks built on a 3D physics simulator. Our experiments\ndemonstrate that our MWM-MARL framework achieves orders-of-magnitude greater\nsample efficiency compared to state-of-the-art model-free MARL baselines. We\nfurther show that our proposed multimodal fusion is essential for task success\nin environments with sensory asymmetry and that our architecture provides\nsuperior robustness to sensor-dropout, a critical feature for real-world\ndeployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5171\u4eab\u751f\u6210\u5f0f\u591a\u6a21\u6001\u4e16\u754c\u6a21\u578b\uff08MWM\uff09\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u591a\u667a\u80fd\u4f53\u7684\u591a\u6a21\u6001\u89c2\u6d4b\u5b66\u4e60\u73af\u5883\u52a8\u6001\u7684\u538b\u7f29\u6f5c\u5728\u8868\u793a\uff0c\u5e76\u5728\u8be5\u6a21\u578b\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8bad\u7ec3\u534f\u4f5c\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6837\u672c\u6548\u7387\u3001\u9c81\u68d2\u6027\u53ca\u5728\u611f\u77e5\u4e0d\u5bf9\u79f0\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u76f4\u63a5\u4ece\u9ad8\u7ef4\u591a\u6a21\u6001\u611f\u5b98\u8f93\u5165\uff08\u5982\u50cf\u7d20\u548c\u97f3\u9891\uff09\u4e2d\u5b66\u4e60\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u7b56\u7565\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65e0\u6a21\u578b\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u5e94\u5bf9\u8868\u5f81\u5b66\u4e60\u3001\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u4fe1\u7528\u5206\u914d\u4e09\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5171\u4eab\u751f\u6210\u5f0f\u591a\u6a21\u6001\u4e16\u754c\u6a21\u578b\uff08MWM\uff09\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u53ef\u6269\u5c55\u7684\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u6240\u6709\u667a\u80fd\u4f53\u7684\u5206\u5e03\u5f0f\u591a\u6a21\u6001\u89c2\u6d4b\uff0c\u5b66\u4e60\u73af\u5883\u52a8\u6001\u7684\u538b\u7f29\u6f5c\u5728\u8868\u793a\uff1b\u968f\u540e\u5728\u8be5MWM\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u4f5c\u4e3a\u201c\u60f3\u8c61\u201d\u6a21\u62df\u5668\u8bad\u7ec3MARL\u7b56\u7565\uff08\u5982MAPPO\uff09\uff0c\u5b9e\u73b0\u8868\u5f81\u5b66\u4e60\u4e0e\u7b56\u7565\u5b66\u4e60\u7684\u89e3\u8026\u3002", "result": "\u5728\u65b0\u6784\u5efa\u7684\u57fa\u4e8e3D\u7269\u7406\u6a21\u62df\u5668\u7684\u591a\u6a21\u6001\u591a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMWM-MARL\u6846\u67b6\u76f8\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65e0\u6a21\u578bMARL\u57fa\u7ebf\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u66f4\u9ad8\u7684\u6837\u672c\u6548\u7387\uff1b\u540c\u65f6\u9a8c\u8bc1\u4e86\u591a\u6a21\u6001\u878d\u5408\u5bf9\u611f\u77e5\u4e0d\u5bf9\u79f0\u4efb\u52a1\u6210\u529f\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u5c55\u73b0\u51fa\u5bf9\u4f20\u611f\u5668\u5931\u6548\u7684\u66f4\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684MWM-MARL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u7ef4\u591a\u6a21\u6001\u8f93\u5165\u4e0b\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7b56\u7565\u5b66\u4e60\u7684\u6837\u672c\u6548\u7387\u4e0e\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.00807", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.00807", "abs": "https://arxiv.org/abs/2511.00807", "authors": ["Xuan He", "Zequan Fang", "Jinzhao Lian", "Danny H. K. Tsang", "Baosen Zhang", "Yize Chen"], "title": "FREESH: Fair, Resource- and Energy-Efficient Scheduling for LLM Serving on Heterogeneous GPUs", "comment": "In Submission, code available at\n  https://github.com/AndrewFangZequan/LLM_Serving_FREESH", "summary": "The ever-increasing computation and energy demand for LLM and AI agents call\nfor holistic and efficient optimization of LLM serving systems. In practice,\nheterogeneous GPU clusters can be deployed in a geographically distributed\nmanner, while LLM load also observes diversity in terms of both query traffic\nand serving patterns. LLM queries running on advanced GPUs during a\nhigh-emission hour at one location can lead to significantly higher carbon\nfootprints versus same queries running on mid-level GPUs at a low-emission time\nand location. By observing LLM serving requirements and leveraging\nspatiotemporal computation flexibility, we consider the joint routing and\nscheduling problem, and propose FREESH to cooperatively run a group of data\ncenters while minimizing user-specified carbon or energy objectives. FREESH\nidentifies the optimal configurations of balanced load serving by matching\ndistinct GPU instance's power-throughput characteristics with predictable LLM\nquery length and workloads. To ensure both latency and fairness requirements,\nFREESH identifies optimized parallelism and query routing schedules together\nwith dynamic GPU frequency scaling for power saving, and Least-Laxity-First\n(LLF) serving strategy for query scheduling. During the 1-hour serving on\nproduction workloads, FREESH reduces energy by 28.6% and emissions by 45.45%\ntogether with improvements in SLO attainment and fairness.", "AI": {"tldr": "FREESH \u662f\u4e00\u79cd\u9762\u5411\u5730\u7406\u5206\u5e03\u5f0f\u5f02\u6784 GPU \u96c6\u7fa4\u7684 LLM \u670d\u52a1\u7cfb\u7edf\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u8def\u7531\u4e0e\u8c03\u5ea6\uff0c\u5728\u6ee1\u8db3\u5ef6\u8fdf\u548c\u516c\u5e73\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u80fd\u8017\u4e0e\u78b3\u6392\u653e\u3002", "motivation": "\u5927\u6a21\u578b\uff08LLM\uff09\u548c AI \u667a\u80fd\u4f53\u7684\u8ba1\u7b97\u4e0e\u80fd\u8017\u9700\u6c42\u4e0d\u65ad\u589e\u957f\uff0c\u800c\u5b9e\u9645\u90e8\u7f72\u4e2d GPU \u96c6\u7fa4\u5177\u6709\u5730\u7406\u5206\u5e03\u6027\u548c\u5f02\u6784\u6027\uff0c\u4e14 LLM \u67e5\u8be2\u8d1f\u8f7d\u5728\u6d41\u91cf\u548c\u6a21\u5f0f\u4e0a\u5b58\u5728\u591a\u6837\u6027\u3002\u4e0d\u540c\u5730\u70b9\u3001\u65f6\u95f4\u3001\u786c\u4ef6\u914d\u7f6e\u4e0b\u7684\u67e5\u8be2\u6267\u884c\u4f1a\u5bfc\u81f4\u663e\u8457\u4e0d\u540c\u7684\u78b3\u8db3\u8ff9\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u7efc\u5408\u8003\u8651\u65f6\u7a7a\u8ba1\u7b97\u7075\u6d3b\u6027\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "method": "FREESH \u6846\u67b6\u901a\u8fc7\u5339\u914d\u4e0d\u540c GPU \u5b9e\u4f8b\u7684\u529f\u8017-\u541e\u5410\u7279\u6027\u4e0e\u53ef\u9884\u6d4b\u7684 LLM \u67e5\u8be2\u957f\u5ea6\u548c\u8d1f\u8f7d\uff0c\u786e\u5b9a\u6700\u4f18\u8d1f\u8f7d\u5747\u8861\u914d\u7f6e\uff1b\u7ed3\u5408\u52a8\u6001 GPU \u9891\u7387\u8c03\u8282\u5b9e\u73b0\u8282\u80fd\uff0c\u5e76\u91c7\u7528 Least-Laxity-First (LLF) \u7b56\u7565\u8fdb\u884c\u67e5\u8be2\u8c03\u5ea6\uff0c\u540c\u65f6\u4f18\u5316\u5e76\u884c\u5ea6\u4e0e\u67e5\u8be2\u8def\u7531\u4ee5\u6ee1\u8db3\u5ef6\u8fdf\u4e0e\u516c\u5e73\u6027\u8981\u6c42\u3002", "result": "\u5728\u771f\u5b9e\u751f\u4ea7\u8d1f\u8f7d\u7684\u4e00\u5c0f\u65f6\u670d\u52a1\u6d4b\u8bd5\u4e2d\uff0cFREESH \u5b9e\u73b0\u4e86 28.6% \u7684\u80fd\u8017\u964d\u4f4e\u548c 45.45% \u7684\u78b3\u6392\u653e\u51cf\u5c11\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u670d\u52a1\u7b49\u7ea7\u76ee\u6807\uff08SLO\uff09\u8fbe\u6210\u7387\u548c\u516c\u5e73\u6027\u3002", "conclusion": "FREESH \u6709\u6548\u5229\u7528\u65f6\u7a7a\u8ba1\u7b97\u7075\u6d3b\u6027\uff0c\u5728\u4fdd\u969c\u670d\u52a1\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u663e\u8457\u4f18\u5316\u4e86 LLM \u670d\u52a1\u7cfb\u7edf\u7684\u80fd\u6548\u4e0e\u73af\u4fdd\u6027\u80fd\uff0c\u4e3a\u7eff\u8272 AI \u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.00517", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00517", "abs": "https://arxiv.org/abs/2511.00517", "authors": ["Shuochuan Li", "Dong Wang", "Patanamon Thongtanunam", "Zan Wang", "Jiuqiao Yu", "Junjie Chen"], "title": "Issue-Oriented Agent-Based Framework for Automated Review Comment Generation", "comment": null, "summary": "Code review (CR) is a crucial practice for ensuring software quality. Various\nautomated review comment generation techniques have been proposed to streamline\nthe labor-intensive process. However, existing approaches heavily rely on a\nsingle model to identify various issues within the code, limiting the model's\nability to handle the diverse, issue-specific nature of code changes and\nleading to non-informative comments, especially in complex scenarios such as\nbug fixes. To address these limitations, we propose RevAgent, a novel\nagent-based issue-oriented framework, decomposes the task into three stages:\n(1) Generation Stage, where five category-specific commentator agents analyze\ncode changes from distinct issue perspectives and generate candidate comments;\n(2) Discrimination Stage, where a critic agent selects the most appropriate\nissue-comment pair; and (3) Training Stage, where all agents are fine-tuned on\ncurated, category-specific data to enhance task specialization. Evaluation\nresults show that RevAgent significantly outperforms state-of-the-art PLM- and\nLLM-based baselines, with improvements of 12.90\\%, 10.87\\%, 6.32\\%, and 8.57\\%\non BLEU, ROUGE-L, METEOR, and SBERT, respectively. It also achieves relatively\nhigher accuracy in issue-category identification, particularly for challenging\nscenarios. Human evaluations further validate the practicality of RevAgent in\ngenerating accurate, readable, and context-aware review comments. Moreover,\nRevAgent delivers a favorable trade-off between performance and efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa RevAgent\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7684\u9762\u5411\u95ee\u9898\u7684\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4efb\u52a1\u5206\u89e3\u4e3a\u751f\u6210\u3001\u5224\u522b\u548c\u8bad\u7ec3\u4e09\u4e2a\u9636\u6bb5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u81ea\u52a8\u8bc4\u4ef7\u6307\u6807\u548c\u4eba\u5de5\u8bc4\u4f30\u4e2d\u5747\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u5355\u4e00\u6a21\u578b\u5904\u7406\u591a\u6837\u5316\u7684\u4ee3\u7801\u95ee\u9898\uff0c\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u573a\u666f\uff08\u5982\u7f3a\u9677\u4fee\u590d\uff09\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u8bc4\u8bba\u4fe1\u606f\u91cf\u4e0d\u8db3\u3002", "method": "RevAgent \u6846\u67b6\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a(1) \u4e94\u4e2a\u9762\u5411\u7279\u5b9a\u95ee\u9898\u7c7b\u522b\u7684\u8bc4\u8bba\u667a\u80fd\u4f53\u751f\u6210\u5019\u9009\u8bc4\u8bba\uff1b(2) \u4e00\u4e2a\u8bc4\u5224\u667a\u80fd\u4f53\u9009\u62e9\u6700\u4f18\u7684\u95ee\u9898-\u8bc4\u8bba\u5bf9\uff1b(3) \u6240\u6709\u667a\u80fd\u4f53\u5728\u7c7b\u522b\u7279\u5b9a\u6570\u636e\u4e0a\u5fae\u8c03\u4ee5\u589e\u5f3a\u4e13\u4e1a\u5316\u80fd\u529b\u3002", "result": "RevAgent \u5728 BLEU\u3001ROUGE-L\u3001METEOR \u548c SBERT \u6307\u6807\u4e0a\u5206\u522b\u63d0\u5347 12.90%\u300110.87%\u30016.32% \u548c 8.57%\uff0c\u5728\u95ee\u9898\u7c7b\u522b\u8bc6\u522b\u51c6\u786e\u7387\u548c\u4eba\u5de5\u8bc4\u4f30\uff08\u51c6\u786e\u6027\u3001\u53ef\u8bfb\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\uff09\u65b9\u9762\u4e5f\u8868\u73b0\u66f4\u4f18\uff0c\u5e76\u5728\u6027\u80fd\u4e0e\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002", "conclusion": "RevAgent \u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u540c\u548c\u4efb\u52a1\u5206\u89e3\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4ee3\u7801\u5ba1\u67e5\u8bc4\u8bba\u751f\u6210\u7684\u8d28\u91cf\u4e0e\u5b9e\u7528\u6027\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u590d\u6742\u4ee3\u7801\u53d8\u66f4\u573a\u666f\u3002"}}
{"id": "2511.01489", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.01489", "abs": "https://arxiv.org/abs/2511.01489", "authors": ["Qurat-ul-ain Shaheen", "Katarzyna Budzynska", "Carles Sierra"], "title": "An Explanation-oriented Inquiry Dialogue Game for Expert Collaborative Recommendations", "comment": null, "summary": "This work presents a requirement analysis for collaborative dialogues among\nmedical experts and an inquiry dialogue game based on this analysis for\nincorporating explainability into multiagent system design. The game allows\nexperts with different knowledge bases to collaboratively make recommendations\nwhile generating rich traces of the reasoning process through combining\nexplanation-based illocutionary forces in an inquiry dialogue. The dialogue\ngame was implemented as a prototype web-application and evaluated against the\nspecification through a formative user study. The user study confirms that the\ndialogue game meets the needs for collaboration among medical experts. It also\nprovides insights on the real-life value of dialogue-based communication tools\nfor the medical community.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u533b\u7597\u4e13\u5bb6\u534f\u4f5c\u5bf9\u8bdd\u7684\u9700\u6c42\u5206\u6790\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u63a2\u7a76\u5f0f\u5bf9\u8bdd\u535a\u5f08\u6a21\u578b\uff0c\u4ee5\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5f15\u5165\u53ef\u89e3\u91ca\u6027\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u7ed3\u5408\u57fa\u4e8e\u89e3\u91ca\u7684\u8a00\u8bed\u884c\u4e3a\uff0c\u5728\u534f\u4f5c\u63a8\u8350\u8fc7\u7a0b\u4e2d\u751f\u6210\u4e30\u5bcc\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u5e76\u901a\u8fc7\u539f\u578b\u7cfb\u7edf\u548c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u533b\u7597\u4e13\u5bb6\u5728\u534f\u4f5c\u51b3\u7b56\u4e2d\u9700\u8981\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u73b0\u6709\u7cfb\u7edf\u7f3a\u4e4f\u652f\u6301\u6b64\u7c7b\u534f\u4f5c\u5bf9\u8bdd\u7684\u6709\u6548\u673a\u5236\u3002", "method": "\u57fa\u4e8e\u9700\u6c42\u5206\u6790\u6784\u5efa\u4e00\u4e2a\u63a2\u7a76\u5f0f\u5bf9\u8bdd\u535a\u5f08\u6a21\u578b\uff0c\u6574\u5408\u89e3\u91ca\u6027\u8a00\u8bed\u884c\u4e3a\uff0c\u5f00\u53d1\u539f\u578bWeb\u5e94\u7528\uff0c\u5e76\u901a\u8fc7\u5f62\u6210\u6027\u7528\u6237\u7814\u7a76\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7528\u6237\u7814\u7a76\u8bc1\u5b9e\u8be5\u5bf9\u8bdd\u535a\u5f08\u6ee1\u8db3\u533b\u7597\u4e13\u5bb6\u534f\u4f5c\u9700\u6c42\uff0c\u5e76\u63ed\u793a\u4e86\u57fa\u4e8e\u5bf9\u8bdd\u7684\u6c9f\u901a\u5de5\u5177\u5728\u533b\u7597\u5b9e\u8df5\u4e2d\u7684\u5b9e\u9645\u4ef7\u503c\u3002", "conclusion": "\u5c06\u89e3\u91ca\u6027\u878d\u5165\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5bf9\u8bdd\u7cfb\u7edf\u662f\u53ef\u884c\u4e14\u6709\u4ef7\u503c\u7684\uff0c\u5c24\u5176\u5728\u533b\u7597\u9886\u57df\u53ef\u6709\u6548\u652f\u6301\u4e13\u5bb6\u95f4\u7684\u534f\u540c\u51b3\u7b56\u4e0e\u63a8\u7406\u900f\u660e\u5316\u3002"}}
{"id": "2511.00527", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00527", "abs": "https://arxiv.org/abs/2511.00527", "authors": ["Robab Aghazadeh-Chakherlou", "Qing Guo", "Siddartha Khastgir", "Peter Popov", "Xiaoge Zhang", "Xingyu Zhao"], "title": "HIP-LLM: A Hierarchical Imprecise Probability Approach to Reliability Assessment of Large Language Models", "comment": "under review", "summary": "Large Language Models (LLMs) are increasingly deployed across diverse\ndomains, raising the need for rigorous reliability assessment methods. Existing\nbenchmark-based evaluations primarily offer descriptive statistics of model\naccuracy over datasets, providing limited insight into the probabilistic\nbehavior of LLMs under real operational conditions. This paper introduces\nHIP-LLM, a Hierarchical Imprecise Probability framework for modeling and\ninferring LLM reliability. Building upon the foundations of software\nreliability engineering, HIP-LLM defines LLM reliability as the probability of\nfailure-free operation over a specified number of future tasks under a given\nOperational Profile (OP). HIP-LLM represents dependencies across (sub-)domains\nhierarchically, enabling multi-level inference from subdomain to system-level\nreliability. HIP-LLM embeds imprecise priors to capture epistemic uncertainty\nand incorporates OPs to reflect usage contexts. It derives posterior\nreliability envelopes that quantify uncertainty across priors and data.\nExperiments on multiple benchmark datasets demonstrate that HIP-LLM offers a\nmore accurate and standardized reliability characterization than existing\nbenchmark and state-of-the-art approaches. A publicly accessible repository of\nHIP-LLM is provided.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HIP-LLM\uff0c\u4e00\u79cd\u57fa\u4e8e\u5206\u5c42\u4e0d\u7cbe\u786e\u6982\u7387\u6846\u67b6\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u5efa\u6a21\u548c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5b9e\u9645\u64cd\u4f5c\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u57fa\u51c6\u7684\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u63d0\u4f9b\u6a21\u578b\u5728\u6570\u636e\u96c6\u4e0a\u7684\u51c6\u786e\u7387\u63cf\u8ff0\u6027\u7edf\u8ba1\uff0c\u96be\u4ee5\u63ed\u793aLLM\u5728\u771f\u5b9e\u8fd0\u884c\u73af\u5883\u4e2d\u7684\u6982\u7387\u884c\u4e3a\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u4e25\u8c28\u7684\u53ef\u9760\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "HIP-LLM\u57fa\u4e8e\u8f6f\u4ef6\u53ef\u9760\u6027\u5de5\u7a0b\uff0c\u5c06LLM\u53ef\u9760\u6027\u5b9a\u4e49\u4e3a\u5728\u7ed9\u5b9a\u64cd\u4f5c\u5256\u9762\uff08OP\uff09\u4e0b\u5728\u672a\u6765\u82e5\u5e72\u4efb\u52a1\u4e2d\u65e0\u6545\u969c\u8fd0\u884c\u7684\u6982\u7387\uff1b\u8be5\u65b9\u6cd5\u91c7\u7528\u5206\u5c42\u7ed3\u6784\u5efa\u6a21\uff08\u5b50\uff09\u9886\u57df\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5d4c\u5165\u4e0d\u7cbe\u786e\u5148\u9a8c\u4ee5\u523b\u753b\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u7ed3\u5408\u64cd\u4f5c\u5256\u9762\u53cd\u6620\u4f7f\u7528\u573a\u666f\uff0c\u4ece\u800c\u63a8\u5bfc\u51fa\u540e\u9a8c\u53ef\u9760\u6027\u5305\u7edc\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHIP-LLM\u76f8\u6bd4\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u548c\u524d\u6cbf\u6280\u672f\uff0c\u80fd\u63d0\u4f9b\u66f4\u51c6\u786e\u3001\u6807\u51c6\u5316\u7684\u53ef\u9760\u6027\u523b\u753b\u3002", "conclusion": "HIP-LLM\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u517c\u987e\u4e0d\u786e\u5b9a\u6027\u3001\u4f7f\u7528\u573a\u666f\u548c\u5c42\u6b21\u7ed3\u6784\u7684\u65b0\u6846\u67b6\uff0c\u5177\u6709\u66f4\u5f3a\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.01554", "categories": ["cs.MA", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01554", "abs": "https://arxiv.org/abs/2511.01554", "authors": ["Aditya Kapoor", "Yash Bhisikar", "Benjamin Freed", "Jan Peters", "Mingfei Sun"], "title": "Learning what to say and how precisely: Efficient Communication via Differentiable Discrete Communication Learning", "comment": "30 pages, 12 figures, 6 tables", "summary": "Effective communication in multi-agent reinforcement learning (MARL) is\ncritical for success but constrained by bandwidth, yet past approaches have\nbeen limited to complex gating mechanisms that only decide \\textit{whether} to\ncommunicate, not \\textit{how precisely}. Learning to optimize message precision\nat the bit-level is fundamentally harder, as the required discretization step\nbreaks gradient flow. We address this by generalizing Differentiable Discrete\nCommunication Learning (DDCL), a framework for end-to-end optimization of\ndiscrete messages. Our primary contribution is an extension of DDCL to support\nunbounded signals, transforming it into a universal, plug-and-play layer for\nany MARL architecture. We verify our approach with three key results. First,\nthrough a qualitative analysis in a controlled environment, we demonstrate\n\\textit{how} agents learn to dynamically modulate message precision according\nto the informational needs of the task. Second, we integrate our variant of\nDDCL into four state-of-the-art MARL algorithms, showing it reduces bandwidth\nby over an order of magnitude while matching or exceeding task performance.\nFinally, we provide direct evidence for the \\enquote{Bitter Lesson} in MARL\ncommunication: a simple Transformer-based policy leveraging DDCL matches the\nperformance of complex, specialized architectures, questioning the necessity of\nbespoke communication designs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u6269\u5c55\u7684\u53ef\u5fae\u5206\u79bb\u6563\u901a\u4fe1\u5b66\u4e60\uff08DDCL\uff09\u65b9\u6cd5\uff0c\u652f\u6301\u65e0\u754c\u4fe1\u53f7\uff0c\u4f7f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u6d88\u606f\u80fd\u5728\u6bd4\u7279\u7ea7\u522b\u52a8\u6001\u8c03\u6574\u7cbe\u5ea6\uff0c\u5728\u5927\u5e45\u964d\u4f4e\u5e26\u5bbd\u7684\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u9a8c\u8bc1\u4e86\u7b80\u5355\u67b6\u6784\u7ed3\u5408\u8be5\u901a\u4fe1\u673a\u5236\u53ef\u5ab2\u7f8e\u590d\u6742\u4e13\u7528\u8bbe\u8ba1\u3002", "motivation": "\u73b0\u6709MARL\u901a\u4fe1\u65b9\u6cd5\u591a\u4f9d\u8d56\u590d\u6742\u95e8\u63a7\u673a\u5236\uff0c\u4ec5\u51b3\u5b9a\u662f\u5426\u901a\u4fe1\uff0c\u800c\u65e0\u6cd5\u4f18\u5316\u901a\u4fe1\u7684\u7cbe\u5ea6\uff1b\u5728\u6bd4\u7279\u7ea7\u522b\u4f18\u5316\u6d88\u606f\u7cbe\u5ea6\u56e0\u79bb\u6563\u5316\u963b\u788d\u68af\u5ea6\u4f20\u64ad\u800c\u6781\u5177\u6311\u6218\u3002", "method": "\u6269\u5c55DDCL\u6846\u67b6\uff0c\u4f7f\u5176\u652f\u6301\u65e0\u754c\u4fe1\u53f7\uff0c\u4ece\u800c\u4f5c\u4e3a\u901a\u7528\u5373\u63d2\u5373\u7528\u901a\u4fe1\u5c42\u5d4c\u5165\u4efb\u610fMARL\u67b6\u6784\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u4f18\u5316\u79bb\u6563\u6d88\u606f\u7684\u7cbe\u5ea6\u3002", "result": "1\uff09\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u5b9a\u6027\u5c55\u793a\u667a\u80fd\u4f53\u5982\u4f55\u6839\u636e\u4efb\u52a1\u4fe1\u606f\u9700\u6c42\u52a8\u6001\u8c03\u8282\u6d88\u606f\u7cbe\u5ea6\uff1b2\uff09\u5728\u56db\u79cd\u5148\u8fdbMARL\u7b97\u6cd5\u4e2d\u96c6\u6210\u8be5\u65b9\u6cd5\uff0c\u5e26\u5bbd\u964d\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\u4e14\u6027\u80fd\u76f8\u5f53\u6216\u66f4\u4f18\uff1b3\uff09\u9a8c\u8bc1\u201c\u82e6\u6da9\u6559\u8bad\u201d\uff1a\u7ed3\u5408DDCL\u7684\u7b80\u5355Transformer\u7b56\u7565\u53ef\u5ab2\u7f8e\u590d\u6742\u4e13\u7528\u901a\u4fe1\u67b6\u6784\u3002", "conclusion": "\u901a\u8fc7\u5c06DDCL\u6269\u5c55\u4e3a\u652f\u6301\u65e0\u754c\u4fe1\u53f7\u7684\u901a\u7528\u901a\u4fe1\u5c42\uff0c\u53ef\u5728\u663e\u8457\u8282\u7701\u901a\u4fe1\u5e26\u5bbd\u7684\u540c\u65f6\u7ef4\u6301\u9ad8\u6027\u80fd\uff0c\u8868\u660e\u590d\u6742\u901a\u4fe1\u8bbe\u8ba1\u672a\u5fc5\u5fc5\u8981\uff0c\u7b80\u5355\u67b6\u6784\u7ed3\u5408\u9ad8\u6548\u901a\u4fe1\u673a\u5236\u5373\u53ef\u53d6\u5f97\u4f18\u5f02\u6548\u679c\u3002"}}
{"id": "2511.00528", "categories": ["cs.SE", "D.2.9"], "pdf": "https://arxiv.org/pdf/2511.00528", "abs": "https://arxiv.org/abs/2511.00528", "authors": ["Muhammad Hamid Raza Mookadam", "Ridewaan Hanslo"], "title": "Employee Performance when Implementing Agile Practices in an IT Workforce", "comment": "11 pages, 1 figure, 1 table, 7th World Symposium on Software\n  Engineering (WSSE 2025)", "summary": "Adoption of agile practices has increased in IT workforces. However, there is\na lack of comprehensive studies in the African context on employee performance\nwhen implementing agile practices. This study addresses this gap by exploring\nemployee performance in agile environments for IT workforces in South Africa.\nAn interpretivist mono-method qualitative approach was used, with the use of\ninterviews as a research strategy. Seventeen semi-structured interviews were\nconducted with agile practitioners from various roles. Our results indicated\nthat agile practices influence employee performance significantly, with\nparticipants reporting on aspects which included planning, communication,\nemployee development and well-being, collaboration, team culture and progress.\nAdditionally, our results reported obstacles when using agile practices that\nincluded adoption, team engagement, leadership and instilling an agile mindset.\nAgile practices influence employee performance in IT workforces by fostering\nimproved team dynamics, enhanced collaboration, improved efficiencies, risk\nmanagement, planning, continuous improvement, learning, personal development\nand well-being. Conclusively, our findings suggest that if agile challenges are\naddressed and additional support is provided, employee performance can be\nsignificantly improved.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u8bbf\u8c08\u5357\u975eIT\u4ece\u4e1a\u8005\uff0c\u53d1\u73b0\u654f\u6377\u5b9e\u8df5\u663e\u8457\u63d0\u5347\u5458\u5de5\u7ee9\u6548\uff0c\u4e3b\u8981\u4f53\u73b0\u5728\u56e2\u961f\u534f\u4f5c\u3001\u6c9f\u901a\u3001\u4e2a\u4eba\u53d1\u5c55\u7b49\u65b9\u9762\uff0c\u4f46\u4e5f\u9762\u4e34\u91c7\u7eb3\u969c\u788d\u3001\u9886\u5bfc\u529b\u4e0d\u8db3\u7b49\u6311\u6218\u3002", "motivation": "\u975e\u6d32\u80cc\u666f\u4e0b\u7f3a\u4e4f\u5173\u4e8e\u654f\u6377\u5b9e\u8df5\u5bf9\u5458\u5de5\u7ee9\u6548\u5f71\u54cd\u7684\u5168\u9762\u7814\u7a76\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7279\u522b\u662f\u5728\u5357\u975eIT\u884c\u4e1a\u4e2d\u7684\u5e94\u7528\u60c5\u51b5\u3002", "method": "\u91c7\u7528\u89e3\u91ca\u4e3b\u4e49\u7684\u5355\u4e00\u65b9\u6cd5\u5b9a\u6027\u7814\u7a76\u8bbe\u8ba1\uff0c\u901a\u8fc717\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u6536\u96c6\u6765\u81ea\u4e0d\u540c\u89d2\u8272\u7684\u654f\u6377\u4ece\u4e1a\u8005\u7684\u89c2\u70b9\u3002", "result": "\u654f\u6377\u5b9e\u8df5\u663e\u8457\u5f71\u54cd\u5458\u5de5\u7ee9\u6548\uff0c\u79ef\u6781\u65b9\u9762\u5305\u62ec\u89c4\u5212\u3001\u6c9f\u901a\u3001\u5458\u5de5\u53d1\u5c55\u4e0e\u798f\u7949\u3001\u534f\u4f5c\u3001\u56e2\u961f\u6587\u5316\u4e0e\u8fdb\u5c55\uff1b\u6311\u6218\u5305\u62ec\u654f\u6377\u91c7\u7eb3\u56f0\u96be\u3001\u56e2\u961f\u53c2\u4e0e\u5ea6\u4f4e\u3001\u9886\u5bfc\u529b\u4e0d\u8db3\u53ca\u654f\u6377\u601d\u7ef4\u96be\u4ee5\u5efa\u7acb\u3002", "conclusion": "\u82e5\u80fd\u6709\u6548\u5e94\u5bf9\u654f\u6377\u5b9e\u65bd\u4e2d\u7684\u6311\u6218\u5e76\u63d0\u4f9b\u989d\u5916\u652f\u6301\uff0cIT\u884c\u4e1a\u5458\u5de5\u7684\u7ee9\u6548\u53ef\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2511.01235", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.01235", "abs": "https://arxiv.org/abs/2511.01235", "authors": ["Shruthi Kannappan", "Ashwina Kumar", "Rupesh Nasre"], "title": "Scalable Maxflow Processing for Dynamic Graphs", "comment": null, "summary": "The Maximum Flow (Max-Flow) problem is a cornerstone in graph theory and\ncombinatorial optimization, aiming to determine the largest possible flow from\na designated source node to a sink node within a capacitated flow network. It\nhas extensive applications across diverse domains such as computer networking,\ntransportation systems, and image segmentation. The objective is to maximize\nthe total throughput while respecting edge capacity constraints and maintaining\nflow conservation at all intermediate vertices.\n  Among the various algorithms proposed for solving the Max-Flow problem, the\nPush--Relabel algorithm is particularly notable for its efficiency and\nsuitability for parallelization, owing to its localized vertex-based\noperations. This property has motivated extensive research into GPU-accelerated\nMax-Flow computation, leveraging the high degree of parallelism inherent to\nmodern GPU architectures.\n  In this paper, we present a novel GPU-parallel Max-Flow algorithm capable of\nincrementally recomputing the maximum flow of a dynamic graph following a batch\nof edge updates. In addition, we introduce a high-performance static GPU\nalgorithm designed for efficiently computing the initial Max-Flow on static\ngraphs. We further describe a series of CUDA-specific implementation\noptimizations that enhance performance, scalability, and memory efficiency on\nGPU platforms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684GPU\u5e76\u884c\u6700\u5927\u6d41\u7b97\u6cd5\uff0c\u652f\u6301\u5728\u52a8\u6001\u56fe\u4e0a\u589e\u91cf\u91cd\u8ba1\u7b97\u6700\u5927\u6d41\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9ad8\u6027\u80fd\u7684\u9759\u6001\u56fe\u521d\u59cb\u6700\u5927\u6d41\u8ba1\u7b97\u65b9\u6cd5\uff0c\u540c\u65f6\u5f15\u5165\u591a\u79cdCUDA\u4f18\u5316\u4ee5\u63d0\u5347GPU\u4e0a\u7684\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u5185\u5b58\u6548\u7387\u3002", "motivation": "\u6700\u5927\u6d41\u95ee\u9898\u662f\u56fe\u8bba\u548c\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u6838\u5fc3\u95ee\u9898\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u3002\u7531\u4e8ePush-Relabel\u7b97\u6cd5\u5177\u5907\u5c40\u90e8\u9876\u70b9\u64cd\u4f5c\u7279\u6027\uff0c\u9002\u5408\u5e76\u884c\u5316\uff0c\u56e0\u6b64\u63a8\u52a8\u4e86\u57fa\u4e8eGPU\u52a0\u901f\u7684\u6700\u5927\u6d41\u8ba1\u7b97\u7814\u7a76\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u52a8\u6001\u56fe\u66f4\u65b0\u65f6\u6548\u7387\u4e0d\u8db3\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u652f\u6301\u589e\u91cf\u66f4\u65b0\u548c\u9759\u6001\u8ba1\u7b97\u7684GPU\u7b97\u6cd5\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684GPU\u5e76\u884c\u6700\u5927\u6d41\u7b97\u6cd5\uff0c\u80fd\u591f\u5bf9\u4e00\u6279\u8fb9\u66f4\u65b0\u540e\u7684\u52a8\u6001\u56fe\u8fdb\u884c\u589e\u91cf\u5f0f\u6700\u5927\u6d41\u91cd\u8ba1\u7b97\uff1b\u540c\u65f6\u5f00\u53d1\u4e86\u4e00\u4e2a\u9ad8\u6548\u7684\u9759\u6001GPU\u7b97\u6cd5\u7528\u4e8e\u521d\u59cb\u6700\u5927\u6d41\u6c42\u89e3\uff0c\u5e76\u7ed3\u5408\u591a\u79cdCUDA\u7279\u5b9a\u4f18\u5316\u6280\u672f\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002", "result": "\u8be5\u65b9\u6cd5\u5728GPU\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u5185\u5b58\u6548\u7387\uff0c\u6709\u6548\u652f\u6301\u52a8\u6001\u56fe\u7684\u6700\u5927\u6d41\u589e\u91cf\u66f4\u65b0\u4e0e\u9759\u6001\u56fe\u7684\u5feb\u901f\u521d\u59cb\u8ba1\u7b97\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684GPU\u5e76\u884c\u6700\u5927\u6d41\u7b97\u6cd5\u53ca\u5176\u4f18\u5316\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u52a8\u6001\u548c\u9759\u6001\u56fe\u573a\u666f\u4e0b\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u5927\u89c4\u6a21\u56fe\u5904\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.00619", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00619", "abs": "https://arxiv.org/abs/2511.00619", "authors": ["Huaijin Ran", "Haoyi Zhang", "Xunzhu Tang"], "title": "GDPR-Bench-Android: A Benchmark for Evaluating Automated GDPR Compliance Detection in Android", "comment": null, "summary": "Automating the detection of EU General Data Protection Regulation (GDPR)\nviolations in source code is a critical but underexplored challenge. We\nintroduce \\textbf{GDPR-Bench-Android}, the first comprehensive benchmark for\nevaluating diverse automated methods for GDPR compliance detection in Android\napplications. It contains \\textbf{1951} manually annotated violation instances\nfrom \\textbf{15} open-source repositories, covering 23 GDPR articles at file-,\nmodule-, and line-level granularities. To enable a multi-paradigm evaluation,\nwe contribute \\textbf{Formal-AST}, a novel, source-code-native formal method\nthat serves as a deterministic baseline. We define two tasks: (1)\n\\emph{multi-granularity violation localization}, evaluated via\nAccuracy@\\textit{k}; and (2) \\emph{snippet-level multi-label classification},\nassessed by macro-F1 and other classification metrics. We benchmark 11 methods,\nincluding eight state-of-the-art LLMs, our Formal-AST analyzer, a\nretrieval-augmented (RAG) method, and an agentic (ReAct) method. Our findings\nreveal that no single paradigm excels across all tasks. For Task 1, the ReAct\nagent achieves the highest file-level Accuracy@1 (17.38%), while the\nQwen2.5-72B LLM leads at the line level (61.60%), in stark contrast to the\nFormal-AST method's 1.86%. For the difficult multi-label Task 2, the\nClaude-Sonnet-4.5 LLM achieves the best Macro-F1 (5.75%), while the RAG method\nyields the highest Macro-Precision (7.10%). These results highlight the\ntask-dependent strengths of different automated approaches and underscore the\nvalue of our benchmark in diagnosing their capabilities. All resources are\navailable at: https://github.com/Haoyi-Zhang/GDPR-Bench-Android.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86 GDPR-Bench-Android\uff0c\u8fd9\u662f\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30 Android \u5e94\u7528\u4e2d GDPR \u5408\u89c4\u6027\u81ea\u52a8\u68c0\u6d4b\u65b9\u6cd5\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u5305\u542b\u6765\u81ea 15 \u4e2a\u5f00\u6e90\u9879\u76ee\u7684 1951 \u4e2a\u624b\u52a8\u6807\u6ce8\u8fdd\u89c4\u5b9e\u4f8b\uff0c\u5e76\u5f15\u5165\u4e86\u540d\u4e3a Formal-AST \u7684\u65b0\u578b\u5f62\u5f0f\u5316\u65b9\u6cd5\u4f5c\u4e3a\u786e\u5b9a\u6027\u57fa\u7ebf\u3002\u7814\u7a76\u8bc4\u4f30\u4e86 11 \u79cd\u65b9\u6cd5\u5728\u4e24\u9879\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4e0d\u540c\u8303\u5f0f\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u5404\u6709\u4f18\u52bf\u3002", "motivation": "\u81ea\u52a8\u5316\u68c0\u6d4b\u6e90\u4ee3\u7801\u4e2d\u7684\u6b27\u76df\u300a\u901a\u7528\u6570\u636e\u4fdd\u62a4\u6761\u4f8b\u300b\uff08GDPR\uff09\u8fdd\u89c4\u884c\u4e3a\u662f\u4e00\u9879\u5173\u952e\u4f46\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u7684\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u4e00\u3001\u5168\u9762\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u96be\u4ee5\u6bd4\u8f83\u4e0d\u540c\u6280\u672f\u5728 GDPR \u5408\u89c4\u6027\u68c0\u6d4b\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86 GDPR-Bench-Android \u57fa\u51c6\uff0c\u6db5\u76d6 23 \u9879 GDPR \u6761\u6b3e\uff0c\u63d0\u4f9b\u6587\u4ef6\u7ea7\u3001\u6a21\u5757\u7ea7\u548c\u884c\u7ea7\u7c92\u5ea6\u7684\u6807\u6ce8\u6570\u636e\u3002\u540c\u65f6\u63d0\u51fa\u4e86 Formal-AST \u65b9\u6cd5\u4f5c\u4e3a\u57fa\u4e8e\u6e90\u4ee3\u7801\u7684\u5f62\u5f0f\u5316\u57fa\u7ebf\uff0c\u5e76\u5b9a\u4e49\u4e86\u4e24\u4e2a\u8bc4\u4f30\u4efb\u52a1\uff1a\u591a\u7c92\u5ea6\u8fdd\u89c4\u5b9a\u4f4d\uff08\u4f7f\u7528 Accuracy@k \u8bc4\u4f30\uff09\u548c\u4ee3\u7801\u7247\u6bb5\u7ea7\u591a\u6807\u7b7e\u5206\u7c7b\uff08\u4f7f\u7528 macro-F1 \u7b49\u6307\u6807\u8bc4\u4f30\uff09\u3002\u5171\u5bf9 11 \u79cd\u65b9\u6cd5\u8fdb\u884c\u4e86\u8bc4\u6d4b\uff0c\u5305\u62ec 8 \u4e2a\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u3001Formal-AST\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\u548c\u57fa\u4e8e ReAct \u6846\u67b6\u7684\u667a\u80fd\u4f53\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6ca1\u6709\u4efb\u4f55\u5355\u4e00\u8303\u5f0f\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f18\u3002\u5728\u4efb\u52a1 1 \u4e2d\uff0cReAct \u667a\u80fd\u4f53\u5728\u6587\u4ef6\u7ea7 Accuracy@1 \u4e0a\u8868\u73b0\u6700\u4f73\uff0817.38%\uff09\uff0c\u800c Qwen2.5-72B \u5728\u884c\u7ea7\u8fbe\u5230\u6700\u9ad8\uff0861.60%\uff09\uff0c\u8fdc\u9ad8\u4e8e Formal-AST \u7684 1.86%\u3002\u5728\u66f4\u5177\u6311\u6218\u6027\u7684\u4efb\u52a1 2 \u4e2d\uff0cClaude-Sonnet-4.5 \u53d6\u5f97\u6700\u4f73 Macro-F1\uff085.75%\uff09\uff0cRAG \u65b9\u6cd5\u5219\u83b7\u5f97\u6700\u9ad8 Macro-Precision\uff087.10%\uff09\u3002", "conclusion": "\u4e0d\u540c\u81ea\u52a8\u5316\u65b9\u6cd5\u5728 GDPR \u5408\u89c4\u6027\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u4efb\u52a1\u4f9d\u8d56\u6027\u7684\u4f18\u52bf\uff0cGDPR-Bench-Android \u57fa\u51c6\u80fd\u6709\u6548\u8bca\u65ad\u5404\u7c7b\u65b9\u6cd5\u7684\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u548c\u65b9\u5411\u3002"}}
{"id": "2511.01255", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.01255", "abs": "https://arxiv.org/abs/2511.01255", "authors": ["He Chen", "ZiHua Zheng", "JingHua Sun"], "title": "Design of quasi phase matching crystal based on differential gray wolf algorithm", "comment": null, "summary": "This paper focuses on the key problem in the development of nonlinear optical\ntechnology, the performance optimization of aperiodically polarized crystals.\nThe performance of the crystal depends on the precise control of the micro\ndistribution of crystal domains, but its optimization belongs to the\nhigh-dimensional discrete combination \"NP hard\" problem. The traditional\nalgorithm has the bottleneck of slow convergence and easy to fall into local\noptimization, while the heuristic methods such as genetic algorithm are limited\nby the CPU serial calculation and inefficient. In order to solve the above\nchallenges, this paper proposes the fusion scheme of hwsda hybrid optimization\nalgorithm and GPU parallel acceleration technology: the differential evolution\nalgorithm (DE) is used to realize the global search, and the gray wolf\noptimization algorithm (GWO) is used to strengthen the local search and\nconvergence speed, and the two coordinate to balance the global and local\noptimization requirements; At the same time, it relies on GPU multi-core\narchitecture to realize thread level parallel computing and improve\noptimization efficiency. This scheme effectively breaks through the\noptimization problem of high-dimensional discrete space, improves the accuracy\nof crystal domain control, improves the efficiency of quasi phase matching\ndesign by hundreds to thousands of times compared with traditional CPU serial\ncomputing, provides a new paradigm for the design of complex nonlinear optical\ndevices, and helps promote the performance breakthrough and industrial\napplication of related devices in the fields of quantum optics and laser\nprocessing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u878d\u5408\u5dee\u5206\u8fdb\u5316\uff08DE\uff09\u4e0e\u7070\u72fc\u4f18\u5316\uff08GWO\uff09\u7684\u6df7\u5408\u4f18\u5316\u7b97\u6cd5\uff0c\u5e76\u7ed3\u5408GPU\u5e76\u884c\u52a0\u901f\u6280\u672f\uff0c\u9ad8\u6548\u89e3\u51b3\u975e\u7ebf\u6027\u5149\u5b66\u4e2d\u51c6\u76f8\u4f4d\u5339\u914d\u6676\u4f53\u7ed3\u6784\u7684\u9ad8\u7ef4\u79bb\u6563\u4f18\u5316\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u8bbe\u8ba1\u6548\u7387\u4e0e\u7cbe\u5ea6\u3002", "motivation": "\u975e\u7ebf\u6027\u5149\u5b66\u6280\u672f\u53d1\u5c55\u4e2d\uff0c\u51c6\u76f8\u4f4d\u5339\u914d\u6676\u4f53\u6027\u80fd\u4f18\u5316\u9762\u4e34\u9ad8\u7ef4\u79bb\u6563\u7ec4\u5408\u7684\u201cNP\u96be\u201d\u95ee\u9898\uff0c\u4f20\u7edf\u7b97\u6cd5\u6536\u655b\u6162\u3001\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u800c\u9057\u4f20\u7b97\u6cd5\u7b49\u542f\u53d1\u5f0f\u65b9\u6cd5\u53d7\u9650\u4e8eCPU\u4e32\u884c\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u91c7\u7528DE\u7b97\u6cd5\u8fdb\u884c\u5168\u5c40\u641c\u7d22\uff0cGWO\u7b97\u6cd5\u5f3a\u5316\u5c40\u90e8\u641c\u7d22\u4e0e\u6536\u655b\u901f\u5ea6\uff0c\u4e8c\u8005\u534f\u540c\u5e73\u8861\u5168\u5c40\u4e0e\u5c40\u90e8\u4f18\u5316\uff1b\u540c\u65f6\u5229\u7528GPU\u591a\u6838\u67b6\u6784\u5b9e\u73b0\u7ebf\u7a0b\u7ea7\u5e76\u884c\u8ba1\u7b97\uff0c\u63d0\u5347\u6574\u4f53\u4f18\u5316\u6548\u7387\u3002", "result": "\u76f8\u6bd4\u4f20\u7edfCPU\u4e32\u884c\u8ba1\u7b97\uff0c\u8be5\u65b9\u6848\u5c06\u51c6\u76f8\u4f4d\u5339\u914d\u8bbe\u8ba1\u6548\u7387\u63d0\u5347\u6570\u767e\u81f3\u6570\u5343\u500d\uff0c\u663e\u8457\u63d0\u9ad8\u6676\u4f53\u7574\u7ed3\u6784\u63a7\u5236\u7cbe\u5ea6\uff0c\u6709\u6548\u7a81\u7834\u9ad8\u7ef4\u79bb\u6563\u7a7a\u95f4\u4f18\u5316\u74f6\u9888\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u4e3a\u590d\u6742\u975e\u7ebf\u6027\u5149\u5b66\u5668\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u91cf\u5b50\u5149\u5b66\u548c\u6fc0\u5149\u52a0\u5de5\u7b49\u9886\u57df\u76f8\u5173\u5668\u4ef6\u7684\u6027\u80fd\u7a81\u7834\u4e0e\u5de5\u4e1a\u5e94\u7528\u3002"}}
{"id": "2511.00624", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00624", "abs": "https://arxiv.org/abs/2511.00624", "authors": ["Haoyi Zhang", "Huaijin Ran", "Xunzhu Tang"], "title": "Can Large Language Models Detect Real-World Android Software Compliance Violations?", "comment": null, "summary": "The rapid development of Large Language Models (LLMs) has transformed\nsoftware engineering, showing promise in tasks like code generation, bug\ndetection, and compliance checking. However, current models struggle to detect\ncompliance violations in Android applications across diverse legal frameworks.\nWe propose \\emph{CompliBench}, a novel evaluation framework for assessing LLMs'\nability to detect compliance violations under regulations like LGPD, PDPA, and\nPIPEDA. The framework defines two tasks: Task 1 evaluates \\emph{retrieval and\nlocalization} at file, module, and line granularities, and Task 2 assesses\n\\emph{multi-label judgment} for code snippets. These tasks mirror the audit\nprocess, where auditors locate problematic code and determine implicated\nprovisions. Traditional metrics fail to capture important aspects like\ncross-granularity stability and jurisdictional consistency. Thus, we introduce\nstability-aware composites (SGS, RCS, CRGS, and OCS) for a more comprehensive\nassessment. Experiments with six models, including GPT-4O and Claude-3.5, show\n\\emph{CompliBench} improves compliance detection, with\nClaude-3.5-sonnet-20241022 achieving the highest OCS score (0.3295), and\nGemini-2.5-pro the lowest (0.0538). This work demonstrates \\emph{CompliBench}'s\npotential for improving LLM performance in compliance tasks and provides a\nfoundation for future tools aligned with data protection standards. Our project\nis available at https://github.com/Haoyi-Zhang/CompliBench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CompliBench\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u68c0\u6d4bAndroid\u5e94\u7528\u4e2d\u9075\u5b88LGPD\u3001PDPA\u548cPIPEDA\u7b49\u6cd5\u89c4\u80fd\u529b\u7684\u65b0\u6846\u67b6\uff0c\u5305\u542b\u4ee3\u7801\u68c0\u7d22\u5b9a\u4f4d\u548c\u591a\u6807\u7b7e\u5224\u65ad\u4e24\u4e2a\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u7a33\u5b9a\u6027\u611f\u77e5\u8bc4\u4f30\u6307\u6807\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347LLMs\u5728\u5408\u89c4\u6027\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4bAndroid\u5e94\u7528\u8de8\u4e0d\u540c\u6cd5\u5f8b\u6846\u67b6\u4e0b\u7684\u5408\u89c4\u8fdd\u89c4\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u8861\u91cf\u5176\u5728\u771f\u5b9e\u5ba1\u8ba1\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faCompliBench\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9a\u4e49\u4e24\u4e2a\u4efb\u52a1\uff1a\u4efb\u52a11\u8bc4\u4f30\u6a21\u578b\u5728\u6587\u4ef6\u3001\u6a21\u5757\u548c\u884c\u7ea7\u522b\u4e0a\u7684\u8fdd\u89c4\u4ee3\u7801\u68c0\u7d22\u4e0e\u5b9a\u4f4d\u80fd\u529b\uff1b\u4efb\u52a12\u8bc4\u4f30\u6a21\u578b\u5bf9\u4ee3\u7801\u7247\u6bb5\u7684\u591a\u6807\u7b7e\u5408\u89c4\u5224\u65ad\u80fd\u529b\u3002\u540c\u65f6\u5f15\u5165\u7a33\u5b9a\u6027\u611f\u77e5\u7684\u590d\u5408\u6307\u6807\uff08SGS\u3001RCS\u3001CRGS\u3001OCS\uff09\u4ee5\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5728\u516d\u4e2a\u4e3b\u6d41\u5927\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCompliBench\u80fd\u6709\u6548\u8bc4\u4f30\u548c\u63d0\u5347\u5408\u89c4\u68c0\u6d4b\u80fd\u529b\uff0c\u5176\u4e2dClaude-3.5-sonnet-20241022\u5728OCS\u6307\u6807\u4e0a\u8868\u73b0\u6700\u4f73\uff080.3295\uff09\uff0cGemini-2.5-pro\u8868\u73b0\u6700\u5dee\uff080.0538\uff09\u3002", "conclusion": "CompliBench\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u636e\u4fdd\u62a4\u5408\u89c4\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u548c\u57fa\u51c6\uff0c\u4e3a\u672a\u6765\u5f00\u53d1\u7b26\u5408\u6cd5\u89c4\u6807\u51c6\u7684\u81ea\u52a8\u5316\u5ba1\u8ba1\u5de5\u5177\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.00658", "categories": ["cs.SE", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2511.00658", "abs": "https://arxiv.org/abs/2511.00658", "authors": ["Guilherme H. Travassos", "Sabrina Rocha", "Rodrigo Feitosa", "Felipe Assis", "Patricia Goncalves", "Andre Gheventer", "Larissa Galeno", "Arthur Sasse", "Julio Cesar Guimaraes", "Carlos Brito", "Joao Pedro Wieland"], "title": "Lessons Learned from the Use of Generative AI in Engineering and Quality Assurance of a WEB System for Healthcare", "comment": "11 pages, 2 figures, in Portuguese language", "summary": "The advances and availability of technologies involving Generative Artificial\nIntelligence (AI) are evolving clearly and explicitly, driving immediate\nchanges in various work activities. Software Engineering (SE) is no exception\nand stands to benefit from these new technologies, enhancing productivity and\nquality in its software development processes. However, although the use of\nGenerative AI in SE practices is still in its early stages, considering the\nlack of conclusive results from ongoing research and the limited technological\nmaturity, we have chosen to incorporate these technologies in the development\nof a web-based software system to be used in clinical trials by a thoracic\ndiseases research group at our university. For this reason, we decided to share\nthis experience report documenting our development team's learning journey in\nusing Generative AI during the software development process. Project\nmanagement, requirements specification, design, development, and quality\nassurance activities form the scope of observation. Although we do not yet have\ndefinitive technological evidence to evolve our development process\nsignificantly, the results obtained and the suggestions shared here represent\nvaluable insights for software organizations seeking to innovate their\ndevelopment practices to achieve software quality with generative AI.", "AI": {"tldr": "\u672c\u6587\u62a5\u544a\u4e86\u5728\u5f00\u53d1\u7528\u4e8e\u80f8\u79d1\u75be\u75c5\u4e34\u5e8a\u8bd5\u9a8c\u7684Web\u8f6f\u4ef6\u7cfb\u7edf\u8fc7\u7a0b\u4e2d\uff0c\u56e2\u961f\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5404\u9636\u6bb5\uff08\u5982\u9879\u76ee\u7ba1\u7406\u3001\u9700\u6c42\u3001\u8bbe\u8ba1\u3001\u5f00\u53d1\u548c\u8d28\u91cf\u4fdd\u8bc1\uff09\u5e94\u7528\u751f\u6210\u5f0fAI\u7684\u521d\u6b65\u7ecf\u9a8c\uff0c\u5c3d\u7ba1\u6280\u672f\u5c1a\u4e0d\u6210\u719f\uff0c\u4f46\u63d0\u4f9b\u4e86\u5bf9\u63d0\u5347\u8f6f\u4ef6\u8d28\u91cf\u5177\u6709\u53c2\u8003\u4ef7\u503c\u7684\u5b9e\u8df5\u89c1\u89e3\u3002", "motivation": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5feb\u901f\u53d1\u5c55\u5e76\u5f00\u59cb\u5f71\u54cd\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff0c\u5c3d\u7ba1\u5176\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u5c1a\u5904\u65e9\u671f\u4e14\u7f3a\u4e4f\u6210\u719f\u7814\u7a76\u6210\u679c\uff0c\u4f5c\u8005\u56e2\u961f\u5e0c\u671b\u63a2\u7d22\u5176\u5728\u771f\u5b9e\u9879\u76ee\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u5206\u4eab\u7ecf\u9a8c\u4ee5\u4f9b\u5176\u4ed6\u7ec4\u7ec7\u53c2\u8003\u3002", "method": "\u901a\u8fc7\u5728\u4e00\u4e2a\u9762\u5411\u80f8\u79d1\u75be\u75c5\u4e34\u5e8a\u8bd5\u9a8c\u7684Web\u8f6f\u4ef6\u7cfb\u7edf\u5f00\u53d1\u9879\u76ee\u4e2d\uff0c\u5c06\u751f\u6210\u5f0fAI\u6280\u672f\u5e94\u7528\u4e8e\u9879\u76ee\u7ba1\u7406\u3001\u9700\u6c42\u89c4\u683c\u8bf4\u660e\u3001\u8bbe\u8ba1\u3001\u5f00\u53d1\u548c\u8d28\u91cf\u4fdd\u8bc1\u7b49\u8f6f\u4ef6\u5de5\u7a0b\u6d3b\u52a8\uff0c\u5e76\u8bb0\u5f55\u56e2\u961f\u7684\u5b66\u4e60\u8fc7\u7a0b\u4e0e\u5b9e\u8df5\u53cd\u9988\u3002", "result": "\u867d\u7136\u5c1a\u672a\u83b7\u5f97\u8db3\u4ee5\u663e\u8457\u6539\u53d8\u5f00\u53d1\u6d41\u7a0b\u7684\u786e\u51ff\u6280\u672f\u8bc1\u636e\uff0c\u4f46\u56e2\u961f\u5728\u5b9e\u8df5\u4e2d\u83b7\u5f97\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u5e76\u63d0\u51fa\u4e86\u5bf9\u5e0c\u671b\u501f\u52a9\u751f\u6210\u5f0fAI\u63d0\u5347\u8f6f\u4ef6\u8d28\u91cf\u7684\u7ec4\u7ec7\u5177\u6709\u53c2\u8003\u610f\u4e49\u7684\u5efa\u8bae\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u4ecd\u5904\u4e8e\u63a2\u7d22\u9636\u6bb5\uff0c\u4f46\u65e9\u671f\u5b9e\u8df5\u7ecf\u9a8c\u8868\u660e\u5176\u5177\u5907\u63d0\u5347\u5f00\u53d1\u6548\u7387\u4e0e\u8f6f\u4ef6\u8d28\u91cf\u7684\u6f5c\u529b\uff0c\u503c\u5f97\u8f6f\u4ef6\u7ec4\u7ec7\u6301\u7eed\u5173\u6ce8\u548c\u5c1d\u8bd5\u3002"}}
{"id": "2511.00678", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00678", "abs": "https://arxiv.org/abs/2511.00678", "authors": ["Tasmia Zerin", "Moumita Asad", "B. M. Mainul Hossain", "Kazi Sakib"], "title": "Repairing Responsive Layout Failures Using Retrieval Augmented Generation", "comment": "Accepted at the 41st IEEE International Conference on Software\n  Maintenance and Evolution 2025 (ICSME'25)", "summary": "Responsive websites frequently experience distorted layouts at specific\nscreen sizes, called Responsive Layout Failures (RLFs). Manually repairing\nthese RLFs involves tedious trial-and-error adjustments of HTML elements and\nCSS properties. In this study, an automated repair approach, leveraging LLM\ncombined with domain-specific knowledge is proposed. The approach is named\nReDeFix, a Retrieval-Augmented Generation (RAG)-based solution that utilizes\nStack Overflow (SO) discussions to guide LLM on CSS repairs. By augmenting\nrelevant SO knowledge with RLF-specific contexts, ReDeFix creates a prompt that\nis sent to the LLM to generate CSS patches. Evaluation demonstrates that our\napproach achieves an 88\\% accuracy in repairing RLFs. Furthermore, a study from\nsoftware engineers reveals that generated repairs produce visually correct\nlayouts while maintaining aesthetics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReDeFix\u7684\u81ea\u52a8\u5316\u4fee\u590d\u65b9\u6cd5\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0eStack Overflow\u4e2d\u7684\u9886\u57df\u77e5\u8bc6\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u4fee\u590d\u54cd\u5e94\u5f0f\u7f51\u9875\u5e03\u5c40\u5931\u6548\uff08RLFs\uff09\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8fbe\u523088%\u7684\u4fee\u590d\u51c6\u786e\u7387\uff0c\u5e76\u83b7\u5f97\u5de5\u7a0b\u5e08\u5bf9\u89c6\u89c9\u6548\u679c\u548c\u7f8e\u89c2\u6027\u7684\u8ba4\u53ef\u3002", "motivation": "\u54cd\u5e94\u5f0f\u7f51\u7ad9\u5728\u7279\u5b9a\u5c4f\u5e55\u5c3a\u5bf8\u4e0b\u5e38\u51fa\u73b0\u5e03\u5c40\u5931\u771f\uff08RLFs\uff09\uff0c\u800c\u4eba\u5de5\u4fee\u590d\u8fc7\u7a0b\u7e41\u7410\u4e14\u4f9d\u8d56\u53cd\u590d\u8bd5\u9519\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u4fee\u590d\u65b9\u6848\u3002", "method": "\u63d0\u51faReDeFix\u65b9\u6cd5\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u4eceStack Overflow\u4e2d\u68c0\u7d22\u4e0eRLF\u76f8\u5173\u7684\u8ba8\u8bba\uff0c\u5e76\u7ed3\u5408\u5177\u4f53\u4e0a\u4e0b\u6587\u6784\u5efa\u63d0\u793a\uff0c\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9488\u5bf9\u6027\u7684CSS\u4fee\u590d\u8865\u4e01\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cReDeFix\u5728\u4fee\u590dRLFs\u65b9\u9762\u51c6\u786e\u7387\u8fbe\u523088%\uff1b\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u8bc4\u4f30\u8ba4\u4e3a\u751f\u6210\u7684\u4fee\u590d\u7ed3\u679c\u4e0d\u4ec5\u5e03\u5c40\u6b63\u786e\uff0c\u800c\u4e14\u4fdd\u6301\u4e86\u826f\u597d\u7684\u89c6\u89c9\u7f8e\u89c2\u6027\u3002", "conclusion": "\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7684ReDeFix\u80fd\u6709\u6548\u81ea\u52a8\u5316\u4fee\u590d\u54cd\u5e94\u5f0f\u5e03\u5c40\u5931\u6548\u95ee\u9898\uff0c\u5177\u6709\u9ad8\u51c6\u786e\u7387\u548c\u826f\u597d\u7684\u5b9e\u7528\u6027\uff0c\u4e3a\u524d\u7aef\u5f00\u53d1\u4e2d\u7684\u5e03\u5c40\u8c03\u8bd5\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.01573", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.01573", "abs": "https://arxiv.org/abs/2511.01573", "authors": ["Melanie Tonarelli", "Simone Riva", "Pietro Benedusi", "Fabrizio Ferrandi", "Rolf Krause"], "title": "Adaptive Multidimensional Quadrature on Multi-GPU Systems", "comment": "9 pages, 8 figures. Submitted to the proceedings of the 29th\n  International Conference on Domain Decomposition Methods (DD29)", "summary": "We introduce a distributed adaptive quadrature method that formulates\nmultidimensional integration as a hierarchical domain decomposition problem on\nmulti-GPU architectures. The integration domain is recursively partitioned into\nsubdomains whose refinement is guided by local error estimators. Each subdomain\nevolves independently on a GPU, which exposes a significant load imbalance as\nthe adaptive process progresses. To address this challenge, we introduce a\ndecentralised load redistribution schemes based on a cyclic round-robin policy.\nThis strategy dynamically rebalance subdomains across devices through\nnon-blocking, CUDA-aware MPI communication that overlaps with computation. The\nproposed strategy has two main advantages compared to a state-of-the-art\nGPU-tailored package: higher efficiency in high dimensions; and improved\nrobustness w.r.t the integrand regularity and the target accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u591aGPU\u67b6\u6784\u7684\u5206\u5e03\u5f0f\u81ea\u9002\u5e94\u79ef\u5206\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u57df\u5206\u89e3\u548c\u53bb\u4e2d\u5fc3\u5316\u8d1f\u8f7d\u91cd\u5206\u914d\u7b56\u7565\uff0c\u5728\u9ad8\u7ef4\u79ef\u5206\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6548\u7387\u548c\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u9ad8\u7ef4\u6570\u503c\u79ef\u5206\u5728\u591aGPU\u7cfb\u7edf\u4e0a\u9762\u4e34\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u6548\u7387\u548c\u5bf9\u88ab\u79ef\u51fd\u6570\u6b63\u5219\u6027\u53ca\u76ee\u6807\u7cbe\u5ea6\u7684\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u5c06\u591a\u7ef4\u79ef\u5206\u5efa\u6a21\u4e3a\u5206\u5c42\u57df\u5206\u89e3\u95ee\u9898\uff0c\u5229\u7528\u5c40\u90e8\u8bef\u5dee\u4f30\u8ba1\u5668\u9012\u5f52\u5212\u5206\u79ef\u5206\u533a\u57df\uff1b\u6bcf\u4e2a\u5b50\u57df\u5728\u72ec\u7acbGPU\u4e0a\u6f14\u5316\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u5faa\u73af\u8f6e\u8be2\u7b56\u7565\u7684\u53bb\u4e2d\u5fc3\u5316\u8d1f\u8f7d\u91cd\u5206\u914d\u673a\u5236\uff0c\u901a\u8fc7\u975e\u963b\u585e\u3001CUDA\u611f\u77e5\u7684MPI\u901a\u4fe1\u4e0e\u8ba1\u7b97\u91cd\u53e0\u5b9e\u73b0\u52a8\u6001\u8d1f\u8f7d\u5747\u8861\u3002", "result": "\u76f8\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u7684GPU\u4e13\u7528\u79ef\u5206\u5305\uff0c\u8be5\u65b9\u6cd5\u5728\u9ad8\u7ef4\u60c5\u5f62\u4e0b\u6548\u7387\u66f4\u9ad8\uff0c\u4e14\u5bf9\u88ab\u79ef\u51fd\u6570\u7684\u6b63\u5219\u6027\u548c\u76ee\u6807\u7cbe\u5ea6\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u81ea\u9002\u5e94\u79ef\u5206\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591aGPU\u73af\u5883\u4e0b\u9ad8\u7ef4\u79ef\u5206\u7684\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u4e0e\u9002\u7528\u6027\u3002"}}
{"id": "2511.00706", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00706", "abs": "https://arxiv.org/abs/2511.00706", "authors": ["Marcos Vinicius Cruz", "Pragya Verma", "Grischa Liebel"], "title": "An Empirical Investigation of the Experiences of Dyslexic Software Engineers", "comment": null, "summary": "Dyslexia is a common learning disorder that primarily impairs an individual's\nreading and writing abilities. In adults, dyslexia can affect both professional\nand personal lives, often leading to mental challenges and difficulties\nacquiring and keeping work. In Software Engineering (SE), reading and writing\ndifficulties appear to pose substantial challenges for core tasks such as\nprogramming. However, initial studies indicate that these challenges may not\nsignificantly affect their performance compared to non-dyslexic colleagues.\nConversely, strengths associated with dyslexia could be particularly valuable\nin areas like programming and design. However, there is currently no work that\nexplores the experiences of dyslexic software engineers, and puts their\nstrengths into relation with their difficulties. To address this, we present a\nqualitative study of the experiences of dyslexic individuals in SE. We followed\nthe basic stage of the Socio-Technical Grounded Theory method and base our\nfindings on data collected through 10 interviews with dyslexic software\nengineers, 3 blog posts and 153 posts on the social media platform Reddit. We\nfind that dyslexic software engineers especially struggle at the programming\nlearning stage, but can succeed and indeed excel at many SE tasks once they\nmaster this step. Common SE-specific support tools, such as code completion and\nlinters are especially useful to these individuals and mitigate many of the\nexperienced difficulties. Finally, dyslexic software engineers exhibit\nstrengths in areas such as visual thinking and creativity. Our findings have\nimplications to SE practice and motivate several areas of future research in\nSE, such as investigating what makes code less/more understandable to dyslexic\nindividuals.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u8d28\u6027\u7814\u7a76\u63a2\u8ba8\u4e86\u9605\u8bfb\u969c\u788d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u7ecf\u5386\uff0c\u53d1\u73b0\u4ed6\u4eec\u5728\u7f16\u7a0b\u5b66\u4e60\u521d\u671f\u9762\u4e34\u56f0\u96be\uff0c\u4f46\u638c\u63e1\u540e\u80fd\u80dc\u4efb\u751a\u81f3\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff1b\u5e38\u7528\u5de5\u5177\uff08\u5982\u4ee3\u7801\u8865\u5168\u3001\u4ee3\u7801\u68c0\u67e5\u5668\uff09\u53ef\u6709\u6548\u7f13\u89e3\u5176\u56f0\u96be\uff0c\u4e14\u4ed6\u4eec\u5728\u89c6\u89c9\u601d\u7ef4\u548c\u521b\u9020\u529b\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "motivation": "\u76ee\u524d\u5c1a\u65e0\u7814\u7a76\u7cfb\u7edf\u63a2\u8ba8\u9605\u8bfb\u969c\u788d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u7684\u5b9e\u9645\u4f53\u9a8c\uff0c\u4ee5\u53ca\u5176\u4f18\u52bf\u4e0e\u56f0\u96be\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u9274\u4e8e\u9605\u8bfb\u969c\u788d\u5728\u9605\u8bfb\u548c\u5199\u4f5c\u4e0a\u7684\u5f71\u54cd\u53ef\u80fd\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u6838\u5fc3\u4efb\u52a1\uff08\u5982\u7f16\u7a0b\uff09\u6784\u6210\u6311\u6218\uff0c\u800c\u521d\u6b65\u7814\u7a76\u8868\u660e\u5176\u8868\u73b0\u672a\u5fc5\u900a\u4e8e\u975e\u9605\u8bfb\u969c\u788d\u8005\uff0c\u751a\u81f3\u53ef\u80fd\u5177\u5907\u72ec\u7279\u4f18\u52bf\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u6df1\u5165\u7406\u89e3\u8fd9\u4e00\u7fa4\u4f53\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u771f\u5b9e\u5904\u5883\u3002", "method": "\u91c7\u7528\u793e\u4f1a\u6280\u672f\u624e\u6839\u7406\u8bba\uff08Socio-Technical Grounded Theory\uff09\u7684\u57fa\u672c\u9636\u6bb5\uff0c\u901a\u8fc7\u8d28\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u6536\u96c6\u5e76\u5206\u6790\u4e8610\u4f4d\u9605\u8bfb\u969c\u788d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u7684\u8bbf\u8c08\u6570\u636e\u30013\u7bc7\u535a\u5ba2\u6587\u7ae0\u4ee5\u53caReddit\u5e73\u53f0\u4e0a153\u7bc7\u76f8\u5173\u5e16\u5b50\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\uff081\uff09\u9605\u8bfb\u969c\u788d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5728\u7f16\u7a0b\u5b66\u4e60\u521d\u671f\u56f0\u96be\u8f83\u5927\uff0c\u4f46\u4e00\u65e6\u638c\u63e1\u57fa\u7840\u540e\u80fd\u5728\u591a\u9879\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u6210\u529f\u751a\u81f3\u8868\u73b0\u4f18\u5f02\uff1b\uff082\uff09\u4ee3\u7801\u8865\u5168\u3001\u4ee3\u7801\u68c0\u67e5\u5668\u7b49\u5e38\u89c1\u5de5\u5177\u80fd\u6709\u6548\u7f13\u89e3\u5176\u56f0\u96be\uff1b\uff083\uff09\u4ed6\u4eec\u5728\u89c6\u89c9\u601d\u7ef4\u548c\u521b\u9020\u529b\u65b9\u9762\u5c55\u73b0\u51fa\u660e\u663e\u4f18\u52bf\u3002", "conclusion": "\u9605\u8bfb\u969c\u788d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u867d\u5728\u521d\u671f\u9762\u4e34\u6311\u6218\uff0c\u4f46\u53ef\u901a\u8fc7\u5de5\u5177\u652f\u6301\u514b\u670d\u56f0\u96be\uff0c\u5e76\u51ed\u501f\u5176\u72ec\u7279\u4f18\u52bf\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u53d6\u5f97\u6210\u529f\u3002\u7814\u7a76\u7ed3\u679c\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u5177\u6709\u542f\u793a\u610f\u4e49\uff0c\u5e76\u547c\u5401\u672a\u6765\u7814\u7a76\u8fdb\u4e00\u6b65\u63a2\u7d22\u5f71\u54cd\u9605\u8bfb\u969c\u788d\u8005\u4ee3\u7801\u53ef\u7406\u89e3\u6027\u7684\u56e0\u7d20\u3002"}}
{"id": "2511.01373", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.01373", "abs": "https://arxiv.org/abs/2511.01373", "authors": ["Kaining Wang", "Bo Yang", "Yusheng Lei", "Zhiwen Yu", "Xuelin Cao", "Liang Wang", "Bin Guo", "George C. Alexandropoulos", "M\u00e9rouane Debbah", "Zhu Han"], "title": "3D Gaussian Radiation Field Modeling for Integrated RIS-FAS Systems: Analysis and Optimization", "comment": null, "summary": "The integration of reconfigurable intelligent surfaces (RIS) and fluid\nantenna systems (FAS) has attracted considerable attention due to its\ntremendous potential in enhancing wireless communication performance. However,\nunder fast-fading channel conditions, rapidly and effectively performing joint\noptimization of the antenna positions in an FAS system and the RIS phase\nconfiguration remains a critical challenge. Traditional optimization methods\ntypically rely on complex iterative computations, thus making it challenging to\nobtain optimal solutions in real time within dynamic channel environments. To\naddress this issue, this paper introduces a field information-driven\noptimization method based on three-dimensional Gaussian radiation-field\nmodeling for real-time optimization of integrated FAS-RIS systems. In the\nproposed approach, obstacles are treated as virtual transmitters and, by\nseparately learning the amplitude and phase variations, the model can quickly\ngenerate high-precision channel information based on the transmitter's\nposition. This design eliminates the need for extensive pilot overhead and\ncumbersome computations. On this framework, an alternating optimization scheme\nis presented to jointly optimize the FAS position and the RIS phase\nconfiguration. Simulation results demonstrate that the proposed method\nsignificantly outperforms existing approaches in terms of spectrum prediction\naccuracy, convergence speed, and minimum achievable rate, validating its\neffectiveness and practicality in fast-fading scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e09\u7ef4\u9ad8\u65af\u8f90\u5c04\u573a\u5efa\u6a21\u7684\u573a\u4fe1\u606f\u9a71\u52a8\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5feb\u8870\u843d\u4fe1\u9053\u4e0b\u5bf9FAS-RIS\u96c6\u6210\u7cfb\u7edf\u8fdb\u884c\u5b9e\u65f6\u8054\u5408\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9891\u8c31\u9884\u6d4b\u7cbe\u5ea6\u3001\u6536\u655b\u901f\u5ea6\u548c\u6700\u5c0f\u53ef\u8fbe\u901f\u7387\u3002", "motivation": "\u5728\u5feb\u8870\u843d\u4fe1\u9053\u6761\u4ef6\u4e0b\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5b9e\u65f6\u9ad8\u6548\u5730\u8054\u5408\u4f18\u5316\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\uff08FAS\uff09\u7684\u5929\u7ebf\u4f4d\u7f6e\u4e0e\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u7684\u76f8\u4f4d\u914d\u7f6e\uff0c\u56e0\u5176\u4f9d\u8d56\u590d\u6742\u7684\u8fed\u4ee3\u8ba1\u7b97\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e09\u7ef4\u9ad8\u65af\u8f90\u5c04\u573a\u5efa\u6a21\u7684\u573a\u4fe1\u606f\u9a71\u52a8\u4f18\u5316\u65b9\u6cd5\uff0c\u5c06\u969c\u788d\u7269\u89c6\u4e3a\u865a\u62df\u53d1\u5c04\u673a\uff0c\u5206\u522b\u5b66\u4e60\u5e45\u5ea6\u548c\u76f8\u4f4d\u53d8\u5316\u4ee5\u5feb\u901f\u751f\u6210\u9ad8\u7cbe\u5ea6\u4fe1\u9053\u4fe1\u606f\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u8bbe\u8ba1\u4ea4\u66ff\u4f18\u5316\u65b9\u6848\u8054\u5408\u4f18\u5316FAS\u4f4d\u7f6e\u4e0eRIS\u76f8\u4f4d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u9891\u8c31\u9884\u6d4b\u7cbe\u5ea6\u3001\u6536\u655b\u901f\u5ea6\u548c\u6700\u5c0f\u53ef\u8fbe\u901f\u7387\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86FAS-RIS\u7cfb\u7edf\u5728\u5feb\u8870\u843d\u573a\u666f\u4e0b\u7684\u5b9e\u65f6\u4f18\u5316\u96be\u9898\uff0c\u5177\u6709\u826f\u597d\u7684\u5b9e\u7528\u6027\u548c\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2511.01843", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.01843", "abs": "https://arxiv.org/abs/2511.01843", "authors": ["Andrew Goodng", "Kevin Porter", "Thomas Lopatic", "Ashish Shinde", "Sunil Sayyaparaju", "Srinivasan Seshadri", "V. Srinivasan"], "title": "LARK -- Linearizability Algorithms for Replicated Keys in Aerospike", "comment": "Submitted to Industry Track of a Database Conference", "summary": "We present LARK (Linearizability Algorithms for Replicated Keys), a\nsynchronous replication protocol that achieves linearizability while minimizing\nlatency and infrastructure cost, at significantly higher availability than\ntraditional quorum-log consensus. LARK introduces Partition Availability\nConditions (PAC) that reason over the entire database cluster rather than fixed\nreplica sets, improving partition availability under independent failures by\nroughly 3x when tolerating one failure and 10x when tolerating two. Unlike\nRaft, Paxos, and Viewstamped Replication, LARK eliminates ordered logs,\nenabling immediate partition readiness after leader changes -- with at most a\nper-key duplicate-resolution round trip when the new leader lacks the latest\ncopy. Under equal storage budgets -- where both systems maintain only f+1 data\ncopies to tolerate f failures -- LARK continues committing through data-node\nfailures while log-based protocols must pause commits for replica rebuilding.\nThese properties also enable zero-downtime rolling restarts even when\nmaintaining only two copies. We provide formal safety arguments and a TLA+\nspecification, and we demonstrate through analysis and experiments that LARK\nachieves significant availability gains.", "AI": {"tldr": "LARK \u662f\u4e00\u79cd\u540c\u6b65\u590d\u5236\u534f\u8bae\uff0c\u901a\u8fc7\u5f15\u5165\u5206\u533a\u53ef\u7528\u6027\u6761\u4ef6\uff08PAC\uff09\u548c\u6452\u5f03\u6709\u5e8f\u65e5\u5fd7\uff0c\u5728\u4fdd\u8bc1\u7ebf\u6027\u4e00\u81f4\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u53ef\u7528\u6027\u3001\u964d\u4f4e\u5ef6\u8fdf\u4e0e\u57fa\u7840\u8bbe\u65bd\u6210\u672c\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6cd5\u5b9a\u65e5\u5fd7\u7684\u5171\u8bc6\u534f\u8bae\uff08\u5982 Raft\u3001Paxos\uff09\u5728\u8282\u70b9\u6545\u969c\u65f6\u9700\u6682\u505c\u63d0\u4ea4\u4ee5\u91cd\u5efa\u526f\u672c\uff0c\u5bfc\u81f4\u53ef\u7528\u6027\u53d7\u9650\uff1bLARK \u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5728\u76f8\u540c\u5b58\u50a8\u5f00\u9500\u4e0b\u5b9e\u73b0\u66f4\u9ad8\u53ef\u7528\u6027\u548c\u66f4\u4f4e\u5ef6\u8fdf\u3002", "method": "LARK \u5f15\u5165\u5206\u533a\u53ef\u7528\u6027\u6761\u4ef6\uff08PAC\uff09\uff0c\u5728\u5168\u96c6\u7fa4\u8303\u56f4\u5185\u800c\u975e\u56fa\u5b9a\u526f\u672c\u96c6\u4e2d\u5224\u65ad\u53ef\u7528\u6027\uff0c\u5e76\u53bb\u9664\u6709\u5e8f\u65e5\u5fd7\u673a\u5236\uff0c\u5141\u8bb8\u5728\u9886\u5bfc\u8005\u53d8\u66f4\u540e\u7acb\u5373\u6062\u590d\u5206\u533a\u670d\u52a1\uff0c\u4ec5\u5728\u5fc5\u8981\u65f6\u8fdb\u884c\u6bcf\u952e\u4e00\u6b21\u7684\u91cd\u590d\u89e3\u51b3\u5f80\u8fd4\u3002", "result": "\u5728\u5bb9\u5fcd\u4e00\u4e2a\u6545\u969c\u65f6\uff0cLARK \u7684\u5206\u533a\u53ef\u7528\u6027\u63d0\u5347\u7ea6 3 \u500d\uff1b\u5bb9\u5fcd\u4e24\u4e2a\u6545\u969c\u65f6\u63d0\u5347\u7ea6 10 \u500d\u3002\u5728\u4ec5\u7ef4\u62a4 f+1 \u4e2a\u6570\u636e\u526f\u672c\u7684\u6761\u4ef6\u4e0b\uff0cLARK \u80fd\u5728\u6570\u636e\u8282\u70b9\u6545\u969c\u671f\u95f4\u6301\u7eed\u63d0\u4ea4\uff0c\u800c\u65e5\u5fd7\u578b\u534f\u8bae\u5fc5\u987b\u6682\u505c\u3002\u6b64\u5916\uff0cLARK \u652f\u6301\u4ec5\u4e24\u526f\u672c\u4e0b\u7684\u96f6\u505c\u673a\u6eda\u52a8\u91cd\u542f\u3002", "conclusion": "LARK \u901a\u8fc7\u521b\u65b0\u7684\u53ef\u7528\u6027\u5224\u65ad\u673a\u5236\u548c\u65e0\u65e5\u5fd7\u8bbe\u8ba1\uff0c\u5728\u4fdd\u8bc1\u7ebf\u6027\u4e00\u81f4\u6027\u7684\u524d\u63d0\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5171\u8bc6\u534f\u8bae\uff0c\u5c24\u5176\u5728\u9ad8\u53ef\u7528\u6027\u548c\u8fd0\u7ef4\u6210\u672c\u65b9\u9762\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2511.00776", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00776", "abs": "https://arxiv.org/abs/2511.00776", "authors": ["Cuiyun Gao", "Guodong Fan", "Chun Yong Chong", "Shizhan Chen", "Chao Liu", "David Lo", "Zibin Zheng", "Qing Liao"], "title": "A Systematic Literature Review of Code Hallucinations in LLMs: Characterization, Mitigation Methods, Challenges, and Future Directions for Reliable AI", "comment": null, "summary": "Model hallucination is one of the most critical challenges faced by Large\nLanguage Models (LLMs), especially in high-stakes code intelligence tasks. As\nLLMs become increasingly integrated into software engineering tasks,\nunderstanding and mitigating hallucination in code becomes essential. In this\nsurvey, we provide a systematic review of hallucination phenomena in\ncode-oriented LLMs from four key perspectives. First, we begin by surveying 60\npapers to define hallucination in the context of code and summarize its primary\ncauses, such as data noise, exposure bias, and insufficient semantic grounding,\nwhile also tracing recent trends in literature across natural language\nprocessing (NLP) and software engineering communities. Second, we review model\nhallucination surveys in a broader span and summarize representative\nhallucination mitigation strategies, such as knowledge-enhanced generation,\nconstrained decoding, and post-editing. Third, we review approaches targeted\nfor code intelligence and highlight code-specific challenges that aggravate\nhallucination, including syntax sensitivity, strict type systems, and\ndependence on external libraries. Meanwhile, we analyze how emerging code\nintelligence tasks, e.g., program analysis, symbolic execution, and unit\ntesting, are utilized to detect and mitigate hallucinations. Fourth, we\nsummarize current evaluation benchmarks, ranging from static metrics to dynamic\nchecks, e.g., compilation and execution correctness, and emphasize the need for\nhallucination-oriented benchmarks.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u9762\u5411\u4ee3\u7801\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u4ece\u5b9a\u4e49\u4e0e\u6210\u56e0\u3001\u901a\u7528\u7f13\u89e3\u7b56\u7565\u3001\u4ee3\u7801\u7279\u5b9a\u6311\u6218\u4e0e\u4efb\u52a1\u5e94\u7528\u3001\u4ee5\u53ca\u8bc4\u4f30\u57fa\u51c6\u56db\u4e2a\u65b9\u9762\u8fdb\u884c\u4e86\u5206\u6790\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u4ee3\u7801\u667a\u80fd\u4efb\u52a1\u4e2d\u9762\u4e34\u4e25\u91cd\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u968f\u7740\u5176\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7406\u89e3\u548c\u7f13\u89e3\u4ee3\u7801\u5e7b\u89c9\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u679060\u7bc7\u76f8\u5173\u8bba\u6587\uff0c\u4ece\u56db\u4e2a\u7ef4\u5ea6\u63a2\u8ba8\u4ee3\u7801\u5e7b\u89c9\uff1a\u5b9a\u4e49\u4e0e\u6210\u56e0\u3001\u901a\u7528\u7f13\u89e3\u65b9\u6cd5\u3001\u4ee3\u7801\u7279\u5b9a\u6311\u6218\u53ca\u65b0\u5174\u4efb\u52a1\u5e94\u7528\u3001\u8bc4\u4f30\u57fa\u51c6\u3002", "result": "\u603b\u7ed3\u4e86\u4ee3\u7801\u5e7b\u89c9\u7684\u4e3b\u8981\u6210\u56e0\uff08\u5982\u6570\u636e\u566a\u58f0\u3001\u66b4\u9732\u504f\u5dee\u3001\u8bed\u4e49\u63a5\u5730\u4e0d\u8db3\uff09\uff0c\u5f52\u7eb3\u4e86\u901a\u7528\u4e0e\u4ee3\u7801\u7279\u5b9a\u7684\u7f13\u89e3\u7b56\u7565\uff0c\u5e76\u6307\u51fa\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u7684\u4e0d\u8db3\u53ca\u5bf9\u4e13\u7528\u57fa\u51c6\u7684\u9700\u6c42\u3002", "conclusion": "\u4ee3\u7801\u5e7b\u89c9\u662f\u4ee3\u7801\u5927\u6a21\u578b\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\uff0c\u9700\u7ed3\u5408\u8f6f\u4ef6\u5de5\u7a0b\u7279\u6027\u5f00\u53d1\u9488\u5bf9\u6027\u7f13\u89e3\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u9762\u5411\u5e7b\u89c9\u7684\u8bc4\u4f30\u4f53\u7cfb\u4ee5\u63a8\u52a8\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2511.00780", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00780", "abs": "https://arxiv.org/abs/2511.00780", "authors": ["Chenyu Zhao", "Shenglin Zhang", "Zeshun Huang", "Weilin Jin", "Yongqian Sun", "Dan Pei", "Chaoyun Zhang", "Qingwei Lin", "Chetan Bansal", "Saravan Rajmohan", "Minghua Ma"], "title": "Can Language Models Go Beyond Coding? Assessing the Capability of Language Models to Build Real-World Systems", "comment": null, "summary": "Large language models (LLMs) have shown growing potential in software\nengineering, yet few benchmarks evaluate their ability to repair software\nduring migration across instruction set architectures (ISAs). Cross-ISA\nmigration, such as between x86_64 and aarch64, requires handling complex\ndependencies, heterogeneous toolchains, and long build logs while ensuring\nexecutable verification. To address this challenge, we present Build-bench, an\nend-to-end benchmark that systematically evaluates the capability of LLMs to\nrepair build failures in cross-ISA settings. Build-bench collects 268\nreal-world failed packages and integrates auxiliary tools including Structure\nExtraction, File Content Extraction, Content Modification, and Build\nVerification to support autonomous, tool-augmented reasoning. The repair\nprocess operates in an iterative loop where, upon failure, the model receives\nupdated build logs and previous repair outcomes to refine subsequent attempts.\nThrough a comparative evaluation of six representative LLMs, Build-bench\nreveals that current models achieve a maximum build success rate of 63% and\ntool usage patterns differ significantly across models. By coupling real build\nenvironments with verifiable outcomes, Build-bench establishes the first\narchitecture-aware benchmark for studying LLM-based software build and repair.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Build-bench\uff0c\u9996\u4e2a\u9762\u5411\u8de8\u6307\u4ee4\u96c6\u67b6\u6784\uff08\u5982x86_64\u4e0eaarch64\uff09\u8fc1\u79fb\u573a\u666f\u7684\u7aef\u5230\u7aef\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4fee\u590d\u6784\u5efa\u5931\u8d25\u65b9\u9762\u7684\u80fd\u529b\u3002\u8be5\u57fa\u51c6\u5305\u542b268\u4e2a\u771f\u5b9e\u5931\u8d25\u8f6f\u4ef6\u5305\uff0c\u5e76\u7ed3\u5408\u7ed3\u6784\u63d0\u53d6\u3001\u6587\u4ef6\u5185\u5bb9\u4fee\u6539\u4e0e\u6784\u5efa\u9a8c\u8bc1\u7b49\u8f85\u52a9\u5de5\u5177\uff0c\u652f\u6301\u6a21\u578b\u8fdb\u884c\u81ea\u4e3b\u3001\u5de5\u5177\u589e\u5f3a\u7684\u8fed\u4ee3\u4fee\u590d\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u524d\u6700\u4f18LLM\u7684\u6784\u5efa\u6210\u529f\u7387\u4ec5\u4e3a63%\uff0c\u4e14\u4e0d\u540c\u6a21\u578b\u5728\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\u4e0a\u5dee\u5f02\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u6307\u4ee4\u96c6\u67b6\u6784\uff08ISA\uff09\u8fc1\u79fb\u8fc7\u7a0b\u4e2d\u4fee\u590d\u8f6f\u4ef6\u6784\u5efa\u5931\u8d25\u80fd\u529b\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002\u8de8ISA\u8fc1\u79fb\u6d89\u53ca\u590d\u6742\u4f9d\u8d56\u3001\u5f02\u6784\u5de5\u5177\u94fe\u548c\u5197\u957f\u6784\u5efa\u65e5\u5fd7\uff0c\u4e9f\u9700\u4e00\u4e2a\u80fd\u7ed3\u5408\u771f\u5b9e\u6784\u5efa\u73af\u5883\u4e0e\u53ef\u9a8c\u8bc1\u7ed3\u679c\u7684\u8bc4\u6d4b\u6846\u67b6\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86Build-bench\u57fa\u51c6\uff0c\u6536\u96c6268\u4e2a\u771f\u5b9e\u4e16\u754c\u4e2d\u5728\u8de8ISA\u8fc1\u79fb\u65f6\u6784\u5efa\u5931\u8d25\u7684\u8f6f\u4ef6\u5305\uff0c\u5e76\u96c6\u6210\u7ed3\u6784\u63d0\u53d6\u3001\u6587\u4ef6\u5185\u5bb9\u63d0\u53d6\u3001\u5185\u5bb9\u4fee\u6539\u548c\u6784\u5efa\u9a8c\u8bc1\u7b49\u8f85\u52a9\u5de5\u5177\u3002\u4fee\u590d\u8fc7\u7a0b\u91c7\u7528\u8fed\u4ee3\u5faa\u73af\u673a\u5236\uff1a\u6a21\u578b\u5728\u6784\u5efa\u5931\u8d25\u540e\u63a5\u6536\u66f4\u65b0\u7684\u6784\u5efa\u65e5\u5fd7\u548c\u5148\u524d\u4fee\u590d\u7ed3\u679c\uff0c\u4ee5\u4f18\u5316\u540e\u7eed\u5c1d\u8bd5\u3002", "result": "\u5728\u5bf9\u516d\u79cd\u4ee3\u8868\u6027\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u4e2d\uff0cBuild-bench\u663e\u793a\u5f53\u524d\u6a21\u578b\u6700\u9ad8\u6784\u5efa\u6210\u529f\u7387\u4e3a63%\uff0c\u4e14\u4e0d\u540c\u6a21\u578b\u5728\u5de5\u5177\u4f7f\u7528\u7b56\u7565\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "Build-bench\u662f\u9996\u4e2a\u7ed3\u5408\u771f\u5b9e\u6784\u5efa\u73af\u5883\u4e0e\u53ef\u9a8c\u8bc1\u7ed3\u679c\u7684\u67b6\u6784\u611f\u77e5\u57fa\u51c6\uff0c\u4e3a\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u6784\u5efa\u4e0e\u4fee\u590d\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u8bc4\u4f30\u5e73\u53f0\u3002"}}
{"id": "2511.00839", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00839", "abs": "https://arxiv.org/abs/2511.00839", "authors": ["John Yang", "Kilian Lieret", "Joyce Yang", "Carlos E. Jimenez", "Ofir Press", "Ludwig Schmidt", "Diyi Yang"], "title": "CodeClash: Benchmarking Goal-Oriented Software Engineering", "comment": null, "summary": "Current benchmarks for coding evaluate language models (LMs) on concrete,\nwell-specified tasks such as fixing specific bugs or writing targeted tests.\nHowever, human programmers do not spend all day incessantly addressing isolated\ntasks. Instead, real-world software development is grounded in the pursuit of\nhigh-level goals, like improving user retention or reducing costs. Evaluating\nwhether LMs can also iteratively develop code to better accomplish open-ended\nobjectives without any explicit guidance remains an open challenge. To address\nthis, we introduce CodeClash, a benchmark where LMs compete in multi-round\ntournaments to build the best codebase for achieving a competitive objective.\nEach round proceeds in two phases: agents edit their code, then their codebases\ncompete head-to-head in a code arena that determines winners based on\nobjectives like score maximization, resource acquisition, or survival. Whether\nit's writing notes, scrutinizing documentation, analyzing competition logs, or\ncreating test suites, models must decide for themselves how to improve their\ncodebases both absolutely and against their opponents. We run 1680 tournaments\n(25,200 rounds total) to evaluate 8 LMs across 6 arenas. Our results reveal\nthat while models exhibit diverse development styles, they share fundamental\nlimitations in strategic reasoning. Models also struggle with long-term\ncodebase maintenance, as repositories become progressively messy and redundant.\nThese limitations are stark: top models lose every round against expert human\nprogrammers. We open-source CodeClash to advance the study of autonomous,\ngoal-oriented code development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CodeClash\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u660e\u786e\u6307\u5bfc\u60c5\u51b5\u4e0b\u8fed\u4ee3\u5f00\u53d1\u4ee3\u7801\u4ee5\u5b9e\u73b0\u5f00\u653e\u5f0f\u76ee\u6807\u7684\u65b0\u57fa\u51c6\u3002\u8be5\u57fa\u51c6\u901a\u8fc7\u591a\u8f6e\u9526\u6807\u8d5b\u5f62\u5f0f\uff0c\u8ba9\u6a21\u578b\u5728\u7ade\u4e89\u73af\u5883\u4e2d\u81ea\u4e3b\u6539\u8fdb\u4ee3\u7801\u5e93\uff0c\u5e76\u5728\u516d\u4e2a\u4e0d\u540c\u573a\u666f\u4e2d\u5bf98\u4e2a\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1\u6a21\u578b\u5c55\u73b0\u51fa\u591a\u6837\u7684\u5f00\u53d1\u98ce\u683c\uff0c\u4f46\u5728\u6218\u7565\u63a8\u7406\u548c\u957f\u671f\u4ee3\u7801\u7ef4\u62a4\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u751a\u81f3\u9876\u5c16\u6a21\u578b\u5728\u6bcf\u4e00\u8f6e\u6bd4\u8d5b\u4e2d\u5747\u8d25\u4e8e\u4eba\u7c7b\u4e13\u5bb6\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u5177\u4f53\u3001\u660e\u786e\u7684\u4efb\u52a1\uff08\u5982\u4fee\u590d\u7279\u5b9abug\u6216\u7f16\u5199\u9488\u5bf9\u6027\u6d4b\u8bd5\uff09\uff0c\u800c\u73b0\u5b9e\u4e2d\u7684\u8f6f\u4ef6\u5f00\u53d1\u901a\u5e38\u56f4\u7ed5\u9ad8\u5c42\u6b21\u76ee\u6807\uff08\u5982\u63d0\u5347\u7528\u6237\u7559\u5b58\u6216\u964d\u4f4e\u6210\u672c\uff09\u5c55\u5f00\u3002\u76ee\u524d\u5c1a\u7f3a\u4e4f\u6709\u6548\u65b9\u6cd5\u6765\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u663e\u5f0f\u6307\u5bfc\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u5426\u901a\u8fc7\u8fed\u4ee3\u5f00\u53d1\u4ee3\u7801\u6765\u8fbe\u6210\u5f00\u653e\u6027\u76ee\u6807\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86CodeClash\u57fa\u51c6\uff0c\u5176\u4e2d\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u9526\u6807\u8d5b\u4e2d\u7ade\u4e89\uff0c\u76ee\u6807\u662f\u6784\u5efa\u6700\u80fd\u5b9e\u73b0\u7279\u5b9a\u7ade\u4e89\u76ee\u6807\u7684\u4ee3\u7801\u5e93\u3002\u6bcf\u8f6e\u5305\u62ec\u4e24\u4e2a\u9636\u6bb5\uff1a\u6a21\u578b\u7f16\u8f91\u5176\u4ee3\u7801\uff0c\u7136\u540e\u5728\u201c\u4ee3\u7801\u7ade\u6280\u573a\u201d\u4e2d\u4e0e\u5176\u4ed6\u6a21\u578b\u7684\u4ee3\u7801\u5e93\u8fdb\u884c\u5bf9\u6297\uff0c\u4f9d\u636e\u5f97\u5206\u6700\u5927\u5316\u3001\u8d44\u6e90\u83b7\u53d6\u6216\u751f\u5b58\u80fd\u529b\u7b49\u76ee\u6807\u5224\u5b9a\u80dc\u8d1f\u3002\u6a21\u578b\u9700\u81ea\u4e3b\u51b3\u5b9a\u5982\u4f55\u6539\u8fdb\u4ee3\u7801\uff0c\u5305\u62ec\u5199\u7b14\u8bb0\u3001\u67e5\u9605\u6587\u6863\u3001\u5206\u6790\u5bf9\u624b\u65e5\u5fd7\u6216\u521b\u5efa\u6d4b\u8bd5\u5957\u4ef6\u7b49\u3002\u7814\u7a76\u5171\u8fd0\u884c1680\u573a\u9526\u6807\u8d5b\uff08\u603b\u8ba125,200\u8f6e\uff09\uff0c\u8bc4\u4f30\u4e868\u4e2a\u8bed\u8a00\u6a21\u578b\u57286\u4e2a\u7ade\u6280\u573a\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5c3d\u7ba1\u4e0d\u540c\u6a21\u578b\u5c55\u73b0\u51fa\u591a\u6837\u5316\u7684\u5f00\u53d1\u7b56\u7565\uff0c\u4f46\u5b83\u4eec\u5728\u6218\u7565\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5171\u540c\u7684\u6839\u672c\u6027\u5c40\u9650\u3002\u6b64\u5916\uff0c\u6a21\u578b\u96be\u4ee5\u8fdb\u884c\u957f\u671f\u7684\u4ee3\u7801\u5e93\u7ef4\u62a4\uff0c\u5bfc\u81f4\u4ee3\u7801\u5e93\u9010\u6e10\u53d8\u5f97\u6df7\u4e71\u548c\u5197\u4f59\u3002\u6700\u663e\u8457\u7684\u662f\uff0c\u5373\u4f7f\u662f\u8868\u73b0\u6700\u597d\u7684\u6a21\u578b\uff0c\u5728\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u7a0b\u5e8f\u5458\u7684\u5bf9\u6297\u4e2d\u4e5f\u8f93\u6389\u4e86\u6240\u6709\u56de\u5408\u3002", "conclusion": "CodeClash\u63ed\u793a\u4e86\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5411\u76ee\u6807\u7684\u81ea\u4e3b\u4ee3\u7801\u5f00\u53d1\u4e2d\u7684\u5173\u952e\u77ed\u677f\uff0c\u7279\u522b\u662f\u5728\u6218\u7565\u89c4\u5212\u548c\u4ee3\u7801\u53ef\u7ef4\u62a4\u6027\u65b9\u9762\u3002\u4f5c\u8005\u5f00\u6e90\u4e86CodeClash\uff0c\u4ee5\u63a8\u52a8\u5bf9\u81ea\u4e3b\u3001\u76ee\u6807\u5bfc\u5411\u578b\u4ee3\u7801\u751f\u6210\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2511.00872", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00872", "abs": "https://arxiv.org/abs/2511.00872", "authors": ["Zhuowen Yin", "Cuifeng Gao", "Chunsong Fan", "Wenzhang Yang", "Yinxing Xue", "Lijun Zhang"], "title": "A Comprehensive Empirical Evaluation of Agent Frameworks on Code-centric Software Engineering Tasks", "comment": null, "summary": "Unlike traditional automation tools or static LLM-based systems, agents\ncombine decision-making and tool utilization to accomplish complex tasks,\nshowing great potential in software engineering. However, existing studies\nlargely focus on specific tasks or isolated aspects, providing an incomplete\npicture of agents' practical capabilities. To address this, we conduct a\ncomprehensive empirical study evaluating seven general-purpose agent frameworks\nacross three representative code-centric tasks: software development,\nvulnerability detection, and program repair. Each task is assessed using\nstandard, widely adopted benchmarks to ensure objective and comparable\nevaluation. Agent performance is systematically analyzed from three\ncomplementary perspectives: effectiveness (task success), efficiency (execution\nprocess), and overhead (token consumption). Our findings reveal distinct\ncapability patterns and trade-offs among the evaluated frameworks. In terms of\neffectiveness, agents achieve moderate overall performance. Regarding\nefficiency, AgentOrchestra tends to exhibit the longest trajectories and the\nmost correction attempts due to coordination overhead, whereas OpenHands\ndemonstrate stronger reflective reasoning abilities. For overhead, software\ndevelopment incurs the highest monetary cost, while GPTswarm remains the most\ncost-efficient. Furthermore, we conduct an in-depth cross-analysis of the\nrelationship between effectiveness and efficiency, exploring the underlying\nreasons behind their interplay. These findings guide both practical adoption\nand future research toward more efficient software engineering agents.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4e03\u4e2a\u901a\u7528\u667a\u80fd\u4f53\u6846\u67b6\u5728\u8f6f\u4ef6\u5f00\u53d1\u3001\u6f0f\u6d1e\u68c0\u6d4b\u548c\u7a0b\u5e8f\u4fee\u590d\u4e09\u9879\u4ee3\u7801\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u8bc1\u7814\u7a76\uff0c\u4ece\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u5f00\u9500\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6846\u67b6\u7684\u80fd\u529b\u7279\u70b9\u4e0e\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u4e8e\u7279\u5b9a\u4efb\u52a1\u6216\u5b64\u7acb\u65b9\u9762\uff0c\u7f3a\u4e4f\u5bf9\u667a\u80fd\u4f53\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5b9e\u9645\u80fd\u529b\u7684\u5168\u9762\u7406\u89e3\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u6027\u8bc4\u4f30\u4ee5\u63d0\u4f9b\u66f4\u5b8c\u6574\u7684\u56fe\u666f\u3002", "method": "\u5728\u4e09\u4e2a\u4ee3\u8868\u6027\u4ee3\u7801\u4efb\u52a1\u4e0a\u4f7f\u7528\u6807\u51c6\u57fa\u51c6\u5bf9\u4e03\u4e2a\u901a\u7528\u667a\u80fd\u4f53\u6846\u67b6\u8fdb\u884c\u8bc4\u4f30\uff0c\u4ece\u6709\u6548\u6027\uff08\u4efb\u52a1\u6210\u529f\u7387\uff09\u3001\u6548\u7387\uff08\u6267\u884c\u8fc7\u7a0b\uff09\u548c\u5f00\u9500\uff08token\u6d88\u8017\uff09\u4e09\u4e2a\u4e92\u8865\u89c6\u89d2\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u5e76\u6df1\u5165\u63a2\u8ba8\u6709\u6548\u6027\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u667a\u80fd\u4f53\u6574\u4f53\u6709\u6548\u6027\u4e2d\u7b49\uff1bAgentOrchestra\u56e0\u534f\u8c03\u5f00\u9500\u5bfc\u81f4\u6267\u884c\u8f68\u8ff9\u6700\u957f\u3001\u4fee\u6b63\u5c1d\u8bd5\u6700\u591a\uff0c\u800cOpenHands\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u53cd\u601d\u63a8\u7406\u80fd\u529b\uff1b\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u6210\u672c\u6700\u9ad8\uff0cGPTswarm\u6700\u5177\u6210\u672c\u6548\u76ca\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u4e0d\u540c\u667a\u80fd\u4f53\u6846\u67b6\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u6a21\u5f0f\u4e0e\u6743\u8861\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u548c\u672a\u6765\u9ad8\u6548\u667a\u80fd\u4f53\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2511.00901", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00901", "abs": "https://arxiv.org/abs/2511.00901", "authors": ["Vincenzo De Martino", "Stefano Lambiase", "Fabiano Pecorelli", "Willem-Jan van den Heuvel", "Filomena Ferrucci", "Fabio Palomba"], "title": "Sustainability of Machine Learning-Enabled Systems: The Machine Learning Practitioner's Perspective", "comment": null, "summary": "Software sustainability is a key multifaceted non-functional requirement that\nencompasses environmental, social, and economic concerns, yet its integration\ninto the development of Machine Learning (ML)-enabled systems remains an open\nchallenge. While previous research has explored high-level sustainability\nprinciples and policy recommendations, limited empirical evidence exists on how\nsustainability is practically managed in ML workflows. Existing studies\npredominantly focus on environmental sustainability, e.g., carbon footprint\nreduction, while missing the broader spectrum of sustainability dimensions and\nthe challenges practitioners face in real-world settings. To address this gap,\nwe conduct an empirical study to characterize sustainability in ML-enabled\nsystems from a practitioner's perspective. We investigate (1) how ML engineers\nperceive and describe sustainability, (2) the software engineering practices\nthey adopt to support it, and (3) the key challenges hindering its adoption. We\nfirst perform a qualitative analysis based on interviews with eight experienced\nML engineers, followed by a large-scale quantitative survey with 203 ML\npractitioners. Our key findings reveal a significant disconnection between\nsustainability awareness and its systematic implementation, highlighting the\nneed for more structured guidelines, measurement frameworks, and regulatory\nsupport.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u8bbf\u8c08\u548c\u5927\u89c4\u6a21\u8c03\u67e5\uff0c\u7814\u7a76\u4e86\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u5e08\u5982\u4f55\u7406\u89e3\u3001\u5b9e\u8df5\u548c\u5e94\u5bf9\u8f6f\u4ef6\u53ef\u6301\u7eed\u6027\u6311\u6218\uff0c\u53d1\u73b0\u5c3d\u7ba1\u5bf9\u53ef\u6301\u7eed\u6027\u6709\u8ba4\u77e5\uff0c\u4f46\u5728\u7cfb\u7edf\u6027\u5b9e\u65bd\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u4e8e\u73af\u5883\u53ef\u6301\u7eed\u6027\uff08\u5982\u78b3\u8db3\u8ff9\uff09\uff0c\u7f3a\u4e4f\u5bf9\u793e\u4f1a\u3001\u7ecf\u6d4e\u7b49\u66f4\u5e7f\u6cdb\u53ef\u6301\u7eed\u6027\u7ef4\u5ea6\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u4e5f\u672a\u5145\u5206\u63ed\u793a\u4ece\u4e1a\u8005\u5728\u5b9e\u9645ML\u5de5\u4f5c\u6d41\u4e2d\u7ba1\u7406\u53ef\u6301\u7eed\u6027\u7684\u5177\u4f53\u505a\u6cd5\u4e0e\u969c\u788d\u3002", "method": "\u7ed3\u5408\u5b9a\u6027\u4e0e\u5b9a\u91cf\u65b9\u6cd5\uff1a\u9996\u5148\u5bf98\u540d\u8d44\u6df1ML\u5de5\u7a0b\u5e08\u8fdb\u884c\u8bbf\u8c08\uff0c\u518d\u5bf9203\u540dML\u4ece\u4e1a\u8005\u5f00\u5c55\u5927\u89c4\u6a21\u95ee\u5377\u8c03\u67e5\uff0c\u4ece\u4ece\u4e1a\u8005\u89c6\u89d2\u5206\u6790\u53ef\u6301\u7eed\u6027\u5728ML\u7cfb\u7edf\u4e2d\u7684\u5b9e\u8df5\u73b0\u72b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4ece\u4e1a\u8005\u5bf9\u53ef\u6301\u7eed\u6027\u6709\u57fa\u672c\u8ba4\u77e5\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u5b9e\u65bd\uff1b\u5b9e\u8df5\u4e2d\u7f3a\u5c11\u7ed3\u6784\u5316\u6307\u5357\u3001\u5ea6\u91cf\u6846\u67b6\u548c\u76d1\u7ba1\u652f\u6301\uff0c\u5bfc\u81f4\u53ef\u6301\u7eed\u6027\u96be\u4ee5\u6709\u6548\u878d\u5165ML\u5de5\u4f5c\u6d41\u3002", "conclusion": "\u4e3a\u4fc3\u8fdbML\u7cfb\u7edf\u7684\u53ef\u6301\u7eed\u6027\uff0c\u4e9f\u9700\u5236\u5b9a\u66f4\u660e\u786e\u7684\u5de5\u7a0b\u6307\u5357\u3001\u53ef\u64cd\u4f5c\u7684\u5ea6\u91cf\u4f53\u7cfb\u4ee5\u53ca\u653f\u7b56\u652f\u6301\uff0c\u4ee5\u5f25\u5408\u8ba4\u77e5\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002"}}
{"id": "2511.00915", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00915", "abs": "https://arxiv.org/abs/2511.00915", "authors": ["Jukka Ruohonen", "Abhishek Tiwari"], "title": "Empirical Derivations from an Evolving Test Suite", "comment": "Submitted", "summary": "The paper presents a longitudinal empirical analysis of the automated,\ncontinuous, and virtualization-based software test suite of the NetBSD\noperating system. The longitudinal period observed spans from the initial roll\nout of the test suite in the early 2010s to late 2025. According to the\nresults, the test suite has grown continuously, currently covering over ten\nthousand individual test cases. Failed test cases exhibit overall stability,\nalthough there have been shorter periods marked with more frequent failures. A\nsimilar observation applies to build failures, failures of the test suite to\ncomplete, and installation failures, all of which are also captured by the\nNetBSD's testing framework. Finally, code churn and kernel modifications do not\nprovide longitudinally consistent statistical explanations for the failures.\nAlthough some periods exhibit larger effects, including particularly with\nrespect to the kernel modifications, the effects are small on average. Even\nthough only in an exploratory manner, these empirical observations contribute\nto efforts to draw conclusions from large-scale and evolving software test\nsuites.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9NetBSD\u64cd\u4f5c\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u3001\u6301\u7eed\u6027\u3001\u57fa\u4e8e\u865a\u62df\u5316\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u5957\u4ef6\u8fdb\u884c\u4e86\u7eb5\u5411\u5b9e\u8bc1\u5206\u6790\uff082010\u5e74\u4ee3\u521d\u81f32025\u5e74\u5e95\uff09\uff0c\u53d1\u73b0\u6d4b\u8bd5\u7528\u4f8b\u6570\u91cf\u6301\u7eed\u589e\u957f\uff08\u73b0\u5df2\u8d851\u4e07\uff09\uff0c\u5931\u8d25\u7387\u603b\u4f53\u7a33\u5b9a\uff0c\u4e14\u4ee3\u7801\u53d8\u66f4\u4e0e\u5185\u6838\u4fee\u6539\u5bf9\u5931\u8d25\u7387\u7684\u7edf\u8ba1\u89e3\u91ca\u529b\u6709\u9650\u3002", "motivation": "\u4e3a\u4e86\u7406\u89e3\u5927\u89c4\u6a21\u3001\u6301\u7eed\u6f14\u5316\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u5957\u4ef6\u5728\u957f\u671f\u8fd0\u884c\u4e2d\u7684\u884c\u4e3a\u7279\u5f81\uff0c\u7279\u522b\u662f\u6d4b\u8bd5\u5931\u8d25\u6a21\u5f0f\u4e0e\u4ee3\u7801\u53d8\u66f4\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u5bf9NetBSD\u64cd\u4f5c\u7cfb\u7edf\u81ea2010\u5e74\u4ee3\u521d\u81f32025\u5e74\u5e95\u7684\u6d4b\u8bd5\u5957\u4ef6\u6570\u636e\u8fdb\u884c\u7eb5\u5411\u5b9e\u8bc1\u5206\u6790\uff0c\u6db5\u76d6\u6d4b\u8bd5\u7528\u4f8b\u6570\u91cf\u3001\u5931\u8d25\u7c7b\u578b\uff08\u6d4b\u8bd5\u5931\u8d25\u3001\u6784\u5efa\u5931\u8d25\u3001\u5b89\u88c5\u5931\u8d25\u7b49\uff09\u4ee5\u53ca\u4ee3\u7801\u53d8\u66f4\u548c\u5185\u6838\u4fee\u6539\u7684\u5f71\u54cd\u3002", "result": "\u6d4b\u8bd5\u5957\u4ef6\u6301\u7eed\u589e\u957f\u81f3\u8d851\u4e07\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff1b\u5404\u7c7b\u5931\u8d25\u603b\u4f53\u7a33\u5b9a\uff0c\u5076\u6709\u77ed\u671f\u6ce2\u52a8\uff1b\u4ee3\u7801\u53d8\u66f4\u548c\u5185\u6838\u4fee\u6539\u5bf9\u5931\u8d25\u7387\u7684\u957f\u671f\u7edf\u8ba1\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\u5c3d\u7ba1\u4ec5\u5177\u63a2\u7d22\u6027\uff0c\u8be5\u7814\u7a76\u4e3a\u4ece\u5927\u89c4\u6a21\u6f14\u5316\u6d4b\u8bd5\u5957\u4ef6\u4e2d\u5f97\u51fa\u5b9e\u8bc1\u7ed3\u8bba\u63d0\u4f9b\u4e86\u521d\u6b65\u4f9d\u636e\uff0c\u8868\u660e\u6d4b\u8bd5\u5931\u8d25\u5e76\u4e0d\u603b\u662f\u4e0e\u4ee3\u7801\u6216\u5185\u6838\u53d8\u66f4\u663e\u8457\u76f8\u5173\u3002"}}
{"id": "2511.01043", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01043", "abs": "https://arxiv.org/abs/2511.01043", "authors": ["Zihan Fang", "Yifan Zhang", "Yueke Zhang", "Kevin Leach", "Yu Huang"], "title": "DPO-F+: Aligning Code Repair Feedback with Developers' Preferences", "comment": "10 pages, 2 figures", "summary": "Large Language Models (LLMs) are increasingly applied to software engineering\ntasks, especially code repair. However, developers often struggle to interpret\nmodel outputs, limiting effective human-AI teaming. Prior work largely\noptimizes repaired code while under-addressing the natural-language feedback\nthat enables comprehension and iterative improvement. We present DPO-f+, a\nnovel framework that aligns code-repair feedback with developer needs and\nprofiles. It (1) formalizes developer-profiled, domain-specific metrics for\nfeedback alignment; (2) automatically constructs pairwise preference datasets\nfrom code-repair tasks; (3) fine-tunes using Direct Preference Optimization\n(DPO) augmented with a lightweight margin signal; and (4) provides an automated\nfeedback evaluation protocol. Empirically, DPO-f+ outperforms both the baseline\nand standard DPO on generated-code accuracy and overall feedback alignment. On\nnovice programming tasks, DPO-f+ raises the top-1 pass rate by 5.71 percentage\npoints (pp) over the baseline and by 3.30 pp over DPO. On the more challenging\nSWE-bench Lite benchmark, it increases the issue-resolution rate by 1.67 pp\nover DPO and by 4.67 pp over the baseline. It also achieves the largest\nimprovement in feedback alignment, outperforming DPO and the baseline. By\naligning feedback more closely with developer needs, DPO-f+ turns LLM-assisted\nrepair from one-shot outputs into a collaborative sensemaking workflow,\nproviding a practical approach to enhancing code comprehension and fostering\nmore effective human-AI teaming in software engineering.", "AI": {"tldr": "DPO-f+ \u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5f00\u53d1\u8005\u753b\u50cf\u4e0e\u9886\u57df\u7279\u5b9a\u6307\u6807\uff0c\u5229\u7528\u589e\u5f3a\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u65b9\u6cd5\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u4fee\u590d\u4efb\u52a1\u4e2d\u751f\u6210\u7684\u81ea\u7136\u8bed\u8a00\u53cd\u9988\u7684\u5bf9\u9f50\u5ea6\u4e0e\u5b9e\u7528\u6027\uff0c\u4ece\u800c\u6539\u5584\u4eba\u673a\u534f\u4f5c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u4fee\u590d\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4fee\u590d\u4ee3\u7801\u672c\u8eab\uff0c\u5ffd\u89c6\u4e86\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u7406\u89e3\u4e0e\u8fed\u4ee3\u6539\u8fdb\u7684\u81ea\u7136\u8bed\u8a00\u53cd\u9988\uff0c\u9650\u5236\u4e86\u4eba\u4e0eAI\u7684\u6709\u6548\u534f\u4f5c\u3002", "method": "DPO-f+ \u6846\u67b6\u5305\u542b\u56db\u4e2a\u6838\u5fc3\u90e8\u5206\uff1a(1) \u57fa\u4e8e\u5f00\u53d1\u8005\u753b\u50cf\u548c\u9886\u57df\u77e5\u8bc6\u5b9a\u4e49\u53cd\u9988\u5bf9\u9f50\u6307\u6807\uff1b(2) \u4ece\u4ee3\u7801\u4fee\u590d\u4efb\u52a1\u4e2d\u81ea\u52a8\u6784\u5efa\u6210\u5bf9\u504f\u597d\u6570\u636e\u96c6\uff1b(3) \u4f7f\u7528\u5e26\u8f7b\u91cf\u8fb9\u754c\u4fe1\u53f7\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u8fdb\u884c\u5fae\u8c03\uff1b(4) \u63d0\u4f9b\u81ea\u52a8\u5316\u7684\u53cd\u9988\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDPO-f+ \u5728\u4ee3\u7801\u51c6\u786e\u7387\u548c\u53cd\u9988\u5bf9\u9f50\u5ea6\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u548c\u6807\u51c6 DPO\u3002\u5728\u521d\u7ea7\u7f16\u7a0b\u4efb\u52a1\u4e2d\uff0ctop-1 \u901a\u8fc7\u7387\u6bd4\u57fa\u7ebf\u63d0\u5347 5.71 \u4e2a\u767e\u5206\u70b9\uff0c\u6bd4 DPO \u63d0\u5347 3.30 \u4e2a\u767e\u5206\u70b9\uff1b\u5728 SWE-bench Lite \u4e0a\uff0c\u95ee\u9898\u89e3\u51b3\u7387\u5206\u522b\u63d0\u5347 4.67 \u548c 1.67 \u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "DPO-f+ \u901a\u8fc7\u66f4\u8d34\u5408\u5f00\u53d1\u8005\u9700\u6c42\u7684\u53cd\u9988\uff0c\u5c06 LLM \u8f85\u52a9\u4ee3\u7801\u4fee\u590d\u4ece\u4e00\u6b21\u6027\u8f93\u51fa\u8f6c\u53d8\u4e3a\u534f\u4f5c\u5f0f\u7406\u89e3\u6d41\u7a0b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u4e0e\u4eba\u673a\u534f\u4f5c\u6548\u7387\u3002"}}
{"id": "2511.01047", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01047", "abs": "https://arxiv.org/abs/2511.01047", "authors": ["Yu Shi", "Hao Li", "Bram Adams", "Ahmed E. Hassan"], "title": "HAFixAgent: History-Aware Automated Program Repair Agent", "comment": "31 pages, 6 figures", "summary": "Automated program repair (APR) has recently shifted toward large language\nmodels and agent-based systems, yet most systems rely on local snapshot\ncontext, overlooking repository history. Prior work shows that repository\nhistory helps repair single-line bugs, since the last commit touching the buggy\nline is often the bug-introducing one. In this paper, we investigate whether\nrepository history can also improve agentic APR systems at scale, especially\nfor complex multi-hunk bugs. We present HAFixAgent, a History-Aware Bug-Fixing\nAgent that injects blame-derived repository heuristics into its repair loop. A\npreliminary study of all 854 real-world bugs from Defects4J motivates our\ndesign, showing that bug-relevant history is both widely available and highly\nconcentrated. Empirical comparison of HAFixAgent with two state-of-the-art\nbaselines shows: (1) Effectiveness: HAFixAgent significantly improves over the\nagent-based baseline (by 212.3%) and the multi-hunk baseline (by 29.9%). (2)\nEfficiency: history does not significantly increase agent steps and keeps token\ncosts comparable, with notably lower median costs for complex\nmulti-file-multi-hunk bugs. (3) Practicality: combining different historical\nheuristics repairs more bugs, offering a clear cost-benefit trade-off.\nHAFixAgent offers a practical recipe for history-aware agentic APR: ground the\nagent in version control history, prioritize diff-based historical context, and\nintegrate complementary heuristics when needed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHAFixAgent\uff0c\u4e00\u79cd\u5229\u7528\u7248\u672c\u5e93\u5386\u53f2\u4fe1\u606f\u589e\u5f3a\u4fee\u590d\u80fd\u529b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5728\u591a\u7247\u6bb5\u590d\u6742\u7f3a\u9677\u4fee\u590d\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u548c\u4f4e\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u667a\u80fd\u4f53\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u7cfb\u7edf\u5927\u591a\u4ec5\u4f9d\u8d56\u5c40\u90e8\u5feb\u7167\u4e0a\u4e0b\u6587\uff0c\u5ffd\u7565\u4e86\u7248\u672c\u5e93\u5386\u53f2\u4fe1\u606f\uff1b\u800c\u5148\u524d\u7814\u7a76\u8868\u660e\uff0c\u7248\u672c\u5e93\u5386\u53f2\u5bf9\u5355\u884c\u7f3a\u9677\u4fee\u590d\u6709\u6548\uff0c\u4f5c\u8005\u56e0\u6b64\u63a2\u7d22\u5176\u5728\u590d\u6742\u591a\u7247\u6bb5\u7f3a\u9677\u4fee\u590d\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faHAFixAgent\uff0c\u5c06\u57fa\u4e8eblame\u7684\u7248\u672c\u5e93\u542f\u53d1\u5f0f\u4fe1\u606f\u6ce8\u5165\u667a\u80fd\u4f53\u4fee\u590d\u5faa\u73af\uff1b\u901a\u8fc7\u5bf9Defects4J\u4e2d854\u4e2a\u771f\u5b9e\u7f3a\u9677\u7684\u521d\u6b65\u5206\u6790\uff0c\u9a8c\u8bc1\u5386\u53f2\u4fe1\u606f\u7684\u53ef\u7528\u6027\u4e0e\u96c6\u4e2d\u6027\uff0c\u5e76\u6574\u5408\u591a\u79cd\u5386\u53f2\u542f\u53d1\u5f0f\u7b56\u7565\u3002", "result": "HAFixAgent\u76f8\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u7684\u667a\u80fd\u4f53\u57fa\u7ebf\u548c\u591a\u7247\u6bb5\u57fa\u7ebf\uff0c\u4fee\u590d\u6210\u529f\u7387\u5206\u522b\u63d0\u5347212.3%\u548c29.9%\uff1b\u4fee\u590d\u8fc7\u7a0b\u672a\u663e\u8457\u589e\u52a0\u667a\u80fd\u4f53\u6b65\u9aa4\u6216token\u6210\u672c\uff0c\u5c24\u5176\u5728\u590d\u6742\u591a\u6587\u4ef6\u591a\u7247\u6bb5\u7f3a\u9677\u4e0a\u6210\u672c\u66f4\u4f4e\uff1b\u7ec4\u5408\u4e0d\u540c\u5386\u53f2\u542f\u53d1\u5f0f\u7b56\u7565\u53ef\u4fee\u590d\u66f4\u591a\u7f3a\u9677\uff0c\u5177\u6709\u660e\u786e\u7684\u6210\u672c\u6548\u76ca\u6743\u8861\u3002", "conclusion": "HAFixAgent\u4e3a\u5386\u53f2\u611f\u77e5\u7684\u667a\u80fd\u4f53\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\uff1a\u4ee5\u7248\u672c\u63a7\u5236\u5386\u53f2\u4e3a\u57fa\u7840\uff0c\u4f18\u5148\u4f7f\u7528\u57fa\u4e8ediff\u7684\u5386\u53f2\u4e0a\u4e0b\u6587\uff0c\u5e76\u5728\u9700\u8981\u65f6\u6574\u5408\u4e92\u8865\u542f\u53d1\u5f0f\u7b56\u7565\u3002"}}
{"id": "2511.01104", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01104", "abs": "https://arxiv.org/abs/2511.01104", "authors": ["Yujian Liu", "Jiabao Ji", "Yang Zhang", "Wenbo Guo", "Tommi Jaakkola", "Shiyu Chang"], "title": "HarnessLLM: Automatic Testing Harness Generation via Reinforcement Learning", "comment": null, "summary": "Existing LLM-based automatic test generation methods mainly produce input and\nexpected output pairs to categorize the intended behavior of correct programs.\nAlthough straightforward, these methods have limited diversity in generated\ntests and cannot provide enough debugging information. We propose HarnessLLM, a\ntwo-stage training pipeline that enables LLMs to write harness code for\ntesting. Particularly, LLMs generate code that synthesizes inputs and validates\nthe observed outputs, allowing complex test cases and flexible output\nvalidation such as invariant checking. To achieve this, we train LLMs with SFT\nfollowed by RLVR with a customized reward design. Experiments show that\nHarnessLLM outperforms input-output-based testing in bug finding and testing\nstrategy diversity. HarnessLLM further benefits the code generation performance\nthrough test-time scaling with our generated test cases as inference-phase\nvalidation. Our code is available at\nhttps://github.com/UCSB-NLP-Chang/HarnessLLM.git.", "AI": {"tldr": "HarnessLLM \u662f\u4e00\u79cd\u4e24\u9636\u6bb5\u8bad\u7ec3\u7684 LLM \u65b9\u6cd5\uff0c\u901a\u8fc7\u751f\u6210\u6d4b\u8bd5\u4ee3\u7801\uff08\u800c\u975e\u4ec5\u8f93\u5165-\u8f93\u51fa\u5bf9\uff09\u63d0\u5347\u6d4b\u8bd5\u591a\u6837\u6027\u548c\u8c03\u8bd5\u80fd\u529b\uff0c\u5e76\u5728\u7f3a\u9677\u68c0\u6d4b\u548c\u4ee3\u7801\u751f\u6210\u6027\u80fd\u4e0a\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e LLM \u7684\u81ea\u52a8\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u4e3b\u8981\u751f\u6210\u8f93\u5165\u4e0e\u671f\u671b\u8f93\u51fa\u5bf9\uff0c\u6d4b\u8bd5\u591a\u6837\u6027\u6709\u9650\u4e14\u7f3a\u4e4f\u8db3\u591f\u7684\u8c03\u8bd5\u4fe1\u606f\u3002", "method": "\u63d0\u51fa HarnessLLM\uff0c\u91c7\u7528\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u52a0\u57fa\u4e8e\u81ea\u5b9a\u4e49\u5956\u52b1\u8bbe\u8ba1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u4e24\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff0c\u4f7f LLM \u80fd\u751f\u6210\u5305\u542b\u8f93\u5165\u5408\u6210\u4e0e\u8f93\u51fa\u9a8c\u8bc1\u903b\u8f91\u7684\u6d4b\u8bd5\u4ee3\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660e HarnessLLM \u5728\u53d1\u73b0\u7f3a\u9677\u548c\u6d4b\u8bd5\u7b56\u7565\u591a\u6837\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u8f93\u5165-\u8f93\u51fa\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5e76\u53ef\u901a\u8fc7\u6d4b\u8bd5\u65f6\u7f29\u653e\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "conclusion": "HarnessLLM \u6709\u6548\u63d0\u5347\u4e86 LLM \u5728\u81ea\u52a8\u6d4b\u8bd5\u751f\u6210\u4e2d\u7684\u80fd\u529b\uff0c\u4e0d\u4ec5\u589e\u5f3a\u6d4b\u8bd5\u6548\u679c\uff0c\u8fd8\u80fd\u53cd\u54fa\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u3002"}}
{"id": "2511.01176", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01176", "abs": "https://arxiv.org/abs/2511.01176", "authors": ["Wenqing Zhu", "Norihiro Yoshida", "Eunjong Choi", "Yutaka Matsubara", "Hiroaki Takada"], "title": "An Empirical Study of LLM-Based Code Clone Detection", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious software engineering tasks, such as code generation and debugging,\nbecause of their ability to translate between programming languages and natural\nlanguages. Existing studies have demonstrated the effectiveness of LLMs in code\nclone detection. However, two crucial issues remain unaddressed: the ability of\nLLMs to achieve comparable performance across different datasets and the\nconsistency of LLMs' responses in code clone detection. To address these\nissues, we constructed seven code clone datasets and then evaluated five LLMs\nin four existing prompts with these datasets. The datasets were created by\nsampling code pairs using their Levenshtein ratio from two different code\ncollections, CodeNet and BigCloneBench. Our evaluation revealed that although\nLLMs perform well in CodeNet-related datasets, with o3-mini achieving a 0.943\nF1 score, their performance significantly decreased in BigCloneBench-related\ndatasets. Most models achieved a high response consistency, with over 90\\% of\njudgments remaining consistent across all five submissions. The fluctuations of\nthe F1 score affected by inconsistency are also tiny; their variations are less\nthan 0.03.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8de8\u6570\u636e\u96c6\u6027\u80fd\u548c\u54cd\u5e94\u4e00\u81f4\u6027\uff0c\u53d1\u73b0LLMs\u5728CodeNet\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728BigCloneBench\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u540c\u65f6\u5927\u591a\u6570\u6a21\u578b\u5177\u6709\u9ad8\u54cd\u5e94\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c1a\u672a\u5145\u5206\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u4ee3\u7801\u514b\u9686\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u4e00\u81f4\u6027\u53ca\u5176\u5728\u591a\u6b21\u8fd0\u884c\u4e2d\u5224\u65ad\u7ed3\u679c\u7684\u7a33\u5b9a\u6027\u3002", "method": "\u6784\u5efa\u4e03\u4e2a\u57fa\u4e8eCodeNet\u548cBigCloneBench\u7684\u4ee3\u7801\u514b\u9686\u6570\u636e\u96c6\uff0c\u91c7\u7528Levenshtein\u6bd4\u503c\u91c7\u6837\u4ee3\u7801\u5bf9\uff0c\u5e76\u5728\u56db\u79cd\u5df2\u6709\u63d0\u793a\u4e0b\u8bc4\u4f30\u4e94\u4e2aLLMs\u7684\u6027\u80fd\u4e0e\u4e00\u81f4\u6027\u3002", "result": "LLMs\u5728CodeNet\u76f8\u5173\u6570\u636e\u96c6\u4e0aF1\u5206\u6570\u9ad8\u8fbe0.943\uff08o3-mini\uff09\uff0c\u4f46\u5728BigCloneBench\u76f8\u5173\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff1b\u591a\u6570\u6a21\u578b\u54cd\u5e94\u4e00\u81f4\u6027\u8d85\u8fc790%\uff0cF1\u5206\u6570\u56e0\u4e0d\u4e00\u81f4\u6027\u5f15\u8d77\u7684\u6ce2\u52a8\u5c0f\u4e8e0.03\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6570\u636e\u96c6\u4f9d\u8d56\u6027\uff0c\u5c3d\u7ba1\u5176\u54cd\u5e94\u4e00\u81f4\u6027\u8f83\u9ad8\uff0c\u4f46\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u4ecd\u9700\u63d0\u5347\u3002"}}
{"id": "2511.01316", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01316", "abs": "https://arxiv.org/abs/2511.01316", "authors": ["Chong Wang", "Chen Zhang", "Jiajun Wu", "Wunan Guo", "Jianfeng Qu", "Yewen Tian", "Yang Liu"], "title": "Exploringand Unleashing the Power of Large Language Models in CI/CD Configuration Translation", "comment": null, "summary": "Continuous Integration (CI) is a cornerstone of modern collaborative software\ndevelopment, and numerous CI platforms are available. Differences in\nmaintenance overhead, reliability, and integration depth with code-hosting\nplatforms make migration between CI platforms a common practice. A central step\nin migration is translating CI configurations, which is challenging due to the\nintrinsic complexity of CI configurations and the need to understand semantic\ndifferences and relationships across CI platforms.\n  With the advent of large language models (LLMs), recent advances in software\nengineering highlight their potential for CI configuration translation. In this\npaper, we present a study on LLM-based CI configuration translation, focusing\non the migration from Travis CI to GitHub Actions. First, using 811 migration\nrecords, we quantify the effort involved and find that developers read an\naverage of 38 lines of Travis configuration and write 58 lines of GitHub\nActions configuration, with nearly half of the migrations requiring multiple\ncommits. We further analyze translations produced by each of the four LLMs and\nidentify 1,121 issues grouped into four categories: logic inconsistencies\n(38%), platform discrepancies (32%), environment errors (25%), and syntax\nerrors (5%). Finally, we evaluate three enhancement strategies and show that\ncombining guideline-based prompting with iterative refinement achieves the best\nperformance, reaching a Build Success Rate of 75.5%-nearly a threefold\nimprovement over GPT-4o with a basic prompt.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684CI\u914d\u7f6e\u8fc1\u79fb\uff0c\u805a\u7126\u4e8e\u4eceTravis CI\u5230GitHub Actions\u7684\u8f6c\u6362\uff0c\u91cf\u5316\u4e86\u4eba\u5de5\u8fc1\u79fb\u7684\u5de5\u4f5c\u91cf\uff0c\u5206\u6790\u4e86LLM\u751f\u6210\u914d\u7f6e\u4e2d\u7684\u5e38\u89c1\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u7ed3\u5408\u6307\u5357\u63d0\u793a\u4e0e\u8fed\u4ee3\u4f18\u5316\u7684\u7b56\u7565\uff0c\u5c06\u6784\u5efa\u6210\u529f\u7387\u63d0\u5347\u81f375.5%\u3002", "motivation": "CI\u5e73\u53f0\u8fc1\u79fb\u666e\u904d\u5b58\u5728\uff0c\u4f46\u914d\u7f6e\u7ffb\u8bd1\u590d\u6742\uff0c\u9700\u7406\u89e3\u4e0d\u540c\u5e73\u53f0\u95f4\u7684\u8bed\u4e49\u5dee\u5f02\uff1b\u968f\u7740LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5174\u8d77\uff0c\u63a2\u7d22\u5176\u5728CI\u914d\u7f6e\u7ffb\u8bd1\u4e2d\u7684\u6548\u679c\u4e0e\u6539\u8fdb\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u610f\u4e49\u3002", "method": "\u57fa\u4e8e811\u4e2a\u771f\u5b9e\u8fc1\u79fb\u8bb0\u5f55\u5206\u6790\u4eba\u5de5\u8fc1\u79fb\u5de5\u4f5c\u91cf\uff1b\u8bc4\u4f30\u56db\u4e2aLLM\u751f\u6210\u7684\u7ffb\u8bd1\u7ed3\u679c\uff0c\u5bf91,121\u4e2a\u95ee\u9898\u8fdb\u884c\u5206\u7c7b\uff1b\u6d4b\u8bd5\u4e09\u79cd\u589e\u5f3a\u7b56\u7565\uff0c\u5305\u62ec\u6307\u5357\u63d0\u793a\u3001\u4e0a\u4e0b\u6587\u793a\u4f8b\u548c\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5f00\u53d1\u8005\u5e73\u5747\u9605\u8bfb38\u884cTravis\u914d\u7f6e\u3001\u7f16\u519958\u884cGitHub Actions\u914d\u7f6e\uff0c\u8fd1\u534a\u6570\u8fc1\u79fb\u9700\u591a\u6b21\u63d0\u4ea4\uff1bLLM\u7ffb\u8bd1\u95ee\u9898\u4e3b\u8981\u4e3a\u903b\u8f91\u4e0d\u4e00\u81f4\uff0838%\uff09\u3001\u5e73\u53f0\u5dee\u5f02\uff0832%\uff09\u3001\u73af\u5883\u9519\u8bef\uff0825%\uff09\u548c\u8bed\u6cd5\u9519\u8bef\uff085%\uff09\uff1b\u7ed3\u5408\u6307\u5357\u63d0\u793a\u4e0e\u8fed\u4ee3\u4f18\u5316\u7b56\u7565\u4f7f\u6784\u5efa\u6210\u529f\u7387\u63d0\u5347\u81f375.5%\uff0c\u662f\u57fa\u7840GPT-4o\u63d0\u793a\u7684\u8fd1\u4e09\u500d\u3002", "conclusion": "LLM\u5728CI\u914d\u7f6e\u7ffb\u8bd1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9700\u9488\u5bf9\u6027\u4f18\u5316\uff1b\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u7684\u63d0\u793a\u5de5\u7a0b\u4e0e\u8fed\u4ee3\u673a\u5236\u53ef\u663e\u8457\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\u4e0e\u6784\u5efa\u6210\u529f\u7387\u3002"}}
{"id": "2511.01324", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.01324", "abs": "https://arxiv.org/abs/2511.01324", "authors": ["Lekshmi Murali Rani", "Richard Berntsson Svensson", "Robert Feldt"], "title": "AI for Requirements Engineering: Industry adoption and Practitioner perspectives", "comment": "Accepted at the Intelligent Software Engineering (ISE) 2025 Workshop\n  at the Automated Software Engineering (ASE) 2025 Conference", "summary": "The integration of AI for Requirements Engineering (RE) presents significant\nbenefits but also poses real challenges.Although RE is fundamental to software\nengineering, limited research has examined AI adoption in RE.We surveyed 55\nsoftware practitioners to map AI usage across four RE phases:Elicitation,\nAnalysis, Specification, and Validation, and four approaches for decision\nmaking: human only decisions, AI validation, Human AI Collaboration (HAIC), and\nfull AI automation.Participants also shared their perceptions, challenges, and\nopportunities when applying AI for RE tasks.Our data show that 58.2% of\nrespondents already use AI in RE, and 69.1% view its impact as positive or very\npositive.HAIC dominates practice, accounting for 54.4% of all RE techniques,\nwhile full AI automation remains minimal at 5.4%.Passive AI validation (4.4 to\n6.2%) lags even further behind, indicating that practitioners value AI's active\nsupport over passive oversight.These findings suggest that AI is most effective\nwhen positioned as a collaborative partner rather than a replacement for human\nexpertise.It also highlights the need for RE specific HAIC frameworks along\nwith robust and responsible AI governance as AI adoption in RE grows.", "AI": {"tldr": "\u4e00\u9879\u9488\u5bf955\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u7684\u8c03\u67e5\u663e\u793a\uff0c58.2%\u5df2\u5728\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u4e2d\u4f7f\u7528AI\uff0c69.1%\u8ba4\u4e3a\u5176\u5f71\u54cd\u79ef\u6781\uff1b\u4eba\u673a\u534f\u4f5c\uff08HAIC\uff09\u662f\u4e3b\u6d41\u6a21\u5f0f\uff0854.4%\uff09\uff0c\u5b8c\u5168\u81ea\u52a8\u5316\u4ec5\u53605.4%\uff0c\u8868\u660eAI\u5728RE\u4e2d\u6700\u6709\u6548\u7684\u65b9\u5f0f\u662f\u4f5c\u4e3a\u4eba\u7c7b\u4e13\u5bb6\u7684\u534f\u4f5c\u4f19\u4f34\u3002", "motivation": "\u5c3d\u7ba1\u9700\u6c42\u5de5\u7a0b\uff08RE\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5173\u4e8eAI\u5728RE\u4e2d\u5e94\u7528\u7684\u7814\u7a76\u4ecd\u6709\u9650\uff1b\u4f5c\u8005\u65e8\u5728\u4e86\u89e3AI\u5728RE\u5404\u9636\u6bb5\u7684\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u3001\u4ece\u4e1a\u8005\u5bf9\u5176\u7684\u770b\u6cd5\u4ee5\u53ca\u9762\u4e34\u7684\u6311\u6218\u4e0e\u673a\u9047\u3002", "method": "\u901a\u8fc7\u95ee\u5377\u8c03\u67e555\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\uff0c\u5206\u6790AI\u5728RE\u56db\u4e2a\u9636\u6bb5\uff08\u83b7\u53d6\u3001\u5206\u6790\u3001\u89c4\u683c\u8bf4\u660e\u3001\u9a8c\u8bc1\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u8003\u5bdf\u56db\u79cd\u51b3\u7b56\u6a21\u5f0f\uff08\u7eaf\u4eba\u5de5\u3001AI\u9a8c\u8bc1\u3001\u4eba\u673a\u534f\u4f5cHAIC\u3001\u5168AI\u81ea\u52a8\u5316\uff09\u7684\u4f7f\u7528\u60c5\u51b5\u3002", "result": "58.2%\u7684\u53d7\u8bbf\u8005\u5df2\u5728RE\u4e2d\u4f7f\u7528AI\uff0c69.1%\u6301\u6b63\u9762\u770b\u6cd5\uff1bHAIC\u5360\u6240\u6709RE\u6280\u672f\u768454.4%\uff0c\u5168\u81ea\u52a8\u5316\u4ec55.4%\uff0c\u88ab\u52a8AI\u9a8c\u8bc1\u4f7f\u7528\u7387\u66f4\u4f4e\uff084.4%\u20136.2%\uff09\u3002", "conclusion": "AI\u5728RE\u4e2d\u6700\u6709\u6548\u7684\u89d2\u8272\u662f\u4f5c\u4e3a\u4eba\u7c7b\u4e13\u5bb6\u7684\u534f\u4f5c\u4f19\u4f34\u800c\u975e\u66ff\u4ee3\u8005\uff0c\u672a\u6765\u9700\u53d1\u5c55\u9762\u5411RE\u7684\u4eba\u673a\u534f\u4f5c\u6846\u67b6\uff0c\u5e76\u52a0\u5f3a\u8d1f\u8d23\u4efb\u7684AI\u6cbb\u7406\u3002"}}
{"id": "2511.01348", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01348", "abs": "https://arxiv.org/abs/2511.01348", "authors": ["Robin Gr\u00f6pler", "Steffen Klepke", "Jack Johns", "Andreas Dreschinski", "Klaus Schmid", "Benedikt Dornauer", "Eray T\u00fcz\u00fcn", "Joost Noppen", "Mohammad Reza Mousavi", "Yongjian Tang", "Johannes Viehmann", "Selin \u015eirin Aslang\u00fcl", "Beum Seuk Lee", "Adam Ziolkowski", "Eric Zie"], "title": "The Future of Generative AI in Software Engineering: A Vision from Industry and Academia in the European GENIUS Project", "comment": "Submitted to 2nd IEEE/ACM International Conference on AI-powered\n  Software (AIware 2025)", "summary": "Generative AI (GenAI) has recently emerged as a groundbreaking force in\nSoftware Engineering, capable of generating code, suggesting fixes, and\nsupporting quality assurance. While its use in coding tasks shows considerable\npromise, applying GenAI across the entire Software Development Life Cycle\n(SDLC) has not yet been fully explored. Critical uncertainties in areas such as\nreliability, accountability, security, and data privacy demand deeper\ninvestigation and coordinated action. The GENIUS project, comprising over 30\nEuropean industrial and academic partners, aims to address these challenges by\nadvancing AI integration across all SDLC phases. It focuses on GenAI's\npotential, the development of innovative tools, and emerging research\nchallenges, actively shaping the future of software engineering. This vision\npaper presents a shared perspective on the future of GenAI-based software\nengineering, grounded in cross-sector dialogue and experience within the GENIUS\nconsortium, supported by an exploratory literature review. The paper explores\nfour central elements: (1) a structured overview of current challenges in GenAI\nadoption across the SDLC; (2) a forward-looking vision outlining key\ntechnological and methodological advances expected over the next five years;\n(3) anticipated shifts in the roles and required skill sets of software\nprofessionals; and (4) the contribution of GENIUS in realizing this\ntransformation through practical tools and industrial validation. By aligning\ntechnical innovation with business relevance, this paper aims to inform both\nresearch agendas and industrial strategies, providing a foundation for\nreliable, scalable, and industry-ready GenAI solutions for software engineering\nteams.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5173\u4e8e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5e94\u7528\u7684\u524d\u77bb\u6027\u613f\u666f\uff0c\u57fa\u4e8eGENIUS\u9879\u76ee\u4e2d30\u591a\u4e2a\u6b27\u6d32\u4ea7\u5b66\u7814\u4f19\u4f34\u7684\u7ecf\u9a8c\u4e0e\u5bf9\u8bdd\uff0c\u7cfb\u7edf\u63a2\u8ba8\u4e86GenAI\u5728\u6574\u4e2a\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\uff08SDLC\uff09\u4e2d\u7684\u6311\u6218\u3001\u672a\u6765\u4e94\u5e74\u6280\u672f\u53d1\u5c55\u65b9\u5411\u3001\u8f6f\u4ef6\u4ece\u4e1a\u8005\u89d2\u8272\u8f6c\u53d8\uff0c\u4ee5\u53caGENIUS\u9879\u76ee\u5982\u4f55\u901a\u8fc7\u5de5\u5177\u5f00\u53d1\u4e0e\u5de5\u4e1a\u9a8c\u8bc1\u63a8\u52a8\u8fd9\u4e00\u8f6c\u578b\u3002", "motivation": "\u5c3d\u7ba1GenAI\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u6574\u4e2a\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684\u5e94\u7528\u4ecd\u4e0d\u5145\u5206\uff0c\u4e14\u5728\u53ef\u9760\u6027\u3001\u95ee\u8d23\u6027\u3001\u5b89\u5168\u6027\u548c\u6570\u636e\u9690\u79c1\u7b49\u65b9\u9762\u5b58\u5728\u5173\u952e\u4e0d\u786e\u5b9a\u6027\uff0c\u4e9f\u9700\u7cfb\u7edf\u6027\u7814\u7a76\u4e0e\u534f\u540c\u884c\u52a8\u3002", "method": "\u901a\u8fc7GENIUS\u8054\u76df\u5185\u90e8\u7684\u8de8\u884c\u4e1a\u5bf9\u8bdd\u3001\u5b9e\u8df5\u7ecf\u9a8c\u603b\u7ed3\u4ee5\u53ca\u63a2\u7d22\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u6784\u5efa\u5bf9GenAI\u9a71\u52a8\u8f6f\u4ef6\u5de5\u7a0b\u672a\u6765\u7684\u5171\u540c\u613f\u666f\uff0c\u5e76\u56f4\u7ed5\u56db\u5927\u6838\u5fc3\u8981\u7d20\u5c55\u5f00\u5206\u6790\u3002", "result": "\u8bba\u6587\u7cfb\u7edf\u68b3\u7406\u4e86GenAI\u5728SDLC\u5404\u9636\u6bb5\u7684\u5f53\u524d\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u4e94\u5e74\u7684\u6280\u672f\u4e0e\u65b9\u6cd5\u6f14\u8fdb\u8def\u5f84\uff0c\u9884\u6d4b\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u89d2\u8272\u4e0e\u6280\u80fd\u9700\u6c42\u7684\u53d8\u5316\uff0c\u5e76\u660e\u786e\u4e86GENIUS\u9879\u76ee\u5728\u63a8\u52a8\u5b9e\u7528\u5316\u5de5\u5177\u548c\u5de5\u4e1a\u9a8c\u8bc1\u65b9\u9762\u7684\u8d21\u732e\u3002", "conclusion": "\u901a\u8fc7\u5c06\u6280\u672f\u521b\u65b0\u4e0e\u4e1a\u52a1\u4ef7\u503c\u5bf9\u9f50\uff0c\u8be5\u7814\u7a76\u4e3a\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u63d0\u4f9b\u4e86\u53ef\u9760\u3001\u53ef\u6269\u5c55\u4e14\u9762\u5411\u4ea7\u4e1a\u7684GenAI\u8f6f\u4ef6\u5de5\u7a0b\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u5c55\u57fa\u7840\u3002"}}
{"id": "2511.01395", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01395", "abs": "https://arxiv.org/abs/2511.01395", "authors": ["Maimouna Tamah Diao", "Moustapha Awwalou Diouf", "Iyiola Emmanuel Olatunji", "Abdoul Kader Kabor\u00e9", "Gervais Mendy", "Jacques Klein", "Tegawend\u00e9 F. Bissyand\u00e9"], "title": "Characterizing Build Compromises Through Vulnerability Disclosure Analysis", "comment": null, "summary": "The software build process transforms source code into deployable artifacts,\nrepresenting a critical yet vulnerable stage in software development. Build\ninfrastructure security poses unique challenges: the complexity of\nmulti-component systems (source code, dependencies, build tools), the\ndifficulty of detecting intrusions during compilation, and prevalent build\nnon-determinism that masks malicious modifications. Despite these risks, the\nsecurity community lacks a systematic understanding of build-specific attack\nvectors, hindering effective defense design.\n  This paper presents an empirically-derived taxonomy of attack vectors\ntargeting the build process, constructed through a large-scale CVE mining (of\n621 vulnerability disclosures from the NVD database). We categorize attack\nvectors by their injection points across the build pipeline, from source code\nmanipulation to compiler compromise. To validate our taxonomy, we analyzed 168\ndocumented software supply chain attacks, identifying 40 incidents specifically\ntargeting build phases. Our analysis reveals that 23.8\\% of supply chain\nattacks exploit build vulnerabilities, with dependency confusion and build\nscript injection representing the most prevalent vectors.\n  Dataset available at:\nhttps://anonymous.4open.science/r/Taxonomizing-Build-Attacks-8BB0.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9621\u4e2aCVE\u6f0f\u6d1e\u548c168\u8d77\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u4e8b\u4ef6\u7684\u5b9e\u8bc1\u5206\u6790\uff0c\u6784\u5efa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u9488\u5bf9\u8f6f\u4ef6\u6784\u5efa\u8fc7\u7a0b\u7684\u653b\u51fb\u5411\u91cf\u5206\u7c7b\u4f53\u7cfb\uff0c\u53d1\u73b023.8%\u7684\u4f9b\u5e94\u94fe\u653b\u51fb\u5229\u7528\u6784\u5efa\u9636\u6bb5\u6f0f\u6d1e\uff0c\u5176\u4e2d\u4f9d\u8d56\u6df7\u6dc6\u548c\u6784\u5efa\u811a\u672c\u6ce8\u5165\u6700\u4e3a\u5e38\u89c1\u3002", "motivation": "\u8f6f\u4ef6\u6784\u5efa\u8fc7\u7a0b\u662f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5173\u952e\u4f46\u8106\u5f31\u73af\u8282\uff0c\u7531\u4e8e\u591a\u7ec4\u4ef6\u7cfb\u7edf\u590d\u6742\u6027\u3001\u7f16\u8bd1\u671f\u95f4\u5165\u4fb5\u68c0\u6d4b\u56f0\u96be\u4ee5\u53ca\u6784\u5efa\u975e\u786e\u5b9a\u6027\u63a9\u76d6\u6076\u610f\u4fee\u6539\u7b49\u95ee\u9898\uff0c\u5b89\u5168\u793e\u533a\u7f3a\u4e4f\u5bf9\u6784\u5efa\u7279\u6709\u653b\u51fb\u5411\u91cf\u7684\u7cfb\u7edf\u6027\u7406\u89e3\uff0c\u963b\u788d\u4e86\u6709\u6548\u9632\u5fa1\u673a\u5236\u7684\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc7\u5927\u89c4\u6a21\u6316\u6398NVD\u6570\u636e\u5e93\u4e2d\u7684621\u4e2a\u6f0f\u6d1e\u62ab\u9732\uff0c\u6784\u5efa\u4e00\u4e2a\u57fa\u4e8e\u6784\u5efa\u6d41\u6c34\u7ebf\u6ce8\u5165\u70b9\uff08\u4ece\u6e90\u7801\u7be1\u6539\u5230\u7f16\u8bd1\u5668\u7834\u574f\uff09\u7684\u653b\u51fb\u5411\u91cf\u5206\u7c7b\u6cd5\uff0c\u5e76\u5229\u7528168\u8d77\u5df2\u8bb0\u5f55\u7684\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u4e8b\u4ef6\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5728\u5206\u6790\u7684\u4f9b\u5e94\u94fe\u653b\u51fb\u4e2d\uff0c\u670940\u8d77\u660e\u786e\u9488\u5bf9\u6784\u5efa\u9636\u6bb5\uff0c\u5360\u6bd423.8%\uff1b\u4f9d\u8d56\u6df7\u6dc6\u548c\u6784\u5efa\u811a\u672c\u6ce8\u5165\u662f\u6700\u4e3b\u8981\u7684\u653b\u51fb\u5411\u91cf\u3002", "conclusion": "\u6784\u5efa\u9636\u6bb5\u662f\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u7684\u91cd\u8981\u76ee\u6807\uff0c\u672c\u6587\u63d0\u51fa\u7684\u5b9e\u8bc1\u5206\u7c7b\u6cd5\u6709\u52a9\u4e8e\u63d0\u5347\u5bf9\u6784\u5efa\u5b89\u5168\u5a01\u80c1\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u9488\u5bf9\u6027\u9632\u5fa1\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2511.01423", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01423", "abs": "https://arxiv.org/abs/2511.01423", "authors": ["Ruidi He", "Yu Zhang", "Meng Zhang", "Andreas Rausch"], "title": "LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations", "comment": null, "summary": "High-definition map transformations are essential in autonomous driving\nsystems, enabling interoperability across tools. Ensuring their semantic\ncorrectness is challenging, since existing rule-based frameworks rely on\nmanually written formulas and domain-specific functions, limiting scalability.\n  In this paper, We present an LLM-assisted pipeline that jointly generates\nlogical formulas and corresponding executable predicates within a computational\nFOL framework, extending the map verifier in CommonRoad scenario designer with\nelevation support. The pipeline leverages prompt-based LLM generation to\nproduce grammar-compliant rules and predicates that integrate directly into the\nexisting system.\n  We implemented a prototype and evaluated it on synthetic bridge and slope\nscenarios. The results indicate reduced manual engineering effort while\npreserving correctness, demonstrating the feasibility of a scalable,\nsemi-automated human-in-the-loop approach to map-transformation verification.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u534a\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u7528\u4e8e\u751f\u6210\u9ad8\u7cbe\u5730\u56fe\u53d8\u6362\u4e2d\u7684\u903b\u8f91\u516c\u5f0f\u4e0e\u53ef\u6267\u884c\u8c13\u8bcd\uff0c\u4ee5\u63d0\u5347\u5730\u56fe\u9a8c\u8bc1\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c4\u5219\u7684\u5730\u56fe\u9a8c\u8bc1\u6846\u67b6\u4f9d\u8d56\u4eba\u5de5\u7f16\u5199\u7684\u516c\u5f0f\u548c\u9886\u57df\u7279\u5b9a\u51fd\u6570\uff0c\u96be\u4ee5\u6269\u5c55\uff0c\u4e14\u96be\u4ee5\u4fdd\u8bc1\u8bed\u4e49\u6b63\u786e\u6027\u3002", "method": "\u6784\u5efa\u4e00\u4e2aLLM\u8f85\u52a9\u7684\u6d41\u6c34\u7ebf\uff0c\u5728\u4e00\u9636\u903b\u8f91\uff08FOL\uff09\u8ba1\u7b97\u6846\u67b6\u4e0b\u8054\u5408\u751f\u6210\u903b\u8f91\u516c\u5f0f\u53ca\u5176\u5bf9\u5e94\u7684\u53ef\u6267\u884c\u8c13\u8bcd\uff0c\u5e76\u96c6\u6210\u5230CommonRoad\u573a\u666f\u8bbe\u8ba1\u5668\u7684\u5730\u56fe\u9a8c\u8bc1\u5668\u4e2d\uff0c\u65b0\u589e\u5bf9\u9ad8\u7a0b\u4fe1\u606f\u7684\u652f\u6301\uff1b\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u5f15\u5bfcLLM\u751f\u6210\u7b26\u5408\u8bed\u6cd5\u7684\u89c4\u5219\u548c\u8c13\u8bcd\u3002", "result": "\u5728\u5408\u6210\u7684\u6865\u6881\u4e0e\u5761\u9053\u573a\u666f\u4e2d\u8fdb\u884c\u539f\u578b\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6b63\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u5de5\u7a0b\u91cf\u3002", "conclusion": "\u8be5\u7814\u7a76\u9a8c\u8bc1\u4e86\u91c7\u7528\u4eba\u673a\u534f\u540c\u3001\u534a\u81ea\u52a8\u5316\u7684LLM\u8f85\u52a9\u65b9\u6cd5\u5728\u9ad8\u7cbe\u5730\u56fe\u53d8\u6362\u9a8c\u8bc1\u4e2d\u7684\u53ef\u884c\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.01529", "categories": ["cs.SE", "cs.CL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.01529", "abs": "https://arxiv.org/abs/2511.01529", "authors": ["Murali Sridharan", "Mikel Robredo", "Leevi Rantala", "Matteo Esposito", "Valentina Lenarduzzi", "Mika Mantyla"], "title": "Hidden in Plain Sight: Where Developers Confess Self-Admitted Technical Debt", "comment": null, "summary": "Context. Detecting Self-Admitted Technical Debt (SATD) is crucial for\nproactive software maintenance. Previous research has primarily targeted\ndetecting and prioritizing SATD, with little focus on the source code afflicted\nwith SATD. Our goal in this work is to connect the SATD comments with source\ncode constructs that surround them.\n  Method. We leverage the extensive SATD dataset PENTACET, containing code\ncomments from over 9000 Java Open Source Software (OSS) repositories. We\nquantitatively infer where SATD most commonly occurs and which code\nconstructs/statements it most frequently affects.\n  Results and Conclusions. Our large-scale study links over 225,000 SATD\ncomments to their surrounding code, showing that SATD mainly arises in inline\ncode near definitions, conditionals, and exception handling, where developers\nface uncertainty and trade-offs, revealing it as an intentional signal of\nawareness during change rather than mere neglect.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790\u8d85\u8fc722.5\u4e07\u6761\u81ea\u8ba4\u6280\u672f\u503a\u52a1\uff08SATD\uff09\u8bc4\u8bba\uff0c\u63ed\u793a\u4e86SATD\u4e3b\u8981\u51fa\u73b0\u5728\u5b9a\u4e49\u3001\u6761\u4ef6\u5224\u65ad\u548c\u5f02\u5e38\u5904\u7406\u9644\u8fd1\u7684\u5185\u8054\u4ee3\u7801\u4e2d\uff0c\u8868\u660e\u5176\u662f\u5f00\u53d1\u8005\u5728\u4ee3\u7801\u53d8\u66f4\u8fc7\u7a0b\u4e2d\u6709\u610f\u8bc6\u7684\u98ce\u9669\u63d0\u793a\uff0c\u800c\u975e\u5355\u7eaf\u7684\u758f\u5ffd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8SATD\u7684\u68c0\u6d4b\u4e0e\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u5374\u8f83\u5c11\u5173\u6ce8\u53d7SATD\u5f71\u54cd\u7684\u5177\u4f53\u6e90\u4ee3\u7801\u3002\u672c\u6587\u65e8\u5728\u5c06SATD\u6ce8\u91ca\u4e0e\u5176\u5468\u56f4\u7684\u4ee3\u7801\u7ed3\u6784\u5173\u8054\u8d77\u6765\uff0c\u4ee5\u66f4\u6df1\u5165\u7406\u89e3\u5176\u51fa\u73b0\u4f4d\u7f6e\u548c\u4e0a\u4e0b\u6587\u3002", "method": "\u5229\u7528\u5305\u542b9000\u591a\u4e2aJava\u5f00\u6e90\u9879\u76ee\u6ce8\u91ca\u7684PENTACET\u6570\u636e\u96c6\uff0c\u5b9a\u91cf\u5206\u6790SATD\u6700\u5e38\u51fa\u73b0\u7684\u4f4d\u7f6e\u53ca\u5176\u5f71\u54cd\u7684\u4ee3\u7801\u7ed3\u6784\u6216\u8bed\u53e5\u7c7b\u578b\u3002", "result": "\u7814\u7a76\u5c06225,000\u591a\u6761SATD\u8bc4\u8bba\u4e0e\u5468\u56f4\u4ee3\u7801\u5173\u8054\uff0c\u53d1\u73b0SATD\u4e3b\u8981\u96c6\u4e2d\u5728\u5b9a\u4e49\u3001\u6761\u4ef6\u8bed\u53e5\u548c\u5f02\u5e38\u5904\u7406\u9644\u8fd1\u7684\u5185\u8054\u4ee3\u7801\u4e2d\u3002", "conclusion": "SATD\u662f\u5f00\u53d1\u8005\u5728\u9762\u4e34\u4e0d\u786e\u5b9a\u6027\u4e0e\u6743\u8861\u65f6\u6709\u610f\u7559\u4e0b\u7684\u4fe1\u53f7\uff0c\u53cd\u6620\u4e86\u5bf9\u6280\u672f\u503a\u52a1\u7684\u4e3b\u52a8\u610f\u8bc6\uff0c\u800c\u975e\u4ee3\u7801\u758f\u5ffd\u3002"}}
{"id": "2511.01757", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01757", "abs": "https://arxiv.org/abs/2511.01757", "authors": ["Shamse Tasnim Cynthia", "Banani Roy"], "title": "Towards LLM-Powered Task-Aware Retrieval of Scientific Workflows for Galaxy", "comment": null, "summary": "Scientific Workflow Management Systems (SWfMSs) such as Galaxy have become\nessential infrastructure in bioinformatics, supporting the design, execution,\nand sharing of complex multi-step analyses. Despite hosting hundreds of\nreusable workflows across domains, Galaxy's current keyword-based retrieval\nsystem offers limited support for semantic query interpretation and often fails\nto surface relevant workflows when exact term matches are absent. To address\nthis gap, we propose a task-aware, two-stage retrieval framework that\nintegrates dense vector search with large language model (LLM)-based reranking.\nOur system first retrieves candidate workflows using state-of-the-art embedding\nmodels and then reranks them using instruction-tuned generative LLMs (GPT-4o,\nMistral-7B) based on semantic task alignment. To support robust evaluation, we\nconstruct a benchmark dataset of Galaxy workflows annotated with semantic\ntopics via BERTopic and synthesize realistic task-oriented queries using LLMs.\nWe conduct a comprehensive comparison of lexical, dense, and reranking models\nusing standard IR metrics, presenting the first systematic evaluation of\nretrieval performance in the Galaxy ecosystem. Results show that our approach\nsignificantly improves top-k accuracy and relevance, particularly for long or\nunder-specified queries. We further integrate our system as a prototype tool\nwithin Galaxy, providing a proof-of-concept for LLM-enhanced workflow search.\nThis work advances the usability and accessibility of scientific workflows,\nespecially for novice users and interdisciplinary researchers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u7a20\u5bc6\u5411\u91cf\u68c0\u7d22\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u5e8f\u7684\u4e24\u9636\u6bb5\u4efb\u52a1\u611f\u77e5\u68c0\u7d22\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347Galaxy\u5e73\u53f0\u4e2d\u79d1\u5b66\u5de5\u4f5c\u6d41\u7684\u8bed\u4e49\u641c\u7d22\u6548\u679c\uff0c\u5c24\u5176\u5728\u5904\u7406\u957f\u6216\u6a21\u7cca\u67e5\u8be2\u65f6\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "Galaxy\u7b49\u79d1\u5b66\u5de5\u4f5c\u6d41\u7ba1\u7406\u7cfb\u7edf\u4f9d\u8d56\u5173\u952e\u8bcd\u68c0\u7d22\uff0c\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u96be\u4ee5\u5728\u65e0\u7cbe\u786e\u672f\u8bed\u5339\u914d\u65f6\u8fd4\u56de\u76f8\u5173\u5de5\u4f5c\u6d41\uff0c\u9650\u5236\u4e86\u7528\u6237\uff08\u5c24\u5176\u662f\u65b0\u624b\u548c\u8de8\u9886\u57df\u7814\u7a76\u8005\uff09\u7684\u4f7f\u7528\u4f53\u9a8c\u3002", "method": "\u9996\u5148\u5229\u7528\u5148\u8fdb\u5d4c\u5165\u6a21\u578b\u8fdb\u884c\u7a20\u5bc6\u5411\u91cf\u68c0\u7d22\u83b7\u53d6\u5019\u9009\u5de5\u4f5c\u6d41\uff0c\u518d\u901a\u8fc7\u6307\u4ee4\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4o\u3001Mistral-7B\uff09\u6839\u636e\u8bed\u4e49\u4efb\u52a1\u5bf9\u9f50\u7a0b\u5ea6\u8fdb\u884c\u91cd\u6392\u5e8f\uff1b\u540c\u65f6\u6784\u5efa\u4e86\u57fa\u4e8eBERTopic\u6807\u6ce8\u7684Galaxy\u5de5\u4f5c\u6d41\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u7528LLM\u5408\u6210\u4efb\u52a1\u5bfc\u5411\u67e5\u8be2\u7528\u4e8e\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728top-k\u51c6\u786e\u7387\u548c\u76f8\u5173\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u8bcd\u6c47\u3001\u7a20\u5bc6\u68c0\u7d22\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u957f\u6216\u63cf\u8ff0\u4e0d\u5145\u5206\u7684\u67e5\u8be2\u4e0a\u6548\u679c\u7a81\u51fa\uff1b\u5e76\u5728Galaxy\u4e2d\u96c6\u6210\u539f\u578b\u5de5\u5177\u9a8c\u8bc1\u4e86\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u5f15\u5165LLM\u589e\u5f3a\u7684\u68c0\u7d22\u673a\u5236\uff0c\u63d0\u5347\u4e86\u79d1\u5b66\u5de5\u4f5c\u6d41\u7cfb\u7edf\u7684\u53ef\u7528\u6027\u4e0e\u53ef\u8bbf\u95ee\u6027\uff0c\u4e3a\u751f\u7269\u4fe1\u606f\u5b66\u7b49\u9886\u57df\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u667a\u80fd\u3001\u66f4\u53cb\u597d\u7684\u5de5\u4f5c\u6d41\u53d1\u73b0\u4f53\u9a8c\u3002"}}
{"id": "2511.01763", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01763", "abs": "https://arxiv.org/abs/2511.01763", "authors": ["Xiaohan Wang", "Yuxin Hu", "Kevin Leach"], "title": "Context-Guided Decompilation: A Step Towards Re-executability", "comment": null, "summary": "Binary decompilation plays an important role in software security analysis,\nreverse engineering, and malware understanding when source code is unavailable.\nHowever, existing decompilation techniques often fail to produce source code\nthat can be successfully recompiled and re-executed, particularly for optimized\nbinaries. Recent advances in large language models (LLMs) have enabled neural\napproaches to decompilation, but the generated code is typically only\nsemantically plausible rather than truly executable, limiting their practical\nreliability. These shortcomings arise from compiler optimizations and the loss\nof semantic cues in compiled code, which LLMs struggle to recover without\ncontextual guidance. To address this challenge, we propose ICL4Decomp, a hybrid\ndecompilation framework that leverages in-context learning (ICL) to guide LLMs\ntoward generating re-executable source code. We evaluate our method across\nmultiple datasets, optimization levels, and compilers, demonstrating around\n40\\% improvement in re-executability over state-of-the-art decompilation\nmethods while maintaining robustness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aICL4Decomp\u7684\u6df7\u5408\u53cd\u7f16\u8bd1\u6846\u67b6\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53ef\u91cd\u65b0\u7f16\u8bd1\u6267\u884c\u7684\u6e90\u4ee3\u7801\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u7f16\u8bd1\u5668\u8bbe\u7f6e\u4e0b\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u91cd\u6267\u884c\u6027\u4e0a\u63d0\u5347\u4e86\u7ea640%\u3002", "motivation": "\u73b0\u6709\u53cd\u7f16\u8bd1\u6280\u672f\uff08\u5305\u62ec\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff09\u96be\u4ee5\u751f\u6210\u53ef\u6210\u529f\u91cd\u65b0\u7f16\u8bd1\u548c\u6267\u884c\u7684\u6e90\u4ee3\u7801\uff0c\u5c24\u5176\u5728\u9762\u5bf9\u7ecf\u8fc7\u4f18\u5316\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u65f6\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u7f16\u8bd1\u5668\u4f18\u5316\u5bfc\u81f4\u7684\u8bed\u4e49\u4fe1\u606f\u4e22\u5931\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u6307\u5bfc\u96be\u4ee5\u6062\u590d\u8fd9\u4e9b\u4fe1\u606f\u3002", "method": "\u63d0\u51faICL4Decomp\u6846\u67b6\uff0c\u7ed3\u5408\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u6765\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u5728\u53cd\u7f16\u8bd1\u8fc7\u7a0b\u4e2d\u751f\u6210\u5177\u5907\u53ef\u91cd\u6267\u884c\u6027\u7684\u6e90\u4ee3\u7801\u3002", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u3001\u4f18\u5316\u7ea7\u522b\u548c\u7f16\u8bd1\u5668\u73af\u5883\u4e0b\u8bc4\u4f30\uff0cICL4Decomp\u76f8\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u7684\u53cd\u7f16\u8bd1\u65b9\u6cd5\u5728\u53ef\u91cd\u6267\u884c\u6027\u65b9\u9762\u63d0\u5347\u4e86\u7ea640%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u4e0a\u4e0b\u6587\u5b66\u4e60\u673a\u5236\uff0cICL4Decomp\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53cd\u7f16\u8bd1\u4efb\u52a1\u4e2d\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u53cd\u7f16\u8bd1\u7ed3\u679c\u7684\u5b9e\u7528\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2511.01850", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01850", "abs": "https://arxiv.org/abs/2511.01850", "authors": ["Jiawei Jin", "Yingxin Su", "Xiaotong Zhu"], "title": "SmartMLOps Studio: Design of an LLM-Integrated IDE with Automated MLOps Pipelines for Model Development and Monitoring", "comment": null, "summary": "The rapid expansion of artificial intelligence and machine learning (ML)\napplications has intensified the demand for integrated environments that unify\nmodel development, deployment, and monitoring. Traditional Integrated\nDevelopment Environments (IDEs) focus primarily on code authoring, lacking\nintelligent support for the full ML lifecycle, while existing MLOps platforms\nremain detached from the coding workflow. To address this gap, this study\nproposes the design of an LLM-Integrated IDE with automated MLOps pipelines\nthat enables continuous model development and monitoring within a single\nenvironment. The proposed system embeds a Large Language Model (LLM) assistant\ncapable of code generation, debugging recommendation, and automatic pipeline\nconfiguration. The backend incorporates automated data validation, feature\nstorage, drift detection, retraining triggers, and CI/CD deployment\norchestration. This framework was implemented in a prototype named SmartMLOps\nStudio and evaluated using classification and forecasting tasks on the UCI\nAdult and M5 datasets. Experimental results demonstrate that SmartMLOps Studio\nreduces pipeline configuration time by 61%, improves experiment reproducibility\nby 45%, and increases drift detection accuracy by 14% compared to traditional\nworkflows. By bridging intelligent code assistance and automated operational\npipelines, this research establishes a novel paradigm for AI engineering -\ntransforming the IDE from a static coding tool into a dynamic, lifecycle-aware\nintelligent platform for scalable and efficient model development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fdIDE\u2014\u2014SmartMLOps Studio\uff0c\u5c06\u4ee3\u7801\u5f00\u53d1\u4e0e\u81ea\u52a8\u5316MLOps\u6d41\u7a0b\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5f00\u53d1\u6548\u7387\u4e0e\u53ef\u590d\u73b0\u6027\u3002", "motivation": "\u4f20\u7edfIDE\u4ec5\u652f\u6301\u4ee3\u7801\u7f16\u5199\uff0c\u7f3a\u4e4f\u5bf9\u673a\u5668\u5b66\u4e60\u5168\u751f\u547d\u5468\u671f\u7684\u667a\u80fd\u652f\u6301\uff1b\u73b0\u6709MLOps\u5e73\u53f0\u53c8\u4e0e\u7f16\u7801\u6d41\u7a0b\u8131\u8282\u3002\u4e3a\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u96c6\u6210LLM\u4e0e\u81ea\u52a8\u5316MLOps\u7684\u7edf\u4e00\u5f00\u53d1\u73af\u5883\u3002", "method": "\u7cfb\u7edf\u5728IDE\u4e2d\u5d4c\u5165LLM\u52a9\u624b\uff0c\u63d0\u4f9b\u4ee3\u7801\u751f\u6210\u3001\u8c03\u8bd5\u5efa\u8bae\u548c\u81ea\u52a8\u6d41\u6c34\u7ebf\u914d\u7f6e\uff1b\u540e\u7aef\u5b9e\u73b0\u81ea\u52a8\u6570\u636e\u9a8c\u8bc1\u3001\u7279\u5f81\u5b58\u50a8\u3001\u6f02\u79fb\u68c0\u6d4b\u3001\u91cd\u8bad\u7ec3\u89e6\u53d1\u53caCI/CD\u90e8\u7f72\u7f16\u6392\uff0c\u5e76\u5728UCI Adult\u548cM5\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSmartMLOps Studio\u76f8\u6bd4\u4f20\u7edf\u5de5\u4f5c\u6d41\uff0c\u6d41\u6c34\u7ebf\u914d\u7f6e\u65f6\u95f4\u51cf\u5c1161%\uff0c\u5b9e\u9a8c\u53ef\u590d\u73b0\u6027\u63d0\u534745%\uff0c\u6f02\u79fb\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u9ad814%\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06IDE\u4ece\u9759\u6001\u7f16\u7801\u5de5\u5177\u8f6c\u53d8\u4e3a\u52a8\u6001\u3001\u5168\u751f\u547d\u5468\u671f\u611f\u77e5\u7684\u667a\u80fd\u5e73\u53f0\uff0c\u4e3aAI\u5de5\u7a0b\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u8303\u5f0f\u3002"}}
