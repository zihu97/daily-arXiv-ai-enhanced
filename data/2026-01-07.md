<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 3]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.SE](#cs.SE) [Total: 20]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Fair Distribution of Digital Payments: Balancing Transaction Flows for Regulatory Compliance](https://arxiv.org/abs/2601.02369)
*Ashlesha Hota,Shashwat Kumar,Daman Deep Singh,Abolfazl Asudeh,Palash Dey,Abhijnan Chakraborty*

Main category: cs.NI

TL;DR: 本文提出一种高效算法DTAS，用于在印度UPI支付系统中公平分配交易量，以避免双头垄断并满足30%交易上限要求。


<details>
  <summary>Details</summary>
Motivation: 解决印度数字支付市场由PhonePe和Google Pay主导所引发的双头垄断问题，确保单一应用不超过30%交易量。

Method: 将问题建模为二分图上的最小边激活流（MEAF）问题，并设计可扩展启发式算法DTAS，利用流量结构与容量复用机制求解。

Result: 在大规模半合成数据上，DTAS能在数秒内逼近最优ILP解，实现快速、公平、高效的交易分配。

Conclusion: DTAS为监管机构提供了一种实用工具，可在最小用户干扰下强制执行交易上限，促进支付生态多样性。

Abstract: The concentration of digital payment transactions in just two UPI apps like PhonePe and Google Pay has raised concerns of duopoly in India s digital financial ecosystem. To address this, the National Payments Corporation of India (NPCI) has mandated that no single UPI app should exceed 30 percent of total transaction volume. Enforcing this cap, however, poses a significant computational challenge: how to redistribute user transactions across apps without causing widespread user inconvenience while maintaining capacity limits? In this paper, we formalize this problem as the Minimum Edge Activation Flow (MEAF) problem on a bipartite network of users and apps, where activating an edge corresponds to a new app installation. The objective is to ensure a feasible flow respecting app capacities while minimizing additional activations. We further prove that Minimum Edge Activation Flow is NP-Complete. To address the computational challenge, we propose scalable heuristics, named Decoupled Two-Stage Allocation Strategy (DTAS), that exploit flow structure and capacity reuse. Experiments on large semi-synthetic transaction network data show that DTAS finds solutions close to the optimal ILP within seconds, offering a fast and practical way to enforce transaction caps fairly and efficiently.

</details>


### [2] [How to Discover Knowledge for FutureG: Contextual RAG and LLM Prompting for O-RAN](https://arxiv.org/abs/2601.02382)
*Nathan Conger,Nathan Scollar,Kemal Davaslioglu,Yalin E. Sagduyu,Sastry Kompella*

Main category: cs.NI

TL;DR: 本文提出一种基于上下文检索增强生成（Contextual RAG）的问答框架，用于应对O-RAN标准快速演进带来的信息检索挑战，提升大语言模型在5G/6G领域问答准确率。


<details>
  <summary>Details</summary>
Motivation: O-RAN规范复杂且频繁更新，人工查阅效率低、易出错，亟需自动化、精准化的问答支持工具。

Method: 采用Contextual RAG方法，利用候选答案引导文档检索与上下文切片，增强LLM对查询的理解与答案生成能力，无需微调模型。

Result: 在ORANBenchmark-13K数据集上，Contextual RAG相比传统RAG和基础提示显著提升准确率，同时保持运行效率与低碳排放。

Conclusion: Contextual RAG是面向动态演进领域的高效、可持续问答方案，适用于O-RAN及更广泛的5G/6G应用场景。

Abstract: We present a retrieval-augmented question answering framework for 5G/6G networks, where the Open Radio Access Network (O-RAN) has become central to disaggregated, virtualized, and AI-driven wireless systems. While O-RAN enables multi-vendor interoperability and cloud-native deployments, its fast-changing specifications and interfaces pose major challenges for researchers and practitioners. Manual navigation of these complex documents is labor-intensive and error-prone, slowing system design, integration, and deployment. To address this challenge, we adopt Contextual Retrieval-Augmented Generation (Contextual RAG), a strategy in which candidate answer choices guide document retrieval and chunk-specific context to improve large language model (LLM) performance. This improvement over traditional RAG achieves more targeted and context-aware retrieval, which improves the relevance of documents passed to the LLM, particularly when the query alone lacks sufficient context for accurate grounding. Our framework is designed for dynamic domains where data evolves rapidly and models must be continuously updated or redeployed, all without requiring LLM fine-tuning. We evaluate this framework using the ORANBenchmark-13K dataset, and compare three LLMs, namely, Llama3.2, Qwen2.5-7B, and Qwen3.0-4B, across both Direct Question Answering (Direct Q&A) and Chain-of-Thought (CoT) prompting strategies. We show that Contextual RAG consistently improves accuracy over standard RAG and base prompting, while maintaining competitive runtime and CO2 emissions. These results highlight the potential of Contextual RAG to serve as a scalable and effective solution for domain-specific Q&A in ORAN and broader 5G/6G environments, enabling more accurate interpretation of evolving standards while preserving efficiency and sustainability.

</details>


### [3] [Eco-WakeLoc: An Energy-Neutral and Cooperative UWB Real-Time Locating System](https://arxiv.org/abs/2601.03171)
*Silvano Cortesi,Lukas Schulthess,Davide Plozza,Christian Vogt,Michele Magno*

Main category: cs.NI

TL;DR: Eco-WakeLoc 实现了厘米级 UWB 室内定位，结合唤醒无线电与太阳能采集，在保证高精度的同时实现能量中性运行。


<details>
  <summary>Details</summary>
Motivation: 解决传统室内定位系统在效率与响应性之间的权衡问题，尤其适用于无 GPS 环境下的移动机器人。

Method: 采用超低功耗唤醒无线电与太阳能采集，按需激活锚点；通过协作定位与 AIMD 能量调度优化性能。

Result: 实测主动标签能耗 3.22mJ/次，被动标签 951μJ/次，锚点 353μJ/次；实际部署平均精度 43cm，年仿真显示每日 2031 次定位且电池余量 >7%。

Conclusion: Eco-WakeLoc 在无需持续基础设施运行的前提下，实现了高精度、可扩展、能量中性的室内定位。

Abstract: Indoor localization systems face a fundamental trade-off between efficiency and responsiveness, which is especially important for emerging use cases such as mobile robots operating in GPS-denied environments. Traditional RTLS either require continuously powered infrastructure, limiting their scalability, or are limited by their responsiveness. This work presents Eco-WakeLoc, designed to achieve centimeter-level UWB localization while remaining energy-neutral by combining ultra-low power wake-up radios (WuRs) with solar energy harvesting. By activating anchor nodes only on demand, the proposed system eliminates constant energy consumption while achieving centimeter-level positioning accuracy. To reduce coordination overhead and improve scalability, Eco-WakeLoc employs cooperative localization where active tags initiate ranging exchanges (trilateration), while passive tags opportunistically reuse these messages for TDOA positioning. An additive-increase/multiplicative-decrease (AIMD)-based energy-aware scheduler adapts localization rates according to the harvested energy, thereby maximizing the overall performance of the sensor network while ensuring long-term energy neutrality. The measured energy consumption is only 3.22mJ per localization for active tags, 951uJ for passive tags, and 353uJ for anchors. Real-world deployment on a quadruped robot with nine anchors confirms the practical feasibility, achieving an average accuracy of 43cm in dynamic indoor environments. Year-long simulations show that tags achieve an average of 2031 localizations per day, retaining over 7% battery capacity after one year -- demonstrating that the RTLS achieves sustained energy-neutral operation. Eco-WakeLoc demonstrates that high-accuracy indoor localization can be achieved at scale without continuous infrastructure operation, combining energy neutrality, cooperative positioning, and adaptive scheduling.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [4] [Proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024)](https://arxiv.org/abs/2601.02898)
*Wim Vanderbauwhede,Lauritz Thamsen,José Cano*

Main category: cs.DC

TL;DR: 这是首届低碳计算国际研讨会（LOCO 2024）的会议论文集。


<details>
  <summary>Details</summary>
Motivation: 推动低碳计算领域的研究与交流。

Method: 通过举办国际研讨会汇集相关研究成果。

Result: 呈现了低碳计算领域的最新进展与讨论。

Conclusion: 为未来低碳计算技术发展奠定基础。

Abstract: This is the proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024).

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [ProSoftArena: Benchmarking Hierarchical Capabilities of Multimodal Agents in Professional Software Environments](https://arxiv.org/abs/2601.02399)
*Jiaxin Ai,Yukang Feng,Fanrui Zhang,Jianwen Sun,Zizhen Li,Chuanhao Li,Yifan Chang,Wenxiao Wu,Ruoxi Wang,Mingliang Zhai,Kaipeng Zhang*

Main category: cs.SE

TL;DR: ProSoftArena是一个专为评估多模态智能体在专业软件环境中表现而设计的基准和平台，涵盖6个学科、13个核心应用的436项真实任务，并引入人机协同评估机制。


<details>
  <summary>Details</summary>
Motivation: 现有基准局限于浏览器和基础桌面应用，无法覆盖科研与工业中主流的专业软件工作流，亟需更贴近实际场景的评估体系。

Method: 构建首个面向专业软件使用的智能体能力层级，搭建可执行的真实计算机环境与基于执行的评估框架，并结合人工参与评估。

Result: 当前最优智能体在L2任务上仅达24.4%成功率，在L3多软件工作流任务中完全失败。

Conclusion: 该研究揭示了当前多模态智能体在专业软件环境中的局限性，为未来更高效的设计原则与能力提升指明方向。

Abstract: Multimodal agents are making rapid progress on general computer-use tasks, yet existing benchmarks remain largely confined to browsers and basic desktop applications, falling short in professional software workflows that dominate real-world scientific and industrial practice. To close this gap, we introduce ProSoftArena, a benchmark and platform specifically for evaluating multimodal agents in professional software environments. We establish the first capability hierarchy tailored to agent use of professional software and construct a benchmark of 436 realistic work and research tasks spanning 6 disciplines and 13 core professional applications. To ensure reliable and reproducible assessment, we build an executable real-computer environment with an execution-based evaluation framework and uniquely incorporate a human-in-the-loop evaluation paradigm. Extensive experiments show that even the best-performing agent attains only a 24.4\% success rate on L2 tasks and completely fails on L3 multi-software workflow. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents in professional software settings. This project is available at: https://prosoftarena.github.io.

</details>


### [6] [The Vibe-Check Protocol: Quantifying Cognitive Offloading in AI Programming](https://arxiv.org/abs/2601.02410)
*Aizierjiang Aiersilan*

Main category: cs.SE

TL;DR: 本文提出Vibe-Check Protocol框架，用以评估‘Vibe Coding’在软件工程教育中的成效与风险。


<details>
  <summary>Details</summary>
Motivation: 探讨AI辅助编程教学是否真正提升学生能力，或仅导致表面掌握与技能退化。

Method: 设计包含三项量化指标的基准框架：冷启动重构、幻觉陷阱检测、可解释性差距。

Result: 该框架可帮助教育者区分AI加速学习与认知外包的不同影响，从而设定合理教学边界。

Conclusion: Vibe Coding在特定情境下有益，但需警惕其可能带来的技术债与浅层能力假象。

Abstract: The integration of Large Language Models (LLMs) into software engineering education has driven the emergence of ``Vibe Coding,'' a paradigm where developers articulate high-level intent through natural language and delegate implementation to AI agents. While proponents argue this approach modernizes pedagogy by emphasizing conceptual design over syntactic memorization, accumulating empirical evidence raises concerns regarding skill retention and deep conceptual understanding. This paper proposes a theoretical framework to investigate the research question: \textit{Is Vibe Coding a better way to learn software engineering?} We posit a divergence in student outcomes between those leveraging AI for acceleration versus those using it for cognitive offloading. To evaluate these educational trade-offs, we propose the \textbf{Vibe-Check Protocol (VCP)}, a systematic benchmarking framework incorporating three quantitative metrics: the \textit{Cold Start Refactor} ($M_{CSR}$) for modeling skill decay; \textit{Hallucination Trap Detection} ($M_{HT}$) based on signal detection theory to evaluate error identification; and the \textit{Explainability Gap} ($E_{gap}$) for quantifying the divergence between code complexity and conceptual comprehension. Through controlled comparisons, VCP aims to provide a quantitative basis for educators to determine the optimal pedagogical boundary: identifying contexts where Vibe Coding fosters genuine mastery and contexts where it introduces hidden technical debt and superficial competence.

</details>


### [7] [Talks that Builds: Exploring Communication factors for the Success of Emerging Professional in Product Teams](https://arxiv.org/abs/2601.02421)
*Nyan Lin Zaw*

Main category: cs.SE

TL;DR: 本研究探讨影响18-27岁新兴职场人士产品团队成功的关键因素，填补现有文献空白。


<details>
  <summary>Details</summary>
Motivation: 现有组织沟通研究多聚焦资深专业人士，忽略年轻群体的特殊性。

Method: 通过实证分析识别对年轻团队更具影响力的新因素，如好奇心、地理位置邻近性、文档和资源获取等。

Result: 发现部分传统因素相关性降低，而新因素显著影响团队生产力与项目成果成功率。

Conclusion: 研究揭示了新兴职场人群团队成功的独特驱动因素，为管理实践提供新视角。

Abstract: This paper recognizes that most organizational communication study focuses on established professionals aged above 27 with more than five years of experience. In contrast, this study examines product teams with younger emerging professionals aged 18-27 and explores which factors influence their success. While some established factors still apply, others become less relevant, and new ones such as curiosity, locational proximity, documentation, access to resources were identified in the study. Overall, this study fills a gap in the literature on how these newer factors shape team productivity and project outcomes based on the success rate of the product the team developed.

</details>


### [8] [WebCoderBench: Benchmarking Web Application Generation with Comprehensive and Interpretable Evaluation Metrics](https://arxiv.org/abs/2601.02430)
*Chenxu Liu,Yingjie Fu,Wei Yang,Ying Zhang,Tao Xie*

Main category: cs.SE

TL;DR: WebCoderBench是首个面向真实用户需求、可泛化且可解释的网页应用生成评测基准，包含1572个真实需求与24项细粒度指标，支持自动化评估并指导LLM针对性优化。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成网页应用缺乏真实需求驱动、无需依赖参考实现的通用评估体系，亟需构建更贴近现实、可解释的评测基准。

Method: 构建包含1572条真实用户需求的数据集，设计9维度24项细粒度评估指标，结合规则与LLM-as-judge方法实现自动化评估，并采用人类偏好加权得出综合评分。

Result: 在12个主流LLM和2个智能体上的实验表明，尚无模型在所有指标上占优，为开发者提供针对性优化空间。

Conclusion: WebCoderBench填补了LLM网页生成领域评测空白，推动模型向更实用、更可控方向演进。

Abstract: Web applications (web apps) have become a key arena for large language models (LLMs) to demonstrate their code generation capabilities and commercial potential. However, building a benchmark for LLM-generated web apps remains challenging due to the need for real-world user requirements, generalizable evaluation metrics without relying on ground-truth implementations or test cases, and interpretable evaluation results. To address these challenges, we introduce WebCoderBench, the first real-world-collected, generalizable, and interpretable benchmark for web app generation. WebCoderBench comprises 1,572 real user requirements, covering diverse modalities and expression styles that reflect realistic user intentions. WebCoderBench provides 24 fine-grained evaluation metrics across 9 perspectives, combining rule-based and LLM-as-a-judge paradigm for fully automated, objective, and general evaluation. Moreover, WebCoderBench adopts human-preference-aligned weights over metrics to yield interpretable overall scores. Experiments across 12 representative LLMs and 2 LLM-based agents show that there exists no dominant model across all evaluation metrics, offering an opportunity for LLM developers to optimize their models in a targeted manner for a more powerful version.

</details>


### [9] [Focus on What Matters: Fisher-Guided Adaptive Multimodal Fusion for Vulnerability Detection](https://arxiv.org/abs/2601.02438)
*Yun Bian,Yi Chen,HaiQuan Wang,ShiHao Li,Zhe Cui*

Main category: cs.SE

TL;DR: TaCCS-DFA 提出基于 Fisher 信息的互补融合框架，优化多模态漏洞检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设多模态必然增益，但序列与图表示常冗余，图质量波动会削弱主模态判别力。

Method: 在线估计低秩 Fisher 子空间，限制跨模态注意力至任务敏感方向，并引入自适应门控抑制噪声传播。

Result: 在 BigVul、Devign 和 ReVeal 上表现优异，CodeT5 骨干下 F1 达 87.80%，较基线提升 6.3%。

Conclusion: TaCCS-DFA 实现更紧风险界，在保持低校准误差与计算开销的同时显著提升检测精度。

Abstract: Software vulnerability detection is a critical task for securing software systems and can be formulated as a binary classification problem: given a code snippet, determine whether it contains a vulnerability. Existing multimodal approaches typically fuse Natural Code Sequence (NCS) representations from pretrained language models with Code Property Graph (CPG) representations from graph neural networks, often under the implicit assumption that adding a modality necessarily yields extra information. In practice, sequence and graph representations can be redundant, and fluctuations in the quality of the graph modality can dilute the discriminative signal of the dominant modality. To address this, we propose TaCCS-DFA, a framework that introduces Fisher information as a geometric measure of how sensitive feature directions are to the classification decision, enabling task-oriented complementary fusion. TaCCS-DFA online estimates a low-rank principal Fisher subspace and restricts cross-modal attention to task-sensitive directions, thereby retrieving structural features from CPG that complement the sequence modality; meanwhile, an adaptive gating mechanism dynamically adjusts the contribution of the graph modality for each sample to suppress noise propagation. Our analysis shows that, under an isotropic perturbation assumption, the proposed mechanism admits a tighter risk bound than conventional full-spectrum attention. Experiments on BigVul, Devign, and ReVeal show that TaCCS-DFA achieves strong performance across multiple backbones. With CodeT5 as the backbone, TaCCS-DFA reaches an F1 score of 87.80\% on the highly imbalanced BigVul dataset, improving over a strong baseline Vul-LMGNNs by 6.3 percentage points while maintaining low calibration error and computational overhead.

</details>


### [10] [The Rise of Agentic Testing: Multi-Agent Systems for Robust Software Quality Assurance](https://arxiv.org/abs/2601.02454)
*Saba Naqvi,Mohammad Baqar,Nawaz Ali Mohammad*

Main category: cs.SE

TL;DR: 本文提出一种多智能体闭环测试框架，通过执行反馈自主优化测试用例，显著提升覆盖率并减少无效测试。


<details>
  <summary>Details</summary>
Motivation: 当前AI测试生成器缺乏执行反馈，导致测试无效或冗余，需构建自修正的自动化测试系统。

Method: 设计三智能体协作框架（生成、执行分析、评审优化），结合沙箱执行、失败报告与迭代修复机制，集成CI/CD管道并利用覆盖率指标强化学习引导优化。

Result: 在微服务应用中实现无效测试减少60%、覆盖率提升30%，大幅降低人工干预。

Conclusion: 多智能体反馈驱动机制可推动软件测试向自主持续学习的质量保障生态演进，支撑高可靠代码库。

Abstract: Software testing has progressed toward intelligent automation, yet current AI-based test generators still suffer from static, single-shot outputs that frequently produce invalid, redundant, or non-executable tests due to the lack of execution aware feedback. This paper introduces an agentic multi-model testing framework a closed-loop, self-correcting system in which a Test Generation Agent, an Execution and Analysis Agent, and a Review and Optimization Agent collaboratively generate, execute, analyze, and refine tests until convergence. By using sandboxed execution, detailed failure reporting, and iterative regeneration or patching of failing tests, the framework autonomously improves test quality and expands coverage. Integrated into a CI/CD-compatible pipeline, it leverages reinforcement signals from coverage metrics and execution outcomes to guide refinement. Empirical evaluations on microservice based applications show up to a 60% reduction in invalid tests, 30% coverage improvement, and significantly reduced human effort compared to single-model baselines demonstrating that multi-agent, feedback-driven loops can evolve software testing into an autonomous, continuously learning quality assurance ecosystem for self-healing, high-reliability codebases.

</details>


### [11] [Enhancing Debugging Skills with AI-Powered Assistance: A Real-Time Tool for Debugging Support](https://arxiv.org/abs/2601.02504)
*Elizaveta Artser,Daniil Karol,Anna Potriasaeva,Aleksei Rostovskii,Katsiaryna Dzialets,Ekaterina Koshchenko,Xiaotian Su,April Yi Wang,Anastasiia Birillo*

Main category: cs.SE

TL;DR: 本文介绍了一种集成于IDE的AI调试助手，通过RAG、程序切片与启发式方法提升调试教学效率。


<details>
  <summary>Details</summary>
Motivation: 调试技能在编程教育中常被忽视，需借助AI工具增强学习体验。

Method: 结合RAG、大语言模型、程序切片与自定义启发式策略，减少LLM调用并提高准确性。

Result: 三层次评估（技术分析、用户体验、课堂测试）验证其教学潜力。

Conclusion: 该工具能有效辅助调试教学，值得在编程课程中推广。

Abstract: Debugging is a crucial skill in programming education and software development, yet it is often overlooked in CS curricula. To address this, we introduce an AI-powered debugging assistant integrated into an IDE. It offers real-time support by analyzing code, suggesting breakpoints, and providing contextual hints. Using RAG with LLMs, program slicing, and custom heuristics, it enhances efficiency by minimizing LLM calls and improving accuracy. A three-level evaluation - technical analysis, UX study, and classroom tests - highlights its potential for teaching debugging.

</details>


### [12] [Green LLM Techniques in Action: How Effective Are Existing Techniques for Improving the Energy Efficiency of LLM-Based Applications in Industry?](https://arxiv.org/abs/2601.02512)
*Pelin Rabia Kuran,Rumbidzai Chitakunye,Vincenzo Stoico,Ilja Heitlager,Justus Bogner*

Main category: cs.SE

TL;DR: 研究通过在工业聊天机器人应用中测试四种优化技术，发现部分方法可大幅降低能耗，但常以牺牲准确性为代价；唯有小大模型协作（NPCC）在显著节能的同时保持性能稳定。


<details>
  <summary>Details</summary>
Motivation: 应对大语言模型部署带来的高能耗问题，填补工业场景下节能技术实证研究的空白。

Method: 选取Prompt优化、量化、批处理和小大模型协作四种技术，在Schuberg Philis公司的聊天机器人上实施八种变体实验，对比基线评估能耗、准确率与响应时间。

Result: Prompt优化与2比特量化最高节能90%，但严重损害准确率；仅NPCC协作方案实现显著节能且不影响其他指标。

Conclusion: 降低LLM应用能耗不难，但兼顾能效与性能仍具挑战，本研究为实际优化提供可行路径。

Abstract: The rapid adoption of large language models (LLMs) has raised concerns about their substantial energy consumption, especially when deployed at industry scale. While several techniques have been proposed to address this, limited empirical evidence exists regarding the effectiveness of applying them to LLM-based industry applications. To fill this gap, we analyzed a chatbot application in an industrial context at Schuberg Philis, a Dutch IT services company. We then selected four techniques, namely Small and Large Model Collaboration, Prompt Optimization, Quantization, and Batching, applied them to the application in eight variations, and then conducted experiments to study their impact on energy consumption, accuracy, and response time compared to the unoptimized baseline.
  Our results show that several techniques, such as Prompt Optimization and 2-bit Quantization, managed to reduce energy use significantly, sometimes by up to 90%. However, these techniques especially impacted accuracy negatively, to a degree that is not acceptable in practice. The only technique that achieved significant and strong energy reductions without harming the other qualities substantially was Small and Large Model Collaboration via Nvidia's Prompt Task and Complexity Classifier (NPCC) with prompt complexity thresholds. This highlights that reducing the energy consumption of LLM-based applications is not difficult in practice. However, improving their energy efficiency, i.e., reducing energy use without harming other qualities, remains challenging. Our study provides practical insights to move towards this goal.

</details>


### [13] [On the Effectiveness of Proposed Techniques to Reduce Energy Consumption in RAG Systems: A Controlled Experiment](https://arxiv.org/abs/2601.02522)
*Zhinuan,Guo,Chushu Gao,Justus Bogner*

Main category: cs.SE

TL;DR: 本研究通过实验评估了五种降低RAG系统能耗的技术，发现调整相似度阈值和减小嵌入尺寸可在不影响准确率的前提下显著节能。


<details>
  <summary>Details</summary>
Motivation: 机器学习日益增长的能耗引发环境可持续性担忧，尤其在RAG系统中缺乏实证研究。

Method: 在合作方构建的类生产RAG系统上，使用CRAG数据集进行200多小时、9种配置的对照实验，评估技术对能耗、延迟与准确率的影响。

Result: 部分技术如提高检索阈值、减小嵌入尺寸、向量索引和BM25S重排序器可节能高达60%，但某些方法（如索引策略）导致准确率下降30%；前两种技术实现零精度损失下的高效节能。

Conclusion: 首次提供RAG系统节能设计的实证指南，为开发者构建可持续应用提供实践依据。

Abstract: The rising energy demands of machine learning (ML), e.g., implemented in popular variants like retrieval-augmented generation (RAG) systems, have raised significant concerns about their environmental sustainability. While previous research has proposed green tactics for ML-enabled systems, their empirical evaluation within RAG systems remains largely unexplored. This study presents a controlled experiment investigating five practical techniques aimed at reducing energy consumption in RAG systems. Using a production-like RAG system developed at our collaboration partner, the Software Improvement Group, we evaluated the impact of these techniques on energy consumption, latency, and accuracy.
  Through a total of 9 configurations spanning over 200 hours of trials using the CRAG dataset, we reveal that techniques such as increasing similarity retrieval thresholds, reducing embedding sizes, applying vector indexing, and using a BM25S reranker can significantly reduce energy usage, up to 60% in some cases. However, several techniques also led to unacceptable accuracy decreases, e.g., by up to 30% for the indexing strategies. Notably, finding an optimal retrieval threshold and reducing embedding size substantially reduced energy consumption and latency with no loss in accuracy, making these two techniques truly energy-efficient. We present the first comprehensive, empirical study on energy-efficient design techniques for RAG systems, providing guidance for developers and researchers aiming to build sustainable RAG applications.

</details>


### [14] [PerspectiveCoach: Exploring LLMs for Developer Reflection](https://arxiv.org/abs/2601.02559)
*Lauren Olson,Emitzá Guzmán,Florian Kunneman*

Main category: cs.SE

TL;DR: PerspectiveCoach是一个由大语言模型驱动的对话工具，旨在帮助开发者通过结构化视角练习，增强对边缘化用户经历的理解与伦理反思。


<details>
  <summary>Details</summary>
Motivation: 软件开发者缺乏有效工具来深入理解边缘群体用户的实际体验，从而影响包容性设计。

Method: 通过18名前端开发者参与的对照实验，结合真实性别骚扰案例，评估PerspectiveCoach在促进伦理推理和用户视角理解方面的作用，并辅以人与人对话研究及文本相似度分析。

Result: 定性分析显示开发者自我意识提升、视角拓宽、伦理表达更细致；文本分析表明多次互动后复述准确性提高，但基线低于人际对话；工具在可用性和相关性上获高评分。

Conclusion: 该工具为支持开发者进行伦理自省提供了探索性设计，并提出增强适应性与多元中心化的实践洞见，有助于构建更具社会响应性的技术。

Abstract: Despite growing awareness of ethical challenges in software development, practitioners still lack structured tools that help them critically engage with the lived experiences of marginalized users. This paper presents PerspectiveCoach, a large language model (LLM)-powered conversational tool designed to guide developers through structured perspective-taking exercises and deepen critical reflection on how software design decisions affect marginalized communities. Through a controlled study with 18 front-end developers (balanced by sex), who interacted with the tool using a real case of online gender-based harassment, we examine how PerspectiveCoach supports ethical reasoning and engagement with user perspectives. Qualitative analysis revealed increased self-awareness, broadened perspectives, and more nuanced ethical articulation, while a complementary human-human study contextualized these findings. Text similarity analyses demonstrated that participants in the human-PerspectiveCoach study improved the fidelity of their restatements over multiple attempts, capturing both surface-level and semantic aspects of user concerns. However, human-PerspectiveCoach's restatements had a lower baseline than the human-human conversations, highlighting contextual differences in impersonal and interpersonal perspective-taking. Across the study, participants rated the tool highly for usability and relevance. This work contributes an exploratory design for LLM-powered end-user perspective-taking that supports critical, ethical self-reflection and offers empirical insights (i.e., enhancing adaptivity, centering plurality) into how such tools can help practitioners build more inclusive and socially responsive technologies.

</details>


### [15] [Compressed code: the hidden effects of quantization and distillation on programming tokens](https://arxiv.org/abs/2601.02563)
*Viacheslav Siniaev,Iaroslav Chelombitko,Aleksey Komissarov*

Main category: cs.SE

TL;DR: 本文研究大型语言模型在代码生成中的分词机制，分析不同优化技术对分词表示和生成质量的影响，并提出冷启动概率分析方法。


<details>
  <summary>Details</summary>
Motivation: 当前对压缩模型中编程语言分词机制的理解尚不充分，需系统性探索以指导实际优化。

Method: 通过词汇分布与关键词覆盖分析编程语言编码方式，引入冷启动概率分析法，并评估量化、蒸馏、缩放与微调等优化技术的影响。

Result: 实验揭示了分词层级行为的关键规律，提供了在多种约束下保持代码生成质量的实证指南。

Conclusion: 本研究深化了对LLM代码生成机理的理论认知，并为生产环境中优化模型的实际部署提供支持。

Abstract: Large Language Models (LLMs) have demonstrated exceptional code generation capabilities, yet their token-level mechanisms remain underexplored, particularly in compressed models. Through systematic analysis of programming language token representations, we characterize how programming languages are encoded in LLM tokenizers by analyzing their vocabulary distribution and keyword coverage patterns. We introduce a novel cold-start probability analysis method that provides insights into model behavior without requiring explicit prompts. Additionally, we present a comprehensive evaluation of how different model optimization techniques - including quantization, distillation, model scaling, and task-specific fine-tuning - affect token-level representations and code generation quality. Our experiments, supported by comprehensive probability distribution analysis and evaluation metrics, reveal critical insights into token-level behavior and provide empirically-validated guidelines for maintaining code generation quality under various optimization constraints. These findings advance both theoretical understanding of LLM code generation and practical implementation of optimized models in production environments.

</details>


### [16] [State of the Quantum Software Engineering Ecosystem](https://arxiv.org/abs/2601.02601)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 本文利用GPT-5分析量子软件工程领域的学术与产业动态，识别活跃机构与成功企业。


<details>
  <summary>Details</summary>
Motivation: 厘清量子软件工程生态现状，聚焦学术界与产业界的成就与创业成果。

Method: 采用GPT-5通过ChatGPT工具分析机构与企业的活跃度及成果表现。

Result: 识别出在同行评审发表或风投融资方面表现突出的机构与公司。

Conclusion: AI大模型可有效辅助新兴科技领域生态调研与趋势识别。

Abstract: We study the current state of the Quantum Software Engineering (QSE) ecosystem, focusing on the achievements, activities, and engagements from academia and industry, with a special focus on successful entrepreneurial endeavors in this arena. Our research methodology is a novel one, featuring the state-of-the-art in Artificial Intelligence (AI), namely Large Language Models (LLMs), especially Generative Pretrained Transformers (GPT). We use one of such models, namely the OpenAI GPT-5 model, through the ChatGPT tool. The goal is to identify institutions and companies that are highly active and have achieved distinguished results in QSE, evidenced by peer-reviewed publications or raised capital in the venture capital market.

</details>


### [17] [TAAF: A Trace Abstraction and Analysis Framework Synergizing Knowledge Graphs and LLMs](https://arxiv.org/abs/2601.02632)
*Alireza Ezaz,Ghazal Khodabandeh,Majid Babaei,Naser Ezzati-Jivan*

Main category: cs.SE

TL;DR: TAAF框架结合时间索引、知识图谱与大语言模型，实现对复杂系统执行轨迹的自然语言查询分析，显著提升准确率。


<details>
  <summary>Details</summary>
Motivation: 现有工具依赖预定义分析或需编写脚本，效率低且易出错，亟需更智能的轨迹分析方法。

Method: 构建时间索引知识图谱表示轨迹实体关系，利用大语言模型解析子图并回答自然语言问题。

Result: 在TraceQA-100基准测试中，TAAF使答案准确率最高提升31.2%，尤其擅长多跳与因果推理任务。

Conclusion: TAAF为下一代轨迹分析工具奠定基础，但仍存在部分局限性需进一步研究。

Abstract: Execution traces are a critical source of information for understanding, debugging, and optimizing complex software systems. However, traces from OS kernels or large-scale applications like Chrome or MySQL are massive and difficult to analyze. Existing tools rely on predefined analyses, and custom insights often require writing domain-specific scripts, which is an error-prone and time-consuming task. This paper introduces TAAF (Trace Abstraction and Analysis Framework), a novel approach that combines time-indexing, knowledge graphs (KGs), and large language models (LLMs) to transform raw trace data into actionable insights. TAAF constructs a time-indexed KG from trace events to capture relationships among entities such as threads, CPUs, and system resources. An LLM then interprets query-specific subgraphs to answer natural-language questions, reducing the need for manual inspection and deep system expertise. To evaluate TAAF, we introduce TraceQA-100, a benchmark of 100 questions grounded in real kernel traces. Experiments across three LLMs and multiple temporal settings show that TAAF improves answer accuracy by up to 31.2%, particularly in multi-hop and causal reasoning tasks. We further analyze where graph-grounded reasoning helps and where limitations remain, offering a foundation for next-generation trace analysis tools.

</details>


### [18] [Enterprise Identity Integration for AI-Assisted Developer Services: Architecture, Implementation, and Case Study](https://arxiv.org/abs/2601.02698)
*Manideep Reddy Chinthareddy*

Main category: cs.SE

TL;DR: 本文提出一种结合OAuth 2.0与OIDC的架构，使MCP支持企业级身份认证，确保AI开发工具在合规前提下安全运行。


<details>
  <summary>Details</summary>
Motivation: 企业需在现有身份治理框架内使用AI辅助开发工具，而MCP缺乏企业SSO集成方案。

Method: 通过VS Code扩展、Python MCP服务器与OIDC IdP构建原型，实现令牌获取、验证及最小权限控制。

Result: 实证显示该架构可行，评估涵盖认证延迟、验证开销、运维考量与AI特有风险。

Conclusion: 本方案为企业部署AI开发助手提供可落地的身份保障与审计能力模式。

Abstract: AI-assisted developer services are increasingly embedded in modern IDEs, yet enterprises must ensure these tools operate within existing identity, access control, and governance requirements. The Model Context Protocol (MCP) enables AI assistants to retrieve structured internal context, but its specification provides only a minimal authorization model and lacks guidance on integrating enterprise SSO. This article presents a practical architecture that incorporates OAuth 2.0 and OpenID Connect (OIDC) into MCP-enabled developer environments. It describes how IDE extensions obtain and present tokens, how MCP servers validate them through an identity provider, and how scopes and claims can enforce least-privilege access. A prototype implementation using Visual Studio Code, a Python-based MCP server, and an OIDC-compliant IdP demonstrates feasibility. A case study evaluates authentication latency, token-validation overhead, operational considerations, and AI-specific risks. The approach provides a deployable pattern for organizations adopting AI-assisted developer tools while maintaining identity assurance and auditability.

</details>


### [19] [Agentic Memory Enhanced Recursive Reasoning for Root Cause Localization in Microservices](https://arxiv.org/abs/2601.02732)
*Lingzhe Zhang,Tong Jia,Yunpeng Zhai,Leyi Pan,Chiming Duan,Minghua He,Mengxi Jia,Ying Li*

Main category: cs.SE

TL;DR: AMER-RCL是一种基于多智能体记忆增强的递归推理框架，用于微服务系统中的根因定位，显著提升准确率与推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法在根因定位中存在浅层推理和缺乏跨告警复用的问题，受SRE专家分析模式启发提出改进方案。

Method: 构建递归推理引擎与智能体记忆机制，实现对告警的递归细化与历史推理复用。

Result: 实验表明AMER-RCL在定位准确率和推理效率上均优于现有最先进方法。

Conclusion: AMER-RCL有效模拟专家分析特性，为复杂微服务系统的根因定位提供高效可靠的新范式。

Abstract: As contemporary microservice systems become increasingly popular and complex-often comprising hundreds or even thousands of fine-grained, interdependent subsystems-they are experiencing more frequent failures. Ensuring system reliability thus demands accurate root cause localization. While many traditional graph-based and deep learning approaches have been explored for this task, they often rely heavily on pre-defined schemas that struggle to adapt to evolving operational contexts. Consequently, a number of LLM-based methods have recently been proposed. However, these methods still face two major limitations: shallow, symptom-centric reasoning that undermines accuracy, and a lack of cross-alert reuse that leads to redundant reasoning and high latency. In this paper, we conduct a comprehensive study of how Site Reliability Engineers (SREs) localize the root causes of failures, drawing insights from professionals across multiple organizations. Our investigation reveals that expert root cause analysis exhibits three key characteristics: recursiveness, multi-dimensional expansion, and cross-modal reasoning. Motivated by these findings, we introduce AMER-RCL, an agentic memory enhanced recursive reasoning framework for root cause localization in microservices. AMER-RCL employs the Recursive Reasoning RCL engine, a multi-agent framework that performs recursive reasoning on each alert to progressively refine candidate causes, while Agentic Memory incrementally accumulates and reuses reasoning from prior alerts within a time window to reduce redundant exploration and lower inference latency. Experimental results demonstrate that AMER-RCL consistently outperforms state-of-the-art methods in both localization accuracy and inference efficiency.

</details>


### [20] [Hypothesize-Then-Verify: Speculative Root Cause Analysis for Microservices with Pathwise Parallelism](https://arxiv.org/abs/2601.02736)
*Lingzhe Zhang,Tong Jia,Yunpeng Zhai,Leyi Pan,Chiming Duan,Minghua He,Pei Xiao,Ying Li*

Main category: cs.SE

TL;DR: SpecRCA是一种用于微服务系统的推测性根因分析框架，采用“假设-验证”范式，在保证高准确率的同时显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的根因分析方法存在探索多样性不足和推理速度慢的问题，限制了其在复杂微服务环境中的实用性。

Method: 提出SpecRCA框架，包含快速生成候选根因的假设起草模块和并行验证这些假设的根因验证器。

Result: 在AIOps 2022数据集上的初步实验表明，SpecRCA在准确性和效率上均优于现有方法。

Conclusion: SpecRCA为复杂微服务系统提供了一种可扩展且可解释的高效根因分析解决方案。

Abstract: Microservice systems have become the backbone of cloud-native enterprise applications due to their resource elasticity, loosely coupled architecture, and lightweight deployment. Yet, the intrinsic complexity and dynamic runtime interactions of such systems inevitably give rise to anomalies. Ensuring system reliability therefore hinges on effective root cause analysis (RCA), which entails not only localizing the source of anomalies but also characterizing the underlying failures in a timely and interpretable manner. Recent advances in intelligent RCA techniques, particularly those powered by large language models (LLMs), have demonstrated promising capabilities, as LLMs reduce reliance on handcrafted features while offering cross-platform adaptability, task generalization, and flexibility. However, existing LLM-based methods still suffer from two critical limitations: (a) limited exploration diversity, which undermines accuracy, and (b) heavy dependence on large-scale LLMs, which results in slow inference. To overcome these challenges, we propose SpecRCA, a speculative root cause analysis framework for microservices that adopts a \textit{hypothesize-then-verify} paradigm. SpecRCA first leverages a hypothesis drafting module to rapidly generate candidate root causes, and then employs a parallel root cause verifier to efficiently validate them. Preliminary experiments on the AIOps 2022 dataset demonstrate that SpecRCA achieves superior accuracy and efficiency compared to existing approaches, highlighting its potential as a practical solution for scalable and interpretable RCA in complex microservice environments.

</details>


### [21] [CodeMEM: AST-Guided Adaptive Memory for Repository-Level Iterative Code Generation](https://arxiv.org/abs/2601.02868)
*Peiding Wang,Li Zhang,Fang Liu,Chongyang Tao,Yinghao Zhu*

Main category: cs.SE

TL;DR: CodeMEM是一种基于AST的动态内存管理系统，用于提升仓库级迭代代码生成的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法因自然语言为中心的表示方式，在保存和更新仓库上下文时存在局限，导致认知负担增加和错误重现。

Method: CodeMEM包含代码上下文内存和代码会话内存两个组件，前者通过AST引导的LLM操作动态维护仓库上下文，后者构建以代码为中心的交互历史表示并检测缓解遗忘。

Result: 在CodeIF-Bench和CoderEval基准测试中，CodeMEM在指令遵循方面分别提升12.2%（当前轮次）和11.5%（会话级别），减少2-3轮交互，同时保持推理延迟和令牌效率。

Conclusion: CodeMEM有效解决了仓库级代码生成中的上下文管理和遗忘问题，实现了更高效、准确的交互式协作。

Abstract: Large language models (LLMs) substantially enhance developer productivity in repository-level code generation through interactive collaboration. However, as interactions progress, repository context must be continuously preserved and updated to integrate newly validated information. Meanwhile, the expanding session history increases cognitive burden, often leading to forgetting and the reintroduction of previously resolved errors. Existing memory management approaches show promise but remain limited by natural language-centric representations. To overcome these limitations, we propose CodeMEM, an AST-guided dynamic memory management system tailored for repository-level iterative code generation. Specifically, CodeMEM introduces the Code Context Memory component that dynamically maintains and updates repository context through AST-guided LLM operations, along with the Code Session Memory that constructs a code-centric representation of interaction history and explicitly detects and mitigates forgetting through AST-based analysis. Experimental results on the instruction-following benchmark CodeIF-Bench and the code generation benchmark CoderEval demonstrate that CodeMEM achieves state-of-the-art performance, improving instruction following by 12.2% for the current turn and 11.5% for the session level, and reducing interaction rounds by 2-3, while maintaining competitive inference latency and token efficiency.

</details>


### [22] [Few-shot learning for security bug report identification](https://arxiv.org/abs/2601.02971)
*Muhammad Laiq*

Main category: cs.SE

TL;DR: 本文提出基于SetFit的少样本学习方法，以少量标注数据高效识别安全漏洞报告，性能优于传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 安全漏洞报告需快速识别以降低风险，但实际中标注数据稀缺导致传统模型效果不佳。

Method: 采用SetFit框架，结合句子变换器、对比学习与参数高效微调，在小规模标注数据上训练分类模型。

Result: 在多个数据集上AUC最高达0.865，全面优于传统机器学习基线方法。

Conclusion: SetFit少样本学习是识别安全漏洞报告的有效替代方案，尤其适用于标注数据稀缺场景。

Abstract: Security bug reports require prompt identification to minimize the window of vulnerability in software systems. Traditional machine learning (ML) techniques for classifying bug reports to identify security bug reports rely heavily on large amounts of labeled data. However, datasets for security bug reports are often scarce in practice, leading to poor model performance and limited applicability in real-world settings. In this study, we propose a few-shot learning-based technique to effectively identify security bug reports using limited labeled data. We employ SetFit, a state-of-the-art few-shot learning framework that combines sentence transformers with contrastive learning and parameter-efficient fine-tuning. The model is trained on a small labeled dataset of bug reports and is evaluated on its ability to classify these reports as either security-related or non-security-related. Our approach achieves an AUC of 0.865, at best, outperforming traditional ML techniques (baselines) for all of the evaluated datasets. This highlights the potential of SetFit to effectively identify security bug reports. SetFit-based few-shot learning offers a promising alternative to traditional ML techniques to identify security bug reports. The approach enables efficient model development with minimal annotation effort, making it highly suitable for scenarios where labeled data is scarce.

</details>


### [23] [A Dataset of Low-Rated Applications from the Amazon Appstore for User Feedback Analysis](https://arxiv.org/abs/2601.03009)
*Nek Dil Khan,Javed Ali Khan,Darvesh Khan,Jianqiang Li,Mumrez Khan,Shah Fahad Khan*

Main category: cs.SE

TL;DR: 本研究提出一个从亚马逊应用商店64款低分应用中提取的包含79,821条用户评论的新数据集，其中6000条评论经人工标注归类为六大问题类别，旨在支持基于机器学习的用户反馈自动分类，助力软件质量改进。


<details>
  <summary>Details</summary>
Motivation: 低分应用常被忽视，但其用户反馈蕴含宝贵洞察，可用于揭示影响用户体验的关键问题并指导软件优化。

Method: 从亚马逊应用商店收集低分应用的用户评论，构建原始数据集，并对其中6000条评论进行人工标注，划分为六类常见问题。

Result: 成功构建并公开发布标注与原始数据集，为研究人员和开发者提供理解低分应用常见问题、开发自动化分类模型的重要资源。

Conclusion: 该数据集为基于用户反馈的数据驱动型软件质量改进奠定基础，并支持探索缺失功能、讽刺语气与情绪等深层演化活动。

Abstract: In todays digital landscape, end-user feedback plays a crucial role in the evolution of software applications, particularly in addressing issues that hinder user experience. While much research has focused on high-rated applications, low-rated applications often remain unexplored, despite their potential to reveal valuable insights. This study introduces a novel dataset curated from 64 low-rated applications sourced from the Amazon Software Appstore (ASA), containing 79,821 user reviews. The dataset is designed to capture the most frequent issues identified by users, which are critical for improving software quality. To further enhance the dataset utility, a subset of 6000 reviews was manually annotated to classify them into six district issue categories: user interface (UI) and user experience (UX), functionality and features, compatibility and device specificity, performance and stability, customer support and responsiveness, and security and privacy issues. This annotated dataset is a valuable resource for developing machine learning-based approaches aiming to automate the classification of user feedback into various issue types. Making both the annotated and raw datasets publicly available provides researchers and developers with a crucial tool to understand common issues in low-rated apps and inform software improvements. The comprehensive analysis and availability of this dataset lay the groundwork for data-derived solutions to improve software quality based on user feedback. Additionally, the dataset can provide opportunities for software vendors and researchers to explore various software evolution-related activities, including frequently missing features, sarcasm, and associated emotions, which will help better understand the reasons for comparatively low app ratings.

</details>


### [24] [NavAI: A Generalizable LLM Framework for Navigation Tasks in Virtual Reality Environments](https://arxiv.org/abs/2601.03251)
*Xue Qin,Matthew DiGiovanni*

Main category: cs.SE

TL;DR: NavAI是一个基于大语言模型的通用导航框架，适用于多种VR环境中的目标导向和探索任务。


<details>
  <summary>Details</summary>
Motivation: 现有技术无法直接应用于沉浸式VR环境中的导航任务，因此需要一种新的解决方案。

Method: 提出NavAI框架，利用大语言模型支持基础动作与复杂目标导向任务，并在三种VR环境中进行评估。

Result: NavAI在目标导向任务中达到89%的成功率，但在动态目标评估场景中仍存在局限。

Conclusion: NavAI展示了在VR导航中的高准确性，同时指出了完全依赖LLM的不足，并为未来研究提供了方向。

Abstract: Navigation is one of the fundamental tasks for automated exploration in Virtual Reality (VR). Existing technologies primarily focus on path optimization in 360-degree image datasets and 3D simulators, which cannot be directly applied to immersive VR environments. To address this gap, we present NavAI, a generalizable large language model (LLM)-based navigation framework that supports both basic actions and complex goal-directed tasks across diverse VR applications. We evaluate NavAI in three distinct VR environments through goal-oriented and exploratory tasks. Results show that it achieves high accuracy, with an 89% success rate in goal-oriented tasks. Our analysis also highlights current limitations of relying entirely on LLMs, particularly in scenarios that require dynamic goal assessment. Finally, we discuss the limitations observed during the experiments and offer insights for future research directions.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [25] [Stigmergic Swarming Agents for Fast Subgraph Isomorphism](https://arxiv.org/abs/2601.02449)
*H. Van Dyke Parunak*

Main category: cs.MA

TL;DR: ASSIST是一种受蚁群优化启发的近似算法，用于解决最大部分子图同构问题，其时间复杂度在查询图规模上线性、数据图规模上恒定。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理最大部分子图同构问题时计算复杂度过高，尤其当图规模增大时效率低下，亟需更高效的启发式算法。

Method: 提出ASSIST算法，先通过节点匹配（peering）预处理，再利用类似蚁群优化的迭代机制进行子图搜索，支持灵活匹配场景。

Result: ASSIST在查询阶段时间复杂度为O(q·log(d))，主搜索阶段复杂度为线性于查询图大小、与数据图大小无关，优于现有O(d²)启发式方法。

Conclusion: ASSIST不仅效率更高，还可扩展支持时序边、模糊匹配和缺失节点/边等复杂匹配需求，具有较强实用性。

Abstract: Maximum partial subgraph isomorphism compares two graphs (nodes joined by edges) to find a largest common subgraph. A common use case, for graphs with labeled nodes, seeks to find instances of a \textit{query} graph with $q$ nodes in a (typically larger) \textit{data} graph with $d$ nodes. The problem is NP-complete, and naïve solutions are exponential in $q + d$. The fastest current heuristic has complexity $O(d^2)$. This paper outlines ASSIST (Approximate Swarming Subgraph Isomorphism through Stigmergy), inspired by the ant colony optimization approach to the traveling salesperson. After peering (identifying matching individual nodes in query and data) in time $O(q\cdot log(d))$, the time required for ASSIST's iterative subgraph search, the combinatorially complex part of the problem, is linear in query size and constant in data size. ASSIST can be extended to support matching problems (such as temporally ordered edges, inexact matches, and missing nodes or edges in the data graph) that frustrate other heuristics.

</details>


### [26] [Modellierung und Simulation der Dynamik von Fussgängerströmen](https://arxiv.org/abs/2601.02526)
*Péter Molnár*

Main category: cs.MA

TL;DR: 本文基于社会力理论构建行人流微观模型，用于基础设施设计与社会学理论验证，揭示了个体简单行为如何自组织形成复杂集体模式，并提出优化建筑布局的进化算法。


<details>
  <summary>Details</summary>
Motivation: 开发现实可行的行人流模型以辅助行人友好型基础设施设计，并通过数据验证社会学理论。

Method: 采用社会力模型描述行人行为，结合进化算法优化建筑布局，集成决策模型与学习机制改进避障与路径选择，并分析路径系统负载分布。

Result: 模型成功再现自组织路径结构，揭示建筑几何形态对行人流性能的显著影响，且通过减少可行走区域反而提升效率；同时实现路径系统最小绕行与成本优化。

Conclusion: 个体遵循简单规则即可涌现出复杂的集体行为，该模型为行人设施设计与社会动力学研究提供了有效工具。

Abstract: This work presents a microscopic model to describe pedestrian flows based on the social force theory. The aim of this study is twofold: (1) developing a realistic model that can be used as a tool for designing pedestrian-friendly infrastructure, and (2) verifying a social science theory using a model with sufficient data. The investigation of the pedestrian model shows that despite simple individual behavior patterns, complex spatial and temporal structures emerge through the interactions in pedestrian flows. Collective behavior emerges from individuals following two basic rules: (1) moving directly towards their goal at a certain speed, and (2) maintaining a distance to other pedestrians and obstacles. This self-organized collective behavior manifests itself as trails that are formed by pedestrians moving in one direction. Furthermore, strong dependencies of the properties of pedestrian flows on geometric forms of buildings are shown, and the influence of geometric changes on performance characteristics is investigated. An example demonstrates how efficiency can be increased by reducing walkable areas. This work also presents an evolutionary algorithm for optimizing building layouts based on the social force model. Additionally, a decision-making model is integrated to describe alternative goal selection, and adaptation and learning capabilities are included to improve pedestrian avoidance behavior and decision strategies based on accumulated experience. A method for determining load distributions in individual sections of a path system considering subjective selection criteria is also developed. Finally, a model that describes the self-organization of path systems with minimal detours is presented, similar to natural transport networks where total length and material costs are optimized.

</details>
