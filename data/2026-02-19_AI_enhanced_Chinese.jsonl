{"id": "2602.16130", "categories": ["cs.NI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.16130", "abs": "https://arxiv.org/abs/2602.16130", "authors": ["Zibin Lin", "Taotao Wang", "Shengli Zhang", "Long Shi", "Shui Yu"], "title": "Managing Credible Anonymous Identities in Web 3.0 Services: A Scalable On-Chain Admission Framework with Recursive Proof Aggregation", "comment": "15 pages, 9 figures", "summary": "Open Web 3.0 platforms increasingly operate as \\emph{service ecosystems} (e.g., DeFi, DAOs, and decentralized social applications) where \\emph{admission control} and \\emph{account provisioning} must be delivered as an always-on service under bursty demand. Service operators face a fundamental tension: enforcing Sybil resistance (one-person-one-account) while preserving user privacy, yet keeping on-chain verification cost and admission latency predictable at scale. Existing credential-based ZK admission approaches typically require per-request on-chain verification, making the provisioning cost grow with the number of concurrent joiners. We present \\textbf{ZK-AMS}, a scalable admission and provisioning layer that bridges real-world \\emph{Personhood Credentials} to anonymous on-chain service accounts. ZK-AMS combines (i) zero-knowledge credential validation, (ii) a \\emph{permissionless} batch submitter model, and (iii) a decentralized, privacy-preserving folding pipeline that uses Nova-style recursive aggregation together with multi-key homomorphic encryption, enabling batch settlement with \\emph{constant} on-chain verification per batch. We implement ZK-AMS end-to-end on an Ethereum testbed and evaluate admission throughput, end-to-end latency, and gas consumption. Results show stable verification cost across batch sizes and substantially improved admission efficiency over non-recursive baselines, providing a practical and cost-predictable admission service for large-scale Web 3.0 communities.", "AI": {"tldr": "\u63d0\u51faZK-AMS\u7cfb\u7edf\uff0c\u901a\u8fc7\u96f6\u77e5\u8bc6\u8bc1\u660e\u548c\u9012\u5f52\u805a\u5408\u5b9e\u73b0Web 3.0\u5e73\u53f0\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u51c6\u5165\u63a7\u5236\u3002", "motivation": "\u89e3\u51b3Web 3.0\u5e73\u53f0\u5728\u7a81\u53d1\u6d41\u91cf\u4e0b\u96be\u4ee5\u540c\u65f6\u4fdd\u8bc1\u5973\u5deb\u653b\u51fb\u9632\u5fa1\u3001\u7528\u6237\u9690\u79c1\u548c\u7a33\u5b9a\u4e0a\u94fe\u6210\u672c\u7684\u95ee\u9898\uff0c\u907f\u514d\u73b0\u6709\u65b9\u6848\u6210\u672c\u968f\u7528\u6237\u6570\u91cf\u7ebf\u6027\u589e\u957f\u3002", "method": "\u7ed3\u5408\u96f6\u77e5\u8bc6\u51ed\u8bc1\u9a8c\u8bc1\u3001\u65e0\u6743\u9650\u6279\u6b21\u63d0\u4ea4\u6a21\u578b\uff0c\u4ee5\u53ca\u57fa\u4e8eNova\u9012\u5f52\u805a\u5408\u4e0e\u591a\u65b9\u540c\u6001\u52a0\u5bc6\u7684\u9690\u79c1\u4fdd\u62a4\u6298\u53e0\u7ba1\u9053\uff0c\u5b9e\u73b0\u6052\u5b9a\u6210\u672c\u7684\u6279\u91cf\u9a8c\u8bc1\u3002", "result": "\u4ee5\u592a\u574a\u6d4b\u8bd5\u663e\u793a\uff1a\u6279\u91cf\u5904\u7406\u4e0b\u9a8c\u8bc1\u6210\u672c\u7a33\u5b9a\uff0c\u51c6\u5165\u541e\u5410\u91cf\u663e\u8457\u63d0\u5347\uff0c\u5ef6\u8fdf\u4e0e\u71c3\u6599\u6d88\u8017\u4f18\u4e8e\u975e\u9012\u5f52\u57fa\u7ebf\u3002", "conclusion": "\u4e3a\u5927\u89c4\u6a21Web 3.0\u793e\u533a\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u53ef\u9884\u6d4b\u3001\u9ad8\u6548\u5b9e\u7528\u7684\u533f\u540d\u8d26\u6237\u51c6\u5165\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2602.16163", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.16163", "abs": "https://arxiv.org/abs/2602.16163", "authors": ["Md Sharif Hossen", "Cole Dickerson", "Ozgur Ozdemir", "Anil Gurses", "Mohamed Rabeek Sarbudeen", "Thomas Zajkowski", "Ahmed Manavi Alam", "Everett Tucker", "William Bjorndahl", "Fred Solis", "Sadaf Javed", "Anirudh Kamath", "Xiangyao Tang", "Joarder Jafor Sadique", "Kevin Liu Hermstein", "Kaies Al Mahmud", "Jose Angel Sanchez Viloria", "Skyler Hawkins", "Yuqing Cui", "Annoy Dey", "Yuchen Liu", "Ali Gurbuz", "Joseph Camp", "Rizwan Ahmad", "Jacobus van der Merwe", "Ahmed Ibrahim Mohamed", "Gil Zussman", "Mehmet Kurum", "Namuduri Kamesh", "Zhangyu Guan", "Dimitris Pados", "George Skilvanitis", "Ismail Guvenc", "Mihail Sichitiu", "Magreth Mushi", "Rudra Dutta"], "title": "Collection: UAV-Based Wireless Multi-modal Measurements from AERPAW Autonomous Data Mule (AADM) Challenge in Digital Twin and Real-World Environments", "comment": "10 pages, 12 figures", "summary": "In this work, we present an unmanned aerial vehicle (UAV) wireless dataset collected as part of the AERPAW Autonomous Aerial Data Mule (AADM) challenge, organized by the NSF Aerial Experimentation and Research Platform for Advanced Wireless (AERPAW) project. The AADM challenge was the second competition in which an autonomous UAV acted as a data mule, where the UAV downloaded data from multiple base stations (BSs) in a dynamic wireless environment. Participating teams designed flight control and decision-making algorithms for choosing which BSs to communicate with and how to plan flight trajectories to maximize data download within a mission completion time. The competition was conducted in two stages: Stage 1 involved development and experimentation using a digital twin (DT) environment, and in Stage 2, the final test run was conducted on the outdoor testbed. The total score for each team was compiled from both stages. The resulting dataset includes link quality and data download measurements, both in DT and physical environments. Along with the USRP measurements used in the contest, the dataset also includes UAV telemetry, Keysight RF sensors position estimates, link quality measurements from LoRa receivers, and Fortem radar measurements. It supports reproducible research on autonomous UAV networking, multi-cell association and scheduling, air-to-ground propagation modeling, DT-to-real-world transfer learning, and integrated sensing and communication, which serves as a benchmark for future autonomous wireless experimentation.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.16345", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.16345", "abs": "https://arxiv.org/abs/2602.16345", "authors": ["Leonardo Spampinato", "Lorenzo Mario Amorosa", "Enrico Testi", "Chiara Buratti", "Riccardo Marini"], "title": "Multi-Agent Meta-Advisor for UAV Fleet Trajectory Design in Vehicular Networks", "comment": null, "summary": "Future vehicular networks require continuous connectivity to serve highly mobile users in urban environments. To mitigate the coverage limitations of fixed terrestrial macro base stations (MBS) under non line-of-sight (NLoS) conditions, fleets of unmanned aerial base stations (UABSs) can be deployed as aerial base stations, dynamically repositioning to track vehicular users and traffic hotspots in coordination with the terrestrial network. This paper addresses cooperative multi-agent trajectory design under different service areas and takeoff configurations, where rapid and safe adaptation across scenarios is essential. We formulate the problem as a multi-task decentralized partially observable Markov decision process and solve it using centralized training and decentralized execution with double dueling deep Q-network (3DQN), enabling online training for real-world deployments. However, efficient exploration remains a bottleneck, with conventional strategies like $\u03b5$-greedy requiring careful tuning. To overcome this, we propose the multi-agent meta-advisor with advisor override (MAMO). This framework guides agent exploration through a meta-policy learned jointly across tasks. It uses a dynamic override mechanism that allows agents to reject misaligned guidance when the advisor fails to generalize to a specific scenario. Simulation results across three realistic urban scenarios and multiple takeoff configurations show that MAMO achieves faster convergence and higher returns than tuned $\u03b5$-greedy baselines, outperforming both an advisor-only ablation and a single generalized policy. Finally, we demonstrate that the learned UABS fleet significantly improves network performance compared to deployments without aerial support.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.16024", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.16024", "abs": "https://arxiv.org/abs/2602.16024", "authors": ["R. Kanda", "H. L. Blevec", "N. Onizawa", "M. Leonardon", "V. Gripon", "T. Hanyu"], "title": "Bit-Width-Aware Design Environment for Few-Shot Learning on Edge AI Hardware", "comment": null, "summary": "In this study, we propose an implementation methodology of real-time few-shot learning on tiny FPGA SoCs such as the PYNQ-Z1 board with arbitrary fixed-point bit-widths. Tensil-based conventional design environments limited hardware implementations to fixed-point bit-widths of 16 or 32 bits. To address this, we adopt the FINN framework, enabling implementations with arbitrary bit-widths. Several customizations and minor adjustments are made, including: 1.Optimization of Transpose nodes to resolve data format mismatches, 2.Addition of handling for converting the final reduce mean operation to Global Average Pooling (GAP). These adjustments allow us to reduce the bit-width while maintaining the same accuracy as the conventional realization, and achieve approximately twice the throughput in evaluations using CIFAR-10 dataset.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u5728PYNQ-Z1\u7b49\u5fae\u578bFPGA SoC\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u5c11\u6837\u672c\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u652f\u6301\u4efb\u610f\u4f4d\u5bbd\u56fa\u5b9a\u70b9\u8fd0\u7b97\u3002", "motivation": "\u4f20\u7edfTensil\u8bbe\u8ba1\u5c40\u9650\u4e8e16\u621632\u4f4d\u56fa\u5b9a\u70b9\u4f4d\u5bbd\uff0c\u9700\u7075\u6d3b\u964d\u4f4e\u4f4d\u5bbd\u4ee5\u63d0\u9ad8\u786c\u4ef6\u6548\u7387\u3002", "method": "\u91c7\u7528FINN\u6846\u67b6\uff0c\u4f18\u5316\u8f6c\u7f6e\u8282\u70b9\u89e3\u51b3\u6570\u636e\u683c\u5f0f\u5931\u914d\uff0c\u5e76\u6dfb\u52a0\u5904\u7406\u4ee5\u5c06reduce\u64cd\u4f5c\u8f6c\u4e3a\u5168\u5c40\u5e73\u5747\u6c60\u5316\u3002", "result": "\u5728CIFAR-10\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u524a\u51cf\u4f4d\u5bbd\uff0c\u63a8\u7406\u541e\u5410\u91cf\u63d0\u5347\u7ea6\u4e24\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f18\u5316\u4e86FPGA\u63a8\u7406\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u9ad8\u6548\u8d44\u6e90\u5229\u7528\u4e0e\u9ad8\u7cbe\u5ea6\u5e73\u8861\u3002"}}
{"id": "2602.15968", "categories": ["cs.SE", "cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.15968", "abs": "https://arxiv.org/abs/2602.15968", "authors": ["Pedro Reynolds-Cu\u00e9llar", "Marisol Wong-Villacres", "Adriana Alvarado Garcia", "Heila Precel"], "title": "From Reflection to Repair: A Scoping Review of Dataset Documentation Tools", "comment": "to be published at the CHI conference on Human Factors in Computing Systems", "summary": "Dataset documentation is widely recognized as essential for the responsible development of automated systems. Despite growing efforts to support documentation through different kinds of artifacts, little is known about the motivations shaping documentation tool design or the factors hindering their adoption. We present a systematic review supported by mixed-methods analysis of 59 dataset documentation publications to examine the motivations behind building documentation tools, how authors conceptualize documentation practices, and how these tools connect to existing systems, regulations, and cultural norms. Our analysis shows four persistent patterns in dataset documentation conceptualization that potentially impede adoption and standardization: unclear operationalizations of documentation's value, decontextualized designs, unaddressed labor demands, and a tendency to treat integration as future work. Building on these findings, we propose a shift in Responsible AI tool design toward institutional rather than individual solutions, and outline actions the HCI community can take to enable sustainable documentation practices.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.15995", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.15995", "abs": "https://arxiv.org/abs/2602.15995", "authors": ["Xiang Fu", "Shiman Meng", "Weiping Zhang", "Luanzheng Guo", "Kento Sato", "Dong H. Ahn", "Ignacio Laguna", "Gregory L. Lee", "Martin Schulz"], "title": "Distributed Order Recording Techniques for Efficient Record-and-Replay of Multi-threaded Programs", "comment": "IEEE Cluster 2024", "summary": "After all these years and all these other shared memory programming frameworks, OpenMP is still the most popular one. However, its greater levels of non-deterministic execution makes debugging and testing more challenging. The ability to record and deterministically replay the program execution is key to address this challenge. However, scalably replaying OpenMP programs is still an unresolved problem. In this paper, we propose two novel techniques that use Distributed Clock (DC) and Distributed Epoch (DE) recording schemes to eliminate excessive thread synchronization for OpenMP record and replay. Our evaluation on representative HPC applications with ReOMP, which we used to realize DC and DE recording, shows that our approach is 2-5x more efficient than traditional approaches that synchronize on every shared-memory access. Furthermore, we demonstrate that our approach can be easily combined with MPI-level replay tools to replay non-trivial MPI+OpenMP applications. We achieve this by integrating \\toolname into ReMPI, an existing scalable MPI record-and-replay tool, with only a small MPI-scale-independent runtime overhead.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.15983", "categories": ["cs.SE", "cs.AI", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.15983", "abs": "https://arxiv.org/abs/2602.15983", "authors": ["Junbo Jacob Lian", "Yujun Sun", "Huiling Chen", "Chaoyu Zhang", "Chung-Piaw Teo"], "title": "ReLoop: Structured Modeling and Behavioral Verification for Reliable LLM-Based Optimization", "comment": "Code and benchmark: \\url{https://github.com/junbolian/ReLoop}", "summary": "Large language models (LLMs) can translate natural language into optimization code, but silent failures pose a critical risk: code that executes and returns solver-feasible solutions may encode semantically incorrect formulations, creating a feasibility-correctness gap of up to 90 percentage points on compositional problems. We introduce ReLoop, addressing silent failures from two complementary directions. Structured generation decomposes code production into a four-stage reasoning chain (understand, formalize, synthesize, verify) that mirrors expert modeling practice, with explicit variable-type reasoning and self-verification to prevent formulation errors at their source. Behavioral verification detects errors that survive generation by testing whether the formulation responds correctly to solver-based parameter perturbation, without requiring ground truth -- an external semantic signal that bypasses the self-consistency problem inherent in LLM-based code review. The two mechanisms are complementary: structured generation dominates on complex compositional problems, while behavioral verification becomes the largest single contributor on problems with localized formulation defects. Together with execution recovery via IIS-enhanced diagnostics, ReLoop raises correctness from 22.6% to 31.1% and execution from 72.1% to 100.0% on the strongest model, with consistent gains across five models spanning three paradigms (foundation, SFT, RL) and three benchmarks. We additionally release RetailOpt-190, 190 compositional retail optimization scenarios targeting the multi-constraint interactions where LLMs most frequently fail.", "AI": {"tldr": "ReLoop\u6846\u67b6\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4f18\u5316\u4ee3\u7801\u65f6\u5b58\u5728\u7684\u8bed\u4e49\u6084\u58f0\u5931\u8d25\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u751f\u6210\u548c\u884c\u4e3a\u9a8c\u8bc1\u65b9\u6cd5\u63d0\u5347\u4ee3\u7801\u6b63\u786e\u6027\u548c\u6267\u884c\u7387\u3002", "motivation": "LLMs\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u4e3a\u4f18\u5316\u4ee3\u7801\u65f6\u53ef\u80fd\u51fa\u73b0\u6084\u58f0\u5931\u8d25\uff1a\u4ee3\u7801\u53ef\u8fd0\u884c\u4f46\u8bed\u4e49\u9519\u8bef\uff08\u53ef\u884c\u6027-\u6b63\u786e\u6027\u5dee\u8ddd\u9ad8\u8fbe90%\uff09\uff0c\u5c24\u5176\u5728\u7ec4\u5408\u95ee\u9898\u4e0a\u5b58\u5728\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u751f\u6210\uff08\u56db\u6b65\u63a8\u7406\u94fe\uff1a\u7406\u89e3/\u5f62\u5f0f\u5316/\u7efc\u5408/\u9a8c\u8bc1\uff09\u907f\u514d\u6e90\u5934\u9519\u8bef\uff0c\u8f85\u4ee5\u884c\u4e3a\u9a8c\u8bc1\uff08\u57fa\u4e8e\u6c42\u89e3\u5668\u53c2\u6570\u6270\u52a8\u68c0\u6d4b\uff09\u5904\u7406\u6b8b\u4f59\u9519\u8bef\uff1b\u7ed3\u5408IIS\u8bca\u65ad\u5b9e\u73b0\u6267\u884c\u6062\u590d\u3002", "result": "\u5728\u6700\u5f3a\u6a21\u578b\u4e0a\uff1a\u6b63\u786e\u7387\u4ece22.6%\u63d0\u5347\u81f331.1%\uff0c\u6267\u884c\u7387\u4ece72.1%\u8fbe100%\uff1b\u4e94\u7c7b\u6a21\u578b\u3001\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u5747\u663e\u8457\u6539\u8fdb\uff0c\u5e76\u53d1\u5e03\u96f6\u552e\u4f18\u5316\u6570\u636e\u96c6RetailOpt-190\u3002", "conclusion": "ReLoop\u901a\u8fc7\u4e92\u8865\u673a\u5236\u6709\u6548\u6d88\u9664\u6084\u58f0\u5931\u8d25\uff0c\u7ed3\u6784\u5316\u751f\u6210\u5728\u7ec4\u5408\u95ee\u9898\u5360\u4f18\uff0c\u884c\u4e3a\u9a8c\u8bc1\u5b9a\u4f4d\u5c40\u90e8\u7f3a\u9677\uff1b\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347LLM\u4ee3\u7801\u751f\u6210\u53ef\u9760\u6027\u5e76\u63d0\u4f9b\u65b0\u6d4b\u8bd5\u57fa\u51c6\u3002"}}
{"id": "2602.16010", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.16010", "abs": "https://arxiv.org/abs/2602.16010", "authors": ["Xin Huang", "Weiping Zhang", "Shiman Meng", "Wubiao Xu", "Xiang Fu", "Luanzheng Guo", "Kento Sato"], "title": "Scrutinizing Variables for Checkpoint Using Automatic Differentiation", "comment": "The Second Workshop on Enabling Predictive Science with Optimization and Uncertainty Quantification in HPC (EPSOUQ-HPC) in conjunction with SC24", "summary": "Checkpoint/Restart (C/R) saves the running state of the programs periodically, which consumes considerable system resources. We observe that not every piece of data is involved in the computation in typical HPC applications; such unused data should be excluded from checkpointing for better storage/compute efficiency. To find out, we propose a systematic approach that leverages automatic differentiation (AD) to scrutinize every element within variables (e.g., arrays) for checkpointing allowing us to identify critical/uncritical elements and eliminate uncritical elements from checkpointing. Specifically, we inspect every single element within a variable for checkpointing with an AD tool to determine whether the element has an impact on the application output or not. We empirically validate our approach with eight benchmarks from the NAS Parallel Benchmark (NPB) suite. We successfully visualize critical/uncritical elements/regions within a variable with respect to its impact (yes or no) on the application output. We find patterns/distributions of critical/uncritical elements/regions quite interesting and follow the physical formulation/logic of the algorithm.The evaluation on NPB benchmarks shows that our approach saves storage for checkpointing by up to 20%.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u81ea\u52a8\u5fae\u5206\u5206\u6790\u53d8\u91cf\u7684\u65b9\u6cd5\uff0c\u8bc6\u522b\u68c0\u67e5\u70b9\u4e2d\u7684\u5173\u952e\u5143\u7d20\u5e76\u6392\u9664\u975e\u5173\u952e\u90e8\u5206\uff0c\u4f18\u5316\u8d44\u6e90\u5229\u7528\u3002", "motivation": "\u68c0\u67e5\u70b9/\u91cd\u542f\u673a\u5236\u6d88\u8017\u9ad8\uff0c\u9ad8\u6027\u80fd\u8ba1\u7b97\u5e94\u7528\u4e2d\u8bb8\u591a\u6570\u636e\u672a\u88ab\u5b9e\u9645\u4f7f\u7528\uff0c\u6392\u9664\u53ef\u63d0\u5347\u6548\u7387\u3002", "method": "\u4f7f\u7528\u81ea\u52a8\u5fae\u5206\u5de5\u5177\u9010\u5143\u7d20\u5206\u6790\u53d8\u91cf\u5bf9\u5e94\u7528\u8f93\u51fa\u7684\u5f71\u54cd\uff0c\u533a\u5206\u5173\u952e\u4e0e\u975e\u5173\u952e\u5143\u7d20\uff0c\u7b5b\u9009\u68c0\u67e5\u70b9\u8303\u56f4\u3002", "result": "\u5728NAS\u5e76\u884c\u57fa\u51c6\u5957\u4ef6\u6d4b\u8bd5\u4e2d\uff0c\u53ef\u89c6\u5316\u5173\u952e/\u975e\u5173\u952e\u533a\u57df\uff0c\u5b58\u50a8\u8282\u7701\u8fbe20%\uff0c\u6a21\u5f0f\u5339\u914d\u7b97\u6cd5\u7269\u7406\u903b\u8f91\u3002", "conclusion": "\u8be5\u7b56\u7565\u6709\u6548\u51cf\u5c11\u5b58\u50a8\u5f00\u9500\uff0c\u63ed\u793a\u6570\u636e\u4f7f\u7528\u89c4\u5f8b\uff0c\u4e3a\u68c0\u67e5\u70b9\u4f18\u5316\u63d0\u4f9b\u53ef\u6269\u5c55\u65b9\u6848\u3002"}}
{"id": "2602.16678", "categories": ["cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.16678", "abs": "https://arxiv.org/abs/2602.16678", "authors": ["Harrison Perone", "Christopher W. Hays"], "title": "Consensus Based Task Allocation for Angles-Only Local Catalog Maintenance of Satellite Systems", "comment": "14 pages, 4 figures. Submitted to the 48th Rocky Mountain American Astronautical Society's Guidance, Navigation and Control Conference", "summary": "In order for close proximity satellites to safely perform their missions, the relative states of all satellites and pieces of debris must be well understood. This presents a problem for ground based tracking and orbit determination since it may not be practical to achieve the required accuracy. Using space-based sensors allows for more accurate relative state estimates, especially if multiple satellites are allowed to communicate. Of interest to this work is the case where several communicating satellites each need to maintain a local catalog of communicating and non-communicating objects using angles-only limited field of view (FOV) measurements. However, this introduces the problem of efficiently scheduling and coordinating observations among the agents. This paper presents a decentralized task allocation algorithm to address this problem and quantifies its performance in terms of fuel usage and overall catalog uncertainty via numerical simulation. It was found that the new method significantly outperforms the uncertainty-fuel Pareto frontier formed by current approaches.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.16143", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.16143", "abs": "https://arxiv.org/abs/2602.16143", "authors": ["Naoya Onizawa", "Taiga Kubuta", "Duckgyu Shin", "Takahiro Hanyu"], "title": "Energy-Efficient p-Bit-Based Fully-Connected Quantum-Inspired Simulated Annealer with Dual BRAM Architecture", "comment": null, "summary": "Probabilistic bits (p-bits) offer an energy-efficient hardware abstraction for stochastic optimization; however, existing p-bit-based simulated annealing accelerators suffer from poor scalability and limited support for fully connected graphs due to fan-out and memory overhead. This paper presents an energy-efficient FPGA architecture for stochastic simulated quantum annealing (SSQA) that addresses these challenges. The proposed design combines a spin-serial and replica-parallel update schedule with a dual-BRAM delay-line architecture, enabling scalable support for fully connected Ising models while eliminating fan-out growth in logic resources. By exploiting SSQA, the architecture achieves fast convergence using only final replica states, significantly reducing memory requirements compared to conventional p-bit-based annealers. Implemented on a Xilinx ZC706 FPGA, the proposed system solves an 800-node MAX-CUT benchmark and achieves up to 50% reduction in energy consumption and over 90\\% reduction in logic resources compared with prior FPGA-based p-bit annealing architectures. These results demonstrate the practicality of quantum-inspired, p-bit-based annealing hardware for large-scale combinatorial optimization under strict energy and resource constraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFPGA\u7684\u968f\u673a\u6a21\u62df\u91cf\u5b50\u9000\u706b\uff08SSQA\uff09\u67b6\u6784\uff0c\u663e\u8457\u6539\u8fdb\u6982\u7387\u6bd4\u7279\u9000\u706b\u7684\u53ef\u6269\u5c55\u6027\u3001\u80fdlehraft and\u8d44\u6e90\u6548\u7387\uff0c\u89e3\u51b3\u4e86\u6247\u51fa\u548c\u5185\u5b58\u5f00\u9500\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6982\u7387\u6bd4\u7279\u9000\u706b\u52a0\u901f\u5668\u56e0\u6247\u51fa\u589e\u957f\u548c\u5185\u5b58\u5f00\u9500\u5bfc\u81f4\u53ef\u6269\u5c55\u6027\u5dee\uff0c\u96be\u4ee5\u652f\u6301\u5168\u8fde\u63a5\u56fe\u7ed3\u6784\uff0c\u9700\u521b\u65b0\u786c\u4ef6\u8bbe\u8ba1\u6765\u4f18\u5316\u5927\u89c4\u6a21\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u3002", "method": "\u91c7\u7528\u81ea\u65cb\u4e32\u884c\u4e0e\u526f\u672c\u5e76\u884c\u66f4\u65b0\u7b56\u7565\uff0c\u7ed3\u5408\u53cc-BRAM\u5ef6\u8fdf\u7ebf\u67b6\u6784\uff0c\u652f\u6301\u5168\u8fde\u901aIsing\u6a21\u578b\uff0c\u907f\u514d\u903b\u8f91\u8d44\u6e90\u6247\u51fa\u589e\u957f\uff0c\u5e76\u5229\u7528SSQA\u4ec5\u9700\u6700\u7ec8\u526f\u672c\u72b6\u6001\u6765\u51cf\u5c11\u5185\u5b58\u9700\u6c42\u3002", "result": "\u5728Xilinx ZC706 FPGA\u4e0a\u5b9e\u73b0800\u8282\u70b9MAX-CUT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bd4\u5148\u524dFPGA\u6982\u7387\u6bd4\u7279\u9000\u706b\u67b6\u6784\u8282\u80fd50%\uff0c\u903b\u8f91\u8d44\u6e90\u51cf\u5c1190%\u4ee5\u4e0a\u3002", "conclusion": "\u8be5\u67b6\u6784\u8bc1\u660e\u4e86\u91cf\u5b50\u542f\u53d1\u5f0f\u6982\u7387\u6bd4\u7279\u9000\u706b\u786c\u4ef6\u5728\u4e25\u683c\u80fd\u6e90\u548c\u8d44\u6e90\u7ea6\u675f\u4e0b\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u7ec4\u5408\u4f18\u5316\u7684\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2602.16100", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.16100", "abs": "https://arxiv.org/abs/2602.16100", "authors": ["Zijie Su", "Muhammed Tawfiqul Islam", "Mohammad Goudarzi", "Adel N. Toosi"], "title": "LLM-Driven Intent-Based Privacy-Aware Orchestration Across the Cloud-Edge Continuum", "comment": null, "summary": "With the rapid advancement of large language models (LLMs), efficiently serving LLM inference under limited GPU resources has become a critical challenge. Recently, an increasing number of studies have explored applying serverless computing paradigms to LLM serving in order to maximize resource utilization. However, LLM inference workloads are highly diverse, and modern GPU clusters are inherently heterogeneous, making it necessary to dynamically adjust deployment configurations online to better adapt to the elastic and dynamic nature of serverless environments. At the same time, enabling such online reconfiguration is particularly challenging due to the stateful nature of LLM inference and the massive size of model parameters. In this paper, we propose a dynamic pipeline reconfiguration approach that enables online adjustment of pipeline configurations while minimizing service downtime and performance degradation. Our method allows the system to select the optimal pipeline configuration in response to changing workloads. Experimental results on heterogeneous GPU platforms, including NVIDIA A100 and L40s, demonstrate that our migration mechanism incurs less than 50 ms of service downtime, while introducing under 10% overhead on both time-to-first-token (TTFT) and time-per-output-token (TPOT).", "AI": {"tldr": "\u63d0\u51fa\u52a8\u6001\u6d41\u6c34\u7ebf\u91cd\u914d\u7f6e\u65b9\u6cd5\u6761\u7684\u89c4\u5b9a\uff0c\u4ee5\u6700\u5c0f\u5316\u505c\u673a\u65f6\u95f4\u548c\u6027\u80fd\u635f\u5931\u5728\u5f02\u6784GPU\u73af\u5883\u4e0b\u7075\u6d3b\u670d\u52a1LLM\u63a8\u7406\u3002", "motivation": "\u56e0LLM\u63a8\u7406\u8d1f\u8f7d\u591a\u5143\u3001GPU\u96c6\u7fa4\u5f02\u6784\uff0c\u4e14\u670d\u52a1\u5668\u5bf9\u65e0\u73af\u5883\u9700\u52a8\u6001\u9002\u5e94\uff0c\u800c\u73b0\u6709\u65b9\u6848\u96be\u4ee5\u5728\u7ebf\u8c03\u6574\u6709\u72b6\u6001\u7684LLM\u90e8\u7f72\u914d\u7f6e\u3002", "method": "\u8bbe\u8ba1\u652f\u6301\u5728\u7ebf\u8c03\u6574\u6d41\u6c34\u7ebf\u914d\u7f6e\u7684\u52a8\u6001\u91cd\u914d\u7f6e\u673a\u5236\uff0c\u4f7f\u7cfb\u7edf\u80fd\u6839\u636e\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u9009\u62e9\u6700\u4f18\u914d\u7f6e\u3002", "result": "\u5728A100/L40 membre\u578bGPU\u6d4b\u8bd5\u4e2d\uff0c\u8fc1\u79fb\u673a\u5236\u5b9e\u73b0<50ms\u505c\u673a\u65f6\u95f4\uff0cTTFT\u4e0eTPOT\u6307\u6807\u989d\u5916\u5f00\u9500\u5747\u4f4e\u4e8e10%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u670d\u52a1\u5668\u5bf9\u65e0\u73af\u5883\u4e0bLLM\u670d\u52a1\u7684\u9ad8\u6548\u5f39\u6027\u9002\u914d\uff0c\u4e3a\u5f02\u6784\u8d44\u6e90\u4f18\u5316\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.16695", "categories": ["cs.MA", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.16695", "abs": "https://arxiv.org/abs/2602.16695", "authors": ["J. Martin Smit", "Fernando P. Santos"], "title": "Fairness Dynamics in Digital Economy Platforms with Biased Ratings", "comment": "9 pages, 6 figures, in proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)", "summary": "The digital services economy consists of online platforms that facilitate interactions between service providers and consumers. This ecosystem is characterized by short-term, often one-off, transactions between parties that have no prior familiarity. To establish trust among users, platforms employ rating systems which allow users to report on the quality of their previous interactions. However, while arguably crucial for these platforms to function, rating systems can perpetuate negative biases against marginalised groups. This paper investigates how to design platforms around biased reputation systems, reducing discrimination while maintaining incentives for all service providers to offer high quality service for users. We introduce an evolutionary game theoretical model to study how digital platforms can perpetuate or counteract rating-based discrimination. We focus on the platforms' decisions to promote service providers who have high reputations or who belong to a specific protected group. Our results demonstrate a fundamental trade-off between user experience and fairness: promoting highly-rated providers benefits users, but lowers the demand for marginalised providers against which the ratings are biased. Our results also provide evidence that intervening by tuning the demographics of the search results is a highly effective way of reducing unfairness while minimally impacting users. Furthermore, we show that even when precise measurements on the level of rating bias affecting marginalised service providers is unavailable, there is still potential to improve upon a recommender system which ignores protected characteristics. Altogether, our model highlights the benefits of proactive anti-discrimination design in systems where ratings are used to promote cooperative behaviour.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u6570\u5b57\u5e73\u53f0\u8bc4\u7ea7\u7cfb\u7edf\u5982\u4f55\u8bbe\u8ba1\u4ee5\u51cf\u5c11\u6b67\u89c6\uff0c\u4f7f\u7528\u535a\u5f08\u8bba\u6a21\u578b\u8bc1\u660e\u8c03\u6574\u641c\u7d22\u7ed3\u679c\u7684\u7fa4\u4f53\u5206\u5e03\u53ef\u964d\u4f4e\u504f\u89c1\u5e76\u7ef4\u62a4\u670d\u52a1\u8d28\u91cf\u3002", "motivation": "\u63a8\u52a8\u7814\u7a76\u7684\u539f\u56e0\u662f\u8bc4\u7ea7\u7cfb\u7edf\u53ef\u80fd\u5728\u6570\u5b57\u5e73\u53f0\u4e2d\u5f3a\u5316\u5bf9\u8fb9\u7f18\u5316\u7fa4\u4f53\u7684\u504f\u89c1\uff0c\u963b\u788d\u516c\u5e73\u4ea4\u6613\uff0c\u9700\u63a2\u7d22\u5728\u4e0d\u5f71\u54cd\u670d\u52a1\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u964d\u4f4e\u6b67\u89c6\u7684\u8bbe\u8ba1\u65b9\u6848\u3002", "method": "\u5f15\u5165\u8fdb\u5316\u535a\u5f08\u8bba \u0645\u0631\u0636\u5efa\u7acb\u4e00\u4e2a\u7406\u8bba\u6a21\u578b\uff0c\u5206\u6790\u5e73\u53f0\u5728\u63a8\u5e7f\u9ad8\u58f0\u8a89\u63d0\u4f9b\u5546\u6216\u53d7\u4fdd\u62a4\u7fa4\u4f53\u65f6\u7684\u51b3\u7b56\u5f71\u54cd\uff0c\u8bc4\u4f30\u6b67\u89c6\u7684\u5b58\u7eed\u4e0e\u5bf9\u6297\u673a\u5236\u3002", "result": "\u7ed3\u679c\u663e\u793aemplos\u4e2d\u5b58\u5728\u7528\u6237\u4f53\u9a8c\u4e0e\u516c\u5e73\u7684\u6743\u8861\uff1a\u63a8\u5e7f\u9ad8\u58f0\u8a89\u63d0\u4f9b\u5546\u5229\u4e8e\u7528\u6237\u4f53\u9a8c\u4f46\u52a0\u5267\u8fb9\u7f18\u5316\u7fa4\u4f53\u9700\u6c42\u964d\u4f4e\uff1b\u8c03\u6574\u641c\u7d22\u7ed3\u679c\u7684\u4eba\u53e3\u5206\u5e03\u80fd\u9ad8\u6548\u51cf\u5c11\u4e0d\u516c\uff0c\u6700\u5c0f\u5316\u7528\u6237\u4f53\u9a8c\u5f71\u54cd\uff1b\u5373\u4f7f\u7f3a\u4e4f\u7cbe\u786e\u504f\u89c1\u6570\u636e\uff0c\u5ffd\u7565\u53d7\u4fdd\u62a4\u7279\u5f81\u7684\u63a8\u8350\u7cfb\u7edf\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "\u6a21\u578b\u5f3a\u8c03\u5728\u4f9d\u8d56\u8bc4\u7ea7\u4fc3\u8fdb\u5408\u4f5c\u7684\u7cfb\u7edf\u4e2d\uff0c\u4e3b\u52a8\u91c7\u7528\u53cd\u6b67\u89c6\u8bbe\u8ba1\u53ef\u663e\u8457\u4f18\u5316\u6574\u4f53\u516c\u5e73\u6027\u548c\u5e73\u53f0\u6548\u80fd\u3002"}}
{"id": "2602.16091", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.16091", "abs": "https://arxiv.org/abs/2602.16091", "authors": ["Amirali Rayegan", "Tim Menzies"], "title": "Can Causality Cure Confusion Caused By Correlation (in Software Analytics)?", "comment": "Submitted to MSR'26 in Registered Report track", "summary": "Background: Symbolic models, particularly decision trees, are widely used in software engineering for explainable analytics in defect prediction, configuration tuning, and software quality assessment. Most of these models rely on correlational split criteria, such as variance reduction or information gain, which identify statistical associations but cannot imply causation between X and Y. Recent empirical studies in software engineering show that both correlational models and causal discovery algorithms suffer from pronounced instability. This instability arises from two complementary issues: 1-Correlation-based methods conflate association with causation. 2-Causal discovery algorithms rely on heuristic approximations to cope with the NP-hard nature of structure learning, causing their inferred graphs to vary widely under minor input perturbations. Together, these issues undermine trust, reproducibility, and the reliability of explanations in real-world SE tasks. Objective: This study investigates whether incorporating causality-aware split criteria into symbolic models can improve their stability and robustness, and whether such gains come at the cost of predictive or optimization performance. We additionally examine how the stability of human expert judgments compares to that of automated models. Method: Using 120+ multi-objective optimization tasks from the MOOT repository of multi-objective optimization tasks, we evaluate stability through a preregistered bootstrap-ensemble protocol that measures variance with win-score assignments. We compare the stability of human causal assessments with correlation-based decision trees (EZR). We would also compare the causality-aware trees, which leverage conditional-entropy split criteria and confounder filtering. Stability and performance differences are analyzed using statistical methods (variance, Gini Impurity, KS test, Cliff's delta)", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u56e0\u679c\u611f\u77e5\u5206\u5272\u51c6\u5219\u63d0\u5347\u7b26\u53f7\u6a21\u578b\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u5206\u6790\u4eba\u7c7b\u4e13\u5bb6\u5224\u65ad\u7684\u7a33\u5b9a\u6027\uff0c\u57fa\u4e8e120\u9879\u591a\u76ee\u6807\u4f18\u5316\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\u3002", "motivation": "\u80cc\u666f\u663e\u793a\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7b26\u53f7\u6a21\u578b\u7684\u5173\u8054\u6027\u5206\u5272\u51c6\u5219\u8bef\u5c06\u7edf\u8ba1\u5173\u8054\u89c6\u4e3a\u56e0\u679c\uff0c\u5bfc\u81f4\u6a21\u578b\u4e0d\u7a33\u5b9a\uff0c\u635f\u5bb3\u89e3\u91ca\u53ef\u9760\u6027\u3002\u76ee\u6807\u4e3a\u8bc4\u4f30\u56e0\u679c\u611f\u77e5\u5206\u5272\u51c6\u5219\u53ef\u5426\u63d0\u5347\u7a33\u5b9a\u6027\u800c\u4e0d\u964d\u4f4e\u6027\u80fd\uff0c\u5e76\u5bf9\u6bd4\u4eba\u7c7b\u5224\u65ad\u3002", "method": "\u4f7f\u7528MOOT\u5e93120+\u4efb\u52a1\uff0c\u91c7\u7528\u9884\u6ce8\u518c\u81ea\u4e3e\u96c6\u6210\u534f\u8bae\u8bc4\u4f30\u7a33\u5b9a\u6027\uff08\u4f7f\u7528\u8d62\u5206\u5206\u914d\uff09\uff0c\u7edf\u8ba1\u5206\u6790\u6db5\u76d6\u65b9\u5dee\u3001\u57fa\u5c3c\u4e0d\u7eaf\u5ea6\u3001KS\u68c0\u9a8c\u548cCliff's delta\uff1b\u6bd4\u8f83\u76f8\u5173\u7cfb\u6570\u51b3\u7b56\u6811\uff08EZR\uff09\u3001\u4eba\u7c7b\u56e0\u679c\u8bc4\u4f30\u53ca\u56e0\u679c\u611f\u77e5\u6811\uff08\u5f15\u5165\u6761\u4ef6\u71b5\u5206\u88c2\u548c\u6df7\u6742\u8fc7\u6ee4\uff09\u3002", "result": "\u6458\u8981\u672a\u63d0\u4f9b\u5b9e\u9a8c\u7ed3\u679c\u7ec6\u8282\u3002", "conclusion": "\u6458\u8981\u672a\u9648\u8ff0\u7ed3\u8bba\u90e8\u5206\uff0c\u4f46\u76ee\u6807\u5f3a\u8c03\u63a2\u7d22\u56e0\u679c\u51c6\u5219\u5bf9\u7a33\u5b9a\u6027\u7684\u6f5c\u5728\u589e\u76ca global insights\u3002"}}
{"id": "2602.16222", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.16222", "abs": "https://arxiv.org/abs/2602.16222", "authors": ["Joel Rybicki", "Jakob Solnerzik", "Robin Vacus"], "title": "Near-optimal population protocols on bounded-degree trees", "comment": "37 pages, 7 figures", "summary": "We investigate space-time trade-offs for population protocols in sparse interaction graphs. In complete interaction graphs, optimal space-time trade-offs are known for the leader election and exact majority problems. However, it has remained open if other graph families exhibit similar space-time complexity trade-offs, as existing lower bound techniques do not extend beyond highly dense graphs.\n  In this work, we show that -- unlike in complete graphs -- population protocols on bounded-degree trees do not exhibit significant asymptotic space-time trade-offs for leader election and exact majority. For these problems, we give constant-space protocols that have near-optimal worst-case expected stabilisation time. These new protocols achieve a linear speed-up compared to the state-of-the-art.\n  Our results are based on two novel protocols, which we believe are of independent interest. First, we give a new fast self-stabilising 2-hop colouring protocol for general interaction graphs, whose stabilisation time we bound using a stochastic drift argument. Second, we give a self-stabilising tree orientation algorithm that builds a rooted tree in optimal time on any tree. As a consequence, we can use simple constant-state protocols designed for directed trees to solve leader election and exact majority fast. For example, we show that ``directed'' annihilation dynamics solve exact majority in $O(n^2 \\log n)$ steps on directed trees.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u7d22\u7a00\u758f\u4ea4\u4e92\u56fe\u4e2d\u7fa4\u4f53\u534f\u8bae\u7684\u65f6\u7a7a\u6743\u8861\uff0c\u53d1\u73b0\u5728\u6709\u754c\u5ea6\u6811\u4e0a\uff0c\u9886\u5bfc\u9009\u4e3e\u548c\u7cbe\u786e\u591a\u6570\u95ee\u9898\u65e0\u663e\u8457\u65f6\u7a7a\u6743\u8861\u65b0\u89c4\uff0c\u63d0\u4f9b\u6052\u7a7a\u95f4\u534f\u8bae\u5b9e\u73b0\u8fd1\u6700\u4f18\u7a33\u5b9a\u65f6\u95f4\u3002", "motivation": "\u4e4b\u524d\u5de5\u4f5c\u5728\u5b8c\u5168\u56fe\u4e2d\u5df2\u77e5\u6700\u4f18\u65f6\u7a7a\u6743\u8861\uff0c\u4f46\u5176\u4ed6\u56fe\u7c7b\u662f\u5426\u7c7b\u4f3c\u672a\u77e5\uff0c\u56e0\u4e0b\u754c\u6280\u672f\u65e0\u6cd5\u6269\u5c55\u5230\u9ad8\u5bc6\u5ea6\u56fe\u5916\uff1b\u672c\u7814\u7a76\u52a8\u673a\u4e3a\u586b\u8865\u7a00\u758f\u56fe\u9886\u57df\u77e5\u8bc6\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b0\u534f\u8bae\uff1a\u4e00\u662f\u57fa\u4e8e\u968f\u673a\u6f02\u79fb\u8bba\u8bc1\u7684\u81ea\u7a33\u5b9a2\u8df3\u7740\u8272\u534f\u8bae\uff0c\u4e8c\u662f\u81ea\u7a33\u5b9a\u6811\u5b9a\u5411\u7b97\u6cd5\u6784\u5efa\u6709\u6839\u6811\uff1b\u7ed3\u5408\u7b80\u5316\u6052\u72b6\u6001\u534f\u8bae\u6c42\u89e3\u95ee\u9898\u3002", "result": "\u5728\u6811\u4e0a\u5b9e\u73b0\u9886\u5bfc\u9009\u4e3e\u548c\u7cbe\u786e\u591a\u6570\u7684\u6052\u7a7a\u95f4\u534f\u8bae\uff0c\u7a33\u5b9a\u65f6\u95f4\u63a5\u8fd1\u6700\u4f18\uff1b\u4e0e\u5f53\u524d\u6700\u4f18\u76f8\u6bd4\u5b9e\u73b0\u7ebf\u6027\u52a0\u901f\uff0c\u5982\u5b9a\u5411\u6811\u4e0a\u7cbe\u786e\u591a\u6570\u95ee\u9898\u5728O(n^2 log n)\u6b65\u89e3\u51b3\u3002", "conclusion": "\u7ed3\u8bba\u8868\u660e\u7a00\u758f\u56fe\u534f\u8bae\u65e0\u663e\u8457\u65f6\u7a7a\u6743\u8861\uff0c\u65b0\u65b9\u6cd5\u63d0\u4f9b\u9ad8\u6548\u8bbe\u8ba1\u548c\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u6269\u5c55\u7fa4\u4f53\u534f\u8bae\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2602.16362", "categories": ["cs.DC", "cs.NI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.16362", "abs": "https://arxiv.org/abs/2602.16362", "authors": ["MHD Saria Allahham", "Hossam S. Hassanein"], "title": "How Reliable is Your Service at the Extreme Edge? Analytical Modeling of Computational Reliability", "comment": null, "summary": "Extreme Edge Computing (XEC) distributes streaming workloads across consumer-owned devices, exploiting their proximity to users and ubiquitous availability. Many such workloads are AI-driven, requiring continuous neural network inference for tasks like object detection and video analytics. Distributed Inference (DI), which partitions model execution across multiple edge devices, enables these streaming services to meet strict throughput and latency requirements. Yet consumer devices exhibit volatile computational availability due to competing applications and unpredictable usage patterns. This volatility poses a fundamental challenge: how can we quantify the probability that a device, or ensemble of devices, will maintain the processing rate required by a streaming service? This paper presents an analytical framework for computational reliability in XEC, defined as the probability that instantaneous capacity meets demand at a specified Quality of Service (QoS) threshold. We derive closed-form reliability expressions under two information regimes: Minimal Information (MI), requiring only declared operational bounds, and historical data, which refines estimates via Maximum Likelihood Estimation from past observations. The framework extends to multi-device deployments, providing reliability expressions for series, parallel, and partitioned workload configurations. We derive optimal workload allocation rules and analytical bounds for device selection, equipping orchestrators with tractable tools to evaluate deployment feasibility and configure distributed streaming systems. We validate the framework using real-time object detection with YOLO11m model as a representative DI streaming workload; experiments on emulated XED environments demonstrate close agreement between analytical predictions, Monte Carlo sampling, and empirical measurements across diverse capacity and demand configurations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.16106", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.16106", "abs": "https://arxiv.org/abs/2602.16106", "authors": ["Shahriar Rumi Dipto", "Saikat Mondal", "Chanchal K. Roy"], "title": "Algorithm-Based Pipeline for Reliable and Intent-Preserving Code Translation with LLMs", "comment": "Accepted at 34th IEEE/ACM International Conference on Program Comprehension (ICPC 2026)", "summary": "Code translation, the automatic conversion of programs between languages, is a growing use case for Large Language Models (LLMs). However, direct one-shot translation often fails to preserve program intent, leading to errors in control flow, type handling, and I/O behavior. We propose an algorithm-based pipeline that introduces a language-neutral intermediate specification to capture these details before code generation. This study empirically evaluates the extent to which structured planning can improve translation accuracy and reliability relative to direct translation. We conduct an automated paired experiment - direct and algorithm-based to translate between Python and Java using five widely used LLMs on the Avatar and CodeNet datasets. For each combination (model, dataset, approach, and direction), we compile and execute the translated program and run the tests provided. We record compilation results, runtime behavior, timeouts (e.g., infinite loop), and test outcomes. We compute accuracy from these tests, counting a translation as correct only if it compiles, runs without exceptions or timeouts, and passes all tests. We then map every failed compile-time and runtime case to a unified, language-aware taxonomy and compare subtype frequencies between the direct and algorithm-based approaches. Overall, the Algorithm-based approach increases micro-average accuracy from 67.7% to 78.5% (10.8% increase). It eliminates lexical and token errors by 100%, reduces incomplete constructs by 72.7%, and structural and declaration issues by 61.1%. It also substantially lowers runtime dependency and entry-point failures by 78.4%. These results demonstrate that algorithm-based pipelines enable more reliable, intent-preserving code translation, providing a foundation for robust multilingual programming assistants.", "AI": {"tldr": "\u7b97\u6cd5\u7ba1\u9053\u63d0\u5347LLMs\u4ee3\u7801\u7ffb\u8bd1\u51c6\u786e\u602710.8%\uff0c\u51cf\u5c11\u9519\u8bef\u7c7b\u578b\u3002", "motivation": "\u76f4\u63a5\u5355\u6b21\u7ffb\u8bd1\u5e38\u672a\u80fd\u4fdd\u7559\u7a0b\u5e8f\u610f\u56fe\uff0c\u6613\u5f15\u53d1\u63a7\u5236\u6d41\u3001\u7c7b\u578b\u5904\u7406\u548cI/O\u884c\u4e3a\u9519\u8bef\u3002", "method": "\u5728Avatar\u548cCodeNet\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u75285\u79cdLLMs\u8fdb\u884cPython\u548cJava\u53cc\u5411\u7ffb\u8bd1\u5bf9\u6bd4\u5b9e\u9a8c\uff08\u76f4\u63a5\u4e0e\u7b97\u6cd5\u7ba1\u9053\uff09\uff0c\u7f16\u8bd1\u5e76\u8fd0\u884c\u6d4b\u8bd5\u7a0b\u5e8f\uff0c\u8bb0\u5f55\u7f16\u8bd1\u7ed3\u679c\u3001\u8fd0\u884c\u65f6\u5f02\u5e38\u4e0e\u6d4b\u8bd5\u901a\u8fc7\u7387\uff0c\u4f7f\u7528\u7edf\u4e00\u5206\u7c7b\u6620\u5c04\u5931\u8d25\u6848\u4f8b\u3002", "result": "\u7b97\u6cd5\u7ba1\u9053\u5fae\u5e73\u5747\u51c6\u786e\u7387\u4ece67.7%\u5347\u81f378.5%\uff0c\u6d88\u9664\u8bcd\u6cd5\u548c\u4ee4\u724c\u9519\u8bef100%\uff0c\u51cf\u5c11\u4e0d\u5b8c\u6574\u7ed3\u678472.7%\u53ca\u7ed3\u6784\u58f0\u660e\u95ee\u989861.1%\uff0c\u964d\u4f4e\u8fd0\u884c\u65f6\u4f9d\u8d56\u5931\u8d2578.4%\u3002", "conclusion": "\u7b97\u6cd5\u7ba1\u9053\u901a\u8fc7\u8bed\u8a00\u4e2d\u7acb\u89c4\u8303\u786e\u4fdd\u4ee3\u7801\u610f\u56fe\u4fdd\u7559\uff0c\u4e3a\u53ef\u9760\u8de8\u8bed\u8a00\u7f16\u7a0b\u52a9\u624b\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2602.16233", "categories": ["cs.DC", "cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.16233", "abs": "https://arxiv.org/abs/2602.16233", "authors": ["Prabhjot Singh", "Adel N. Toosi", "Rajkumar Buyya"], "title": "DistributedEstimator: Distributed Training of Quantum Neural Networks via Circuit Cutting", "comment": null, "summary": "Circuit cutting decomposes a large quantum circuit into a collection of smaller subcircuits. The outputs of these subcircuits are then classically reconstructed to recover the original expectation values. While prior work characterises cutting overhead largely in terms of subcircuit counts and sampling complexity, its end-to-end impact on iterative, estimator-driven training pipelines remains insufficiently measured from a systems perspective. In this paper, we propose a cut-aware estimator execution pipeline that treats circuit cutting as a staged distributed workload and instruments each estimator query into partitioning, subexperiment generation, parallel execution, and classical reconstruction phases. Using logged runtime traces and learning outcomes on two binary classification workloads (Iris and MNIST), we quantify cutting overheads, scaling limits, and sensitivity to injected stragglers, and we evaluate whether accuracy and robustness are preserved under matched training budgets. Our measurements show that cutting introduces substantial end-to-end overheads that grow with the number of cuts, and that reconstruction constitutes a dominant fraction of per-query time, bounding achievable speed-up under increased parallelism. Despite these systems costs, test accuracy and robustness are preserved in the measured regimes, with configuration-dependent improvements observed in some cut settings. These results indicate that practical scaling of circuit cutting for learning workloads hinges on reducing and overlapping reconstruction and on scheduling policies that account for barrier-dominated critical paths.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.16499", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.16499", "abs": "https://arxiv.org/abs/2602.16499", "authors": ["Carsten Ellwein", "David Dietrich", "Jessica Roth", "Rozana Cvitkovic", "Andreas Wortmann"], "title": "Software-heavy Asset Administration Shells: Classification and Use Cases", "comment": null, "summary": "The Asset Administration Shell (AAS) is an emerging technology for the implementation of digital twins in the field of manufacturing. Software is becoming increasingly important, not only in general but specifically in relation to manufacturing, especially with regard to digital manufacturing and a shift towards the usage of artificial intelligence. This increases the need not only to model software, but also to integrate services directly into the AAS. The existing literature contains individual solutions to implement such software-heavy AAS. However, there is no systematic analysis of software architectures that integrate software services directly into the AAS. This paper aims to fill this research gap and differentiate architectures based on software quality criteria as well as typical manufacturing use cases. This work may be considered as an interpretation guideline for software-heavy AAS, both in academia and for practitioners.", "AI": {"tldr": "\u5206\u6790\u96c6\u6210\u8f6f\u4ef6\u670d\u52a1\u7684\u8d44\u4ea7\u7ba1\u7406\u58f3\u67b6\u6784", "motivation": "\u5236\u9020\u4e1a\u6570\u5b57\u5316\u548cAI\u5e94\u7528\u589e\u957f\u51f8\u663e\u8f6f\u4ef6\u5efa\u6a21\u4e0e\u670d\u52a1\u96c6\u6210\u9700\u6c42\uff0c\u4f46\u7f3a\u4e4f\u8f6f\u4ef6\u67b6\u6784\u7cfb\u7edf\u5206\u6790", "method": "\u57fa\u4e8e\u8f6f\u4ef6\u8d28\u91cf\u6807\u51c6\u548c\u5178\u578b\u5236\u9020\u7528\u4f8b\u5bf9\u67b6\u6784\u8fdb\u884c\u5dee\u5f02\u5316\u7814\u7a76", "result": "\u586b\u8865\u7814\u7a76\u7a7a\u767d\uff0c\u63d0\u4f9b\u7cfb\u7edf\u5316\u67b6\u6784\u89e3\u51b3\u65b9\u6848", "conclusion": "\u4e3a\u5b66\u672f\u754c\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u8f6f\u4ef6\u5bc6\u96c6\u578b\u8d44\u4ea7\u7ba1\u7406\u58f3\u5b9e\u65bd\u6307\u5357"}}
{"id": "2602.16671", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16671", "abs": "https://arxiv.org/abs/2602.16671", "authors": ["Jaid Monwar Chowdhury", "Chi-An Fu", "Reyhaneh Jabbarvand"], "title": "SPARC: Scenario Planning and Reasoning for Automated C Unit Test Generation", "comment": "9 pages, 6 figures, 4 tables", "summary": "Automated unit test generation for C remains a formidable challenge due to the semantic gap between high-level program intent and the rigid syntactic constraints of pointer arithmetic and manual memory management. While Large Language Models (LLMs) exhibit strong generative capabilities, direct intent-to-code synthesis frequently suffers from the leap-to-code failure mode, where models prematurely emit code without grounding in program structure, constraints, and semantics. This will result in non-compilable tests, hallucinated function signatures, low branch coverage, and semantically irrelevant assertions that cannot properly capture bugs. We introduce SPARC, a neuro-symbolic, scenario-based framework that bridges this gap through four stages: (1) Control Flow Graph (CFG) analysis, (2) an Operation Map that grounds LLM reasoning in validated utility helpers, (3) Path-targeted test synthesis, and (4) an iterative, self-correction validation loop using compiler and runtime feedback. We evaluate SPARC on 59 real-world and algorithmic subjects, where it outperforms the vanilla prompt generation baseline by 31.36% in line coverage, 26.01% in branch coverage, and 20.78% in mutation score, matching or exceeding the symbolic execution tool KLEE on complex subjects. SPARC retains 94.3% of tests through iterative repair and produces code with significantly higher developer-rated readability and maintainability. By aligning LLM reasoning with program structure, SPARC provides a scalable path for industrial-grade testing of legacy C codebases.", "AI": {"tldr": "SPARC\u6846\u67b6\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u548c\u573a\u666f\u57fa\u7840\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347C\u8bed\u8a00\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u7684\u6548\u80fd", "motivation": "C\u8bed\u8a00\u7684\u81ea\u52a8\u5316\u5355\u5143\u6d4b\u8bd5\u56e0\u8bed\u4e49\u9e3f\u6c9f\u3001\u6307\u9488\u7b97\u672f\u548c\u5185\u5b58\u7ba1\u7406\u7684\u590d\u6742\u6027\u800c\u5177\u6709\u6311\u6218\u6027\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6613\u4ea7\u751f\u8df3\u8dc3\u5230\u4ee3\u7801\u9519\u8bef\uff0c\u5bfc\u81f4\u975e\u53ef\u7f16\u8bd1\u6d4b\u8bd5\u3001\u4f4e\u8986\u76d6\u7387\u548c\u65e0\u5173\u65ad\u8a00", "method": "SPARC\u91c7\u7528\u56db\u9636\u6bb5\u6846\u67b6\uff1a\uff081\uff09\u63a7\u5236\u6d41\u56fe\u5206\u6790\uff0c\uff082\uff09\u64cd\u4f5c\u5730\u56fe\u4ee5\u5b9e\u7528\u5de5\u5177\u4e3a\u57fa\u7840\u7ea6\u675fLLM\u63a8\u7406\uff0c\uff083\uff09\u8def\u5f84\u76ee\u6807\u6d4b\u8bd5\u751f\u6210\uff0c\uff084\uff09\u57fa\u4e8e\u7f16\u8bd1\u5668\u4e0e\u8fd0\u884c\u65f6\u53cd\u9988\u7684\u8fed\u4ee3\u81ea\u6821\u6b63\u5faa\u73af", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.16347", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.16347", "abs": "https://arxiv.org/abs/2602.16347", "authors": ["Jon Vehovar", "Miha Rot", "Matja\u017e Depolli", "Gregor Kosec"], "title": "Load Balanced Parallel Node Generation for Meshless Numerical Methods", "comment": null, "summary": "Meshless methods are used to solve partial differential equations by approximating differential operators at a node as a weighted sum of values at its neighbours. One of the algorithms for generating nodes suitable for meshless numerical analysis is an n-dimensional Poisson disc sampling based method. It can handle complex geometries and supports variable node density, a crucial feature for adaptive analysis. We modify this method for parallel execution using coupled spatial indexing and work distribution hypertrees. The latter is prebuilt according to the node density function, ensuring that each leaf represents a balanced work unit. Threads advance separate fronts and claim work hypertree leaves as needed while avoiding leaves neighbouring those claimed by other threads. Node placement constraints and the partially prebuilt spatial hypertree are combined to eliminate the need to lock the tree while it is being modified. Thread collision handling is managed by the work hypertree at the leaf level, drastically reducing the number of required mutex acquisitions for point insertion collision checks. We explore the behaviour of the proposed algorithm and compare the performance with existing attempts at parallelisation and consider the requirements for adapting the developed algorithm to distributed systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8d85\u6811\u7ed3\u6784\u7684\u5e76\u884c\u5316n\u7ef4\u6cca\u677e\u5706\u76d8\u91c7\u6837\u7b97\u6cd5\uff0c\u7528\u4e8e\u652f\u6301\u81ea\u9002\u5e94\u5206\u6790\u7684\u65e0\u7f51\u683c\u6570\u503c\u8ba1\u7b97", "motivation": "\u89e3\u51b3\u590d\u6742\u51e0\u4f55\u548c\u53ef\u53d8\u8282\u70b9\u5bc6\u5ea6\u9700\u6c42\u4e0b\uff0c\u6cca\u677e\u5706\u76d8\u91c7\u6837\u5e76\u884c\u5316\u7684\u9501\u7ade\u4e89\u4e0e\u8ba1\u7b97\u6548\u7387\u95ee\u9898", "method": "\u8026\u5408\u7a7a\u95f4\u7d22\u5f15\u4e0e\u9884\u6784\u5efa\u5de5\u4f5c\u5206\u914d\u8d85\u6811\uff0c\u6309\u5bc6\u5ea6\u5206\u914d\u5e73\u8861\u4efb\u52a1\u5355\u5143\uff0c\u7ebf\u7a0b\u901a\u8fc7\u53f6\u8282\u70b9\u7ea7\u78b0\u649e\u68c0\u6d4b\u51cf\u5c11\u4e92\u65a5\u9501\u4f7f\u7528", "result": "\u5927\u5e45\u964d\u4f4e\u8282\u70b9\u63d2\u5165\u65f6\u7684\u9501\u4e89\u7528\uff0c\u53f6\u8282\u70b9\u5c42\u7ea7\u51b2\u7a81\u5904\u7406\u663e\u8457\u51cf\u5c11\u4e92\u65a5\u9501\u83b7\u53d6\u6b21\u6570", "conclusion": "\u8be5\u5e76\u884c\u7b97\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u80ae\u6ee1\u8db3\u5206\u5e03\u5f0f\u7cfb\u7edf\u9002\u914d\u9700\u6c42\uff0c\u4e3a\u590d\u6742\u573a\u666f\u63d0\u4f9b\u9ad8\u6548\u8282\u70b9\u751f\u6210\u65b9\u6848"}}
{"id": "2602.16603", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16603", "abs": "https://arxiv.org/abs/2602.16603", "authors": ["Chia-chi Hsieh", "Zan Zong", "Xinyang Chen", "Jianjiang Li", "Jidong Zhai", "Lijie Wen"], "title": "FlowPrefill: Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM Serving", "comment": "13 pages", "summary": "The growing demand for large language models (LLMs) requires serving systems to handle many concurrent requests with diverse service level objectives (SLOs). This exacerbates head-of-line (HoL) blocking during the compute-intensive prefill phase, where long-running requests monopolize resources and delay higher-priority ones, leading to widespread time-to-first-token (TTFT) SLO violations. While chunked prefill enables interruptibility, it introduces an inherent trade-off between responsiveness and throughput: reducing chunk size improves response latency but degrades computational efficiency, whereas increasing chunk size maximizes throughput but exacerbates blocking. This necessitates an adaptive preemption mechanism. However, dynamically balancing execution granularity against scheduling overheads remains a key challenge.\n  In this paper, we propose FlowPrefill, a TTFT-goodput-optimized serving system that resolves this conflict by decoupling preemption granularity from scheduling frequency. To achieve adaptive prefill scheduling, FlowPrefill introduces two key innovations: 1) Operator-Level Preemption, which leverages operator boundaries to enable fine-grained execution interruption without the efficiency loss associated with fixed small chunking; and 2) Event-Driven Scheduling, which triggers scheduling decisions only upon request arrival or completion events, thereby supporting efficient preemption responsiveness while minimizing control-plane overhead. Evaluation on real-world production traces shows that FlowPrefill improves maximum goodput by up to 5.6$\\times$ compared to state-of-the-art systems while satisfying heterogeneous SLOs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFlowPrefill\u7cfb\u7edf\uff0c\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u7684\u9884\u586b\u5145\u9636\u6bb5\uff0c\u901a\u8fc7\u89e3\u8026\u62a2\u5360\u7c92\u5ea6\u548c\u8c03\u5ea6\u9891\u7387\uff0c\u89e3\u51b3\u54cd\u5e94\u6027\u548c\u541e\u5410\u7387\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u51cf\u5c11\u5934\u7ebf\u963b\u585e\u548cTTFT SLO\u8fdd\u89c4\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u4e2d\uff0c\u9ad8\u5e76\u53d1\u8bf7\u6c42\u5728\u9884\u586b\u5145\u9636\u6bb5\u6613\u5f15\u53d1\u5934\u7ebf\u963b\u585e\uff0c\u5bfc\u81f4\u4f18\u5148\u7ea7\u8bf7\u6c42\u5ef6\u8fdf\u548cTTFT\u670d\u52a1\u76ee\u6807\u8fdd\u89c4\uff1b\u56fa\u5b9a\u7684Chunk\u9884\u586b\u5145\u867d\u53ef\u4e2d\u65ad\u4f46\u5b58\u5728\u54cd\u5e94\u6027\u4e0e\u541e\u5410\u7387\u7684\u56fa\u6709\u77db\u76fe\uff0c\u9700\u81ea\u9002\u5e94\u62a2\u5360\u673a\u5236\u3002", "method": "FlowPrefill\u5f15\u5165\u4e24\u9879\u521b\u65b0\uff1a1\uff09\u64cd\u4f5c\u5458\u7ea7\u62a2\u5360\uff0c\u5728\u65e0\u6548\u7387\u635f\u5931\u4e0b\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u4e2d\u65ad\uff1b2\uff09\u4e8b\u4ef6\u9a71\u52a8\u8c03\u5ea6\uff0c\u4ec5\u5728\u8bf7\u6c42\u5230\u8fbe\u6216\u5b8c\u6210\u4e8b\u4ef6\u89e6\u53d1\u8c03\u5ea6\u51b3\u7b56\uff0c\u786e\u4fdd\u9ad8\u6548\u54cd\u5e94\u5e76\u6700\u5c0f\u5316\u5f00\u9500\u3002", "result": "\u5b9e\u9645\u751f\u4ea7\u8ddf\u8e2a\u8bc4\u4f30\u663e\u793a\uff0c\u76f8\u6bd4\u4e8e\u5148\u8fdb\u7cfb\u7edf\uff0cFlowPrefill\u6700\u9ad8\u5c06\u6709\u6548\u541e\u5410\u7387\u63d0\u5347\u8fbe5.6\u500d\uff0c\u540c\u65f6\u6ee1\u8db3\u5f02\u6784SLOs\u9700\u6c42\u3002", "conclusion": "FlowPrefill\u901a\u8fc7\u89e3\u8026\u9884\u586b\u5145\u8c03\u5ea6\uff0c\u89e3\u51b3\u4e86LLM\u670d\u52a1\u4e2d\u963b\u585e\u548c\u6548\u7387\u77db\u76fe\uff0c\u663e\u8457\u4f18\u5316\u6027\u80fd\u5e76\u652f\u6301\u591a\u6837\u670d\u52a1\u76ee\u6807\u3002"}}
