<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 3]
- [cs.SE](#cs.SE) [Total: 13]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [A Scheduling Framework for Efficient MoE Inference on Edge GPU-NDP Systems](https://arxiv.org/abs/2601.03992)
*Qi Wu,Chao Fang,Jiayuan Chen,Ye Lin,Yueqi Zhang,Yichuan Bai,Yuan Du,Li Du*

Main category: cs.DC

TL;DR: 本文提出了一种针对边缘GPU-NDP系统的高效MoE推理框架，通过张量并行、负载均衡调度和无数据预取策略，显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 解决MoE模型在边缘GPU-NDP系统部署时面临的负载不均、GPU利用率低和专家激活不可预测导致的预取开销问题。

Method: 1）利用张量并行分拆专家参数至多个NDP单元；2）设计负载均衡调度算法分配计算任务；3）采用无数据集依赖的预取策略提前加载高频专家。

Result: 实验表明，该框架相比现有方法平均实现2.41倍、最高2.56倍的端到端延迟加速。

Conclusion: 所提框架有效提升了资源受限环境下MoE模型在GPU-NDP系统上的推理效率与实用性。

Abstract: Mixture-of-Experts (MoE) models facilitate edge deployment by decoupling model capacity from active computation, yet their large memory footprint drives the need for GPU systems with near-data processing (NDP) capabilities that offload experts to dedicated processing units. However, deploying MoE models on such edge-based GPU-NDP systems faces three critical challenges: 1) severe load imbalance across NDP units due to non-uniform expert selection and expert parallelism, 2) insufficient GPU utilization during expert computation within NDP units, and 3) extensive data pre-profiling necessitated by unpredictable expert activation patterns for pre-fetching. To address these challenges, this paper proposes an efficient inference framework featuring three key optimizations. First, the underexplored tensor parallelism in MoE inference is exploited to partition and compute large expert parameters across multiple NDP units simultaneously towards edge low-batch scenarios. Second, a load-balancing-aware scheduling algorithm distributes expert computations across NDP units and GPU to maximize resource utilization. Third, a dataset-free pre-fetching strategy proactively loads frequently accessed experts to minimize activation delays. Experimental results show that our framework enables GPU-NDP systems to achieve 2.41x on average and up to 2.56x speedup in end-to-end latency compared to state-of-the-art approaches, significantly enhancing MoE inference efficiency in resource-constrained environments.

</details>


### [2] [Hummingbird: SLO-Oriented GPU Preemption at Microsecond-scale](https://arxiv.org/abs/2601.04071)
*Tiancheng Hu,Chenxi Wang,Ting Cao,Jin Qin,Lei Chen,Xinyu Xiao,Junhao Hu,Hongliang Tian,Shoumeng Yan,Huimin Cui,Quan Chen,Tao Xie*

Main category: cs.DC

TL;DR: Hummingbird 是一种面向 SLO 的 GPU 调度系统，通过微秒级抢占和回收空闲 GPU 时间片，在闭源 GPU 上同时保障高优先级任务的 SLO 并提升利用率。


<details>
  <summary>Details</summary>
Motivation: 现有 GPU 共享技术难以在闭源 GPU 上兼顾 SLO 保障与效率最大化，缺乏细粒度调度能力。

Method: 提出 Hummingbird 系统，实现闭源 GPU 上的微秒级抢占，并有效利用空闲时间片进行低优先级任务调度。

Result: 相比最新空间/时间共享方法，高优先级任务 SLO 达成率提升 9.7x/3.5x；与独占执行相比，SLO 下降小于 1%；低优先级任务吞吐量提升 2.4x。

Conclusion: Hummingbird 在保障 SLO 的同时显著提升 GPU 利用率，验证了其有效性。

Abstract: Existing GPU-sharing techniques, including spatial and temporal sharing, aim to improve utilization but face challenges in simultaneously ensuring SLO adherence and maximizing efficiency due to the lack of fine-grained task scheduling on closed-source GPUs. This paper presents Hummingbird, an SLO-oriented GPU scheduling system that overcomes these challenges by enabling microsecond-scale preemption on closed-source GPUs while effectively harvesting idle GPU time slices. Comprehensive evaluations across diverse GPU architectures reveal that Hummingbird improves the SLO attainment of high-priority tasks by 9.7x and 3.5x compared to the state-of-the-art spatial and temporal-sharing approaches. When compared to executing exclusively, the SLO attainment of the high-priority task, collocating with low-priority tasks on Hummingbird, only drops by less than 1%. Meanwhile, the throughput of the low-priority task outperforms the state-of-the-art temporal-sharing approaches by 2.4x. Hummingbird demonstrates significant effectiveness in ensuring the SLO while enhancing GPU utilization.

</details>


### [3] [Failure-Resilient and Carbon-Efficient Deployment of Microservices over the Cloud-Edge Continuum](https://arxiv.org/abs/2601.04123)
*Francisco Ponce,Simone Gazza,Andrea D'Iapico,Roberto Amadini,Antonio Brogi,Stefano Forti,Saverio Giallorenzo,Pierluigi Plebani,Davide Usai,Monica Vitali,Gianluigi Zavattaro,Jacopo Soldani*

Main category: cs.DC

TL;DR: FREEDA工具链实现了在云边连续体上自动部署微服务应用，兼顾故障恢复能力与碳效率。


<details>
  <summary>Details</summary>
Motivation: 在异构动态的云边基础设施上部署微服务需平衡弹性、性能与可持续性目标。

Method: 通过持续调整部署配置应对运行条件变化，并利用模拟/仿真场景验证工具链有效性。

Result: FREEDA可自主迁移服务、调整资源配置或负载均衡，在弹性、效率与环保间达成最优平衡。

Conclusion: 该工具链有效支持了面向可持续发展的高弹性微服务部署。

Abstract: Deploying microservice-based applications (MSAs) on heterogeneous and dynamic Cloud-Edge infrastructures requires balancing conflicting objectives, such as failure resilience, performance, and environmental sustainability. In this article, we introduce the FREEDA toolchain, designed to automate the failure-resilient and carbon-efficient deployment of MSAs over the Cloud-Edge Continuum.
  The FREEDA toolchain continuously adapts deployment configurations to changing operational conditions, resource availability, and sustainability constraints, aiming to maintain the MSA quality and service continuity while reducing carbon emissions. We also introduce an experimental suite using diverse simulated and emulated scenarios to validate the effectiveness of the toolchain against real-world challenges, including resource exhaustion, node failures, and carbon intensity fluctuations. The results demonstrate FREEDA's capability to autonomously reconfigure deployments by migrating services, adjusting flavour selections, or rebalancing workloads, successfully achieving an optimal balance among resilience, efficiency, and environmental impact.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [The Anatomy of a Successful Student Scrum Team: Motivation, Personalities, and Academic Adaptation](https://arxiv.org/abs/2601.03364)
*Nadia Damianova,Santiago Berrezueta-Guzman*

Main category: cs.SE

TL;DR: 本研究通过一年的案例分析，探讨学生团队在学术与混合工作限制下如何调整Scrum实践以维持协作与生产力。


<details>
  <summary>Details</summary>
Motivation: 填补敏捷方法（尤其是Scrum）在长期学生项目中实际运作效果的实证研究空白。

Method: 对八人学生团队进行定性观察，结合Discord、Notion、GitHub等工具数据及自定义沟通效率指数进行多维度评估。

Result: 轻量级工具协调、一周冲刺周期与灵活仪式有效适应学术节奏；团队动机、角色清晰与工作风格兼容性至关重要。

Conclusion: 为教育者和学生团队在混合式项目学习中采用敏捷方法提供实用建议。

Abstract: Agile methods, and Scrum in particular, are widely taught in software engineering education; however, there is limited empirical evidence on how these practices function in long-running, student-led projects under academic and hybrid work constraints. This paper presents a year-long case study of an eight-person student development team tasked with designing and implementing a virtual reality game that simulates a university campus and provides program-related educational content. We analyze how the team adapted Scrum practices (sprint structure, roles, backlog management) to fit semester rhythms, exams, travel, and part-time availability, and how communication and coordination were maintained in a hybrid on-site/remote environment. Using qualitative observations and artifacts from Discord, Notion, and GitHub, as well as contribution metrics and a custom communication effectiveness index (score: 0.76/1.00), we evaluate three dimensions: (1) the effectiveness of collaboration tools, (2) the impact of hybrid work on communication and productivity, and (3) the feasibility of aligning Scrum with academic timelines. Our findings show that (i) lightweight, tool-mediated coordination enabled stable progress even during remote periods; (ii) one-week sprints and flexible ceremonies helped reconcile Scrum with academic obligations; and (iii) shared motivation, role clarity, and compatible working styles were as critical as process mechanics. We propose practical recommendations for instructors and student teams adopting agile methods in hybrid, project-based learning settings.

</details>


### [5] [An Empirical Analysis of Community and Coding Patterns in OSS4SG vs. Conventional OSS](https://arxiv.org/abs/2601.03430)
*Mohamed Ouf,Shayan Noei,Zeph Van Iterson,Mariam Guizani,Ying Zou*

Main category: cs.SE

TL;DR: 该研究比较了开源软件用于社会公益（OSS4SG）与传统开源项目在社区结构、贡献者参与和编码实践上的差异，发现OSS4SG社区更稳定、全年活跃且依赖核心贡献者。


<details>
  <summary>Details</summary>
Motivation: 探索使命驱动型开源项目（OSS4SG）如何因其社会目标影响开发实践，填补现有研究空白。

Method: 对1039个GitHub仓库（含422个OSS4SG与617个传统OSS）进行大规模实证分析，对比其社区结构、贡献模式与编码行为。

Result: OSS4SG项目拥有更稳定（63.4%“黏性”）的社区，全年持续活跃；传统OSS则更具“磁性”（75.4%），吸引高流动贡献者，并呈现季节性波动。OSS4SG高度依赖核心成员兼顾代码与问题解决，传统OSS则由核心成员专注代码质量，外围成员处理问题。

Conclusion: OSS4SG项目的使命导向塑造了独特而稳定的协作模式，这对保障其可持续性与社会影响力具有重要启示。

Abstract: Open Source Software for Social Good (OSS4SG) projects aim to address critical societal challenges, such as healthcare access and community safety. Understanding the community dynamics and contributor patterns in these projects is essential for ensuring their sustainability and long-term impact. However, while extensive research has focused on conventional Open Source Software (OSS), little is known about how the mission-driven nature of OSS4SG influences its development practices. To address this gap, we conduct a large-scale empirical study of 1,039 GitHub repositories, comprising 422 OSS4SG and 617 conventional OSS projects, to compare community structure, contributor engagement, and coding practices. Our findings reveal that OSS4SG projects foster significantly more stable and "sticky" (63.4%) communities, whereas conventional OSS projects are more "magnetic" (75.4%), attracting a high turnover of contributors. OSS4SG projects also demonstrate consistent engagement throughout the year, while conventional OSS communities exhibit seasonal fluctuations. Additionally, OSS4SG projects rely heavily on core contributors for both code quality and issue resolution, while conventional OSS projects leverage casual contributors for issue resolution, with core contributors focusing primarily on code quality.

</details>


### [6] [CodeEval: A pedagogical approach for targeted evaluation of code-trained Large Language Models](https://arxiv.org/abs/2601.03432)
*Danny Brahman,Mohammad Mahoor*

Main category: cs.SE

TL;DR: 本文提出CodeEval和RunCodeEval，用于多维度评估大语言模型在Python编程中的代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准数据集无法精准定位模型在代码生成中的优缺点，阻碍针对性改进。

Method: 构建涵盖24个维度、三个难度级别的CodeEval数据集，并开发配套开源执行框架RunCodeEval。

Result: 该方法能细致分析模型在不同复杂度、问题类型和编程类别中的表现，提供可操作的改进方向。

Conclusion: CodeEval与RunCodeEval的结合有助于推动大语言模型编程能力的精准评估与提升。

Abstract: Large Language Models (LLMs) are predominantly assessed based on their common sense reasoning, language comprehension, and logical reasoning abilities. While models trained in specialized domains like mathematics or coding have demonstrated remarkable advancements in logical reasoning, there remains a significant gap in evaluating their code generation capabilities. Existing benchmark datasets fall short in pinpointing specific strengths and weaknesses, impeding targeted enhancements in models' reasoning abilities to synthesize code. To bridge this gap, our paper introduces an innovative, pedagogical benchmarking method that mirrors the evaluation processes encountered in academic programming courses. We introduce CodeEval, a multi-dimensional benchmark dataset designed to rigorously evaluate LLMs across 24 distinct aspects of Python programming. The dataset covers three proficiency levels - beginner, intermediate, and advanced - and includes both class-based and function-based problem types with detailed problem specifications and comprehensive test suites. To facilitate widespread adoption, we also developed RunCodeEval, an open-source execution framework that provides researchers with a ready-to-use evaluation pipeline for CodeEval. RunCodeEval handles test execution, context setup, and metrics generation, enabling researchers to quickly obtain detailed insights into model strengths and weaknesses across complexity levels, problem types, and programming categories. This combination enables targeted evaluation and guides improvements in LLMs' programming proficiencies.

</details>


### [7] [Bootstrapping Code Translation with Weighted Multilanguage Exploration](https://arxiv.org/abs/2601.03512)
*Yuhan Wu,Huan Zhang,Wei Cheng,Chen Shen,Jingyue Yang,Wei Hu*

Main category: cs.SE

TL;DR: BootTrans是一种通过引导式方法解决代码翻译中数据稀缺和优化不平衡问题的新框架。


<details>
  <summary>Details</summary>
Motivation: 现有代码翻译面临平行数据稀缺和多语言对优化不平衡的挑战。

Method: 利用测试套件的功能不变性，构建双池架构进行数据扩展，并引入语言感知加权机制动态优化翻译方向。

Result: 在HumanEval-X和TransCoder-Test基准上显著优于基线模型，消融实验证明各组件有效。

Conclusion: BootTrans为多语言代码翻译提供了一种高效且可扩展的解决方案。

Abstract: Code translation across multiple programming languages is essential yet challenging due to two vital obstacles: scarcity of parallel data paired with executable test oracles, and optimization imbalance when handling diverse language pairs. We propose BootTrans, a bootstrapping method that resolves both obstacles. Its key idea is to leverage the functional invariance and cross-lingual portability of test suites, adapting abundant pivot-language unit tests to serve as universal verification oracles for multilingual RL training. Our method introduces a dual-pool architecture with seed and exploration pools to progressively expand training data via execution-guided experience collection. Furthermore, we design a language-aware weighting mechanism that dynamically prioritizes harder translation directions based on relative performance across sibling languages, mitigating optimization imbalance. Extensive experiments on the HumanEval-X and TransCoder-Test benchmarks demonstrate substantial improvements over baseline LLMs across all translation directions, with ablations validating the effectiveness of both bootstrapping and weighting components.

</details>


### [8] [On the Robustness of Fairness Practices: A Causal Framework for Systematic Evaluation](https://arxiv.org/abs/2601.03621)
*Verya Monjezi,Ashish Kumar,Ashutosh Trivedi,Gang Tan,Saeid Tizpaz-Niari*

Main category: cs.SE

TL;DR: 本文探讨了机器学习算法在社会经济应用中的公平性问题，评估现有公平性干预措施在数据缺陷或分布变化下的可靠性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于机器学习算法可能对边缘群体造成不公平影响，亟需评估当前公平性实践在现实复杂数据环境中的有效性。

Method: 通过分析现有公平性干预方法（如敏感特征处理、偏差缓解器等）在标签错误、数据缺失和分布偏移情况下的表现，评估其鲁棒性和通用性。

Result: 现有公平性推荐实践在理想数据条件下有效，但在数据缺陷或分布变化下效果不稳定，泛化能力有限。

Conclusion: 开发数据驱动系统时，不能盲目依赖当前公平性最佳实践，需结合具体数据环境进行适应性调整与验证。

Abstract: Machine learning (ML) algorithms are increasingly deployed to make critical decisions in socioeconomic applications such as finance, criminal justice, and autonomous driving. However, due to their data-driven and pattern-seeking nature, ML algorithms may develop decision logic that disproportionately distributes opportunities, benefits, resources, or information among different population groups, potentially harming marginalized communities. In response to such fairness concerns, the software engineering and ML communities have made significant efforts to establish the best practices for creating fair ML software. These include fairness interventions for training ML models, such as including sensitive features, selecting non-sensitive attributes, and applying bias mitigators. But how reliably can software professionals tasked with developing data-driven systems depend on these recommendations? And how well do these practices generalize in the presence of faulty labels, missing data, or distribution shifts? These questions form the core theme of this paper.

</details>


### [9] [Verbatim Data Transcription Failures in LLM Code Generation: A State-Tracking Stress Test](https://arxiv.org/abs/2601.03640)
*Mohd Ariful Haque,Kishor Datta Gupta,Mohammad Ashiqur Rahman,Roy George*

Main category: cs.SE

TL;DR: 该论文提出一个最小化基准测试，用于评估大语言模型在代码生成中精确转录数据的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现实软件任务常需将数据精确转录为代码，微小错误可能导致严重后果，因此需专门评估模型在此类任务中的表现。

Method: 设计高精度小数列表转Python代码的任务，通过字符串精确匹配评估模型输出，并分析其状态跟踪与长程生成失败。

Result: 该基准可作为现有代码生成评测的补充，专注于数据完整性而非算法推理能力。

Conclusion: 此紧凑压力测试有助于揭示LLM在敏感操作任务中的可靠性缺陷。

Abstract: Many real-world software tasks require exact transcription of provided data into code, such as cryptographic constants, protocol test vectors, allowlists, and calibration tables. These tasks are operationally sensitive because small omissions or alterations can remain silent while producing syntactically valid programs. This paper introduces a deliberately minimal transcription-to-code benchmark to isolate this reliability concern in LLM-based code generation. Given a list of high-precision decimal constants, a model must generate Python code that embeds the constants verbatim and performs a simple aggregate computation. We describe the prompting variants, evaluation protocol based on exact-string inclusion, and analysis framework used to characterize state-tracking and long-horizon generation failures. The benchmark is intended as a compact stress test that complements existing code-generation evaluations by focusing on data integrity rather than algorithmic reasoning.

</details>


### [10] [From Laboratory to Real-World Applications: Benchmarking Agentic Code Reasoning at the Repository Level](https://arxiv.org/abs/2601.03731)
*Jia Li,Yuxin Su,Michael R. Lyu*

Main category: cs.SE

TL;DR: RepoReason是一个用于评估大型语言模型在仓库级别推理能力的白盒诊断基准，通过动态程序切片和三个正交指标量化模型表现。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试在孤立代码片段和黑盒评估之间波动，无法有效衡量模型在真实复杂文件系统中的逻辑一致性能力。

Method: 提出执行驱动的变异框架与动态程序切片技术，结合ESV、MCL、DFI三项指标进行细粒度诊断。

Result: 前沿模型普遍存在聚合缺陷，其中集成宽度是主要认知瓶颈。

Conclusion: 本研究为下一代智能体软件工程优化提供了细粒度的白盒洞察。

Abstract: As large language models (LLMs) evolve into autonomous agents, evaluating repository-level reasoning, the ability to maintain logical consistency across massive, real-world, interdependent file systems, has become critical. Current benchmarks typically fluctuate between isolated code snippets and black-box evaluations. We present RepoReason, a white-box diagnostic benchmark centered on abductive assertion verification. To eliminate memorization while preserving authentic logical depth, we implement an execution-driven mutation framework that utilizes the environment as a semantic oracle to regenerate ground-truth states. Furthermore, we establish a fine-grained diagnostic system using dynamic program slicing, quantifying reasoning via three orthogonal metrics: $ESV$ (reading load), $MCL$ (simulation depth), and $DFI$ (integration width). Comprehensive evaluations of frontier models (e.g., Claude-4.5-Sonnet, DeepSeek-v3.1-Terminus) reveal a prevalent aggregation deficit, where integration width serves as the primary cognitive bottleneck. Our findings provide granular white-box insights for optimizing the next generation of agentic software engineering.

</details>


### [11] [Assessing and Improving the Representativeness of Code Generation Benchmarks Using Knowledge Units (KUs) of Programming Languages -- An Empirical Study](https://arxiv.org/abs/2601.03780)
*Md Ahasanuzzaman,Bram Adams,Emad Fallahzadeh,Gustavo A. Oliva,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 该论文首次通过知识单元（KU）分析主流代码生成基准的代表性，发现其覆盖不足且分布偏斜，提出基于LLM的任务合成框架以增强基准，结果表明现有模型性能被高估。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成基准未系统评估其是否覆盖真实项目中的编程概念，可能导致对LLM能力的误判。

Method: 定义知识单元（KU），对比HumanEval与MBPP基准和30个真实项目中的KU分布，设计LLM提示框架合成新任务以平衡分布。

Result: 基准仅覆盖50% KU且分布偏斜；新框架生成440任务，使KU覆盖率显著提升，分布对齐度提高60%以上；LLM在增强基准上性能下降12.54-44.82%。

Conclusion: 当前基准因KU覆盖有限而高估LLM代码生成能力，需构建更贴近真实场景的评估体系。

Abstract: Large Language Models (LLMs) such as GPT-4, Claude and LLaMA have shown impressive performance in code generation, typically evaluated using benchmarks (e.g., HumanEval). However, effective code generation requires models to understand and apply a wide range of language concepts. If the concepts exercised in benchmarks are not representative of those used in real-world projects, evaluations may yield incomplete. Despite this concern, the representativeness of code concepts in benchmarks has not been systematically examined.
  To address this gap, we present the first empirical study that analyzes the representativeness of code generation benchmarks through the lens of Knowledge Units (KUs) - cohesive sets of programming language capabilities provided by language constructs and APIs. We analyze KU coverage in two widely used Python benchmarks, HumanEval and MBPP, and compare them with 30 real-world Python projects. Our results show that each benchmark covers only half of the identified 20 KUs, whereas projects exercise all KUs with relatively balanced distributions. In contrast, benchmark tasks exhibit highly skewed KU distributions.
  To mitigate this misalignment, we propose a prompt-based LLM framework that synthesizes KU-based tasks to rebalance benchmark KU distributions and better align them with real-world usage. Using this framework, we generate 440 new tasks and augment existing benchmarks. The augmented benchmarks substantially improve KU coverage and achieve over a 60% improvement in distributional alignment. Evaluations of state-of-the-art LLMs on these augmented benchmarks reveal consistent and statistically significant performance drops (12.54-44.82%), indicating that existing benchmarks overestimate LLM performance due to their limited KU coverage. Our findings provide actionable guidance for building more realistic evaluations of LLM code-generation capabilities.

</details>


### [12] [Once Upon a Team: Investigating Bias in LLM-Driven Software Team Composition and Task Allocation](https://arxiv.org/abs/2601.03857)
*Alessandra Parziale,Gianmario Voria,Valeria Pontillo,Amleto Di Salle,Patrizio Pelliccione,Gemma Catolino,Fabio Palomba*

Main category: cs.SE

TL;DR: 研究发现大语言模型在团队组成和任务分配中存在系统性偏见，加剧了软件工程领域的不平等。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型在涉及社会敏感决策时是否会产生偏见，尤其是在团队构成与任务分配场景中。

Method: 通过三个大语言模型模拟3000次决策，分析候选人国籍与代词组合对结果的影响。

Result: 模型输出显示人口统计属性显著影响选择概率与任务分配，技术与领导角色分布呈现刻板印象差异。

Conclusion: 大语言模型在软件工程应用中会加剧人口不平等，亟需引入公平性评估机制。

Abstract: LLMs are increasingly used to boost productivity and support software engineering tasks. However, when applied to socially sensitive decisions such as team composition and task allocation, they raise concerns of fairness. Prior studies have revealed that LLMs may reproduce stereotypes; however, these analyses remain exploratory and examine sensitive attributes in isolation. This study investigates whether LLMs exhibit bias in team composition and task assignment by analyzing the combined effects of candidates' country and pronouns. Using three LLMs and 3,000 simulated decisions, we find systematic disparities: demographic attributes significantly shaped both selection likelihood and task allocation, even when accounting for expertise-related factors. Task distributions further reflected stereotypes, with technical and leadership roles unevenly assigned across groups. Our findings indicate that LLMs exacerbate demographic inequities in software engineering contexts, underscoring the need for fairness-aware assessment.

</details>


### [13] [Understanding Specification-Driven Code Generation with LLMs: An Empirical Study Design](https://arxiv.org/abs/2601.03878)
*Giovanni Rosa,David Moreno-Lumbreras,Gregorio Robles,Jesús M. González-Barahona*

Main category: cs.SE

TL;DR: 本研究通过CURRANTE工具实证分析人类在LLM辅助编程中对规范与测试的干预如何影响代码生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前对LLM在结构化开发流程中的行为理解不足，需探究人机协作机制以优化下一代开发环境。

Method: 使用VS Code扩展CURRANTE引导开发者分三阶段（规范、测试、函数）完成LiveCodeBench中等难度题目，记录交互日志与效能指标。

Result: 将量化人类干预对LLM生成代码的通过率、耗时及迭代行为的影响，尚未公布具体数据。

Conclusion: 研究成果将为融合人类推理与模型驱动的开发环境设计提供实证依据。

Abstract: Large Language Models (LLMs) are increasingly integrated into software development workflows, yet their behavior in structured, specification-driven processes remains poorly understood. This paper presents an empirical study design using CURRANTE, a Visual Studio Code extension that enables a human-in-the-loop workflow for LLM-assisted code generation. The tool guides developers through three sequential stages--Specification, Tests, and Function--allowing them to define requirements, generate and refine test suites, and produce functions that satisfy those tests. Participants will solve medium-difficulty problems from the LiveCodeBench dataset, while the tool records fine-grained interaction logs, effectiveness metrics (e.g., pass rate, all-pass completion), efficiency indicators (e.g., time-to-pass), and iteration behaviors. The study aims to analyze how human intervention in specification and test refinement influences the quality and dynamics of LLM-generated code. The results will provide empirical insights into the design of next-generation development environments that align human reasoning with model-driven code generation.

</details>


### [14] [Using Small Language Models to Reverse-Engineer Machine Learning Pipelines Structures](https://arxiv.org/abs/2601.03988)
*Nicolas Lacroix,Mireille Blay-Fornarino,Sébastien Mosser,Frederic Precioso*

Main category: cs.SE

TL;DR: 本文评估小型语言模型（SLMs）在识别机器学习管道阶段中的有效性，以克服现有方法的局限性并深化对数据科学实践的理解。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖人工标注或无法应对ML领域多样性的分类器，亟需更灵活可靠的解决方案。

Method: 通过Cochran's Q检验比较多个SLMs，用McNemar检验与参考研究对比，再分析分类法变化的影响，并用卡方检验比较实践洞察。

Result: SLMs在代码理解和分类任务中表现优异，能有效支持对数据科学实践的深入理解。

Conclusion: SLMs是解决ML管道结构提取挑战的有前景方案，有助于推动数据科学实践的研究。

Abstract: Background: Extracting the stages that structure Machine Learning (ML) pipelines from source code is key for gaining a deeper understanding of data science practices. However, the diversity caused by the constant evolution of the ML ecosystem (e.g., algorithms, libraries, datasets) makes this task challenging. Existing approaches either depend on non-scalable, manual labeling, or on ML classifiers that do not properly support the diversity of the domain. These limitations highlight the need for more flexible and reliable solutions.
  Objective: We evaluate whether Small Language Models (SLMs) can leverage their code understanding and classification abilities to address these limitations, and subsequently how they can advance our understanding of data science practices.
  Method: We conduct a confirmatory study based on two reference works selected for their relevance regarding current state-of-the-art's limitations. First, we compare several SLMs using Cochran's Q test. The best-performing model is then evaluated against the reference studies using two distinct McNemar's tests. We further analyze how variations in taxonomy definitions affect performance through an additional Cochran's Q test. Finally, a goodness-of-fit analysis is conducted using Pearson's chi-squared tests to compare our insights on data science practices with those from prior studies.

</details>


### [15] [An Ontology-Based Approach to Security Risk Identification of Container Deployments in OT Contexts](https://arxiv.org/abs/2601.04010)
*Yannick Landeck,Dian Balta,Martin Wimmer,Christian Knierim*

Main category: cs.SE

TL;DR: 提出基于本体的容器安全风险评估方法CSRO，实现自动化、可复现的风险识别。


<details>
  <summary>Details</summary>
Motivation: OT环境中容器权限过高导致隔离性下降，现有方法缺乏可复现性和跨上下文解释能力。

Method: 构建整合五个关键领域的本体模型CSRO：对抗行为、上下文假设、攻击场景、风险评估规则与容器安全工件。

Result: 案例研究表明CSRO能从工件到风险级别端到端形式化计算，实现自动化风险识别。

Conclusion: CSRO当前聚焦容器级技术措施，其模块化设计为扩展至主机级和组织级风险因素奠定基础。

Abstract: In operational technology (OT) contexts, containerised applications often require elevated privileges to access low-level network interfaces or perform administrative tasks such as application monitoring. These privileges reduce the default isolation provided by containers and introduce significant security risks. Security risk identification for OT container deployments is challenged by hybrid IT/OT architectures, fragmented stakeholder knowledge, and continuous system changes. Existing approaches lack reproducibility, interpretability across contexts, and technical integration with deployment artefacts. We propose a model-based approach, implemented as the Container Security Risk Ontology (CSRO), which integrates five key domains: adversarial behaviour, contextual assumptions, attack scenarios, risk assessment rules, and container security artefacts. Our evaluation of CSRO in a case study demonstrates that the end-to-end formalisation of risk calculation, from artefact to risk level, enables automated and reproducible risk identification. While CSRO currently focuses on technical, container-level treatment measures, its modular and flexible design provides a solid foundation for extending the approach to host-level and organisational risk factors.

</details>


### [16] [Smells Depend on the Context: An Interview Study of Issue Tracking Problems and Smells in Practice](https://arxiv.org/abs/2601.04124)
*Lloyd Montgomery,Clara Lüders,Christian Rahe,Walid Maalej*

Main category: cs.SE

TL;DR: 本文通过访谈26位软件工程从业者，识别出14个常见问题及31种ITS异味的实际影响，强调其高度依赖上下文，并提出工具化解决方案。


<details>
  <summary>Details</summary>
Motivation: 填补当前对软件团队在问题跟踪系统中实际挑战和异味实践研究的空白。

Method: 采用主题分析法对26位从业者的深度访谈数据进行归纳分析。

Result: 识别出如问题可发现性、僵尸问题等14类常见问题，多数文献提及的异味在实践中并不普遍或不构成问题。

Conclusion: ITS问题与异味高度依赖团队规模、工作流阶段等上下文因素，需定制化工具支持监控与可视化。

Abstract: Issue Tracking Systems (ITSs) enable software developers and managers to collect and resolve issues collaboratively. While researchers have extensively analysed ITS data to automate or assist specific activities such as issue assignments, duplicate detection, or priority prediction, developer studies on ITSs remain rare. Particularly, little is known about the challenges Software Engineering (SE) teams encounter in ITSs and when certain practices and workarounds (such as leaving issue fields like "priority" empty) are considered problematic. To fill this gap, we conducted an in-depth interview study with 26 experienced SE practitioners from different organisations and industries. We asked them about general problems encountered, as well as the relevance of 31 ITS smells (aka potentially problematic practices) discussed in the literature. By applying Thematic Analysis to the interview notes, we identified 14 common problems including issue findability, zombie issues, workflow bloat, and lack of workflow enforcement. Participants also stated that many of the ITS smells do not occur or are not problematic. Our results suggest that ITS problems and smells are highly dependent on context factors such as ITS configuration, workflow stage, and team size. We also discuss potential tooling solutions to configure, monitor, and visualise ITS smells to cope with these challenges.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [17] [PC2P: Multi-Agent Path Finding via Personalized-Enhanced Communication and Crowd Perception](https://arxiv.org/abs/2601.03301)
*Guotao Li,Shaoyun Xu,Yuexing Hao,Yang Wang,Yuhui Sun*

Main category: cs.MA

TL;DR: PC2P是一种基于Q学习的分布式多智能体路径规划方法，通过个性化通信机制、局部人群感知和区域死锁解除策略，在多种环境中实现优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有分布式MAPF方法因协作与感知能力不足，难以适应多样环境，亟需提升可扩展性与实时决策能力。

Method: 提出PC2P框架：1）基于动态图拓扑的三阶段（选择、生成、聚合）个性化通信机制；2）融合静态空间约束与动态占用变化的局部人群感知；3）基于专家指导的区域死锁解除策略。

Result: 实验表明PC2P在多种环境下性能优于现有分布式MAPF方法，消融研究验证各模块有效性。

Conclusion: PC2P有效提升了分布式多智能体在复杂环境中的协作路径规划能力，具备良好的可扩展性与实用性。

Abstract: Distributed Multi-Agent Path Finding (MAPF) integrated with Multi-Agent Reinforcement Learning (MARL) has emerged as a prominent research focus, enabling real-time cooperative decision-making in partially observable environments through inter-agent communication. However, due to insufficient collaborative and perceptual capabilities, existing methods are inadequate for scaling across diverse environmental conditions. To address these challenges, we propose PC2P, a novel distributed MAPF method derived from a Q-learning-based MARL framework. Initially, we introduce a personalized-enhanced communication mechanism based on dynamic graph topology, which ascertains the core aspects of ``who" and ``what" in interactive process through three-stage operations: selection, generation, and aggregation. Concurrently, we incorporate local crowd perception to enrich agents' heuristic observation, thereby strengthening the model's guidance for effective actions via the integration of static spatial constraints and dynamic occupancy changes. To resolve extreme deadlock issues, we propose a region-based deadlock-breaking strategy that leverages expert guidance to implement efficient coordination within confined areas. Experimental results demonstrate that PC2P achieves superior performance compared to state-of-the-art distributed MAPF methods in varied environments. Ablation studies further confirm the effectiveness of each module for overall performance.

</details>


### [18] [A Chromatographic Process Design and Optimization Platform Powered by Large Language Models: A Case Application on Extract of Ginkgo Biloba Leaf](https://arxiv.org/abs/2601.03702)
*Zhilong Tang,Shaohua Wu,Xinyan Zhao,Yu Wang,Xingchu Gong*

Main category: cs.MA

TL;DR: ChromR是一个基于大语言模型的色谱工艺设计与优化平台，通过多智能体系统和自动化设备实现全流程智能化，显著缩短开发周期并减少人工依赖。


<details>
  <summary>Details</summary>
Motivation: 传统色谱工艺开发依赖专家经验、周期长、劳动强度大，亟需智能化解决方案提升效率。

Method: 构建专用大语言模型ChromLLM，结合四模块多智能体系统（知识问答、实验设计、执行、数据分析）与自动化色谱装置，实现参数推荐、实验、分析与优化全流程自动化。

Result: 以银杏叶提取物纯化为例，ChromR在一周内完成多目标优化工艺开发，耗时仅为传统方法的七分之一。

Conclusion: ChromR建立了智能、自动、通用的色谱工艺开发新范式，大幅降低对专家经验的依赖并提升开发效率。

Abstract: Chromatographic separation technology has been widely applied in pharmaceutical, chemical, and food industries due to its high efficiency. However, traditional human-dependent chromatographic process development faces challenges such as reliance on expert experience, long development cycles, and labor intensity. ChromR, a large language model (LLM)-driven platform for chromatographic process design and optimization, is presented in this work. The platform integrates ChromLLM, a domain-specific LLM trained for chromatography, along with a multi-agent system and an automated chromatographic experimental device. The multi-agent system comprises four agents: domain knowledge answering, experimental design, experimental execution, and data analysis. ChromR enables automatic completion of the entire workflow-including initial process parameter recommendation, experimental design, automated execution, data analysis, and multi-objective optimization. By utilizing ChromR, dependency on expert knowledge is effectively reduced, while labor input and development time are significantly decreased. Chromatographic purification of the extract of Ginkgo biloba leaf (EGBL) was selected as a case study. ChromR successfully developed a chromatographic process within one week that meets multiple objectives, including fraction quality and production efficiency, reducing development time to approximately one-seventh of that required by the conventional paradigm. An intelligent, automated, and universally applicable new paradigm was established for chromatographic process development.

</details>


### [19] [When Numbers Start Talking: Implicit Numerical Coordination Among LLM-Based Agents](https://arxiv.org/abs/2601.03846)
*Alessio Buscemi,Daniele Proverbio,Alessandro Di Stefano,The Anh Han,German Castignani,Pietro Liò*

Main category: cs.MA

TL;DR: 本文研究了基于大语言模型的多智能体系统中隐性通信的博弈论分析，探讨了不同通信机制下隐性信号如何影响协调与策略结果。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注显式通信或多智能体个体行为，对隐性协调机制缺乏深入理解。

Method: 采用博弈论框架，在四种典型博弈场景下，结合不同通信模式、智能体个性及单次/重复博弈设置进行分析。

Result: 揭示了隐性信号在特定条件下如何自发产生，并有效塑造多智能体间的协调行为与策略均衡。

Conclusion: 隐性通信是LLM驱动多智能体系统中实现高效协调的重要机制，其效果受通信限制、智能体异质性及交互频率影响。

Abstract: LLMs-based agents increasingly operate in multi-agent environments where strategic interaction and coordination are required. While existing work has largely focused on individual agents or on interacting agents sharing explicit communication, less is known about how interacting agents coordinate implicitly. In particular, agents may engage in covert communication, relying on indirect or non-linguistic signals embedded in their actions rather than on explicit messages. This paper presents a game-theoretic study of covert communication in LLM-driven multi-agent systems. We analyse interactions across four canonical game-theoretic settings under different communication regimes, including explicit, restricted, and absent communication. Considering heterogeneous agent personalities and both one-shot and repeated games, we characterise when covert signals emerge and how they shape coordination and strategic outcomes.

</details>
