{"id": "2512.16956", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16956", "abs": "https://arxiv.org/abs/2512.16956", "authors": ["Shravan Chaudhari", "Rahul Thomas Jacob", "Mononito Goswami", "Jiajun Cao", "Shihab Rashid", "Christian Bock"], "title": "SpIDER: Spatially Informed Dense Embedding Retrieval for Software Issue Localization", "comment": "Initial preprint", "summary": "Retrieving code units (e.g., files, classes, functions) that are semantically relevant to a given user query, bug report, or feature request from large codebases is a fundamental challenge for LLM-based coding agents. Agentic approaches typically employ sparse retrieval methods like BM25 or dense embedding strategies to identify relevant units. While embedding-based approaches can outperform BM25 by large margins, they often lack exploration of the codebase and underutilize its underlying graph structure. To address this, we propose SpIDER (Spatially Informed Dense Embedding Retrieval), an enhanced dense retrieval approach that incorporates LLM-based reasoning over auxiliary context obtained through graph-based exploration of the codebase. Empirical results show that SpIDER consistently improves dense retrieval performance across several programming languages.", "AI": {"tldr": "SpIDER\u662f\u4e00\u79cd\u7ed3\u5408\u56fe\u7ed3\u6784\u63a2\u7d22\u548cLLM\u63a8\u7406\u7684\u589e\u5f3a\u578b\u7a20\u5bc6\u68c0\u7d22\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4ee3\u7801\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7a20\u5bc6\u68c0\u7d22\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u4ee3\u7801\u5e93\u56fe\u7ed3\u6784\u7684\u63a2\u7d22\u548c\u5229\u7528\uff0c\u9650\u5236\u4e86\u68c0\u7d22\u6548\u679c\u3002", "method": "\u63d0\u51faSpIDER\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fe\u7ed3\u6784\u63a2\u7d22\u83b7\u53d6\u8f85\u52a9\u4e0a\u4e0b\u6587\uff0c\u5e76\u7ed3\u5408LLM\u63a8\u7406\u589e\u5f3a\u7a20\u5bc6\u68c0\u7d22\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSpIDER\u5728\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u4e2d\u5747\u80fd\u7a33\u5b9a\u63d0\u5347\u7a20\u5bc6\u68c0\u7d22\u6027\u80fd\u3002", "conclusion": "SpIDER\u6709\u6548\u5f25\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u5bf9\u4ee3\u7801\u5e93\u7ed3\u6784\u4fe1\u606f\u5229\u7528\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u662f\u66f4\u4f18\u7684\u4ee3\u7801\u68c0\u7d22\u65b9\u6848\u3002"}}
{"id": "2512.17334", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.17334", "abs": "https://arxiv.org/abs/2512.17334", "authors": ["Zhi Ma", "Cheng Wen", "Zhexin Su", "Xiao Liang", "Cong Tian", "Shengchao Qin", "Mengfei Yang"], "title": "Bridging Natural Language and Formal Specification--Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs", "comment": null, "summary": "Automating the translation of natural language (NL) software requirements into formal specifications remains a critical challenge in scaling formal verification practices to industrial settings, particularly in safety-critical domains. Existing approaches, both rule-based and learning-based, face significant limitations. While large language models (LLMs) like GPT-4o demonstrate proficiency in semantic extraction, they still encounter difficulties in addressing the complexity, ambiguity, and logical depth of real-world industrial requirements. In this paper, we propose Req2LTL, a modular framework that bridges NL and Linear Temporal Logic (LTL) through a hierarchical intermediate representation called OnionL. Req2LTL leverages LLMs for semantic decomposition and combines them with deterministic rule-based synthesis to ensure both syntactic validity and semantic fidelity. Our comprehensive evaluation demonstrates that Req2LTL achieves 88.4% semantic accuracy and 100% syntactic correctness on real-world aerospace requirements, significantly outperforming existing methods.", "AI": {"tldr": "Req2LTL\u6846\u67b6\u901a\u8fc7\u4e2d\u95f4\u8868\u793aOnionL\u7ed3\u5408LLM\u4e0e\u89c4\u5219\u65b9\u6cd5\uff0c\u9ad8\u6548\u51c6\u786e\u5730\u5c06\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u8f6c\u4e3aLTL\u5f62\u5f0f\u5316\u89c4\u8303\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5de5\u4e1a\u7ea7\u9700\u6c42\u7684\u590d\u6742\u6027\u4e0e\u6b67\u4e49\u6027\uff0c\u963b\u788d\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5728\u5173\u952e\u9886\u57df\u7684\u89c4\u6a21\u5316\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u6846\u67b6Req2LTL\uff0c\u5229\u7528LLM\u8fdb\u884c\u8bed\u4e49\u5206\u89e3\uff0c\u7ed3\u5408\u786e\u5b9a\u6027\u89c4\u5219\u5408\u6210\u786e\u4fdd\u8bed\u6cd5\u6b63\u786e\u4e0e\u8bed\u4e49\u4fdd\u771f\u3002", "result": "\u5728\u822a\u7a7a\u822a\u5929\u771f\u5b9e\u9700\u6c42\u4e0a\u8fbe\u523088.4%\u8bed\u4e49\u51c6\u786e\u7387\u4e0e100%\u8bed\u6cd5\u6b63\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Req2LTL\u6709\u6548\u5f25\u5408\u81ea\u7136\u8bed\u8a00\u4e0e\u5f62\u5f0f\u903b\u8f91\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u5de5\u4e1a\u7ea7\u5f62\u5f0f\u5316\u9a8c\u8bc1\u63d0\u4f9b\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.16926", "categories": ["cs.DC", "cs.OS", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.16926", "abs": "https://arxiv.org/abs/2512.16926", "authors": ["Oren Bell", "Harun Teper", "Mario G\u00fcnzel", "Chris Gill", "Jian-Jia Chen"], "title": "Fixed-Priority and EDF Schedules for ROS2 Graphs on Uniprocessor", "comment": "18 pages, 5 figure", "summary": "This paper addresses limitations of current scheduling methods in the Robot Operating System (ROS)2, focusing on scheduling tasks beyond simple chains and analyzing arbitrary Directed Acyclic Graphs (DAGs). While previous research has focused mostly on chain-based scheduling with ad-hoc response time analyses, we propose a novel approach using the events executor to implement fixed-job-level-priority schedulers for arbitrary ROS2 graphs on uniprocessor systems. We demonstrate that ROS 2 applications can be abstracted as forests of trees, enabling the mapping of ROS 2 applications to traditional real-time DAG task models. Our usage of the events executor requires a special implementation of the events queue and a communication middleware that supports LIFO-ordered message delivery, features not yet standard in ROS2. We show that our implementation generates the same schedules as a conventional fixed-priority DAG task scheduler, in spite of lacking access to the precedence information that usually is required. This further closes the gap between established real-time systems theory and ROS2 scheduling analyses.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e8b\u4ef6\u6267\u884c\u5668\u7684\u56fa\u5b9a\u4f5c\u4e1a\u7ea7\u4f18\u5148\u7ea7\u8c03\u5ea6\u65b9\u6cd5\uff0c\u652f\u6301ROS2\u4e2d\u4efb\u610fDAG\u4efb\u52a1\u8c03\u5ea6\uff0c\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u8df5\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709ROS2\u8c03\u5ea6\u65b9\u6cd5\u5c40\u9650\u4e8e\u7b80\u5355\u94fe\u5f0f\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u4efb\u610fDAG\u7ed3\u6784\u7684\u652f\u6301\u548c\u4e25\u8c28\u5b9e\u65f6\u5206\u6790\u3002", "method": "\u5229\u7528\u4e8b\u4ef6\u6267\u884c\u5668\u5b9e\u73b0\u56fa\u5b9a\u4f5c\u4e1a\u7ea7\u4f18\u5148\u7ea7\u8c03\u5ea6\u5668\uff0c\u5c06ROS2\u5e94\u7528\u62bd\u8c61\u4e3a\u6811\u68ee\u6797\u5e76\u6620\u5c04\u5230\u4f20\u7edf\u5b9e\u65f6DAG\u6a21\u578b\uff0c\u9700\u5b9a\u5236LIFO\u6d88\u606f\u961f\u5217\u4e0e\u4e2d\u95f4\u4ef6\u3002", "result": "\u5728\u65e0\u524d\u7f6e\u4fe1\u606f\u6761\u4ef6\u4e0b\u751f\u6210\u4e0e\u4f20\u7edf\u56fa\u5b9a\u4f18\u5148\u7ea7DAG\u8c03\u5ea6\u5668\u4e00\u81f4\u7684\u8c03\u5ea6\u7ed3\u679c\uff0c\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5f25\u5408\u4e86\u7ecf\u5178\u5b9e\u65f6\u7cfb\u7edf\u7406\u8bba\u4e0eROS2\u5b9e\u9645\u8c03\u5ea6\u5206\u6790\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002"}}
{"id": "2512.17589", "categories": ["cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17589", "abs": "https://arxiv.org/abs/2512.17589", "authors": ["Yunhao Deng", "Fanchen Kong", "Xiaoling Yi", "Ryan Antonio", "Marian Verhelst"], "title": "Torrent: A Distributed DMA for Efficient and Flexible Point-to-Multipoint Data Movement", "comment": "7 pages, 11 figures, Proceeded by the 2026 Design, Automation and Test in Europe Conference (DATE 26)", "summary": "The growing disparity between computational power and on-chip communication bandwidth is a critical bottleneck in modern Systems-on-Chip (SoCs), especially for data-parallel workloads like AI. Efficient point-to-multipoint (P2MP) data movement, such as multicast, is essential for high performance. However, native multicast support is lacking in standard interconnect protocols. Existing P2MP solutions, such as multicast-capable Network-on-Chip (NoC), impose additional overhead to the network hardware and require modifications to the interconnect protocol, compromising scalability and compatibility.\n  This paper introduces Torrent, a novel distributed DMA architecture that enables efficient P2MP data transfers without modifying NoC hardware and interconnect protocol. Torrent conducts P2MP data transfers by forming logical chains over the NoC, where the data traverses through targeted destinations resembling a linked list. This Chainwrite mechanism preserves the P2P nature of every data transfer while enabling flexible data transfers to an unlimited number of destinations. To optimize the performance and energy consumption of Chainwrite, two scheduling algorithms are developed to determine the optimal chain order based on NoC topology.\n  Our RTL and FPGA prototype evaluations using both synthetic and real workloads demonstrate significant advantages in performance, flexibility, and scalability over network-layer multicast. Compared to the unicast baseline, Torrent achieves up to a 7.88x speedup. ASIC synthesis on 16nm technology confirms the architecture's minimal footprint in area (1.2%) and power (2.3%). Thanks to the Chainwrite, Torrent delivers scalable P2MP data transfers with a small cycle overhead of 82CC and area overhead of 207um2 per destination.", "AI": {"tldr": "Torrent\u662f\u4e00\u79cd\u65b0\u578b\u5206\u5e03\u5f0fDMA\u67b6\u6784\uff0c\u901a\u8fc7\u94fe\u5f0f\u5199\u5165\u673a\u5236\u5b9e\u73b0\u9ad8\u6548\u7684\u70b9\u5bf9\u591a\u70b9\u6570\u636e\u4f20\u8f93\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709NoC\u786c\u4ef6\u6216\u534f\u8bae\uff0c\u517c\u5177\u9ad8\u6027\u80fd\u3001\u4f4e\u5f00\u9500\u4e0e\u826f\u597d\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u4ee3SoC\u4e2d\u8ba1\u7b97\u80fd\u529b\u4e0e\u7247\u4e0a\u901a\u4fe1\u5e26\u5bbd\u7684\u5dee\u8ddd\u6210\u4e3a\u74f6\u9888\uff0c\u5c24\u5176\u5728AI\u7b49\u6570\u636e\u5e76\u884c\u8d1f\u8f7d\u4e2d\uff0c\u7f3a\u4e4f\u539f\u751f\u7ec4\u64ad\u652f\u6301\u7684\u6807\u51c6\u4e92\u8fde\u534f\u8bae\u9650\u5236\u4e86\u6027\u80fd\u3002", "method": "\u63d0\u51faTorrent\u67b6\u6784\uff0c\u5229\u7528\u903b\u8f91\u94fe\u5728NoC\u4e0a\u4f20\u8f93\u6570\u636e\uff0c\u4fdd\u6301\u70b9\u5bf9\u70b9\u7279\u6027\u540c\u65f6\u652f\u6301\u65e0\u9650\u76ee\u6807\u8282\u70b9\uff1b\u5e76\u8bbe\u8ba1\u4e24\u79cd\u8c03\u5ea6\u7b97\u6cd5\u4f18\u5316\u94fe\u987a\u5e8f\u4ee5\u63d0\u5347\u6027\u80fd\u4e0e\u80fd\u6548\u3002", "result": "\u5b9e\u6d4b\u663e\u793aTorrent\u76f8\u6bd4\u5355\u64ad\u57fa\u7ebf\u6700\u9ad8\u63d0\u901f7.88\u500d\uff0c16nm ASIC\u5b9e\u73b0\u4ec5\u53601.2%\u9762\u79ef\u548c2.3%\u529f\u8017\uff0c\u6bcf\u76ee\u6807\u8282\u70b9\u4ec5\u589e\u52a082\u5468\u671f\u548c207um\u00b2\u5f00\u9500\u3002", "conclusion": "Torrent\u5728\u4e0d\u6539\u52a8\u73b0\u6709\u786c\u4ef6\u548c\u534f\u8bae\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684P2MP\u6570\u636e\u4f20\u8f93\uff0c\u662f\u89e3\u51b3\u73b0\u4ee3SoC\u901a\u4fe1\u74f6\u9888\u7684\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.17060", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.17060", "abs": "https://arxiv.org/abs/2512.17060", "authors": ["Monika Zamojska", "Jaros\u0142aw A. Chudziak"], "title": "On the Role of Contextual Information and Ego States in LLM Agent Behavior for Transactional Analysis Dialogues", "comment": "Presented at the 39th Pacific Asia Conference on Language, Information and Computation (PACLIC 39)", "summary": "LLM-powered agents are now used in many areas, from customer support to education, and there is increasing interest in their ability to act more like humans. This includes fields such as social, political, and psychological research, where the goal is to model group dynamics and social behavior. However, current LLM agents often lack the psychological depth and consistency needed to capture the real patterns of human thinking. They usually provide direct or statistically likely answers, but they miss the deeper goals, emotional conflicts, and motivations that drive real human interactions. This paper proposes a Multi-Agent System (MAS) inspired by Transactional Analysis (TA) theory. In the proposed system, each agent is divided into three ego states - Parent, Adult, and Child. The ego states are treated as separate knowledge structures with their own perspectives and reasoning styles. To enrich their response process, they have access to an information retrieval mechanism that allows them to retrieve relevant contextual information from their vector stores. This architecture is evaluated through ablation tests in a simulated dialogue scenario, comparing agents with and without information retrieval. The results are promising and open up new directions for exploring how psychologically grounded structures can enrich agent behavior. The contribution is an agent architecture that integrates Transactional Analysis theory with contextual information retrieval to enhance the realism of LLM-based multi-agent simulations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4ea4\u4e92\u5206\u6790\u7406\u8bba\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u5212\u5206Parent\u3001Adult\u3001Child\u4e09\u79cd\u81ea\u6211\u72b6\u6001\u5e76\u7ed3\u5408\u4fe1\u606f\u68c0\u7d22\u673a\u5236\uff0c\u63d0\u5347LLM\u667a\u80fd\u4f53\u5728\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\u65f6\u7684\u5fc3\u7406\u6df1\u5ea6\u4e0e\u771f\u5b9e\u6027\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u7f3a\u4e4f\u5fc3\u7406\u6df1\u5ea6\u548c\u4e00\u81f4\u6027\uff0c\u96be\u4ee5\u771f\u5b9e\u6a21\u62df\u4eba\u7c7b\u601d\u7ef4\u6a21\u5f0f\u4e0e\u793e\u4f1a\u4e92\u52a8\uff0c\u56e0\u6b64\u9700\u8981\u5f15\u5165\u5fc3\u7406\u5b66\u7406\u8bba\u589e\u5f3a\u5176\u884c\u4e3a\u771f\u5b9e\u6027\u3002", "method": "\u6784\u5efa\u53d7\u4ea4\u4e92\u5206\u6790\u7406\u8bba\u542f\u53d1\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u5305\u542bParent\u3001Adult\u3001Child\u4e09\u4e2a\u72ec\u7acb\u77e5\u8bc6\u7ed3\u6784\uff0c\u5e76\u914d\u5907\u5411\u91cf\u5e93\u652f\u6301\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u68c0\u7d22\u673a\u5236\uff0c\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u8bc4\u4f30\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u67b6\u6784\u80fd\u6709\u6548\u63d0\u5347\u667a\u80fd\u4f53\u5bf9\u8bdd\u7684\u771f\u5b9e\u6027\uff0c\u4fe1\u606f\u68c0\u7d22\u673a\u5236\u5bf9\u8868\u73b0\u6709\u79ef\u6781\u5f71\u54cd\uff0c\u4e3a\u5fc3\u7406\u5b66\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u884c\u4e3a\u5efa\u6a21\u5f00\u8f9f\u65b0\u65b9\u5411\u3002", "conclusion": "\u878d\u5408\u4ea4\u4e92\u5206\u6790\u7406\u8bba\u4e0e\u4e0a\u4e0b\u6587\u68c0\u7d22\u7684\u667a\u80fd\u4f53\u67b6\u6784\u663e\u8457\u589e\u5f3a\u4e86LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6a21\u62df\u4eba\u7c7b\u5fc3\u7406\u548c\u793e\u4f1a\u884c\u4e3a\u65b9\u9762\u7684\u8868\u73b0\u529b\u4e0e\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2512.17158", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.17158", "abs": "https://arxiv.org/abs/2512.17158", "authors": ["Changfu Xu", "Jianxiong Guo", "Jiandian Zeng", "Houming Qiu", "Tian Wang", "Xiaowen Chu", "Jiannong Cao"], "title": "Enhancing AIGC Service Efficiency with Adaptive Multi-Edge Collaboration in A Distributed System", "comment": "16 pages", "summary": "The Artificial Intelligence Generated Content (AIGC) technique has gained significant traction for producing diverse content. However, existing AIGC services typically operate within a centralized framework, resulting in high response times. To address this issue, we integrate collaborative Mobile Edge Computing (MEC) technology to reduce processing delays for AIGC services. Current collaborative MEC methods primarily support single-server offloading or facilitate interactions among fixed Edge Servers (ESs), limiting flexibility and resource utilization across all ESs to meet the varying computing and networking requirements of AIGC services. We propose AMCoEdge, an adaptive multi-server collaborative MEC approach to enhancing AIGC service efficiency. The AMCoEdge fully utilizes the computing and networking resources across all ESs through adaptive multi-ES selection and dynamic workload allocation, thereby minimizing the offloading make-span of AIGC services. Our design features an online distributed algorithm based on deep reinforcement learning, accompanied by theoretical analyses that confirm an approximate linear time complexity. Simulation results show that our method outperforms state-of-the-art baselines, achieving at least an 11.04% reduction in task offloading make-span and a 44.86% decrease in failure rate. Additionally, we develop a distributed prototype system to implement and evaluate our AMCoEdge method for real AIGC service execution, demonstrating service delays that are 9.23% - 31.98% lower than the three representative methods.", "AI": {"tldr": "\u63d0\u51faAMCoEdge\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u591a\u670d\u52a1\u5668\u534f\u4f5cMEC\u4f18\u5316AIGC\u670d\u52a1\u6548\u7387\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u4e0e\u5931\u8d25\u7387\u3002", "motivation": "\u73b0\u6709AIGC\u670d\u52a1\u4f9d\u8d56\u4e2d\u5fc3\u5316\u67b6\u6784\uff0c\u54cd\u5e94\u5ef6\u8fdf\u9ad8\uff1b\u534f\u4f5cMEC\u65b9\u6848\u7075\u6d3b\u6027\u4e0e\u8d44\u6e90\u5229\u7528\u7387\u4e0d\u8db3\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u5728\u7ebf\u5206\u5e03\u5f0f\u7b97\u6cd5\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u591a\u8fb9\u7f18\u670d\u52a1\u5668\u9009\u62e9\u4e0e\u52a8\u6001\u8d1f\u8f7d\u5206\u914d\u3002", "result": "\u4eff\u771f\u8868\u660e\u4efb\u52a1\u5378\u8f7d\u8de8\u5ea6\u51cf\u5c11\u81f3\u5c1111.04%\uff0c\u5931\u8d25\u7387\u4e0b\u964d44.86%\uff1b\u539f\u578b\u7cfb\u7edf\u5b9e\u6d4b\u5ef6\u8fdf\u964d\u4f4e9.23%-31.98%\u3002", "conclusion": "AMCoEdge\u6709\u6548\u63d0\u5347AIGC\u670d\u52a1\u5728\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u517c\u987e\u4f4e\u5ef6\u8fdf\u4e0e\u9ad8\u53ef\u9760\u6027\u3002"}}
{"id": "2512.17363", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.17363", "abs": "https://arxiv.org/abs/2512.17363", "authors": ["Yuqing Niu", "Jieke Shi", "Ruidong Han", "Ye Liu", "Chengyan Ma", "Yunbo Lyu", "David Lo"], "title": "What You Trust Is Insecure: Demystifying How Developers (Mis)Use Trusted Execution Environments in Practice", "comment": "Accepted by the 33rd IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER 2026), 13 Pages", "summary": "Trusted Execution Environments (TEEs), such as Intel SGX and ARM TrustZone, provide isolated regions of CPU and memory for secure computation and are increasingly used to protect sensitive data and code across diverse application domains. However, little is known about how developers actually use TEEs in practice. This paper presents the first large-scale empirical study of real-world TEE applications. We collected and analyzed 241 open-source projects from GitHub that utilize the two most widely-adopted TEEs, Intel SGX and ARM TrustZone. By combining manual inspection with customized static analysis scripts, we examined their adoption contexts, usage patterns, and development practices across three phases. First, we categorized the projects into 8 application domains and identified trends in TEE adoption over time. We found that the dominant use case is IoT device security (30%), which contrasts sharply with prior academic focus on blockchain and cryptographic systems (7%), while AI model protection (12%) is rapidly emerging as a growing domain. Second, we analyzed how TEEs are integrated into software and observed that 32.4% of the projects reimplement cryptographic functionalities instead of using official SDK APIs, suggesting that current SDKs may have limited usability and portability to meet developers' practical needs. Third, we examined security practices through manual inspection and found that 25.3% (61 of 241) of the projects exhibit insecure coding behaviors when using TEEs, such as hardcoded secrets and missing input validation, which undermine their intended security guarantees. Our findings have important implications for improving the usability of TEE SDKs and supporting developers in trusted software development.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9241\u4e2a\u5f00\u6e90TEE\u9879\u76ee\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u63ed\u793a\u5f00\u53d1\u8005\u5728\u7269\u8054\u7f51\u5b89\u5168\u3001AI\u6a21\u578b\u4fdd\u62a4\u7b49\u9886\u57df\u7684\u5b9e\u9645\u4f7f\u7528\u6a21\u5f0f\u53ca\u5e38\u89c1\u5b89\u5168\u7f3a\u9677\u3002", "motivation": "\u4e86\u89e3\u5f00\u53d1\u8005\u5982\u4f55\u5b9e\u9645\u4f7f\u7528TEE\uff0c\u4ee5\u6539\u8fdbSDK\u53ef\u7528\u6027\u5e76\u652f\u6301\u53ef\u4fe1\u8f6f\u4ef6\u5f00\u53d1\u3002", "method": "\u7ed3\u5408\u4eba\u5de5\u68c0\u67e5\u4e0e\u5b9a\u5236\u9759\u6001\u5206\u6790\u811a\u672c\uff0c\u4eceGitHub\u6536\u96c6\u5e76\u5206\u6790\u4f7f\u7528Intel SGX\u548cARM TrustZone\u7684241\u4e2a\u9879\u76ee\u3002", "result": "\u53d1\u73b030%\u9879\u76ee\u7528\u4e8e\u7269\u8054\u7f51\u5b89\u5168\uff0c32.4%\u9879\u76ee\u81ea\u884c\u5b9e\u73b0\u52a0\u5bc6\u529f\u80fd\uff0c25.3%\u9879\u76ee\u5b58\u5728\u786c\u7f16\u7801\u5bc6\u94a5\u7b49\u4e0d\u5b89\u5168\u884c\u4e3a\u3002", "conclusion": "\u5f53\u524dTEE SDK\u53ef\u7528\u6027\u4e0d\u8db3\uff0c\u9700\u4f18\u5316\u4ee5\u51cf\u5c11\u5f00\u53d1\u8005\u8bef\u7528\u5e76\u63d0\u5347\u6574\u4f53\u5b89\u5168\u6027\u3002"}}
{"id": "2512.17834", "categories": ["cs.AR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.17834", "abs": "https://arxiv.org/abs/2512.17834", "authors": ["Darja Nonaca", "J\u00e9r\u00e9my Guichemerre", "Reinhard Wiesmayr", "Nihat Engin Tunali", "Christoph Studer"], "title": "A 14ns-Latency 9Gb/s 0.44mm$^2$ 62pJ/b Short-Blocklength LDPC Decoder ASIC in 22FDX", "comment": "Presented at the 2025 IEEE European Solid-State Electronics Research Conference (ESSERC)", "summary": "Ultra-reliable low latency communication (URLLC) is a key part of 5G wireless systems. Achieving low latency necessitates codes with short blocklengths for which polar codes with successive cancellation list (SCL) decoding typically outperform message-passing (MP)-based decoding of low-density parity-check (LDPC) codes. However, SCL decoders are known to exhibit high latency and poor area efficiency. In this paper, we propose a new short-blocklength multi-rate binary LDPC code that outperforms the 5G-LDPC code for the same blocklength and is suitable for URLLC applications using fully parallel MP. To demonstrate our code's efficacy, we present a 0.44mm$^2$ GlobalFoundries 22FDX LDPC decoder ASIC which supports three rates and achieves the lowest-in-class decoding latency of 14ns while reaching an information throughput of 9Gb/s at 62pJ/b energy efficiency for a rate-1/2 code with 128-bit blocklength.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9002\u7528\u4e8eURLLC\u7684\u65b0\u578b\u77ed\u5757\u957f\u591a\u901f\u7387LDPC\u7801\u53ca\u9ad8\u6548ASIC\u89e3\u7801\u5668\uff0c\u5b9e\u73b014ns\u6700\u4f4e\u5ef6\u8fdf\u4e0e9Gb/s\u541e\u5410\u91cf\u3002", "motivation": "\u89e3\u51b35G URLLC\u573a\u666f\u4e0b\u6781\u4f4e\u5ef6\u8fdf\u9700\u6c42\u4e0e\u73b0\u6709SCL\u89e3\u7801\u5668\u9ad8\u5ef6\u8fdf\u3001\u4f4e\u9762\u79ef\u6548\u7387\u7684\u77db\u76fe\u3002", "method": "\u8bbe\u8ba1\u65b0\u578b\u591a\u901f\u7387\u4e8c\u8fdb\u5236LDPC\u7801\u5e76\u91c7\u7528\u5168\u5e76\u884c\u6d88\u606f\u4f20\u9012\u89e3\u7801\uff0c\u572822FDX\u5de5\u827a\u4e0a\u5b9e\u73b0ASIC\u786c\u4ef6\u3002", "result": "\u5728128\u4f4d\u5757\u957f\u30011/2\u7801\u7387\u4e0b\u8fbe\u621014ns\u89e3\u7801\u5ef6\u8fdf\u30019Gb/s\u4fe1\u606f\u541e\u5410\u91cf\u53ca62pJ/b\u80fd\u6548\uff0c\u6027\u80fd\u4f18\u4e8e5G-LDPC\u7801\u3002", "conclusion": "\u8be5LDPC\u7801\u53ca\u89e3\u7801\u5668\u67b6\u6784\u663e\u8457\u63d0\u5347\u77ed\u5757\u957f\u573a\u666f\u4e0b\u7684\u5ef6\u8fdf\u4e0e\u80fd\u6548\u8868\u73b0\uff0c\u9002\u5408URLLC\u5e94\u7528\u90e8\u7f72\u3002"}}
{"id": "2512.17187", "categories": ["cs.MA", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.17187", "abs": "https://arxiv.org/abs/2512.17187", "authors": ["Zhaoqilin Yang", "Axin Xiang", "Kedi Yang", "Tianjun Liu", "Youliang Tian"], "title": "MAPPO-LCR: Multi-Agent Policy Optimization with Local Cooperation Reward in Spatial Public Goods Games", "comment": null, "summary": "Spatial public goods games model collective dilemmas where individual payoffs depend on population-level strategy configurations. Most existing studies rely on evolutionary update rules or value-based reinforcement learning methods. These approaches struggle to represent payoff coupling and non-stationarity in large interacting populations. This work introduces Multi-Agent Proximal Policy Optimization (MAPPO) into spatial public goods games for the first time. In these games, individual returns are intrinsically coupled through overlapping group interactions. Proximal Policy Optimization (PPO) treats agents as independent learners and ignores this coupling during value estimation. MAPPO addresses this limitation through a centralized critic that evaluates joint strategy configurations. To study neighborhood-level cooperation signals under this framework, we propose MAPPO with Local Cooperation Reward, termed MAPPO-LCR. The local cooperation reward aligns policy updates with surrounding cooperative density without altering the original game structure. MAPPO-LCR preserves decentralized execution while enabling population-level value estimation during training. Extensive simulations demonstrate stable cooperation emergence and reliable convergence across enhancement factors. Statistical analyses further confirm the learning advantage of MAPPO over PPO in spatial public goods games.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5c06\u591a\u667a\u80fd\u4f53\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08MAPPO\uff09\u5f15\u5165\u7a7a\u95f4\u516c\u5171\u7269\u54c1\u535a\u5f08\uff0c\u63d0\u51faMAPPO-LCR\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c40\u90e8\u5408\u4f5c\u5956\u52b1\u4fc3\u8fdb\u5408\u4f5c\u6d8c\u73b0\u5e76\u5b9e\u73b0\u7a33\u5b9a\u6536\u655b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u5927\u89c4\u6a21\u4ea4\u4e92\u7fa4\u4f53\u4e2d\u7684\u6536\u76ca\u8026\u5408\u4e0e\u975e\u5e73\u7a33\u6027\u95ee\u9898\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u7684\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u91c7\u7528\u96c6\u4e2d\u5f0f\u8bc4\u8bba\u5bb6\u67b6\u6784\u7684MAPPO\uff0c\u5e76\u8bbe\u8ba1\u5c40\u90e8\u5408\u4f5c\u5956\u52b1\u673a\u5236\uff08MAPPO-LCR\uff09\uff0c\u5728\u4e0d\u6539\u53d8\u539f\u535a\u5f08\u7ed3\u6784\u524d\u63d0\u4e0b\u5f15\u5bfc\u7b56\u7565\u66f4\u65b0\u3002", "result": "\u4eff\u771f\u8868\u660eMAPPO-LCR\u80fd\u7a33\u5b9a\u4fc3\u8fdb\u5408\u4f5c\u884c\u4e3a\uff0c\u5728\u4e0d\u540c\u589e\u5f3a\u56e0\u5b50\u4e0b\u5747\u53ef\u9760\u6536\u655b\uff1b\u7edf\u8ba1\u5206\u6790\u8bc1\u5b9e\u5176\u4f18\u4e8e\u4f20\u7edfPPO\u65b9\u6cd5\u3002", "conclusion": "MAPPO-LCR\u6709\u6548\u89e3\u51b3\u4e86\u7a7a\u95f4\u516c\u5171\u7269\u54c1\u535a\u5f08\u4e2d\u6536\u76ca\u8026\u5408\u4e0e\u5408\u4f5c\u6fc0\u52b1\u96be\u9898\uff0c\u4e3a\u7fa4\u4f53\u534f\u4f5c\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.17381", "categories": ["cs.NI", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17381", "abs": "https://arxiv.org/abs/2512.17381", "authors": ["Yu-Pin Hsu", "Yi-Hsuan Tseng"], "title": "Timely Information Updating for Mobile Devices Without and With ML Advice", "comment": "23 pages, journal version of arXiv:1901.03137, submitted for possible journal publication", "summary": "This paper investigates an information update system in which a mobile device monitors a physical process and sends status updates to an access point (AP). A fundamental trade-off arises between the timeliness of the information maintained at the AP and the update cost incurred at the device. To address this trade-off, we propose an online algorithm that determines when to transmit updates using only available observations. The proposed algorithm asymptotically achieves the optimal competitive ratio against an adversary that can simultaneously manipulate multiple sources of uncertainty, including the operation duration, the information staleness, the update cost, and the availability of update opportunities. Furthermore, by incorporating machine learning (ML) advice of unknown reliability into the design, we develop an ML-augmented algorithm that asymptotically attains the optimal consistency-robustness trade-off, even when the adversary can additionally corrupt the ML advice. The optimal competitive ratio scales linearly with the range of update costs, but is unaffected by other uncertainties. Moreover, an optimal competitive online algorithm exhibits a threshold-like response to the ML advice: it either fully trusts or completely ignores the ML advice, as partially trusting the advice cannot improve the consistency without severely degrading the robustness. Extensive simulations in stochastic settings further validate the theoretical findings in the adversarial environment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u7ebf\u7b97\u6cd5\uff0c\u5728\u5bf9\u6297\u591a\u79cd\u4e0d\u786e\u5b9a\u6027\u7684\u540c\u65f6\u4f18\u5316\u4fe1\u606f\u66f4\u65b0\u6210\u672c\u4e0e\u53ca\u65f6\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u5efa\u8bae\u5b9e\u73b0\u6700\u4f18\u4e00\u81f4\u6027-\u9c81\u68d2\u6027\u5e73\u8861\u3002", "motivation": "\u89e3\u51b3\u79fb\u52a8\u8bbe\u5907\u5411\u63a5\u5165\u70b9\u53d1\u9001\u72b6\u6001\u66f4\u65b0\u65f6\uff0c\u4fe1\u606f\u65f6\u6548\u6027\u4e0e\u66f4\u65b0\u6210\u672c\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4ec5\u4f9d\u8d56\u53ef\u89c2\u6d4b\u6570\u636e\u7684\u5728\u7ebf\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u672a\u77e5\u53ef\u9760\u6027\u7684\u673a\u5668\u5b66\u4e60\u5efa\u8bae\u4ee5\u589e\u5f3a\u6027\u80fd\u3002", "result": "\u7b97\u6cd5\u6e10\u8fd1\u8fbe\u5230\u6700\u4f18\u7ade\u4e89\u6bd4\u548c\u4e00\u81f4\u6027-\u9c81\u68d2\u6027\u6743\u8861\uff1b\u6700\u4f18\u7b97\u6cd5\u5bf9ML\u5efa\u8bae\u5448\u73b0\u2018\u5168\u4fe1\u6216\u5168\u4e0d\u4fe1\u2019\u7684\u9608\u503c\u54cd\u5e94\u7279\u6027\u3002", "conclusion": "\u7406\u8bba\u5206\u6790\u4e0e\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u5bf9\u6297\u6027\u548c\u968f\u673a\u73af\u5883\u4e0b\u5747\u6709\u6548\uff0c\u4e14\u7ade\u4e89\u6bd4\u4ec5\u4e0e\u66f4\u65b0\u6210\u672c\u8303\u56f4\u7ebf\u6027\u76f8\u5173\u3002"}}
{"id": "2512.17023", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.17023", "abs": "https://arxiv.org/abs/2512.17023", "authors": ["Patrick Diehl", "Noujoud Nader", "Deepti Gupta"], "title": "LLM-HPC++: Evaluating LLM-Generated Modern C++ and MPI+OpenMP Codes for Scalable Mandelbrot Set Computation", "comment": null, "summary": "Parallel programming remains one of the most challenging aspects of High-Performance Computing (HPC), requiring deep knowledge of synchronization, communication, and memory models. While modern C++ standards and frameworks like OpenMP and MPI have simplified parallelism, mastering these paradigms is still complex. Recently, Large Language Models (LLMs) have shown promise in automating code generation, but their effectiveness in producing correct and efficient HPC code is not well understood. In this work, we systematically evaluate leading LLMs including ChatGPT 4 and 5, Claude, and LLaMA on the task of generating C++ implementations of the Mandelbrot set using shared-memory, directive-based, and distributed-memory paradigms. Each generated program is compiled and executed with GCC 11.5.0 to assess its correctness, robustness, and scalability. Results show that ChatGPT-4 and ChatGPT-5 achieve strong syntactic precision and scalable performance.", "AI": {"tldr": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u9ad8\u6027\u80fd\u8ba1\u7b97C++\u4ee3\u7801\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u9488\u5bf9Mandelbrot\u96c6\u7684\u5e76\u884c\u5b9e\u73b0\u3002", "motivation": "\u5e76\u884c\u7f16\u7a0b\u590d\u6742\u4e14\u9700\u8981\u6df1\u539a\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5e0c\u671b\u501f\u52a9LLM\u964d\u4f4e\u5f00\u53d1\u95e8\u69db\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30ChatGPT 4/5\u3001Claude\u548cLLaMA\u751f\u6210\u7684C++\u4ee3\u7801\uff0c\u5728\u5171\u4eab\u5185\u5b58\u3001\u6307\u4ee4\u5f0f\u548c\u5206\u5e03\u5f0f\u5185\u5b58\u8303\u5f0f\u4e0b\u7684\u6b63\u786e\u6027\u4e0e\u6027\u80fd\u3002", "result": "ChatGPT-4\u548cChatGPT-5\u5728\u8bed\u6cd5\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u90e8\u5206LLM\u5df2\u5177\u5907\u751f\u6210\u9ad8\u6548HPC\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u4f46\u6574\u4f53\u4ecd\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4e0e\u9a8c\u8bc1\u3002"}}
{"id": "2512.17814", "categories": ["cs.SE", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.17814", "abs": "https://arxiv.org/abs/2512.17814", "authors": ["Rolf Drechsler", "Qian Liu"], "title": "LLM-based Behaviour Driven Development for Hardware Design", "comment": "7 pages, keynote given at 2nd International Symposium on Artificial Intelligence and Internet of Things (AIIoT-25), December 22-24th, 2025", "summary": "Test and verification are essential activities in hardware and system design, but their complexity grows significantly with increasing system sizes. While Behavior Driven Development (BDD) has proven effective in software engineering, it is not yet well established in hardware design, and its practical use remains limited. One contributing factor is the manual effort required to derive precise behavioral scenarios from textual specifications.\n  Recent advances in Large Language Models (LLMs) offer new opportunities to automate this step. In this paper, we investigate the use of LLM-based techniques to support BDD in the context of hardware design.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u5316\u652f\u6301\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u884c\u4e3a\u9a71\u52a8\u5f00\u53d1\uff08BDD\uff09\uff0c\u4ee5\u964d\u4f4e\u6d4b\u8bd5\u4e0e\u9a8c\u8bc1\u7684\u590d\u6742\u6027\u3002", "motivation": "\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u6d4b\u8bd5\u4e0e\u9a8c\u8bc1\u590d\u6742\u5ea6\u968f\u7cfb\u7edf\u89c4\u6a21\u589e\u957f\uff0c\u800cBDD\u5c1a\u672a\u5728\u8be5\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u4e3b\u8981\u56e0\u9700\u624b\u52a8\u4ece\u6587\u672c\u89c4\u8303\u63d0\u53d6\u884c\u4e3a\u573a\u666f\u3002", "method": "\u7814\u7a76\u57fa\u4e8eLLM\u7684\u6280\u672f\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u751f\u6210\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u884c\u4e3a\u573a\u666f\u3002", "result": "\u521d\u6b65\u8868\u660eLLM\u6709\u6f5c\u529b\u8f85\u52a9\u786c\u4ef6BDD\u6d41\u7a0b\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3002", "conclusion": "LLM\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684BDD\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u81ea\u52a8\u5316\u8def\u5f84\uff0c\u6709\u671b\u63d0\u5347\u6548\u7387\u5e76\u63a8\u52a8\u5176\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2512.17077", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17077", "abs": "https://arxiv.org/abs/2512.17077", "authors": ["Jiakun Fan", "Yanglin Zhang", "Xiangchen Li", "Dimitrios S. Nikolopoulos"], "title": "Taming the Memory Footprint Crisis: System Design for Production Diffusion LLM Serving", "comment": null, "summary": "Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to Autoregressive Models (ARMs), utilizing parallel decoding to overcome sequential bottlenecks. However, existing research focuses primarily on kernel-level optimizations, lacking a holistic serving framework that addresses the unique memory dynamics of diffusion processes in production. We identify a critical \"memory footprint crisis\" specific to dLLMs, driven by monolithic logit tensors and the severe resource oscillation between compute-bound \"Refresh\" phases and bandwidth-bound \"Reuse\" phases. To bridge this gap, we present dLLM-Serve, an efficient dLLM serving system that co-optimizes memory footprint, computational scheduling, and generation quality. dLLM-Serve introduces Logit-Aware Activation Budgeting to decompose transient tensor peaks, a Phase-Multiplexed Scheduler to interleave heterogeneous request phases, and Head-Centric Sparse Attention to decouple logical sparsity from physical storage. We evaluate dLLM-Serve on diverse workloads (LiveBench, Burst, OSC) and GPUs (RTX 4090, L40S). Relative to the state-of-the-art baseline, dLLM-Serve improves throughput by 1.61$\\times$-1.81$\\times$ on the consumer-grade RTX 4090 and 1.60$\\times$-1.74$\\times$ on the server-grade NVIDIA L40S, while reducing tail latency by nearly 4$\\times$ under heavy contention. dLLM-Serve establishes the first blueprint for scalable dLLM inference, converting theoretical algorithmic sparsity into tangible wall-clock acceleration across heterogeneous hardware.", "AI": {"tldr": "dLLM-Serve \u662f\u9996\u4e2a\u9762\u5411\u6269\u6563\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u5185\u5b58\u3001\u8c03\u5ea6\u4e0e\u7a00\u758f\u6ce8\u610f\u529b\u534f\u540c\u4f18\u5316\uff0c\u5728\u6d88\u8d39\u7ea7\u548c\u670d\u52a1\u5668\u7ea7 GPU \u4e0a\u5b9e\u73b0 1.6 \u500d\u4ee5\u4e0a\u541e\u5410\u63d0\u5347\u4e0e\u8fd1 4 \u500d\u5c3e\u5ef6\u8fdf\u964d\u4f4e\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u9002\u914d\u5176\u5185\u5b58\u52a8\u6001\u7684\u670d\u52a1\u6846\u67b6\uff0c\u9762\u4e34\u8ba1\u7b97\u4e0e\u5e26\u5bbd\u9636\u6bb5\u8d44\u6e90\u9707\u8361\u53ca\u65e5\u5fd7\u5f20\u91cf\u5185\u5b58\u5cf0\u503c\u95ee\u9898\u3002", "method": "\u63d0\u51fa Logit-Aware \u6fc0\u6d3b\u9884\u7b97\u5206\u89e3\u5f20\u91cf\u5cf0\u503c\u3001Phase-Multiplexed \u8c03\u5ea6\u5668\u4ea4\u9519\u5f02\u6784\u8bf7\u6c42\u3001Head-Centric \u7a00\u758f\u6ce8\u610f\u529b\u89e3\u8026\u903b\u8f91\u4e0e\u7269\u7406\u5b58\u50a8\u3002", "result": "\u5728 RTX 4090 \u548c L40S \u4e0a\u5206\u522b\u5b9e\u73b0 1.61\u20131.81 \u500d\u548c 1.60\u20131.74 \u500d\u541e\u5410\u63d0\u5347\uff0c\u91cd\u8d1f\u8f7d\u4e0b\u5c3e\u5ef6\u8fdf\u964d\u4f4e\u8fd1 4 \u500d\u3002", "conclusion": "dLLM-Serve \u9996\u6b21\u5b9e\u73b0\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u89c4\u6a21\u5316\uff0c\u5c06\u7b97\u6cd5\u7a00\u758f\u6027\u8f6c\u5316\u4e3a\u8de8\u786c\u4ef6\u7684\u5b9e\u9645\u52a0\u901f\u6548\u679c\u3002"}}
{"id": "2512.17387", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.17387", "abs": "https://arxiv.org/abs/2512.17387", "authors": ["Sravani Gunnu", "Shanmukha Guttula", "Hima Patel"], "title": "CIFE: Code Instruction-Following Evaluation", "comment": "20 pages, 22 figures, 2 tables", "summary": "Large Language Models (LLMs) are increasingly applied to real-world code generation, where functional correctness alone is insufficient for reliable deployment, developers also expect adherence to explicit requirements for robustness, formatting, and security. Existing benchmarks primarily assess correctness through test-case execution, offering limited insight into how reliably models follow such constraints. We introduce a benchmark of 1,000 Python tasks, each paired with an average of 7 developer-specified constraints spanning 13 categories. Constraints are curated through a four-stage human-LLM pipeline to ensure they are atomic, relevant, and objective. We evaluate 14 open- and closed-source models using complementary adherence metrics and propose the C2A Score, a composite measure that jointly captures correctness and constraint compliance. Results reveal a substantial gap between partial and strict satisfaction, while strong models achieve over 90% partial adherence, strict adherence remains between 39-66%. These findings highlight that trustworthy code generation requires not only correctness but also consistent adherence to developer intent.", "AI": {"tldr": "\u63d0\u51fa\u5305\u542b1000\u4e2aPython\u4efb\u52a1\u7684\u57fa\u51c6\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5bf9\u5f00\u53d1\u8005\u7ea6\u675f\u7684\u9075\u5b88\u60c5\u51b5\uff0c\u5e76\u5f15\u5165C2A\u8bc4\u5206\u8861\u91cf\u6b63\u786e\u6027\u4e0e\u7ea6\u675f\u7b26\u5408\u5ea6\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5ffd\u89c6\u5f00\u53d1\u8005\u5bf9\u9c81\u68d2\u6027\u3001\u683c\u5f0f\u548c\u5b89\u5168\u7b49\u663e\u5f0f\u7ea6\u675f\u7684\u9075\u5faa\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u56db\u9636\u6bb5\u6d41\u7a0b\u6784\u5efa\u542b13\u7c7b\u7ea6\u675f\u7684\u4efb\u52a1\u96c6\uff0c\u8bc4\u4f3014\u4e2a\u5f00\u6e90\u4e0e\u95ed\u6e90\u6a21\u578b\uff0c\u8bbe\u8ba1C2A\u7efc\u5408\u8bc4\u5206\u3002", "result": "\u5f3a\u6a21\u578b\u90e8\u5206\u7b26\u5408\u7387\u8fbe90%\u4ee5\u4e0a\uff0c\u4f46\u4e25\u683c\u7b26\u5408\u7387\u4ec539-66%\uff0c\u663e\u793a\u5f53\u524d\u6a21\u578b\u5728\u7cbe\u786e\u9075\u5faa\u610f\u56fe\u65b9\u9762\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "\u53ef\u4fe1\u4ee3\u7801\u751f\u6210\u9700\u517c\u987e\u529f\u80fd\u6b63\u786e\u6027\u4e0e\u5f00\u53d1\u8005\u610f\u56fe\u7684\u7a33\u5b9a\u9075\u5faa\u3002"}}
{"id": "2512.17264", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17264", "abs": "https://arxiv.org/abs/2512.17264", "authors": ["Yuming Xu", "Qianxi Zhang", "Qi Chen", "Baotong Lu", "Menghao Li", "Philip Adams", "Mingqin Li", "Zengzhong Li", "Jing Liu", "Cheng Li", "Fan Yang"], "title": "Scalable Distributed Vector Search via Accuracy Preserving Index Construction", "comment": null, "summary": "Scaling Approximate Nearest Neighbor Search (ANNS) to billions of vectors requires distributed indexes that balance accuracy, latency, and throughput. Yet existing index designs struggle with this tradeoff. This paper presents SPIRE, a scalable vector index based on two design decisions. First, it identifies a balanced partition granularity that avoids read-cost explosion. Second, it introduces an accuracy-preserving recursive construction that builds a multi-level index with predictable search cost and stable accuracy. In experiments with up to 8 billion vectors across 46 nodes, SPIRE achieves high scalability and up to 9.64X higher throughput than state-of-the-art systems.", "AI": {"tldr": "SPIRE\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u5411\u91cf\u7d22\u5f15\uff0c\u901a\u8fc7\u5e73\u8861\u5206\u533a\u7c92\u5ea6\u548c\u9012\u5f52\u6784\u5efa\u591a\u7ea7\u7d22\u5f15\uff0c\u5728\u6570\u5341\u4ebf\u5411\u91cf\u89c4\u6a21\u4e0b\u5b9e\u73b0\u9ad8\u541e\u5410\u4e0e\u7a33\u5b9a\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\u7cfb\u7edf\u5728\u7cbe\u5ea6\u3001\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u4e4b\u95f4\u96be\u4ee5\u53d6\u5f97\u5e73\u8861\uff0c\u4e9f\u9700\u66f4\u4f18\u7684\u5206\u5e03\u5f0f\u7d22\u5f15\u8bbe\u8ba1\u3002", "method": "\u91c7\u7528\u5e73\u8861\u5206\u533a\u7c92\u5ea6\u907f\u514d\u8bfb\u53d6\u6210\u672c\u6fc0\u589e\uff0c\u5e76\u901a\u8fc7\u9012\u5f52\u6784\u5efa\u591a\u7ea7\u7d22\u5f15\u786e\u4fdd\u641c\u7d22\u6210\u672c\u53ef\u9884\u6d4b\u4e14\u7cbe\u5ea6\u7a33\u5b9a\u3002", "result": "\u572846\u8282\u70b9\u300180\u4ebf\u5411\u91cf\u89c4\u6a21\u5b9e\u9a8c\u4e2d\uff0cSPIRE\u541e\u5410\u91cf\u6bd4\u73b0\u6709\u6700\u4f18\u7cfb\u7edf\u63d0\u5347\u6700\u9ad8\u8fbe9.64\u500d\u3002", "conclusion": "SPIRE\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u5411\u91cf\u68c0\u7d22\u4e2d\u7684\u6269\u5c55\u6027\u4e0e\u6027\u80fd\u5e73\u8861\u95ee\u9898\uff0c\u662f\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5206\u5e03\u5f0f\u5411\u91cf\u7d22\u5f15\u65b9\u6848\u4e4b\u4e00\u3002"}}
{"id": "2512.17419", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17419", "abs": "https://arxiv.org/abs/2512.17419", "authors": ["Lilin Wang", "Lucas Ramalho", "Alan Celestino", "Phuc Anthony Pham", "Yu Liu", "Umang Kumar Sinha", "Andres Portillo", "Onassis Osunwa", "Gabriel Maduekwe"], "title": "SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories", "comment": null, "summary": "Benchmarks like SWE-bench have standardized the evaluation of Large Language Models (LLMs) on repository-level software engineering tasks. However, these efforts remain limited by manual curation, static datasets, and a focus on Python-based bug fixes. We introduce SWE-Bench++, an automated framework that generates repository-level coding tasks from open-source GitHub projects. Unlike synthetic approaches, our pipeline harvests live pull requests to cover both bug fixes and feature requests across 11 languages. SWE-Bench++ turns GitHub pull requests (PRs) into reproducible, execution-based tasks via four stages: programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance. A final hint-guided trajectory synthesis step converts instances that strong models fail on into training trajectories. Our initial benchmark consists of 11,133 instances from 3,971 repositories across 11 languages. On a subset of 1,782 instances of this benchmark, today's strongest models perform as follows: claude-sonnet-4.5 achieves 36.20% pass@10, gpt-5-2025-08-07 34.57%, gemini/gemini-2.5-pro 24.92%, and gpt-4o 16.89%. We further demonstrate the utility of our dataset by showing that fine-tuning on SWE-Bench++ instances yields measurable improvements on the SWE-bench Multilingual benchmark. SWE-Bench++ provides a scalable, multilingual benchmark for evaluating and improving repository-level code generation.", "AI": {"tldr": "SWE-Bench++\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u4eceGitHub\u62c9\u53d6\u8bf7\u6c42\u4e2d\u751f\u6210\u8de811\u79cd\u8bed\u8a00\u7684\u4ee3\u7801\u4efb\u52a1\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ed3\u5e93\u7ea7\u7f16\u7a0b\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u5982SWE-bench\u53d7\u9650\u4e8e\u4eba\u5de5\u6574\u7406\u3001\u9759\u6001\u6570\u636e\u96c6\u548c\u4ec5\u652f\u6301Python\uff0c\u4e9f\u9700\u66f4\u901a\u7528\u3001\u591a\u8bed\u8a00\u3001\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u56db\u4e2a\u9636\u6bb5\uff1a\u7a0b\u5e8f\u5316\u91c7\u96c6\u3001\u73af\u5883\u5408\u6210\u3001\u6d4b\u8bd5\u9884\u8a00\u63d0\u53d6\u548c\u8d28\u91cf\u4fdd\u8bc1\uff0c\u5c06\u771f\u5b9eGitHub PR\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u4efb\u52a1\uff0c\u5e76\u52a0\u5165\u63d0\u793a\u5f15\u5bfc\u8f68\u8ff9\u5408\u6210\u7528\u4e8e\u8bad\u7ec3\u3002", "result": "\u6784\u5efa\u5305\u542b11,133\u4e2a\u5b9e\u4f8b\u7684\u591a\u8bed\u8a00\u57fa\u51c6\uff0c\u57281,782\u4e2a\u5b50\u96c6\u4e0aClaude Sonnet 4.5\u8868\u73b0\u6700\u4f73\uff0836.20% pass@10\uff09\uff0c\u4e14\u5fae\u8c03\u540e\u80fd\u663e\u8457\u63d0\u5347\u591a\u8bed\u8a00SWE-bench\u8868\u73b0\u3002", "conclusion": "SWE-Bench++\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u591a\u8bed\u8a00\u7684\u4ed3\u5e93\u7ea7\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u4e0e\u8bad\u7ec3\u57fa\u51c6\uff0c\u63a8\u52a8LLM\u5728\u771f\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u573a\u666f\u4e2d\u7684\u8fdb\u6b65\u3002"}}
{"id": "2512.17506", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.17506", "abs": "https://arxiv.org/abs/2512.17506", "authors": ["Brienna M. Larrick", "L. Philip Schumm", "Mingfei Shao", "Craig Barnes", "Anthony Juehne", "Hara Prasad Juvvla", "Michael B. Kranz", "Michael Lukowski", "Clint Malson", "Jessica N. Mazerik", "Christopher G. Meyer", "Jawad Qureshi", "Erin Spaniol", "Andrea Tentner", "Alexander VanTol", "Peter Vassilatos", "Sara Volk de Garcia", "Robert L. Grossman"], "title": "The HEAL Data Platform", "comment": "12 pages, 3 figures", "summary": "Objective: The objective was to develop a cloud-based, federated system to serve as a single point of search, discovery and analysis for data generated under the NIH Helping to End Addiction Long-term (HEAL) Initiative.\n  Materials and methods: The HEAL Data Platform is built on the open source Gen3 platform, utilizing a small set of framework services and exposed APIs to interoperate with both NIH and non-NIH data repositories. Framework services include those for authentication and authorization, creating persistent identifiers for data objects, and adding and updating metadata.\n  Results: The HEAL Data Platform serves as a single point of discovery of over one thousand studies funded under the HEAL Initiative. With hundreds of users per month, the HEAL Data Platform provides rich metadata and interoperates with data repositories and commons to provide access to shared datasets. Secure, cloud-based compute environments that are integrated with STRIDES facilitate secondary analysis of HEAL data. The HEAL Data Platform currently interoperates with nineteen data repositories.\n  Discussion: Studies funded under the HEAL Initiative generate a wide variety of data types, which are deposited across multiple NIH and third-party data repositories. The mesh architecture of the HEAL Data Platform provides a single point of discovery of these data resources, accelerating and facilitating secondary use.\n  Conclusion: The HEAL Data Platform enables search, discovery, and analysis of data that are deposited in connected data repositories and commons. By ensuring that these data are fully Findable, Accessible, Interoperable and Reusable (FAIR), the HEAL Data Platform maximizes the value of data generated under the HEAL Initiative.", "AI": {"tldr": "HEAL\u6570\u636e\u5e73\u53f0\u57fa\u4e8eGen3\u5f00\u6e90\u5e73\u53f0\uff0c\u63d0\u4f9b\u7edf\u4e00\u7684\u6570\u636e\u641c\u7d22\u3001\u53d1\u73b0\u4e0e\u5206\u6790\u670d\u52a1\uff0c\u652f\u6301\u8de8\u591a\u4e2a\u6570\u636e\u4ed3\u5e93\u7684\u4e92\u64cd\u4f5c\u6027\uff0c\u786e\u4fdd\u6570\u636e\u7b26\u5408FAIR\u539f\u5219\u3002", "motivation": "\u4e3a\u89e3\u51b3HEAL\u8ba1\u5212\u8d44\u52a9\u7814\u7a76\u4ea7\u751f\u7684\u591a\u6e90\u5f02\u6784\u6570\u636e\u96be\u4ee5\u7edf\u4e00\u53d1\u73b0\u4e0e\u5206\u6790\u7684\u95ee\u9898\uff0c\u6784\u5efa\u4e00\u4e2a\u96c6\u4e2d\u5f0f\u8054\u90a6\u7cfb\u7edf\u3002", "method": "\u91c7\u7528Gen3\u5f00\u6e90\u5e73\u53f0\uff0c\u96c6\u6210\u8ba4\u8bc1\u6388\u6743\u3001\u6301\u4e45\u6807\u8bc6\u7b26\u3001\u5143\u6570\u636e\u7ba1\u7406\u7b49\u6846\u67b6\u670d\u52a1\uff0c\u5e76\u901a\u8fc7API\u5b9e\u73b0\u4e0eNIH\u53ca\u7b2c\u4e09\u65b9\u6570\u636e\u4ed3\u5e93\u7684\u4e92\u64cd\u4f5c\u3002", "result": "\u5e73\u53f0\u5df2\u6574\u540819\u4e2a\u6570\u636e\u4ed3\u5e93\uff0c\u652f\u6301\u6bcf\u6708\u6570\u767e\u7528\u6237\u8bbf\u95ee\uff0c\u63d0\u4f9b\u4e30\u5bcc\u5143\u6570\u636e\u548c\u5b89\u5168\u4e91\u73af\u5883\u4ee5\u4fc3\u8fdb\u4e8c\u6b21\u5206\u6790\u3002", "conclusion": "HEAL\u6570\u636e\u5e73\u53f0\u6709\u6548\u5b9e\u73b0\u4e86\u8de8\u5e93\u6570\u636e\u7684\u53ef\u53d1\u73b0\u3001\u53ef\u8bbf\u95ee\u3001\u53ef\u4e92\u64cd\u4f5c\u4e0e\u53ef\u91cd\u7528\uff0c\u6700\u5927\u5316HEAL\u8ba1\u5212\u6570\u636e\u4ef7\u503c\u3002"}}
{"id": "2512.17455", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.17455", "abs": "https://arxiv.org/abs/2512.17455", "authors": ["Ronnie de Souza Santos", "Italo Santos", "Maria Teresa Baldassarre", "Cleyton Magalhaes", "Mairieli Wessel"], "title": "An Investigation on How AI-Generated Responses Affect SoftwareEngineering Surveys", "comment": null, "summary": "Survey research is a fundamental empirical method in software engineering, enabling the systematic collection of data on professional practices, perceptions, and experiences. However, recent advances in large language models (LLMs) have introduced new risks to survey integrity, as participants can use generative tools to fabricate or manipulate their responses. This study explores how LLMs are being misused in software engineering surveys and investigates the methodological implications of such behavior for data authenticity, validity, and research integrity. We collected data from two survey deployments conducted in 2025 through the Prolific platform and analyzed the content of participants' answers to identify irregular or falsified responses. A subset of responses suspected of being AI generated was examined through qualitative pattern inspection, narrative characterization, and automated detection using the Scribbr AI Detector. The analysis revealed recurring structural patterns in 49 survey responses indicating synthetic authorship, including repetitive sequencing, uniform phrasing, and superficial personalization. These false narratives mimicked coherent reasoning while concealing fabricated content, undermining construct, internal, and external validity. Our study identifies data authenticity as an emerging dimension of validity in software engineering surveys. We emphasize that reliable evidence now requires combining automated and interpretive verification procedures, transparent reporting, and community standards to detect and prevent AI generated responses, thereby protecting the credibility of surveys in software engineering.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u8c03\u67e5\u4e2d\u7684\u6ee5\u7528\u73b0\u8c61\u53ca\u5176\u5bf9\u6570\u636e\u771f\u5b9e\u6027\u3001\u6709\u6548\u6027\u548c\u7814\u7a76\u8bda\u4fe1\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u7ed3\u5408\u81ea\u52a8\u5316\u4e0e\u4eba\u5de5\u9a8c\u8bc1\u65b9\u6cd5\u4ee5\u4fdd\u969c\u8c03\u67e5\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\uff0c\u53d7\u8bbf\u8005\u53ef\u80fd\u5229\u7528\u751f\u6210\u5f0f\u5de5\u5177\u4f2a\u9020\u6216\u64cd\u7eb5\u8c03\u67e5\u56de\u7b54\uff0c\u5a01\u80c1\u8f6f\u4ef6\u5de5\u7a0b\u8c03\u67e5\u7684\u6570\u636e\u5b8c\u6574\u6027\u4e0e\u7814\u7a76\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7Prolific\u5e73\u53f0\u6536\u96c62025\u5e74\u4e24\u6b21\u8c03\u67e5\u6570\u636e\uff0c\u91c7\u7528\u5b9a\u6027\u6a21\u5f0f\u5206\u6790\u3001\u53d9\u4e8b\u7279\u5f81\u8bc6\u522b\u53caScribbr AI\u68c0\u6d4b\u5668\u81ea\u52a8\u7b5b\u67e5\u53ef\u7591\u56de\u7b54\u3002", "result": "\u572849\u4efd\u56de\u7b54\u4e2d\u53d1\u73b0\u91cd\u590d\u53e5\u5f0f\u3001\u7edf\u4e00\u63aa\u8f9e\u548c\u8868\u9762\u4e2a\u6027\u5316\u7b49\u5408\u6210\u6587\u672c\u7279\u5f81\uff0c\u8fd9\u4e9b\u865a\u5047\u53d9\u8ff0\u635f\u5bb3\u4e86\u6784\u5ff5\u6548\u5ea6\u3001\u5185\u90e8\u6548\u5ea6\u548c\u5916\u90e8\u6548\u5ea6\u3002", "conclusion": "\u6570\u636e\u771f\u5b9e\u6027\u5df2\u6210\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u8c03\u67e5\u7684\u65b0\u6548\u5ea6\u7ef4\u5ea6\uff0c\u9700\u7ed3\u5408\u900f\u660e\u62a5\u544a\u3001\u793e\u533a\u6807\u51c6\u4e0e\u6df7\u5408\u9a8c\u8bc1\u673a\u5236\u9632\u8303AI\u751f\u6210\u5185\u5bb9\uff0c\u7ef4\u62a4\u7814\u7a76\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2512.17574", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17574", "abs": "https://arxiv.org/abs/2512.17574", "authors": ["Lingxiao Zhao", "Haoran Zhou", "Yuezhi Che", "Dazhao Cheng"], "title": "Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing", "comment": null, "summary": "Multimodal large language models (MLLMs) extend LLMs with visual understanding through a three-stage pipeline: multimodal preprocessing, vision encoding, and LLM inference. While these stages enhance capability, they introduce significant system bottlenecks. First, multimodal preprocessing-especially video decoding-often dominates Time-to-First-Token (TTFT). Most systems rely on CPU-based decoding, which severely limits throughput, while existing GPU-based approaches prioritize throughput-oriented parallelism and fail to meet the latency-sensitive requirements of MLLM inference. Second, the vision encoder is a standalone, compute-intensive stage that produces visual embeddings and cannot be co-batched with LLM prefill or decoding. This heterogeneity forces inter-stage blocking and increases token-generation latency. Even when deployed on separate GPUs, these stages underutilize available compute and memory resources, reducing overall utilization and constraining system throughput.\n  To address these challenges, we present FlashCodec and UnifiedServe, two complementary designs that jointly optimize the end-to-end MLLM pipeline. FlashCodec accelerates the multimodal preprocessing stage through collaborative multi-GPU video decoding, reducing decoding latency while preserving high throughput. UnifiedServe optimizes the vision-to-text and inference stages using a logically decoupled their execution to eliminate inter-stage blocking, yet physically sharing GPU resources to maximize GPU system utilization. By carefully orchestrating execution across stages and minimizing interference, UnifiedServe Together, our proposed framework forms an end-to-end optimized stack that can serve up to 3.0$\\times$ more requests or enforce 1.5$\\times$ tighter SLOs, while achieving up to 4.4$\\times$ higher throughput compared to state-of-the-art systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFlashCodec\u548cUnifiedServe\uff0c\u4f18\u5316\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u63a8\u7406\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u5e76\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u9884\u5904\u7406\u4e0e\u89c6\u89c9\u7f16\u7801\u9636\u6bb5\u9020\u6210\u7684\u7cfb\u7edf\u74f6\u9888\u95ee\u9898\u3002", "method": "FlashCodec\u91c7\u7528\u591aGPU\u534f\u540c\u89c6\u9891\u89e3\u7801\u52a0\u901f\u9884\u5904\u7406\uff1bUnifiedServe\u901a\u8fc7\u903b\u8f91\u89e3\u8026\u3001\u7269\u7406\u8d44\u6e90\u5171\u4eab\u6d88\u9664\u9636\u6bb5\u963b\u585e\uff0c\u63d0\u5347GPU\u5229\u7528\u7387\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edf\uff0c\u652f\u63013\u500d\u8bf7\u6c42\u91cf\u62161.5\u500d\u66f4\u4e25SLO\uff0c\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53474.4\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u4f18\u5316\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u63a8\u7406\u6548\u7387\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2512.17460", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.17460", "abs": "https://arxiv.org/abs/2512.17460", "authors": ["Emmanuel Charleson Dapaah", "Jens Grabowski"], "title": "When Data Quality Issues Collide: A Large-Scale Empirical Study of Co-Occurring Data Quality Issues in Software Defect Prediction", "comment": null, "summary": "Software Defect Prediction (SDP) models are central to proactive software quality assurance, yet their effectiveness is often constrained by the quality of available datasets. Prior research has typically examined single issues such as class imbalance or feature irrelevance in isolation, overlooking that real-world data problems frequently co-occur and interact. This study presents, to our knowledge, the first large-scale empirical analysis in SDP that simultaneously examines five co-occurring data quality issues (class imbalance, class overlap, irrelevant features, attribute noise, and outliers) across 374 datasets and five classifiers. We employ Explainable Boosting Machines together with stratified interaction analysis to quantify both direct and conditional effects under default hyperparameter settings, reflecting practical baseline usage.\n  Our results show that co-occurrence is nearly universal: even the least frequent issue (attribute noise) appears alongside others in more than 93% of datasets. Irrelevant features and imbalance are nearly ubiquitous, while class overlap is the most consistently harmful issue. We identify stable tipping points around 0.20 for class overlap, 0.65-0.70 for imbalance, and 0.94 for irrelevance, beyond which most models begin to degrade. We also uncover counterintuitive patterns, such as outliers improving performance when irrelevant features are low, underscoring the importance of context-aware evaluation. Finally, we expose a performance-robustness trade-off: no single learner dominates under all conditions.\n  By jointly analyzing prevalence, co-occurrence, thresholds, and conditional effects, our study directly addresses a persistent gap in SDP research. Hence, moving beyond isolated analyses to provide a holistic, data-aware understanding of how quality issues shape model performance in real-world settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5927\u89c4\u6a21\u5206\u6790\u4e86\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u4e2d\u4e94\u79cd\u6570\u636e\u8d28\u91cf\u95ee\u9898\u7684\u5171\u73b0\u53ca\u5176\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u95ee\u9898\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u548c\u6027\u80fd\u9608\u503c\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u901a\u5e38\u5b64\u7acb\u5206\u6790\u5355\u4e00\u6570\u636e\u95ee\u9898\uff0c\u5ffd\u7565\u4e86\u73b0\u5b9e\u6570\u636e\u95ee\u9898\u5e38\u5171\u5b58\u4e14\u76f8\u4e92\u5f71\u54cd\uff0c\u5bfc\u81f4\u6a21\u578b\u6548\u679c\u53d7\u9650\u3002", "method": "\u4f7f\u7528\u53ef\u89e3\u91ca\u63d0\u5347\u673a\u4e0e\u5206\u5c42\u4ea4\u4e92\u5206\u6790\uff0c\u5728374\u4e2a\u6570\u636e\u96c6\u548c5\u4e2a\u5206\u7c7b\u5668\u4e0a\u91cf\u5316\u4e94\u79cd\u6570\u636e\u8d28\u91cf\u95ee\u9898\u7684\u76f4\u63a5\u4e0e\u6761\u4ef6\u6548\u5e94\u3002", "result": "\u6570\u636e\u95ee\u9898\u51e0\u4e4e\u666e\u904d\u5b58\u5728\uff1b\u7c7b\u91cd\u53e0\u6700\u5177\u7834\u574f\u6027\uff1b\u8bc6\u522b\u51fa\u5404\u7c7b\u95ee\u9898\u7684\u6027\u80fd\u62d0\u70b9\uff1b\u53d1\u73b0\u5f02\u5e38\u503c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53cd\u800c\u63d0\u5347\u6027\u80fd\uff1b\u65e0\u5355\u4e00\u6a21\u578b\u5728\u6240\u6709\u6761\u4ef6\u4e0b\u5747\u5360\u4f18\u3002", "conclusion": "\u9700\u4ece\u5b64\u7acb\u5206\u6790\u8f6c\u5411\u6574\u4f53\u3001\u6570\u636e\u9a71\u52a8\u7684\u7406\u89e3\uff0c\u4ee5\u66f4\u51c6\u786e\u8bc4\u4f30\u548c\u63d0\u5347\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u6a21\u578b\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2512.17540", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.17540", "abs": "https://arxiv.org/abs/2512.17540", "authors": ["Kai Wang", "Bingcheng Mao", "Shuai Jia", "Yujie Ding", "Dongming Han", "Tianyi Ma", "Bin Cao"], "title": "SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review", "comment": null, "summary": "Automating code review with Large Language Models (LLMs) shows immense promise, yet practical adoption is hampered by their lack of reliability, context-awareness, and control. To address this, we propose Specification-Grounded Code Review (SGCR), a framework that grounds LLMs in human-authored specifications to produce trustworthy and relevant feedback. SGCR features a novel dual-pathway architecture: an explicit path ensures deterministic compliance with predefined rules derived from these specifications, while an implicit path heuristically discovers and verifies issues beyond those rules. Deployed in a live industrial environment at HiThink Research, SGCR's suggestions achieved a 42% developer adoption rate-a 90.9% relative improvement over a baseline LLM (22%). Our work demonstrates that specification-grounding is a powerful paradigm for bridging the gap between the generative power of LLMs and the rigorous reliability demands of software engineering.", "AI": {"tldr": "SGCR\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u663e\u5f0f\u89c4\u5219\u548c\u9690\u5f0f\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347LLM\u4ee3\u7801\u5ba1\u67e5\u7684\u53ef\u9760\u6027\u4e0e\u91c7\u7eb3\u7387\u3002", "motivation": "\u89e3\u51b3\u5f53\u524dLLM\u5728\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7f3a\u4e4f\u53ef\u9760\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u63a7\u5236\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u53cc\u8def\u5f84\u67b6\u6784\uff1a\u663e\u5f0f\u8def\u5f84\u786e\u4fdd\u7b26\u5408\u4eba\u5de5\u89c4\u8303\uff0c\u9690\u5f0f\u8def\u5f84\u53d1\u73b0\u5e76\u9a8c\u8bc1\u989d\u5916\u95ee\u9898\u3002", "result": "\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u5b9e\u73b042%\u7684\u5f00\u53d1\u8005\u91c7\u7eb3\u7387\uff0c\u8f83\u57fa\u7ebfLLM\u63d0\u534790.9%\u3002", "conclusion": "\u89c4\u8303\u5f15\u5bfc\u662f\u5f25\u5408LLM\u751f\u6210\u80fd\u529b\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u53ef\u9760\u6027\u9700\u6c42\u4e4b\u95f4\u5dee\u8ddd\u7684\u6709\u6548\u8303\u5f0f\u3002"}}
{"id": "2512.17710", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.17710", "abs": "https://arxiv.org/abs/2512.17710", "authors": ["Martin Rosso", "Muhammad Asad Jahangir Jaffar", "Alessandro Brighente", "Mauro Conti"], "title": "A Practical Solution to Systematically Monitor Inconsistencies in SBOM-based Vulnerability Scanners", "comment": "to be published in the proceedings of The 41st ACM/SIGAPP Symposium on Applied Computing (SAC '26)", "summary": "Software Bill of Materials (SBOM) provides new opportunities for automated vulnerability identification in software products. While the industry is adopting SBOM-based Vulnerability Scanning (SVS) to identify vulnerabilities, we increasingly observe inconsistencies and unexpected behavior, that result in false negatives and silent failures. In this work, we present the background necessary to understand the underlying complexity of SVS and introduce SVS-TEST, a method and tool to analyze the capability, maturity, and failure conditions of SVS-tools in real-world scenarios. We showcase the utility of SVS-TEST in a case study evaluating seven real-world SVS-tools using 16 precisely crafted SBOMs and their respective ground truth. Our results unveil significant differences in the reliability and error handling of SVS-tools; multiple SVS-tools silently fail on valid input SBOMs, creating a false sense of security. We conclude our work by highlighting implications for researchers and practitioners, including how organizations and developers of SVS-tools can utilize SVS-TEST to monitor SVS capability and maturity. All results and research artifacts are made publicly available and all findings were disclosed to the SVS-tool developers ahead of time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSVS-TEST\u5de5\u5177\uff0c\u7528\u4e8e\u8bc4\u4f30SBOM\u6f0f\u6d1e\u626b\u63cf\u5de5\u5177\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u80fd\u529b\u3001\u6210\u719f\u5ea6\u4e0e\u5931\u6548\u6761\u4ef6\uff0c\u53d1\u73b0\u591a\u4e2a\u5de5\u5177\u5b58\u5728\u9759\u9ed8\u5931\u8d25\u95ee\u9898\u3002", "motivation": "\u5f53\u524dSBOM\u6f0f\u6d1e\u626b\u63cf\u5de5\u5177\u5b58\u5728\u4e0d\u4e00\u81f4\u884c\u4e3a\u548c\u9759\u9ed8\u5931\u8d25\uff0c\u5bfc\u81f4\u8bef\u62a5\u6f0f\u62a5\uff0c\u4e9f\u9700\u7cfb\u7edf\u5316\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0SVS-TEST\u65b9\u6cd5\u4e0e\u5de5\u5177\uff0c\u901a\u8fc716\u4e2a\u7cbe\u5fc3\u6784\u9020\u7684SBOM\u53ca\u771f\u5b9e\u6570\u636e\uff0c\u5bf97\u6b3e\u4e3b\u6d41SVS\u5de5\u5177\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e0d\u540c\u5de5\u5177\u5728\u53ef\u9760\u6027\u548c\u9519\u8bef\u5904\u7406\u4e0a\u5dee\u5f02\u663e\u8457\uff0c\u90e8\u5206\u5de5\u5177\u5bf9\u5408\u6cd5\u8f93\u5165\u9759\u9ed8\u5931\u8d25\uff0c\u5e26\u6765\u865a\u5047\u5b89\u5168\u611f\u3002", "conclusion": "\u5efa\u8bae\u7814\u7a76\u8005\u4e0e\u5b9e\u8df5\u8005\u4f7f\u7528SVS-TEST\u6301\u7eed\u76d1\u63a7\u5de5\u5177\u80fd\u529b\uff0c\u5e76\u5df2\u5411\u5f00\u53d1\u8005\u62ab\u9732\u5168\u90e8\u7ed3\u679c\uff0c\u76f8\u5173\u6210\u679c\u516c\u5f00\u5171\u4eab\u3002"}}
