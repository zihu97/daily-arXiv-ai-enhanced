{"id": "2601.10582", "categories": ["cs.DC", "cs.OS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.10582", "abs": "https://arxiv.org/abs/2601.10582", "authors": ["Mridankan Mandal", "Smit Sanjay Shende"], "title": "Mitigating GIL Bottlenecks in Edge AI Systems", "comment": null, "summary": "Deploying Python based AI agents on resource-constrained edge devices presents a runtime optimization challenge: high thread counts are needed to mask I/O latency, yet Python's Global Interpreter Lock (GIL) serializes execution. We demonstrate that naive thread-pool scaling causes a \"saturation cliff\": >= 20% throughput degradation at overprovisioned thread counts (N >= 512) on edge-representative configurations. We present a lightweight profiling tool and adaptive runtime system using a Blocking Ratio metric (beta) that distinguishes genuine I/O wait from GIL contention. Our library-based solution achieves 96.5% of optimal performance without manual tuning, outperforming multiprocessing (limited by ~8x memory overhead on devices with 512 MB-2 GB RAM) and asyncio (blocked by CPU-bound phases). Evaluation across seven edge AI workload profiles, including real ML inference with ONNX Runtime MobileNetV2, demonstrates 93.9% average efficiency. Comparative experiments with Python 3.13t (free threading) show that while GIL elimination enables ~4x throughput on multi-core edge devices, the saturation cliff persists on single-core devices, validating our beta metric for both GIL and no-GIL environments. This provides practical optimization for edge AI systems."}
{"id": "2601.09742", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.09742", "abs": "https://arxiv.org/abs/2601.09742", "authors": ["Sathish Sampath", "Anuradha Baskaran"], "title": "Adaptive Orchestration: Scalable Self-Evolving Multi-Agent Systems", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed as autonomous agents, they face a critical scalability bottleneck known as the \"Generalization-Specialization Dilemma.\" Monolithic agents equipped with extensive toolkits suffer from context pollution and attention decay, leading to hallucinations. Conversely, static multi-agent swarms introduce significant latency and resource overhead. This paper introduces a Self-Evolving Concierge System, a novel architecture utilizing a Dynamic Mixture of Experts (DMoE) approach. Unlike recent self-improving agents that rewrite their own codebase, our system preserves stability by dynamically restructuring its runtime environment: \"hiring\" specialized sub-agents based on real-time conversation analysis. We introduce an asynchronous \"Meta-Cognition Engine\" that detects capability gaps, a Least Recently Used (LRU) eviction policy for resource constraints, and a novel \"Surgical History Pruning\" mechanism to mitigate refusal bias. Experimental results demonstrate that this architecture maintains high task success rates while minimizing token consumption compared to static agent swarms."}
{"id": "2601.09773", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09773", "abs": "https://arxiv.org/abs/2601.09773", "authors": ["Binglei Lou", "Ruilin Wu", "Philip Leong"], "title": "Enhancing LUT-based Deep Neural Networks Inference through Architecture and Connectivity Optimization", "comment": "arXiv admin note: substantial text overlap with arXiv:2503.12829, arXiv:2406.04910", "summary": "Deploying deep neural networks (DNNs) on resource-constrained edge devices such as FPGAs requires a careful balance among latency, power, and hardware resource usage, while maintaining high accuracy. Existing Lookup Table (LUT)-based DNNs -- such as LogicNets, PolyLUT, and NeuraLUT -- face two critical challenges: the exponential growth of LUT size and inefficient random sparse connectivity. This paper presents SparseLUT, a comprehensive framework that addresses these challenges through two orthogonal optimizations. First, we propose an architectural enhancement that aggregates multiple PolyLUT sub-neurons via an adder, significantly reducing LUT consumption by 2.0x-13.9x and lowering inference latency by 1.2x-1.6x, all while maintaining comparable accuracy. Building upon this foundation, we further introduce a non-greedy training algorithm that optimizes neuron connectivity by selectively pruning less significant inputs and strategically regrowing more effective ones. This training optimization, which incurs no additional area and latency overhead, delivers consistent accuracy improvements across benchmarks -- achieving up to a 2.13% gain on MNIST and 0.94% on Jet Substructure Classification compared to existing LUT-DNN approaches."}
{"id": "2601.09978", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.09978", "abs": "https://arxiv.org/abs/2601.09978", "authors": ["Jer Shyuan Ng", "Wathsara Daluwatta", "Shehan Edirimannage", "Charitha Elvitigala", "Asitha Kottahachchi Kankanamge Don", "Ibrahim Khalil", "Heng Zhang", "Dusit Niyato"], "title": "Federated Unlearning in Edge Networks: A Survey of Fundamentals, Challenges, Practical Applications and Future Directions", "comment": null, "summary": "The proliferation of connected devices and privacy-sensitive applications has accelerated the adoption of Federated Learning (FL), a decentralized paradigm that enables collaborative model training without sharing raw data. While FL addresses data locality and privacy concerns, it does not inherently support data deletion requests that are increasingly mandated by regulations such as the Right to be Forgotten (RTBF). In centralized learning, this challenge has been studied under the concept of Machine Unlearning (MU), that focuses on efficiently removing the influence of specific data samples or clients from trained models. Extending this notion to federated settings has given rise to Federated Unlearning (FUL), a new research area concerned with eliminating the contributions of individual clients or data subsets from the global FL model in a distributed and heterogeneous environment. In this survey, we first introduce the fundamentals of FUL. Then, we review the FUL frameworks that are proposed to address the three main implementation challenges, i.e., communication cost, resource allocation as well as security and privacy. Furthermore, we discuss applications of FUL in the modern distributed computer networks. We also highlight the open challenges and future research opportunities. By consolidating existing knowledge and mapping open problems, this survey aims to serve as a foundational reference for researchers and practitioners seeking to advance FL to build trustworthy, regulation-compliant and user-centric federated systems."}
{"id": "2601.10083", "categories": ["cs.NI", "cs.ET", "math.DG"], "pdf": "https://arxiv.org/pdf/2601.10083", "abs": "https://arxiv.org/abs/2601.10083", "authors": ["Shayan Hamidi Dehshali", "Tzu-Hsuan Liao", "Shaileshh Bojja Venkatakrishnan"], "title": "Starfield: Demand-Aware Satellite Topology Design for Low-Earth Orbit Mega Constellations", "comment": "31 pages, 13 figures, 2 Tables, 1 Algorithm", "summary": "Low-Earth orbit (LEO) mega-constellations are emerging as high-capacity backbones for next-generation Internet. Deployment of laser terminals enables high-bandwidth, low-latency inter-satellite links (ISLs); however, their limited number, slow acquisition, and instability make forming a stable satellite topology difficult. Existing patterns like +Grid and Motif ignore regional traffic, ground station placement, and constellation geometry. Given sparse population distribution on Earth and the isolation of rural areas, traffic patterns are inherently non-uniform, providing an opportunity to orient inter-satellite links (ISLs) according to these traffic patterns. In this paper, we propose Starfield, a novel demand-aware satellite topology design heuristic algorithm supported by mathematical analysis. We first formulate a vector field on the constellation's shell according to traffic flows and define a corresponding Riemannian metric on the spherical manifold of the shell. The metric, combined with the spatial geometry, is used to assign a distance to each potential ISL, which we then aggregate over all demand flows to generate a heuristic for each satellite's link selection. Inspired by +Grid, each satellite selects the link with the minimum Riemannian heuristic along with its corresponding angular links. To evaluate Starfield, we developed a custom, link-aware, and link-configurable packet-level simulator, comparing it against +Grid and Random topologies. For the Phase 1 Starlink, simulation results show up to a 30% reduction in hop count and a 15% improvement in stretch factor across multiple traffic distributions. Moreover, static Starfield, an inter-orbital link matching modification of Starfield, achieves a 20% improvement in stretch factor under realistic traffic patterns compared to +Grid. Experiments further demonstrate Starfield's robustness under traffic demand perturbations."}
{"id": "2601.10041", "categories": ["cs.PF", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10041", "abs": "https://arxiv.org/abs/2601.10041", "authors": ["Sahba Baniasadi", "Paul M. Griffin", "Prakash Chakraborty"], "title": "Emergency Department Patient Flow Optimization with an Alternative Care Threshold Policy", "comment": "37 pages, 14 figures", "summary": "Emergency department (ED) overcrowding and patient boarding represent critical systemic challenges that compromise care quality. We propose a threshold-based admission policy that redirects non-urgent patients to alternative care pathways, such as telemedicine, during peak congestion. The ED is modeled as a two-class $M/M/c$ preemptive-priority queuing system, where high-acuity patients are prioritized and low-acuity patients are subject to state-dependent redirection. Analyzed via a level-dependent Quasi-Birth-Death (QBD) process, the model determines the optimal threshold by maximizing a long-run time-averaged objective function comprising redirection-affected revenue and costs associated with patient balking and system occupancy. Numerical analysis using national healthcare data reveals that optimal policies are highly context-dependent. While rural EDs generally optimize at lower redirection thresholds, urban EDs exhibit performance peaks at moderate thresholds. Results indicate that our optimal policy yields significant performance gains of up to $4.84\\%$ in rural settings and $5.90\\%$ in urban environments. This research provides a mathematically rigorous framework for balancing clinical priority with operational efficiency across diverse ED settings."}
{"id": "2601.09741", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09741", "abs": "https://arxiv.org/abs/2601.09741", "authors": ["James Uther"], "title": "Putting green software principles into practice", "comment": "1st International Workshop on Low Carbon Computing (LOCO 2024)", "summary": "The need and theoretical methods for measuring and reducing CO2 emitted by computing systems are well understood, but real-world examples are still limited. We describe a journey towards green software for a live product running on a public cloud. We discuss practical solutions found, in particular using the cost implications of serverless systems to drive efficiency. We end with some `green software' principles that worked well in this project."}
{"id": "2601.09746", "categories": ["cs.MA", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09746", "abs": "https://arxiv.org/abs/2601.09746", "authors": ["Philip Xu", "Isabel Wagner", "Eerke Boiten"], "title": "Multi-Agent Cooperative Learning for Robust Vision-Language Alignment under OOD Concepts", "comment": null, "summary": "This paper introduces a novel Multi-Agent Cooperative Learning (MACL) framework to address cross-modal alignment collapse in vision-language models when handling out-of-distribution (OOD) concepts. Four core agents, including image, text, name, and coordination agents, collaboratively mitigate modality imbalance through structured message passing. The proposed framework enables multi-agent feature space name learning, incorporates a context exchange enhanced few-shot learning algorithm, and adopts an adaptive dynamic balancing mechanism to regulate inter-agent contributions. Experiments on the VISTA-Beyond dataset demonstrate that MACL significantly improves performance in both few-shot and zero-shot settings, achieving 1-5% precision gains across diverse visual domains."}
{"id": "2601.10463", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.10463", "abs": "https://arxiv.org/abs/2601.10463", "authors": ["Xinyu Shi", "Simei Yang", "Francky Catthoor"], "title": "Architectural Classification of XR Workloads: Cross-Layer Archetypes and Implications", "comment": null, "summary": "Edge and mobile platforms for augmented and virtual reality, collectively referred to as extended reality (XR) must deliver deterministic ultra-low-latency performance under stringent power and area constraints. However, the diversity of XR workloads is rapidly increasing, characterized by heterogeneous operator types and complex dataflow structures. This trend poses significant challenges to conventional accelerator architectures centered around convolutional neural networks (CNNs), resulting in diminishing returns for traditional compute-centric optimization strategies. Despite the importance of this problem, a systematic architectural understanding of the full XR pipeline remains lacking. In this paper, we present an architectural classification of XR workloads using a cross-layer methodology that integrates model-based high-level design space exploration (DSE) with empirical profiling on commercial GPU and CPU hardware. By analyzing a representative set of workloads spanning 12 distinct XR kernels, we distill their complex architectural characteristics into a small set of cross-layer workload archetypes (e.g., capacity-limited and overhead-sensitive). Building on these archetypes, we further extract key architectural insights and provide actionable design guidelines for next-generation XR SoCs. Our study highlights that XR architecture design must shift from generic resource scaling toward phase-aware scheduling and elastic resource allocation in order to achieve greater energy efficiency and high performance in future XR systems."}
{"id": "2601.10177", "categories": ["cs.DC", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10177", "abs": "https://arxiv.org/abs/2601.10177", "authors": ["Ziting Zhang", "Kai Wan", "Minquan Cheng", "Shuo Shao", "Giuseppe Caire"], "title": "Distributed Linearly Separable Computation with Arbitrary Heterogeneous Data Assignment", "comment": null, "summary": "Distributed linearly separable computation is a fundamental problem in large-scale distributed systems, requiring the computation of linearly separable functions over different datasets across distributed workers. This paper studies a heterogeneous distributed linearly separable computation problem, including one master and N distributed workers. The linearly separable task function involves Kc linear combinations of K messages, where each message is a function of one dataset. Distinguished from the existing homogeneous settings that assume each worker holds the same number of datasets, where the data assignment is carefully designed and controlled by the data center (e.g., the cyclic assignment), we consider a more general setting with arbitrary heterogeneous data assignment across workers, where `arbitrary' means that the data assignment is given in advance and `heterogeneous' means that the workers may hold different numbers of datasets. Our objective is to characterize the fundamental tradeoff between the computable dimension of the task function and the communication cost under arbitrary heterogeneous data assignment. Under the constraint of integer communication costs, for arbitrary heterogeneous data assignment, we propose a universal computing scheme and a universal converse bound by characterizing the structure of data assignment, where they coincide under some parameter regimes. We then extend the proposed computing scheme and converse bound to the case of fractional communication costs."}
{"id": "2601.10544", "categories": ["cs.NI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.10544", "abs": "https://arxiv.org/abs/2601.10544", "authors": ["Andrea Piroddi", "Riccardo Fonti"], "title": "SDN-Driven Innovations in MANETs and IoT: A Path to Smarter Networks", "comment": null, "summary": "Mobile Ad Hoc Networks (MANETs) and Internet of Things (IoT) networks operate in decentralized and dynamic environments, making them ideal for scenarios lacking traditional infrastructure. However, these networks face challenges such as inefficient routing, limited scalability, and security vulnerabilities due to their decentralized nature and resource constraints. This paper explores the integration of Software-Defined Networking (SDN) as a unified solution that leverages its centralized control and network programmability to improve routing, resource management, and security. A mathematical model evaluates the impact of SDN integration on Capital Expenditure (CAPEX), Operational Expenditure (OPEX), and performance metrics. Results demonstrate that SDN-enhanced MANETs and IoT networks offer superior scalability, reduced latency, increased throughput, and lower packet loss, especially in dynamic and large-scale environments. While SDN introduces computational overhead, it significantly enhances routing efficiency, resource optimization, and adaptability. The proposed framework provides a robust and scalable solution, enabling the development of network architectures that efficiently manage growing node densities, dynamic topologies, and high data traffic. This approach ensures resilience, making it well-suited to meet the performance and reliability demands of modern, large-scale applications."}
{"id": "2601.10572", "categories": ["cs.PF"], "pdf": "https://arxiv.org/pdf/2601.10572", "abs": "https://arxiv.org/abs/2601.10572", "authors": ["Fang Zhou", "Yuyang Huang", "Miao Yu", "Sixiang Ma", "Tongping Liu", "Yang Wang"], "title": "Long-term Monitoring of Kernel and Hardware Events to Understand Latency Variance", "comment": null, "summary": "This paper presents our experience to understand latency variance caused by kernel and hardware events, which are often invisible at the application level. For this purpose, we have built VarMRI, a tool chain to monitor and analyze those events in the long term. To mitigate the \"big data\" problem caused by long-term monitoring, VarMRI selectively records a subset of events following two principles: it only records events that are affecting the requests recorded by the application; it records coarse-grained information first and records additional information only when necessary. Furthermore, VarMRI introduces an analysis method that is efficient on large amount of data, robust on different data set and against missing data, and informative to the user.\n  VarMRI has helped us to carry out a 3,000-hour study of six applications and benchmarks on CloudLab. It reveals a wide variety of events causing latency variance, including interrupt preemption, Java GC, pipeline stall, NUMA balancing etc.; simple optimization or tuning can reduce tail latencies by up to 31%. Furthermore, the impacts of some of these events vary significantly across different experiments, which confirms the necessity of long-term monitoring."}
{"id": "2601.09744", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09744", "abs": "https://arxiv.org/abs/2601.09744", "authors": ["Vignesh Alagappan"], "title": "A Governance Model for IoT Data in Global Manufacturing", "comment": null, "summary": "Industrial IoT platforms in global manufacturing environments generate continuous operational data across production assets, utilities, and connected products. While data ingestion and storage capabilities have matured significantly, enterprises continue to face systemic challenges in governing IoT data at scale. These challenges are not rooted in tooling limitations but in the absence of a governance model that aligns with the realities of distributed operational ownership, heterogeneous source systems, and continuous change at the edge. This paper presents a federated governance model that emphasizes contract-driven interoperability, policy-as-code enforcement, and asset-centric accountability across global manufacturing organizations. The model addresses governance enforcement at architectural boundaries, enabling semantic consistency, quality assurance, and regulatory compliance without requiring centralized control of operational technology systems. This work contributes a systems architecture and design framework grounded in analysis of manufacturing IoT requirements and constraints; empirical validation remains future work"}
{"id": "2601.10102", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.10102", "abs": "https://arxiv.org/abs/2601.10102", "authors": ["Viswonathan Manoranjan", "Snehalkumar `Neil' S. Gaikwad"], "title": "When Personas Override Payoffs: Role Identity Bias in Multi-Agent LLM Decision-Making", "comment": null, "summary": "Large language models are increasingly deployed in multi-agent systems for strategic tasks, yet how design choices such as role-based personas and payoff visibility affect reasoning remains poorly understood. We investigate whether multi-agent systems function as strategic reasoners capable of payoff optimization or as identity-driven actors that prioritize role alignment over explicit incentives. Using Nash equilibrium achievement as a diagnostic for strategic reasoning, we conduct systematic experiments across four LLM architectures (Qwen-7B, Qwen-32B, Llama-8B, Mistral-7B) in complex environmental decision-making games involving four agents. We show that role identity bias fundamentally alters strategic reasoning even when payoff-optimal equilibria exist and complete payoff information is available. Removing personas and providing explicit payoffs enables Qwen models to achieve high Nash equilibrium rates, indicating that both conditions are necessary for strategic reasoning. In contrast, personas systematically bias equilibrium selection toward socially preferred outcomes: with personas present, all of the achieved equilibria correspond to Green Transition, while models entirely fail to reach equilibrium when Tragedy of the Commons is payoff-optimal. The effect of explicit payoffs depends entirely on persona presence, revealing strong interactions between representational design choices. We also observe clear model-dependent patterns. Qwen architectures are highly sensitive to both personas and payoff visibility, whereas Llama and Mistral exhibit rigid reasoning behavior across conditions. These findings demonstrate that representational choices are substantive governance decisions that determine whether multi-agent systems act as strategic reasoners or identity-driven actors, with important implications for real-world deployment."}
{"id": "2601.10277", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.10277", "abs": "https://arxiv.org/abs/2601.10277", "authors": ["Evangelos Kolyvas", "Alexandros Antonov", "Spyros Voulgaris"], "title": "SCRamble: Adaptive Decentralized Overlay Construction for Blockchain Networks", "comment": "5 pages, 3 figures, The 27th ACM International Conference on Distributed Computing and Networking, ACM ICDCN 2026", "summary": "Despite being under development for over 15 years, transaction throughput remains one of the key challenges confronting blockchains, which typically has a cap of a limited number of transactions per second. A fundamental factor limiting this metric is the network latency associated with the block propagation throughout of the underlying peer-to-peer network, typically formed through random connections. Accelerating the dissemination of blocks not only improves transaction rates, but also enhances system security by reducing the probability of forks. This paper introduces SCRamble: a decentralized protocol that significantly reduces block dissemination time in blockchain networks. SCRamble's effectiveness is attributed to its innovative link selection strategy, which integrates two heuristics: a scoring mechanism that assesses block arrival times from neighboring peers, and a second heuristic that takes network latency into account."}
{"id": "2601.10556", "categories": ["cs.NI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.10556", "abs": "https://arxiv.org/abs/2601.10556", "authors": ["Riccardo Fonti", "Andrea Piroddi"], "title": "Enhancing Mobile Ad Hoc Networks (MANETs) with Software-Defined Networking (SDN): A Balanced Approach", "comment": null, "summary": "Mobile Ad Hoc Networks (MANETs) are decentralized wireless networks, characterized by their dynamic topologies and node mobility. In the era of cutting-edge technologies, integrating Software-Defined Networking (SDN) with MANETs offers a promising solution to manage these challenges more efficiently. This paper presents a balanced discussion of MANETs and SDN, demonstrating how SDN principles, such as centralized control and network virtualization, can optimize MANET performance in terms of scalability, cost-efficiency, and security. A mathematical model is developed to analyze Capital Expenditures (CAPEX), Operational Expenditures (OPEX), and network efficiency."}
{"id": "2601.10582", "categories": ["cs.DC", "cs.OS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.10582", "abs": "https://arxiv.org/abs/2601.10582", "authors": ["Mridankan Mandal", "Smit Sanjay Shende"], "title": "Mitigating GIL Bottlenecks in Edge AI Systems", "comment": null, "summary": "Deploying Python based AI agents on resource-constrained edge devices presents a runtime optimization challenge: high thread counts are needed to mask I/O latency, yet Python's Global Interpreter Lock (GIL) serializes execution. We demonstrate that naive thread-pool scaling causes a \"saturation cliff\": >= 20% throughput degradation at overprovisioned thread counts (N >= 512) on edge-representative configurations. We present a lightweight profiling tool and adaptive runtime system using a Blocking Ratio metric (beta) that distinguishes genuine I/O wait from GIL contention. Our library-based solution achieves 96.5% of optimal performance without manual tuning, outperforming multiprocessing (limited by ~8x memory overhead on devices with 512 MB-2 GB RAM) and asyncio (blocked by CPU-bound phases). Evaluation across seven edge AI workload profiles, including real ML inference with ONNX Runtime MobileNetV2, demonstrates 93.9% average efficiency. Comparative experiments with Python 3.13t (free threading) show that while GIL elimination enables ~4x throughput on multi-core edge devices, the saturation cliff persists on single-core devices, validating our beta metric for both GIL and no-GIL environments. This provides practical optimization for edge AI systems."}
{"id": "2601.09745", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09745", "abs": "https://arxiv.org/abs/2601.09745", "authors": ["Antonio Abu Nassar", "Eitan Farchi"], "title": "Enhancing Formal Software Specification with Artificial Intelligence", "comment": null, "summary": "Formal software specification is known to enable early error detection and explicit invariants, yet it has seen limited industrial adoption due to its high notation overhead and the expertise required to use traditional formal languages. This paper presents a case study showing that recent advances in artificial intelligence make it possible to retain many of the benefits of formal specification while substantially reducing these costs. The necessity of a clear distinction between what is controlled by the system analyst and can highly benefits from the rigor of formal specification and what need not be controlled is demonstrated. We use natural language augmented with lightweight mathematical notation and written in \\LaTeX\\ as an intermediate specification language, which is reviewed and refined by AI prior to code generation. Applied to a nontrivial simulation of organizational knowledge growth, this approach enables early validation, explicit invariants, and correctness by design, while significantly reducing development effort and producing a correct implementation on the first attempt."}
{"id": "2601.10120", "categories": ["cs.MA", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10120", "abs": "https://arxiv.org/abs/2601.10120", "authors": ["Rui Sun", "Jie Ding", "Chenghua Gong", "Tianjun Gu", "Yihang Jiang", "Juyuan Zhang", "Liming Pan", "Linyuan Lü"], "title": "TopoDIM: One-shot Topology Generation of Diverse Interaction Modes for Multi-Agent Systems", "comment": null, "summary": "Optimizing communication topology in LLM-based multi-agent system is critical for enabling collective intelligence. Existing methods mainly rely on spatio-temporal interaction paradigms, where the sequential execution of multi-round dialogues incurs high latency and computation. Motivated by the recent insights that evaluation and debate mechanisms can improve problem-solving in multi-agent systems, we propose TopoDIM, a framework for one-shot Topology generation with Diverse Interaction Modes. Designed for decentralized execution to enhance adaptability and privacy, TopoDIM enables agents to autonomously construct heterogeneous communication without iterative coordination, achieving token efficiency and improved task performance. Experiments demonstrate that TopoDIM reduces total token consumption by 46.41% while improving average performance by 1.50% over state-of-the-art methods. Moreover, the framework exhibits strong adaptability in organizing communication among heterogeneous agents. Code is available at: https://anonymous.4open.science/r/TopoDIM-8D35/"}
{"id": "2601.10582", "categories": ["cs.DC", "cs.OS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.10582", "abs": "https://arxiv.org/abs/2601.10582", "authors": ["Mridankan Mandal", "Smit Sanjay Shende"], "title": "Mitigating GIL Bottlenecks in Edge AI Systems", "comment": null, "summary": "Deploying Python based AI agents on resource-constrained edge devices presents a runtime optimization challenge: high thread counts are needed to mask I/O latency, yet Python's Global Interpreter Lock (GIL) serializes execution. We demonstrate that naive thread-pool scaling causes a \"saturation cliff\": >= 20% throughput degradation at overprovisioned thread counts (N >= 512) on edge-representative configurations. We present a lightweight profiling tool and adaptive runtime system using a Blocking Ratio metric (beta) that distinguishes genuine I/O wait from GIL contention. Our library-based solution achieves 96.5% of optimal performance without manual tuning, outperforming multiprocessing (limited by ~8x memory overhead on devices with 512 MB-2 GB RAM) and asyncio (blocked by CPU-bound phases). Evaluation across seven edge AI workload profiles, including real ML inference with ONNX Runtime MobileNetV2, demonstrates 93.9% average efficiency. Comparative experiments with Python 3.13t (free threading) show that while GIL elimination enables ~4x throughput on multi-core edge devices, the saturation cliff persists on single-core devices, validating our beta metric for both GIL and no-GIL environments. This provides practical optimization for edge AI systems."}
{"id": "2601.10605", "categories": ["cs.NI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10605", "abs": "https://arxiv.org/abs/2601.10605", "authors": ["José-Ramón Vidal", "Luis Guijarro", "Vicent Pla"], "title": "A user subscription model in mobile radio access networks with network slicing", "comment": null, "summary": "Network slicing is an architectural enabling technology that logically decouples the current cellular networks into infrastructure providers (InPs) and Network Slice Tenants (NSTs). The network resources (e.g., radio access resources at each cell) are owned by the InP, and are shared by the NSTs to provide a service to their mobile users. In this context, we proposed a business model that includes resource allocation and user subscription to NSTs in a competitive setting, and provides, among other things, closed-form expressions for the subscription indicators in equilibrium of each NST at each cell. This model relies on the widely adopted logit model to characterize user subscriptions. However, as a consequence of user mobility and radio propagation, some of the underlying assumptions in the logit model do not hold. Therefore, further research is needed to assess the accuracy of the results provided by the logit model in a mobile radio scenario. We carry out a thorough evaluation of the validity of the model by comparing its results against those obtained through computer simulation. Our simulation model includes complete and realistic characterizations of user mobility and radio propagation. From the results, we conclude in most cases the logit model provides valid results in a mobile radio scenario."}
{"id": "2601.09749", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09749", "abs": "https://arxiv.org/abs/2601.09749", "authors": ["Suriya Sureshkumar"], "title": "R-LAM: Reproducibility-Constrained Large Action Models for Scientific Workflow Automation", "comment": "9 pages, 3 figures, 1 Table, 2 Artifacts", "summary": "Large Action Models (LAMs) extend large language models by enabling autonomous decision-making and tool execution, making them promising for automating scientific workflows. However, scientific workflows impose strict requirements on reproducibility, auditability, and deterministic execution, which are not satisfied by generic LLM-based agents. Unconstrained action generation can lead to silent state changes, non-deterministic executions, and irreproducible experimental results, limiting the applicability of LAMs in scientific settings.\n  In this paper, we propose R-LAM, a reproducibility-constrained framework for applying Large Action Models to scientific workflow automation. R-LAM introduces structured action schemas, deterministic execution policies, and explicit provenance tracking to ensure that every action and intermediate artifact is auditable and replayable. The framework supports failure-aware execution loops and controlled workflow forking, enabling iterative experimentation without compromising reproducibility.\n  We implement R-LAM as a lightweight Python framework and release it as an open-source PyPI package to facilitate reproducible research. An experimental evaluation of representative scientific workflows demonstrates that R-LAM improves reproducibility success rates and execution reliability compared to unconstrained LLM-based agents, while retaining adaptive control over workflow execution."}
{"id": "2601.10123", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.10123", "abs": "https://arxiv.org/abs/2601.10123", "authors": ["Aditi Anand", "Dildar Ali", "Suman Banerjee"], "title": "Fairness Driven Multi-Agent Path Finding Problem", "comment": "This paper has been accepted in the 18th International Conference on Agents and Artificial Intelligence (ICCART 2026)", "summary": "The Multi-Agent Path Finding (MAPF) problem aims at finding non-conflicting paths for multiple agents from their respective sources to destinations. This problem arises in multiple real-life situations, including robot motion planning and airspace assignment for unmanned aerial vehicle movement. The problem is computationally expensive, and adding to it, the agents are rational and can misreport their private information. In this paper, we study both variants of the problem under the realm of fairness. For the non-rational agents, we propose a heuristic solution for this problem. Considering the agents are rational, we develop a mechanism and demonstrate that it is a dominant strategy, incentive compatible, and individually rational. We employ various solution methodologies to highlight the effectiveness and efficiency of the proposed solution approaches."}
{"id": "2601.10277", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.10277", "abs": "https://arxiv.org/abs/2601.10277", "authors": ["Evangelos Kolyvas", "Alexandros Antonov", "Spyros Voulgaris"], "title": "SCRamble: Adaptive Decentralized Overlay Construction for Blockchain Networks", "comment": "5 pages, 3 figures, The 27th ACM International Conference on Distributed Computing and Networking, ACM ICDCN 2026", "summary": "Despite being under development for over 15 years, transaction throughput remains one of the key challenges confronting blockchains, which typically has a cap of a limited number of transactions per second. A fundamental factor limiting this metric is the network latency associated with the block propagation throughout of the underlying peer-to-peer network, typically formed through random connections. Accelerating the dissemination of blocks not only improves transaction rates, but also enhances system security by reducing the probability of forks. This paper introduces SCRamble: a decentralized protocol that significantly reduces block dissemination time in blockchain networks. SCRamble's effectiveness is attributed to its innovative link selection strategy, which integrates two heuristics: a scoring mechanism that assesses block arrival times from neighboring peers, and a second heuristic that takes network latency into account."}
{"id": "2601.09750", "categories": ["cs.SE", "cs.AI", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.09750", "abs": "https://arxiv.org/abs/2601.09750", "authors": ["Robert K. Strehlow", "Tobias Küster", "Oskar F. Kupke", "Brandon Llanque Kurps", "Fikret Sivrikaya", "Sahin Albayrak"], "title": "SAGE: Tool-Augmented LLM Task Solving Strategies in Scalable Multi-Agent Environments", "comment": null, "summary": "Large language models (LLMs) have proven to work well in question-answering scenarios, but real-world applications often require access to tools for live information or actuation. For this, LLMs can be extended with tools, which are often defined in advance, also allowing for some fine-tuning for specific use cases. However, rapidly evolving software landscapes and individual services require the constant development and integration of new tools. Domain- or company-specific tools can greatly elevate the usefulness of an LLM, but such custom tools can be problematic to integrate, or the LLM may fail to reliably understand and use them. For this, we need strategies to define new tools and integrate them into the LLM dynamically, as well as robust and scalable zero-shot prompting methods that can make use of those tools in an efficient manner. In this paper, we present SAGE, a specialized conversational AI interface, based on the OPACA framework for tool discovery and execution. The integration with OPACA makes it easy to add new tools or services for the LLM to use, while SAGE itself presents rich extensibility and modularity. This not only provides the ability to seamlessly switch between different models (e.g. GPT, LLAMA), but also to add and select prompting methods, involving various setups of differently prompted agents for selecting and executing tools and evaluating the results. We implemented a number of task-solving strategies, making use of agentic concepts and prompting methods in various degrees of complexity, and evaluated those against a comprehensive set of benchmark services. The results are promising and highlight the distinct strengths and weaknesses of different task-solving strategies. Both SAGE and the OPACA framework, as well as the different benchmark services and results, are available as Open Source/Open Data on GitHub."}
{"id": "2601.10299", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.10299", "abs": "https://arxiv.org/abs/2601.10299", "authors": ["Zhenyu Zhao", "Tiankui Zhang", "Xiaoxia Xu", "Junjie Li", "Yuanwei Liu", "Wenjuan Xing"], "title": "Multipath Routing for Multi-Hop UAV Networks", "comment": "This paper has been submitted to IEEE Transactions on Communications", "summary": "Multi-hop uncrewed aerial vehicle (UAV) networks are promising to extend the terrestrial network coverage. Existing multi-hop UAV networks employ a single routing path by selecting the next-hop forwarding node in a hop-by-hop manner, which leads to local congestion and increases traffic delays. In this paper, a novel traffic-adaptive multipath routing method is proposed for multi-hop UAV networks, which enables each UAV to dynamically split and forward traffic flows across multiple next-hop neighbors, thus meeting latency requirements of diverse traffic flows in dynamic mobile environments. An on-time packet delivery ratio maximization problem is formulated to determine the traffic splitting ratios at each hop. This sequential decision-making problem is modeled as a decentralized partially observable Markov decision process (Dec-POMDP). To solve this Dec-POMDP, a novel multi-agent deep reinforcement leaning (MADRL) algorithm, termed Independent Proximal Policy Optimization with Dirichlet Modeling (IPPO-DM), is developed. Specifically, the IPPO serves as the core optimization framework, where the Dirichlet distribution is leveraged to parameterize a continuous stochastic policy network on the probability simplex, inherently ensuring feasible traffic splitting ratios. Simulation results demonstrate that IPPO-DM outperforms benchmark schemes in terms of both delivery latency guarantee and packet loss performance."}
{"id": "2601.09760", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09760", "abs": "https://arxiv.org/abs/2601.09760", "authors": ["Jiali Cheng", "Rui Pan", "Hadi Amiri"], "title": "Investigating Tool-Memory Conflicts in Tool-Augmented LLMs", "comment": "R2-FM Workshop @ ICML 2025", "summary": "Tool-augmented large language models (LLMs) have powered many applications. However, they are likely to suffer from knowledge conflict. In this paper, we propose a new type of knowledge conflict -- Tool-Memory Conflict (TMC), where the internal parametric knowledge contradicts with the external tool knowledge for tool-augmented LLMs. We find that existing LLMs, though powerful, suffer from TMC, especially on STEM-related tasks. We also uncover that under different conditions, tool knowledge and parametric knowledge may be prioritized differently. We then evaluate existing conflict resolving techniques, including prompting-based and RAG-based methods. Results show that none of these approaches can effectively resolve tool-memory conflicts."}
{"id": "2601.10560", "categories": ["cs.MA", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10560", "abs": "https://arxiv.org/abs/2601.10560", "authors": ["Xi Shi", "Mengxin Zheng", "Qian Lou"], "title": "Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems", "comment": "Preprint", "summary": "Multi-agent systems (MAS) enable complex reasoning by coordinating multiple agents, but often incur high inference latency due to multi-step execution and repeated model invocations, severely limiting their scalability and usability in time-sensitive scenarios. Most existing approaches primarily optimize task performance and inference cost, and explicitly or implicitly assume sequential execution, making them less optimal for controlling latency under parallel execution. In this work, we investigate learning-based orchestration of multi-agent systems with explicit latency supervision under parallel execution. We propose Latency-Aware Multi-agent System (LAMaS), a latency-aware multi-agent orchestration framework that enables parallel execution and explicitly optimizes the critical execution path, allowing the controller to construct execution topology graphs with lower latency under parallel execution. Our experiments show that our approach reduces critical path length by 38-46% compared to the state-of-the-art baseline for multi-agent architecture search across multiple benchmarks, while maintaining or even improving task performance. These results highlight the importance of explicitly optimizing latency under parallel execution when designing efficient multi-agent systems. The code is available at https://github.com/xishi404/LAMaS"}
{"id": "2601.09762", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09762", "abs": "https://arxiv.org/abs/2601.09762", "authors": ["Zhiyi Xue", "Xiaohong Chen", "Min Zhang"], "title": "Explicating Tacit Regulatory Knowledge from LLMs to Auto-Formalize Requirements for Compliance Test Case Generation", "comment": "16 pages, 8 figures, 4 tables", "summary": "Compliance testing in highly regulated domains is crucial but largely manual, requiring domain experts to translate complex regulations into executable test cases. While large language models (LLMs) show promise for automation, their susceptibility to hallucinations limits reliable application. Existing hybrid approaches mitigate this issue by constraining LLMs with formal models, but still rely on costly manual modeling. To solve this problem, this paper proposes RAFT, a framework for requirements auto-formalization and compliance test generation via explicating tacit regulatory knowledge from multiple LLMs. RAFT employs an Adaptive Purification-Aggregation strategy to explicate tacit regulatory knowledge from multiple LLMs and integrate it into three artifacts: a domain meta-model, a formal requirements representation, and testability constraints. These artifacts are then dynamically injected into prompts to guide high-precision requirement formalization and automated test generation. Experiments across financial, automotive, and power domains show that RAFT achieves expert-level performance, substantially outperforms state-of-the-art (SOTA) methods while reducing overall generation and review time."}
{"id": "2601.10600", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10600", "abs": "https://arxiv.org/abs/2601.10600", "authors": ["Joshua Caiata", "Carter Blair", "Kate Larson"], "title": "Procedural Fairness in Multi-Agent Bandits", "comment": null, "summary": "In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides equal decision-making power for all agents, lies in the core, and provides for proportionality in outcomes. Empirical results confirm that fairness notions based on optimizing for outcomes sacrifice equal voice and representation, while the sacrifice in outcome-based fairness objectives (like equality and utilitarianism) is minimal under procedurally fair policies. We further prove that different fairness notions prioritize fundamentally different and incompatible values, highlighting that fairness requires explicit normative choices. This paper argues that procedural legitimacy deserves greater focus as a fairness objective, and provides a framework for putting procedural fairness into practice."}
{"id": "2601.09822", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09822", "abs": "https://arxiv.org/abs/2601.09822", "authors": ["Yongjian Tang", "Thomas Runkler"], "title": "LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities", "comment": "Accepted to GenSE 2026 workshop", "summary": "Despite recent advancements in Large Language Models (LLMs), complex Software Engineering (SE) tasks require more collaborative and specialized approaches. This concept paper systematically reviews the emerging paradigm of LLM-based multi-agent systems, examining their applications across the Software Development Life Cycle (SDLC), from requirements engineering and code generation to static code checking, testing, and debugging. We delve into a wide range of topics such as language model selection, SE evaluation benchmarks, state-of-the-art agentic frameworks and communication protocols. Furthermore, we identify key challenges and outline future research opportunities, with a focus on multi-agent orchestration, human-agent coordination, computational cost optimization, and effective data collection. This work aims to provide researchers and practitioners with valuable insights into the current forefront landscape of agentic systems within the software engineering domain."}
{"id": "2601.09750", "categories": ["cs.SE", "cs.AI", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.09750", "abs": "https://arxiv.org/abs/2601.09750", "authors": ["Robert K. Strehlow", "Tobias Küster", "Oskar F. Kupke", "Brandon Llanque Kurps", "Fikret Sivrikaya", "Sahin Albayrak"], "title": "SAGE: Tool-Augmented LLM Task Solving Strategies in Scalable Multi-Agent Environments", "comment": null, "summary": "Large language models (LLMs) have proven to work well in question-answering scenarios, but real-world applications often require access to tools for live information or actuation. For this, LLMs can be extended with tools, which are often defined in advance, also allowing for some fine-tuning for specific use cases. However, rapidly evolving software landscapes and individual services require the constant development and integration of new tools. Domain- or company-specific tools can greatly elevate the usefulness of an LLM, but such custom tools can be problematic to integrate, or the LLM may fail to reliably understand and use them. For this, we need strategies to define new tools and integrate them into the LLM dynamically, as well as robust and scalable zero-shot prompting methods that can make use of those tools in an efficient manner. In this paper, we present SAGE, a specialized conversational AI interface, based on the OPACA framework for tool discovery and execution. The integration with OPACA makes it easy to add new tools or services for the LLM to use, while SAGE itself presents rich extensibility and modularity. This not only provides the ability to seamlessly switch between different models (e.g. GPT, LLAMA), but also to add and select prompting methods, involving various setups of differently prompted agents for selecting and executing tools and evaluating the results. We implemented a number of task-solving strategies, making use of agentic concepts and prompting methods in various degrees of complexity, and evaluated those against a comprehensive set of benchmark services. The results are promising and highlight the distinct strengths and weaknesses of different task-solving strategies. Both SAGE and the OPACA framework, as well as the different benchmark services and results, are available as Open Source/Open Data on GitHub."}
{"id": "2601.09832", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09832", "abs": "https://arxiv.org/abs/2601.09832", "authors": ["Alvari Kupari", "Nasser Giacaman", "Valerio Terragni"], "title": "Adoption and Evolution of Code Style and Best Programming Practices in Open-Source Projects", "comment": "Published in IEEE International Conference on Software Maintenance and Evolution (ICSME 2025). Authors' version", "summary": "Following code style conventions in software projects is essential for maintaining overall code quality. Adhering to these conventions improves maintainability, understandability, and extensibility. Additionally, following best practices during software development enhances performance and reduces the likelihood of errors. This paper analyzes 1,036 popular open-source JAVA projects on GITHUB to study how code style and programming practices are adopted and evolve over time, examining their prevalence and the most common violations. Additionally, we study a subset of active repositories on a monthly basis to track changes in adherence to coding standards over time. We found widespread violations across repositories, with Javadoc and Naming violations being the most common. We also found a significant number of violations of the GOOGLE Java Style Guide in categories often missed by modern static analysis tools. Furthermore, repositories claiming to follow code-style practices exhibited slightly higher overall adherence to code-style and best-practices. The results provide valuable insights into the adoption of code style and programming practices, highlighting key areas for improvement in the open-source development community. Furthermore, the paper identifies important lessons learned and suggests future directions for improving code quality in JAVA projects."}
{"id": "2601.09842", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09842", "abs": "https://arxiv.org/abs/2601.09842", "authors": ["Walid Maalej"], "title": "On Fun for Teaching Large Programming Courses", "comment": "Accepted at 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE-SEET '26)", "summary": "Teaching software development basics to hundreds of students in a frontal setting is cost-efficient and thus still common in universities. However, in a large lecture hall, students can easily get bored, distracted, and disengaged. The frontal setting can also frustrate lecturers since interaction opportunities are limited and hard to scale. Fun activities can activate students and, if well designed, can also help remember and reflect on abstract software development concepts. We present a novel catalogue of ten physical fun activities, developed over years to reflect on basic programming and software development concepts. The catalogue includes the execution of a LA-OLA algorithm as in stadiums, using paper planes to simulate object messages and pointers, and traversing a lecture hall as a tree or a recursive structure. We report our experience of using the activities in a large course with 500+ students three years in a row. We also conducted an interview study with 15 former students of the course and 14 experienced educators from around the globe. The results suggest that the fun activities can enable students to stay focused, remember key concepts, and reflect afterwards. However, keeping the activities concise and clearly linked to the concepts taught seems to be key to their acceptance and effectiveness."}
{"id": "2601.09873", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09873", "abs": "https://arxiv.org/abs/2601.09873", "authors": ["Saymon Souza", "Amanda Santana", "Eduardo Figueiredo", "Igor Muzetti", "João Eduardo Montandon", "Lionel Briand"], "title": "Beyond Strict Rules: Assessing the Effectiveness of Large Language Models for Code Smell Detection", "comment": null, "summary": "Code smells are symptoms of potential code quality problems that may affect software maintainability, thus increasing development costs and impacting software reliability. Large language models (LLMs) have shown remarkable capabilities for supporting various software engineering activities, but their use for detecting code smells remains underexplored. However, unlike the rigid rules of static analysis tools, LLMs can support flexible and adaptable detection strategies tailored to the unique properties of code smells. This paper evaluates the effectiveness of four LLMs -- DeepSeek-R1, GPT-5 mini, Llama-3.3, and Qwen2.5-Code -- for detecting nine code smells across 30 Java projects. For the empirical evaluation, we created a ground-truth dataset by asking 76 developers to manually inspect 268 code-smell candidates. Our results indicate that LLMs perform strongly for structurally straightforward smells, such as Large Class and Long Method. However, we also observed that different LLMs and tools fare better for distinct code smells. We then propose and evaluate a detection strategy that combines LLMs and static analysis tools. The proposed strategy outperforms LLMs and tools in five out of nine code smells in terms of F1-Score. However, it also generates more false positives for complex smells. Therefore, we conclude that the optimal strategy depends on whether Recall or Precision is the main priority for code smell detection."}
{"id": "2601.09905", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09905", "abs": "https://arxiv.org/abs/2601.09905", "authors": ["Zackary Okun Dunivin", "Mobina Noori", "Seth Frey", "Curtis Atkinson"], "title": "Self-reflection in Automated Qualitative Coding: Improving Text Annotation through Secondary LLM Critique", "comment": null, "summary": "Large language models (LLMs) allow for sophisticated qualitative coding of large datasets, but zero- and few-shot classifiers can produce an intolerable number of errors, even with careful, validated prompting. We present a simple, generalizable two-stage workflow: an LLM applies a human-designed, LLM-adapted codebook; a secondary LLM critic performs self-reflection on each positive label by re-reading the source text alongside the first model's rationale and issuing a final decision. We evaluate this approach on six qualitative codes over 3,000 high-content emails from Apache Software Foundation project evaluation discussions. Our human-derived audit of 360 positive annotations (60 passages by six codes) found that the first-line LLM had a false-positive rate of 8% to 54%, despite F1 scores of 0.74 and 1.00 in testing. Subsequent recoding of all stage-one annotations via a second self-reflection stage improved F1 by 0.04 to 0.25, bringing two especially poor performing codes up to 0.69 and 0.79 from 0.52 and 0.55 respectively. Our manual evaluation identified two recurrent error classes: misinterpretation (violations of code definitions) and meta-discussion (debate about a project evaluation criterion mistaken for its use as a decision justification). Code-specific critic clauses addressing observed failure modes were especially effective with testing and refinement, replicating the codebook-adaption process for LLM interpretation in stage-one. We explain how favoring recall in first-line LLM annotation combined with secondary critique delivers precision-first, compute-light control. With human guidance and validation, self-reflection slots into existing LLM-assisted annotation pipelines to reduce noise and potentially salvage unusable classifiers."}
{"id": "2601.10068", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.10068", "abs": "https://arxiv.org/abs/2601.10068", "authors": ["Lianjing Wang", "Yufeng Zhang", "Kenli Li", "Zhenbang Chen", "Xu Zhou", "Pengfei Wang", "Guangning Song", "Ji Wang"], "title": "S$^2$F: Principled Hybrid Testing With Fuzzing, Symbolic Execution, and Sampling", "comment": null, "summary": "Hybrid testing that integrates fuzzing, symbolic execution, and sampling has demonstrated superior testing efficiency compared to individual techniques. However, the state-of-the-art (SOTA) hybrid testing tools do not fully exploit the capabilities of symbolic execution and sampling in two key aspects. First, the SOTA hybrid testing tools employ tailored symbolic execution engines that tend to over-prune branches, leading to considerable time wasted waiting for seeds from the fuzzer and missing opportunities to discover crashes. Second, existing methods do not apply sampling to the appropriate branches and therefore cannot utilize the full capability of sampling. To address these two limitations, we propose a novel hybrid testing architecture that combines the precision of conventional symbolic execution with the scalability of tailored symbolic execution engines. Based on this architecture, we propose several principles for combining fuzzing, symbolic execution, and sampling. We implement our method in a hybrid testing tool S$^2$F. To evaluate its effectiveness, we conduct extensive experiments on 15 real-world programs. Experimental results demonstrate that S$^2$F outperforms the SOTA tool, achieving an average improvement of 6.14% in edge coverage and 32.6% in discovered crashes. Notably, our tool uncovers three previously unknown crashes in real-world programs."}
{"id": "2601.10093", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.10093", "abs": "https://arxiv.org/abs/2601.10093", "authors": ["Yiding Qiu", "Seyed Mahdi Azimi", "Artem Lensky"], "title": "Mark My Works Autograder for Programming Courses", "comment": null, "summary": "Large programming courses struggle to provide timely, detailed feedback on student code. We developed Mark My Works, a local autograding system that combines traditional unit testing with LLM-generated explanations. The system uses role-based prompts to analyze submissions, critique code quality, and generate pedagogical feedback while maintaining transparency in its reasoning process.\n  We piloted the system in a 191-student engineering course, comparing AI-generated assessments with human grading on 79 submissions. While AI scores showed no linear correlation with human scores (r = -0.177, p = 0.124), both systems exhibited similar left-skewed distributions, suggesting they recognize comparable quality hierarchies despite different scoring philosophies. The AI system demonstrated more conservative scoring (mean: 59.95 vs 80.53 human) but generated significantly more detailed technical feedback."}
{"id": "2601.10112", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10112", "abs": "https://arxiv.org/abs/2601.10112", "authors": ["Tsvi Cherny-Shahar", "Amiram Yehudai"], "title": "Repository Intelligence Graph: Deterministic Architectural Map for LLM Code Assistants", "comment": "35 pages, 5 figures", "summary": "Repository aware coding agents often struggle to recover build and test structure, especially in multilingual projects where cross language dependencies are encoded across heterogeneous build systems and tooling. We introduce the Repository Intelligence Graph (RIG), a deterministic, evidence backed architectural map that represents buildable components, aggregators, runners, tests, external packages, and package managers, connected by explicit dependency and coverage edges that trace back to concrete build and test definitions. We also present SPADE, a deterministic extractor that constructs RIG from build and test artifacts (currently with an automatic CMake plugin based on the CMake File API and CTest metadata), and exposes RIG as an LLM friendly JSON view that agents can treat as the authoritative description of repository structure.\n  We evaluate three commercial agents (Claude Code, Cursor, Codex) on eight repositories spanning low to high build oriented complexity, including the real world MetaFFI project. Each agent answers thirty structured questions per repository with and without RIG in context, and we measure accuracy, wall clock completion time, and efficiency (seconds per correct answer). Across repositories and agents, providing RIG improves mean accuracy by 12.2\\% and reduces completion time by 53.9\\%, yielding a mean 57.8\\% reduction in seconds per correct answer. Gains are larger in multilingual repositories, which improve by 17.7\\% in accuracy and 69.5\\% in efficiency on average, compared to 6.6\\% and 46.1\\% in single language repositories. Qualitative analysis suggests that RIG shifts failures from structural misunderstandings toward reasoning mistakes over a correct structure, while rare regressions highlight that graph based reasoning quality remains a key factor."}
{"id": "2601.10164", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.10164", "abs": "https://arxiv.org/abs/2601.10164", "authors": ["Themistoklis Diamantopoulos", "Dimosthenis Natsos", "Andreas L. Symeonidis"], "title": "Towards Online Malware Detection using Process Resource Utilization Metrics", "comment": "6 pages, 6 figures", "summary": "The rapid growth of Cloud Computing and Internet of Things (IoT) has significantly increased the interconnection of computational resources, creating an environment where malicious software (malware) can spread rapidly. To address this challenge, researchers are increasingly utilizing Machine Learning approaches to identify malware through behavioral (i.e. dynamic) cues. However, current approaches are limited by their reliance on large labeled datasets, fixed model training, and the assumption that a trained model remains effective over time-disregarding the ever-evolving sophistication of malware. As a result, they often fail to detect evolving malware attacks that adapt over time. This paper proposes an online learning approach for dynamic malware detection, that overcomes these limitations by incorporating temporal information to continuously update its models using behavioral features, specifically process resource utilization metrics. By doing so, the proposed models can incrementally adapt to emerging threats and detect zero-day malware effectively. Upon evaluating our approach against traditional batch algorithms, we find it effective in detecting zero-day malware. Moreover, we demonstrate its efficacy in scenarios with limited data availability, where traditional batch-based approaches often struggle to perform reliably."}
{"id": "2601.10220", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.10220", "abs": "https://arxiv.org/abs/2601.10220", "authors": ["Simin Sun", "Miroslaw Staron"], "title": "Agentic Pipelines in Embedded Software Engineering: Emerging Practices and Challenges", "comment": null, "summary": "A new transformation is underway in software engineering, driven by the rapid adoption of generative AI in development workflows. Similar to how version control systems once automated manual coordination, AI tools are now beginning to automate many aspects of programming. For embedded software engineering organizations, however, this marks their first experience integrating AI into safety-critical and resource-constrained environments. The strict demands for determinism, reliability, and traceability pose unique challenges for adopting generative technologies.\n  In this paper, we present findings from a qualitative study with ten senior experts from four companies who are evaluating generative AI-augmented development for embedded software. Through semi-structured focus group interviews and structured brainstorming sessions, we identified eleven emerging practices and fourteen challenges related to the orchestration, responsible governance, and sustainable adoption of generative AI tools. Our results show how embedded software engineering teams are rethinking workflows, roles, and toolchains to enable a sustainable transition toward agentic pipelines and generative AI-augmented development."}
{"id": "2601.10258", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.10258", "abs": "https://arxiv.org/abs/2601.10258", "authors": ["Agnia Sergeyuk", "Eric Huang", "Dariia Karaeva", "Anastasiia Serova", "Yaroslav Golubev", "Iftekhar Ahmed"], "title": "Evolving with AI: A Longitudinal Analysis of Developer Logs", "comment": "Accepted to ICSE'26 Research track. 12 pages, 5 figures, 1 table", "summary": "AI-powered coding assistants are rapidly becoming fixtures in professional IDEs, yet their sustained influence on everyday development remains poorly understood. Prior research has focused on short-term use or self-reported perceptions, leaving open questions about how sustained AI use reshapes actual daily coding practices in the long term. We address this gap with a mixed-method study of AI adoption in IDEs, combining longitudinal two-year fine-grained telemetry from 800 developers with a survey of 62 professionals. We analyze five dimensions of workflow change: productivity, code quality, code editing, code reuse, and context switching. Telemetry reveals that AI users produce substantially more code but also delete significantly more. Meanwhile, survey respondents report productivity gains and perceive minimal changes in other dimensions. Our results offer empirical insights into the silent restructuring of software workflows and provide implications for designing future AI-augmented tooling."}
{"id": "2601.10496", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10496", "abs": "https://arxiv.org/abs/2601.10496", "authors": ["Ali Al-Kaswan", "Claudio Spiess", "Prem Devanbu", "Arie van Deursen", "Maliheh Izadi"], "title": "Model See, Model Do? Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code LLMs", "comment": "MSR 2026 Technical Track", "summary": "Large language models are increasingly used for code generation and debugging, but their outputs can still contain bugs, that originate from training data. Distinguishing whether an LLM prefers correct code, or a familiar incorrect version might be influenced by what it's been exposed to during training. We introduce an exposure-aware evaluation framework that quantifies how prior exposure to buggy versus fixed code influences a model's preference. Using the ManySStuBs4J benchmark, we apply Data Portraits for membership testing on the Stack-V2 corpus to estimate whether each buggy and fixed variant was seen during training. We then stratify examples by exposure and compare model preference using code completion as well as multiple likelihood-based scoring metrics We find that most examples (67%) have neither variant in the training data, and when only one is present, fixes are more frequently present than bugs. In model generations, models reproduce buggy lines far more often than fixes, with bug-exposed examples amplifying this tendency and fix-exposed examples showing only marginal improvement. In likelihood scoring, minimum and maximum token-probability metrics consistently prefer the fixed code across all conditions, indicating a stable bias toward correct fixes. In contrast, metrics like the Gini coefficient reverse preference when only the buggy variant was seen. Our results indicate that exposure can skew bug-fix evaluations and highlight the risk that LLMs may propagate memorised errors in practice."}
