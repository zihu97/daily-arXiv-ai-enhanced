{"id": "2510.24112", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.24112", "abs": "https://arxiv.org/abs/2510.24112", "authors": ["Junchi Wu", "Xinfei Wan", "Zhuoran Li", "Yuyang Jin", "Guangyu Sun", "Yun Liang", "Diyu Zhou", "Youwei Zhuo"], "title": "SlowPoke: Understanding and Detecting On-Chip Fail-Slow Failures in Many-Core Systems", "comment": "15 pages, 15 figures", "summary": "Many-core architectures are essential for high-performance computing, but\ntheir performance is undermined by widespread fail-slow failures. Detecting\nsuch failures on-chip is challenging, as prior methods from distributed systems\nare unsuitable due to strict memory limits and their inability to track\nfailures across the hardware topology. This paper introduces SlowPoke, a\nlightweight, hardware-aware framework for practical on-chip fail-slow\ndetection. SlowPoke combines compiler-based instrumentation for low-overhead\nmonitoring, on-the-fly trace compression to operate within kilobytes of memory,\nand a novel topology-aware ranking algorithm to pinpoint a failure's root\ncause. We evaluate SlowPoke on a wide range of representative many-core\nworkloads, and the results demonstrate that SlowPoke reduces the storage\noverhead of detection traces by an average of 115.9$\\times$, while achieving an\naverage fail-slow detection accuracy of 86.77% and a false positive rate (FPR)\nof 12.11%. More importantly, SlowPoke scales effectively across different\nmany-core architectures, making it practical for large-scale deployments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SlowPoke\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u786c\u4ef6\u611f\u77e5\u7684\u7247\u4e0a\u6162\u901f\u6545\u969c\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u7f16\u8bd1\u5668\u63d2\u6869\u3001\u5b9e\u65f6\u8ffd\u8e2a\u538b\u7f29\u548c\u62d3\u6251\u611f\u77e5\u6392\u5e8f\u7b97\u6cd5\uff0c\u5728\u6781\u4f4e\u5185\u5b58\u5f00\u9500\u4e0b\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u7684\u6545\u969c\u68c0\u6d4b\u3002", "motivation": "\u591a\u6838\u67b6\u6784\u4e2d\u666e\u904d\u5b58\u5728\u201c\u6162\u901f\u6545\u969c\u201d\uff08fail-slow\uff09\u95ee\u9898\uff0c\u4e25\u91cd\u5f71\u54cd\u6027\u80fd\uff1b\u73b0\u6709\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u68c0\u6d4b\u65b9\u6cd5\u56e0\u5185\u5b58\u9650\u5236\u548c\u65e0\u6cd5\u8ffd\u8e2a\u786c\u4ef6\u62d3\u6251\u7ed3\u6784\u800c\u4e0d\u9002\u7528\u4e8e\u7247\u4e0a\u73af\u5883\u3002", "method": "SlowPoke\u7ed3\u5408\u4e86\u57fa\u4e8e\u7f16\u8bd1\u5668\u7684\u4f4e\u5f00\u9500\u76d1\u63a7\u3001\u5343\u5b57\u8282\u7ea7\u5185\u5b58\u5185\u8fd0\u884c\u7684\u5b9e\u65f6\u8ffd\u8e2a\u538b\u7f29\u6280\u672f\uff0c\u4ee5\u53ca\u4e00\u79cd\u65b0\u9896\u7684\u62d3\u6251\u611f\u77e5\u6839\u56e0\u6392\u5e8f\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSlowPoke\u5e73\u5747\u5c06\u68c0\u6d4b\u8ffd\u8e2a\u7684\u5b58\u50a8\u5f00\u9500\u964d\u4f4e115.9\u500d\uff0c\u5e73\u5747\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe86.77%\uff0c\u8bef\u62a5\u7387\u4e3a12.11%\uff0c\u5e76\u5728\u591a\u79cd\u591a\u6838\u67b6\u6784\u4e0a\u5177\u6709\u826f\u597d\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "SlowPoke\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u7247\u4e0a\u6162\u901f\u6545\u969c\u68c0\u6d4b\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u591a\u6838\u7cfb\u7edf\u90e8\u7f72\u3002"}}
{"id": "2510.23911", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.23911", "abs": "https://arxiv.org/abs/2510.23911", "authors": ["Arno Uhlig", "Iris Braun", "Matthias W\u00e4hlisch"], "title": "The SAP Cloud Infrastructure Dataset: A Reality Check of Scheduling and Placement of VMs in Cloud Computing", "comment": "15 pages", "summary": "Allocating resources in a distributed environment is a fundamental challenge.\nIn this paper, we analyze the scheduling and placement of virtual machines\n(VMs) in the cloud platform of SAP, the world's largest enterprise resource\nplanning software vendor. Based on data from roughly 1,800 hypervisors and\n48,000 VMs within a 30-day observation period, we highlight potential\nimprovements for workload management. The data was measured through\nobservability tooling that tracks resource usage and performance metrics across\nthe entire infrastructure. In contrast to existing datasets, ours uniquely\noffers fine-grained time-series telemetry data of fully virtualized\nenterprise-level workloads from both long-running and memory-intensive SAP\nS/4HANA and diverse, general-purpose applications. Our key findings include\nseveral suboptimal scheduling situations, such as CPU resource contention\nexceeding 40%, CPU ready times of up to 220 seconds, significantly imbalanced\ncompute hosts with a maximum CPU~utilization on intra-building block hosts of\nup to 99%, and overprovisioned CPU and memory resources resulting into over 80%\nof VMs using less than 70% of the provided resources. Bolstered by these\nfindings, we derive requirements for the design and implementation of novel\nplacement and scheduling algorithms and provide guidance to optimize resource\nallocations. We make the full dataset used in this study publicly available to\nenable data-driven evaluations of scheduling approaches for large-scale cloud\ninfrastructures in future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u57fa\u4e8eSAP\u4e91\u5e73\u53f0\u4e2d\u7ea61800\u53f0\u7269\u7406\u673a\u548c48000\u4e2a\u865a\u62df\u673a\u768430\u5929\u89c2\u6d4b\u6570\u636e\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u865a\u62df\u673a\u8c03\u5ea6\u4e0e\u653e\u7f6e\u4e2d\u7684\u591a\u79cd\u8d44\u6e90\u5229\u7528\u4f4e\u6548\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u8c03\u5ea6\u7b97\u6cd5\u7684\u8bbe\u8ba1\u9700\u6c42\uff0c\u540c\u65f6\u516c\u5f00\u4e86\u8be5\u7ec6\u7c92\u5ea6\u4f01\u4e1a\u7ea7\u6570\u636e\u96c6\u4ee5\u652f\u6301\u540e\u7eed\u7814\u7a76\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u9ad8\u6548\u5206\u914d\u8d44\u6e90\u662f\u4e00\u9879\u57fa\u672c\u6311\u6218\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u6765\u81ea\u771f\u5b9e\u4f01\u4e1a\u7ea7\u4e91\u5e73\u53f0\u3001\u6db5\u76d6\u957f\u671f\u8fd0\u884c\u548c\u5185\u5b58\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u7684\u7ec6\u7c92\u5ea6\u65f6\u5e8f\u9065\u6d4b\u6570\u636e\uff0c\u9650\u5236\u4e86\u8c03\u5ea6\u7b97\u6cd5\u7684\u8bc4\u4f30\u4e0e\u4f18\u5316\u3002", "method": "\u4f5c\u8005\u5229\u7528SAP\u4e91\u5e73\u53f0\u7684\u53ef\u89c2\u6d4b\u6027\u5de5\u5177\u6536\u96c6\u4e861800\u53f0hypervisor\u548c48000\u4e2aVM\u572830\u5929\u5185\u7684\u8d44\u6e90\u4f7f\u7528\u4e0e\u6027\u80fd\u6307\u6807\u6570\u636e\uff0c\u5206\u6790\u5176\u4e2d\u7684\u8c03\u5ea6\u4e0e\u653e\u7f6e\u95ee\u9898\uff0c\u5e76\u57fa\u4e8e\u53d1\u73b0\u63d0\u70bc\u51fa\u65b0\u8c03\u5ea6\u7b97\u6cd5\u7684\u8bbe\u8ba1\u9700\u6c42\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u591a\u4e2a\u6b21\u4f18\u8c03\u5ea6\u73b0\u8c61\uff1aCPU\u8d44\u6e90\u4e89\u7528\u8d85\u8fc740%\u3001CPU\u5c31\u7eea\u65f6\u95f4\u9ad8\u8fbe220\u79d2\u3001\u4e3b\u673a\u95f4CPU\u5229\u7528\u7387\u6781\u5ea6\u4e0d\u5747\u8861\uff08\u6700\u9ad8\u8fbe99%\uff09\u3001\u8d85\u8fc780%\u7684VM\u4f7f\u7528\u4e0d\u523070%\u5206\u914d\u7684CPU\u548c\u5185\u5b58\u8d44\u6e90\u3002", "conclusion": "\u8bba\u6587\u63ed\u793a\u4e86\u4f01\u4e1a\u4e91\u73af\u5883\u4e2d\u8d44\u6e90\u8c03\u5ea6\u7684\u663e\u8457\u4f18\u5316\u7a7a\u95f4\uff0c\u63d0\u51fa\u4e86\u9762\u5411\u65b0\u578b\u8c03\u5ea6\u4e0e\u653e\u7f6e\u7b97\u6cd5\u7684\u5173\u952e\u9700\u6c42\uff0c\u5e76\u516c\u5f00\u4e86\u771f\u5b9e\u4e16\u754c\u7684\u5927\u89c4\u6a21\u7ec6\u7c92\u5ea6\u6570\u636e\u96c6\uff0c\u4ee5\u63a8\u52a8\u672a\u6765\u4e91\u8d44\u6e90\u7ba1\u7406\u7814\u7a76\u3002"}}
{"id": "2510.23899", "categories": ["cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23899", "abs": "https://arxiv.org/abs/2510.23899", "authors": ["Maria G. Mendoza", "Addison Kalanther", "Daniel Bostwick", "Emma Stephan", "Chinmay Maheshwari", "Shankar Sastry"], "title": "Coordinated Autonomous Drones for Human-Centered Fire Evacuation in Partially Observable Urban Environments", "comment": "Accepted to IEEE Global Humanitarian Technology Conference (GHTC\n  2025). 8 pages, 4 figures", "summary": "Autonomous drone technology holds significant promise for enhancing search\nand rescue operations during evacuations by guiding humans toward safety and\nsupporting broader emergency response efforts. However, their application in\ndynamic, real-time evacuation support remains limited. Existing models often\noverlook the psychological and emotional complexity of human behavior under\nextreme stress. In real-world fire scenarios, evacuees frequently deviate from\ndesignated safe routes due to panic and uncertainty. To address these\nchallenges, this paper presents a multi-agent coordination framework in which\nautonomous Unmanned Aerial Vehicles (UAVs) assist human evacuees in real-time\nby locating, intercepting, and guiding them to safety under uncertain\nconditions. We model the problem as a Partially Observable Markov Decision\nProcess (POMDP), where two heterogeneous UAV agents, a high-level rescuer (HLR)\nand a low-level rescuer (LLR), coordinate through shared observations and\ncomplementary capabilities. Human behavior is captured using an agent-based\nmodel grounded in empirical psychology, where panic dynamically affects\ndecision-making and movement in response to environmental stimuli. The\nenvironment features stochastic fire spread, unknown evacuee locations, and\nlimited visibility, requiring UAVs to plan over long horizons to search for\nhumans and adapt in real-time. Our framework employs the Proximal Policy\nOptimization (PPO) algorithm with recurrent policies to enable robust\ndecision-making in partially observable settings. Simulation results\ndemonstrate that the UAV team can rapidly locate and intercept evacuees,\nsignificantly reducing the time required for them to reach safety compared to\nscenarios without UAV assistance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u534f\u540c\u6846\u67b6\uff0c\u5229\u7528\u4e24\u7c7b\u81ea\u4e3b\u65e0\u4eba\u673a\uff08UAV\uff09\u5728\u706b\u707e\u7b49\u7d27\u6025\u758f\u6563\u573a\u666f\u4e2d\u5b9e\u65f6\u5f15\u5bfc\u53d7\u56f0\u4eba\u5458\uff0c\u901a\u8fc7\u7ed3\u5408\u57fa\u4e8e\u5fc3\u7406\u5b66\u7684\u4eba\u7c7b\u884c\u4e3a\u5efa\u6a21\u4e0ePOMDP\u51b3\u7b56\u6a21\u578b\uff0c\u663e\u8457\u7f29\u77ed\u758f\u6563\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u758f\u6563\u8f85\u52a9\u6a21\u578b\u5e38\u5ffd\u7565\u6781\u7aef\u538b\u529b\u4e0b\u4eba\u7c7b\u5fc3\u7406\u4e0e\u60c5\u7eea\u7684\u590d\u6742\u6027\uff0c\u5bfc\u81f4\u5728\u771f\u5b9e\u706b\u707e\u573a\u666f\u4e2d\uff0c\u53d7\u56f0\u8005\u56e0\u6050\u614c\u548c\u4e0d\u786e\u5b9a\u6027\u504f\u79bb\u5b89\u5168\u8def\u5f84\uff1b\u540c\u65f6\uff0c\u65e0\u4eba\u673a\u5728\u52a8\u6001\u5b9e\u65f6\u758f\u6563\u652f\u6301\u4e2d\u7684\u5e94\u7528\u4ecd\u6709\u9650\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\uff0c\u7531\u9ad8\u9636\u6551\u63f4\u65e0\u4eba\u673a\uff08HLR\uff09\u4e0e\u4f4e\u9636\u6551\u63f4\u65e0\u4eba\u673a\uff08LLR\uff09\u901a\u8fc7\u5171\u4eab\u89c2\u6d4b\u4e0e\u4e92\u8865\u80fd\u529b\u534f\u540c\u5de5\u4f5c\uff1b\u4eba\u7c7b\u884c\u4e3a\u91c7\u7528\u57fa\u4e8e\u5b9e\u8bc1\u5fc3\u7406\u5b66\u7684\u667a\u80fd\u4f53\u6a21\u578b\uff0c\u6050\u614c\u7a0b\u5ea6\u52a8\u6001\u5f71\u54cd\u5176\u51b3\u7b56\uff1b\u4f7f\u7528\u5e26\u5faa\u73af\u7b56\u7565\u7684\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO\uff09\u7b97\u6cd5\u8fdb\u884c\u9c81\u68d2\u51b3\u7b56\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65e0\u4eba\u673a\u56e2\u961f\u80fd\u5feb\u901f\u5b9a\u4f4d\u5e76\u62e6\u622a\u53d7\u56f0\u4eba\u5458\uff0c\u663e\u8457\u7f29\u77ed\u5176\u62b5\u8fbe\u5b89\u5168\u533a\u57df\u6240\u9700\u65f6\u95f4\uff0c\u4f18\u4e8e\u65e0\u65e0\u4eba\u673a\u8f85\u52a9\u7684\u573a\u666f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53\u65e0\u4eba\u673a\u534f\u540c\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u706b\u707e\u758f\u6563\u4e2d\u4eba\u7c7b\u884c\u4e3a\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u73af\u5883\u52a8\u6001\u6027\uff0c\u4e3a\u63d0\u5347\u5e94\u6025\u54cd\u5e94\u6548\u7387\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.23627", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23627", "abs": "https://arxiv.org/abs/2510.23627", "authors": ["Fred Zimmerman"], "title": "AI-Driven Development of a Publishing Imprint: Xynapse Traces", "comment": null, "summary": "Xynapse Traces is an experimental publishing imprint created via a fusion of\nhuman and algorithmic methods using a configuration-driven architecture and a\nmulti-model AI integration framework. The system achieved a remarkable 90%\nreduction in time-to-market (from a typical 6-12 months to just 2-4 weeks),\nwith 80% cost reduction compared to traditional imprint development, while\npublishing 52 books in its first year and maintaining exceptional quality\nmetrics, including 99% citation accuracy and 100% validation success after\ninitial corrections. Key technical innovations include a continuous ideation\npipeline with tournament-style evaluation, a novel codex design for\ntranscriptive meditation practice, comprehensive automation spanning from\nideation through production and distribution, and publisher personas that\ndefine and guide the imprint's mission. The system also integrates automated\nverification with human oversight, ensuring that gains in speed do not\ncompromise publishing standards. This effort has significant implications for\nthe future of book publishing, suggesting new paradigms for human-AI\ncollaboration that democratize access to sophisticated publishing capabilities\nand make previously unviable niche markets accessible.", "AI": {"tldr": "Xynapse Traces \u662f\u4e00\u4e2a\u7ed3\u5408\u4eba\u7c7b\u4e0e\u7b97\u6cd5\u65b9\u6cd5\u7684\u5b9e\u9a8c\u6027\u51fa\u7248\u54c1\u724c\uff0c\u901a\u8fc7\u914d\u7f6e\u9a71\u52a8\u67b6\u6784\u548c\u591a\u6a21\u578bAI\u96c6\u6210\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u51fa\u7248\u5468\u671f\u7f29\u77ed90%\u3001\u6210\u672c\u964d\u4f4e80%\uff0c\u5e76\u5728\u9996\u5e74\u51fa\u724852\u672c\u4e66\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u8d28\u91cf\u6807\u51c6\u3002", "motivation": "\u4f20\u7edf\u51fa\u7248\u6d41\u7a0b\u8017\u65f6\u957f\u3001\u6210\u672c\u9ad8\uff0c\u9650\u5236\u4e86\u5c0f\u4f17\u5e02\u573a\u7684\u53d1\u5c55\u3002\u8be5\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u4eba\u673a\u534f\u4f5c\u7684\u65b0\u8303\u5f0f\uff0c\u4ee5\u63d0\u5347\u51fa\u7248\u6548\u7387\u3001\u964d\u4f4e\u6210\u672c\uff0c\u5e76\u62d3\u5c55\u51fa\u7248\u7684\u53ef\u53ca\u6027\u3002", "method": "\u91c7\u7528\u914d\u7f6e\u9a71\u52a8\u67b6\u6784\u4e0e\u591a\u6a21\u578bAI\u96c6\u6210\u6846\u67b6\uff0c\u6784\u5efa\u6db5\u76d6\u521b\u610f\u751f\u6210\u3001\u8bc4\u4f30\u3001\u751f\u4ea7\u5230\u53d1\u884c\u7684\u5168\u6d41\u7a0b\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u7ed3\u5408\u6301\u7eed\u521b\u610f\u6d41\u6c34\u7ebf\u3001\u7ade\u8d5b\u5f0f\u8bc4\u4f30\u673a\u5236\u3001\u65b0\u578b\u6284\u672c\u8bbe\u8ba1\u3001\u51fa\u7248\u4eba\u89d2\u8272\u5efa\u6a21\uff0c\u5e76\u8f85\u4ee5\u4eba\u5de5\u76d1\u7763\u7684\u81ea\u52a8\u9a8c\u8bc1\u673a\u5236\u3002", "result": "\u7cfb\u7edf\u5c06\u51fa\u7248\u5468\u671f\u4ece6\u201312\u4e2a\u6708\u7f29\u77ed\u81f32\u20134\u5468\uff08\u51cf\u5c1190%\uff09\uff0c\u6210\u672c\u964d\u4f4e80%\uff0c\u9996\u5e74\u6210\u529f\u51fa\u724852\u672c\u4e66\uff0c\u5f15\u7528\u51c6\u786e\u7387\u8fbe99%\uff0c\u4fee\u6b63\u540e\u9a8c\u8bc1\u6210\u529f\u7387\u8fbe100%\u3002", "conclusion": "Xynapse Traces \u5c55\u793a\u4e86\u4eba\u673a\u534f\u540c\u5728\u51fa\u7248\u9886\u57df\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u4e3a\u9ad8\u8d28\u91cf\u3001\u9ad8\u6548\u7387\u3001\u4f4e\u6210\u672c\u7684\u51fa\u7248\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u5e76\u6709\u671b\u63a8\u52a8\u5c0f\u4f17\u51fa\u7248\u5e02\u573a\u7684\u7e41\u8363\u3002"}}
{"id": "2510.24242", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24242", "abs": "https://arxiv.org/abs/2510.24242", "authors": ["Zihan Li", "Jiahao Yang", "Yuxin Zhang", "Zhe Chen", "Yue Gao"], "title": "Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration of Large Vision-Language Models", "comment": "15 pages, 11 figures", "summary": "Large vision-language models (LVLMs) have recently demonstrated great\npotential in remote sensing (RS) tasks (e.g., disaster monitoring) conducted by\nlow Earth orbit (LEO) satellites. However, their deployment in real-world LEO\nsatellite systems remains largely unexplored, hindered by limited onboard\ncomputing resources and brief satellite-ground contacts. We propose Grace, a\nsatellite-ground collaborative system designed for near-realtime LVLM inference\nin RS tasks. Accordingly, we deploy compact LVLM on satellites for realtime\ninference, but larger ones on ground stations (GSs) to guarantee end-to-end\nperformance. Grace is comprised of two main phases that are asynchronous\nsatellite-GS Retrieval-Augmented Generation (RAG), and a task dispatch\nalgorithm. Firstly, we still the knowledge archive of GS RAG to satellite\narchive with tailored adaptive update algorithm during limited satellite-ground\ndata exchange period. Secondly, propose a confidence-based test algorithm that\neither processes the task onboard the satellite or offloads it to the GS.\nExtensive experiments based on real-world satellite orbital data show that\nGrace reduces the average latency by 76-95% compared to state-of-the-art\nmethods, without compromising inference accuracy.", "AI": {"tldr": "Grace \u662f\u4e00\u4e2a\u661f\u5730\u534f\u540c\u7cfb\u7edf\uff0c\u901a\u8fc7\u5728\u536b\u661f\u4e0a\u90e8\u7f72\u8f7b\u91cf\u7ea7\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLM\uff09\uff0c\u5728\u5730\u9762\u7ad9\u90e8\u7f72\u66f4\u5927\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u5f02\u6b65\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e0e\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5728\u4fdd\u8bc1\u63a8\u7406\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u5c06\u9065\u611f\u4efb\u52a1\u7684\u5e73\u5747\u5ef6\u8fdf\u964d\u4f4e76\u201395%\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLM\uff09\u5728\u4f4e\u8f68\u536b\u661f\u9065\u611f\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u53d7\u9650\u4e8e\u661f\u4e0a\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u548c\u661f\u5730\u901a\u4fe1\u7a97\u53e3\u77ed\u6682\uff0c\u96be\u4ee5\u5728\u771f\u5b9e\u536b\u661f\u7cfb\u7edf\u4e2d\u90e8\u7f72\u3002", "method": "\u63d0\u51fa Grace \u7cfb\u7edf\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u673a\u5236\uff1a1\uff09\u5728\u6709\u9650\u661f\u5730\u901a\u4fe1\u671f\u5185\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u66f4\u65b0\u7b97\u6cd5\u5c06\u5730\u9762\u7ad9 RAG \u77e5\u8bc6\u5e93\u540c\u6b65\u81f3\u536b\u661f\uff1b2\uff09\u8bbe\u8ba1\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u6d4b\u8bd5\u7b97\u6cd5\uff0c\u52a8\u6001\u51b3\u5b9a\u4efb\u52a1\u662f\u5728\u661f\u4e0a\u5904\u7406\u8fd8\u662f\u5378\u8f7d\u81f3\u5730\u9762\u7ad9\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u536b\u661f\u8f68\u9053\u6570\u636e\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGrace \u76f8\u6bd4\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\uff0c\u5728\u4e0d\u635f\u5931\u63a8\u7406\u51c6\u786e\u7387\u7684\u524d\u63d0\u4e0b\uff0c\u5c06\u5e73\u5747\u5ef6\u8fdf\u964d\u4f4e\u4e86 76\u201395%\u3002", "conclusion": "Grace \u6709\u6548\u89e3\u51b3\u4e86 LVLM \u5728\u4f4e\u8f68\u536b\u661f\u7cfb\u7edf\u4e2d\u90e8\u7f72\u7684\u5ef6\u8fdf\u4e0e\u8d44\u6e90\u9650\u5236\u95ee\u9898\uff0c\u4e3a\u8fd1\u5b9e\u65f6\u9065\u611f\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u661f\u5730\u534f\u540c\u63a8\u7406\u6846\u67b6\u3002"}}
{"id": "2510.24030", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2510.24030", "abs": "https://arxiv.org/abs/2510.24030", "authors": ["Ahmet Akkaya Melih", "Yamuna Singh", "Kunal L. Agarwal", "Priya Mukherjee", "Kiran Pattnaik", "Hanuman Bhatia"], "title": "Human Machine Social Hybrid Intelligence:A Collaborative Decision Making Framework for Large Model Agent Groups and Human Experts", "comment": null, "summary": "The rapid advancements in large foundation models and multi-agent systems\noffer unprecedented capabilities, yet current Human-in-the-Loop (HiTL)\nparadigms inadequately integrate human expertise, often leading to cognitive\noverload and decision-making bottlenecks in complex, high-stakes environments.\nWe propose the \"Human-Machine Social Hybrid Intelligence\" (HMS-HI) framework, a\nnovel architecture designed for deep, collaborative decision-making between\ngroups of human experts and LLM-powered AI agents. HMS-HI is built upon three\ncore pillars: (1) a \\textbf{Shared Cognitive Space (SCS)} for unified,\nmulti-modal situational awareness and structured world modeling; (2) a\n\\textbf{Dynamic Role and Task Allocation (DRTA)} module that adaptively assigns\ntasks to the most suitable agent (human or AI) based on capabilities and\nworkload; and (3) a \\textbf{Cross-Species Trust Calibration (CSTC)} protocol\nthat fosters transparency, accountability, and mutual adaptation through\nexplainable declarations and structured feedback. Validated in a high-fidelity\nurban emergency response simulation, HMS-HI significantly reduced civilian\ncasualties by 72\\% and cognitive load by 70\\% compared to traditional HiTL\napproaches, demonstrating superior decision quality, efficiency, and human-AI\ntrust. An ablation study confirms the critical contribution of each module,\nhighlighting that engineered trust and shared context are foundational for\nscalable, synergistic human-AI collaboration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u4eba\u673a\u793e\u4f1a\u6df7\u5408\u667a\u80fd\u201d\uff08HMS-HI\uff09\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u8ba4\u77e5\u7a7a\u95f4\u3001\u52a8\u6001\u89d2\u8272\u4efb\u52a1\u5206\u914d\u548c\u8de8\u7269\u79cd\u4fe1\u4efb\u6821\u51c6\u4e09\u5927\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u590d\u6742\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u4eba\u673a\u534f\u4f5c\u7684\u51b3\u7b56\u8d28\u91cf\u4e0e\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u7684\u4eba\u5728\u73af\u8def\uff08HiTL\uff09\u8303\u5f0f\u672a\u80fd\u6709\u6548\u6574\u5408\u4eba\u7c7b\u4e13\u5bb6\u77e5\u8bc6\uff0c\u5728\u590d\u6742\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u6613\u5bfc\u81f4\u8ba4\u77e5\u8fc7\u8f7d\u548c\u51b3\u7b56\u74f6\u9888\u3002", "method": "\u6784\u5efaHMS-HI\u6846\u67b6\uff0c\u5305\u542b\uff1a(1) \u5171\u4eab\u8ba4\u77e5\u7a7a\u95f4\uff08SCS\uff09\u5b9e\u73b0\u591a\u6a21\u6001\u6001\u52bf\u611f\u77e5\u4e0e\u7ed3\u6784\u5316\u4e16\u754c\u5efa\u6a21\uff1b(2) \u52a8\u6001\u89d2\u8272\u4e0e\u4efb\u52a1\u5206\u914d\uff08DRTA\uff09\u6a21\u5757\u6839\u636e\u80fd\u529b\u4e0e\u8d1f\u8377\u81ea\u9002\u5e94\u5206\u914d\u4efb\u52a1\uff1b(3) \u8de8\u7269\u79cd\u4fe1\u4efb\u6821\u51c6\uff08CSTC\uff09\u534f\u8bae\u901a\u8fc7\u53ef\u89e3\u91ca\u58f0\u660e\u4e0e\u7ed3\u6784\u5316\u53cd\u9988\u589e\u5f3a\u900f\u660e\u5ea6\u4e0e\u4e92\u9002\u5e94\u6027\u3002", "result": "\u5728\u9ad8\u4fdd\u771f\u57ce\u5e02\u5e94\u6025\u54cd\u5e94\u6a21\u62df\u4e2d\uff0c\u76f8\u6bd4\u4f20\u7edfHiTL\u65b9\u6cd5\uff0cHMS-HI\u5c06\u5e73\u6c11\u4f24\u4ea1\u51cf\u5c1172%\uff0c\u8ba4\u77e5\u8d1f\u8377\u964d\u4f4e70%\uff0c\u5e76\u663e\u8457\u63d0\u5347\u51b3\u7b56\u8d28\u91cf\u3001\u6548\u7387\u4e0e\u4eba\u673a\u4fe1\u4efb\uff1b\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5404\u6a21\u5757\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u5de5\u7a0b\u5316\u7684\u4fe1\u4efb\u673a\u5236\u4e0e\u5171\u4eab\u4e0a\u4e0b\u6587\u662f\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u534f\u540c\u6027\u4eba\u673a\u534f\u4f5c\u7684\u57fa\u7840\uff0cHMS-HI\u4e3a\u590d\u6742\u573a\u666f\u4e0b\u7684\u4eba\u673a\u6df1\u5ea6\u878d\u5408\u63d0\u4f9b\u4e86\u6709\u6548\u67b6\u6784\u3002"}}
{"id": "2510.23993", "categories": ["cs.DC", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.23993", "abs": "https://arxiv.org/abs/2510.23993", "authors": ["Anthony Carreon", "Jagmohan Singh", "Shivank Sharma", "Shuzhi Zhang", "Venkat Raman"], "title": "A GPU-based Compressible Combustion Solver for Applications Exhibiting Disparate Space and Time Scales", "comment": "32 pages, 12 figures", "summary": "High-speed chemically active flows present significant computational\nchallenges due to their disparate space and time scales, where stiff chemistry\noften dominates simulation time. While modern supercomputing scientific codes\nachieve exascale performance by leveraging graphics processing units (GPUs),\nexisting GPU-based compressible combustion solvers face critical limitations in\nmemory management, load balancing, and handling the highly localized nature of\nchemical reactions. To this end, we present a high-performance compressible\nreacting flow solver built on the AMReX framework and optimized for multi-GPU\nsettings. Our approach addresses three GPU performance bottlenecks: memory\naccess patterns through column-major storage optimization, computational\nworkload variability via a bulk-sparse integration strategy for chemical\nkinetics, and multi-GPU load distribution for adaptive mesh refinement\napplications. The solver adapts existing matrix-based chemical kinetics\nformulations to multigrid contexts. Using representative combustion\napplications including hydrogen-air detonations and jet in supersonic crossflow\nconfigurations, we demonstrate $2-5\\times$ performance improvements over\ninitial GPU implementations with near-ideal weak scaling across $1-96$ NVIDIA\nH100 GPUs. Roofline analysis reveals substantial improvements in arithmetic\nintensity for both convection ($\\sim 10 \\times$) and chemistry ($\\sim 4\n\\times$) routines, confirming efficient utilization of GPU memory bandwidth and\ncomputational resources.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAMReX\u6846\u67b6\u3001\u9762\u5411\u591aGPU\u4f18\u5316\u7684\u9ad8\u6027\u80fd\u53ef\u538b\u7f29\u53cd\u5e94\u6d41\u6c42\u89e3\u5668\uff0c\u901a\u8fc7\u6539\u8fdb\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u3001\u91c7\u7528\u6279\u91cf\u7a00\u758f\u79ef\u5206\u7b56\u7565\u5904\u7406\u5316\u5b66\u53cd\u5e94\uff0c\u5e76\u4f18\u5316\u591aGPU\u8d1f\u8f7d\u5747\u8861\uff0c\u5728\u5178\u578b\u71c3\u70e7\u6a21\u62df\u4e2d\u5b9e\u73b0\u4e862\u20135\u500d\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5c55\u73b0\u51fa\u63a5\u8fd1\u7406\u60f3\u7684\u5f31\u6269\u5c55\u6027\u3002", "motivation": "\u9ad8\u901f\u5316\u5b66\u53cd\u5e94\u6d41\u7684\u6a21\u62df\u56e0\u65f6\u7a7a\u5c3a\u5ea6\u5dee\u5f02\u5927\u3001\u5316\u5b66\u53cd\u5e94\u521a\u6027\u5f3a\u800c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff1b\u73b0\u6709\u57fa\u4e8eGPU\u7684\u53ef\u538b\u7f29\u71c3\u70e7\u6c42\u89e3\u5668\u5728\u5185\u5b58\u7ba1\u7406\u3001\u8d1f\u8f7d\u5747\u8861\u53ca\u5904\u7406\u5c40\u90e8\u5316\u5316\u5b66\u53cd\u5e94\u65b9\u9762\u5b58\u5728\u74f6\u9888\u3002", "method": "\u8be5\u6c42\u89e3\u5668\u57fa\u4e8eAMReX\u6846\u67b6\uff0c\u9488\u5bf9GPU\u6027\u80fd\u74f6\u9888\u8fdb\u884c\u4e86\u4e09\u9879\u4f18\u5316\uff1a\u91c7\u7528\u5217\u4e3b\u5b58\u50a8\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u3001\u901a\u8fc7\u6279\u91cf\u7a00\u758f\u79ef\u5206\u7b56\u7565\u5904\u7406\u5316\u5b66\u52a8\u529b\u5b66\u4ee5\u5e94\u5bf9\u8ba1\u7b97\u8d1f\u8f7d\u4e0d\u5747\u3001\u5e76\u5728\u81ea\u9002\u5e94\u7f51\u683c\u7ec6\u5316\uff08AMR\uff09\u5e94\u7528\u4e2d\u5b9e\u73b0\u591aGPU\u8d1f\u8f7d\u5747\u8861\uff1b\u540c\u65f6\u5c06\u57fa\u4e8e\u77e9\u9635\u7684\u5316\u5b66\u52a8\u529b\u5b66\u65b9\u6cd5\u9002\u914d\u5230\u591a\u91cd\u7f51\u683c\u73af\u5883\u4e2d\u3002", "result": "\u5728\u6c22\u6c14-\u7a7a\u6c14\u7206\u8f70\u548c\u8d85\u97f3\u901f\u6a2a\u5411\u5c04\u6d41\u7b49\u5178\u578b\u71c3\u70e7\u6848\u4f8b\u4e2d\uff0c\u76f8\u6bd4\u521d\u59cbGPU\u5b9e\u73b0\u83b7\u5f972\u20135\u500d\u6027\u80fd\u63d0\u5347\uff0c\u57281\u201396\u5757NVIDIA H100 GPU\u4e0a\u5b9e\u73b0\u63a5\u8fd1\u7406\u60f3\u7684\u5f31\u6269\u5c55\u6027\uff1b\u5c4b\u9876\u7ebf\u5206\u6790\u663e\u793a\u5bf9\u6d41\u548c\u5316\u5b66\u53cd\u5e94\u90e8\u5206\u7684\u7b97\u672f\u5f3a\u5ea6\u5206\u522b\u63d0\u5347\u7ea610\u500d\u548c4\u500d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684GPU\u4f18\u5316\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u53ef\u538b\u7f29\u53cd\u5e94\u6d41\u6a21\u62df\u7684\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u6709\u6548\u5229\u7528\u4e86GPU\u7684\u5185\u5b58\u5e26\u5bbd\u4e0e\u8ba1\u7b97\u8d44\u6e90\uff0c\u4e3a\u5927\u89c4\u6a21\u71c3\u70e7\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u5de5\u5177\u3002"}}
{"id": "2510.24595", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.24595", "abs": "https://arxiv.org/abs/2510.24595", "authors": ["Azadeh Pourkabirian", "Kai Li", "Photios A. Stavrou", "Wei Ni"], "title": "A New Hybrid Precoding Approach for Multi-user Massive MIMO over Fading Channels", "comment": null, "summary": "Hybrid precoding is an indispensable technique to harness the full potential\nof a multi-user massive multiple-input, multiple-output (MU-MMIMO) system. In\nthis paper, we propose a new hybrid precoding approach that combines digital\nand analog precoding to optimize data transmission over multiple antennas. This\napproach steers signals in specific directions, leading to maximizing sum-rate\nand suppressing side-lobe interference. When dealing with complex signals,\nchanges in phase are naturally associated with changes in angle, and these\nvariations are inherently correlated. The correlation between the angle and\nphase is essential for accurately determining the channel characteristics. An\nimportant aspect of this approach is that we model the angle and phase as\ncorrelated variables following a bivariate Gaussian distribution, and for the\nfirst time, we define a joint angle and phase entropy to measure the\nuncertainty of angle and phase variations in wireless channels. This entropy is\ncrucial to adapt the proposed precoding method with variations. Simulation\nresult validate the accuracy of our analytical findings, demonstrating 18.31%\nincrease in sum-rate and an 11.47% improvement in robustness compared to other\nstate-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u9884\u7f16\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u89d2\u5ea6\u4e0e\u76f8\u4f4d\u5efa\u6a21\u4e3a\u670d\u4ece\u4e8c\u5143\u9ad8\u65af\u5206\u5e03\u7684\u5173\u8054\u53d8\u91cf\uff0c\u5e76\u9996\u6b21\u5b9a\u4e49\u4e86\u8054\u5408\u89d2\u5ea6-\u76f8\u4f4d\u71b5\uff0c\u4ee5\u63d0\u5347MU-MIMO\u7cfb\u7edf\u7684\u548c\u901f\u7387\u4e0e\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u9884\u7f16\u7801\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u65e0\u7ebf\u4fe1\u9053\u4e2d\u89d2\u5ea6\u4e0e\u76f8\u4f4d\u4e4b\u95f4\u7684\u5185\u5728\u76f8\u5173\u6027\uff0c\u9650\u5236\u4e86\u7cfb\u7edf\u6027\u80fd\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "method": "\u5c06\u89d2\u5ea6\u4e0e\u76f8\u4f4d\u5efa\u6a21\u4e3a\u670d\u4ece\u4e8c\u5143\u9ad8\u65af\u5206\u5e03\u7684\u5173\u8054\u53d8\u91cf\uff0c\u5b9a\u4e49\u8054\u5408\u89d2\u5ea6-\u76f8\u4f4d\u71b5\u4ee5\u523b\u753b\u5176\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u636e\u6b64\u4f18\u5316\u6df7\u5408\u9884\u7f16\u7801\u8bbe\u8ba1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\uff0c\u548c\u901f\u7387\u63d0\u5347\u4e8618.31%\uff0c\u9c81\u68d2\u6027\u63d0\u9ad8\u4e8611.47%\u3002", "conclusion": "\u901a\u8fc7\u5efa\u6a21\u89d2\u5ea6\u4e0e\u76f8\u4f4d\u7684\u76f8\u5173\u6027\u5e76\u5f15\u5165\u8054\u5408\u71b5\u5ea6\u91cf\uff0c\u6240\u63d0\u51fa\u7684\u6df7\u5408\u9884\u7f16\u7801\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347MU-MIMO\u7cfb\u7edf\u7684\u6027\u80fd\u4e0e\u9002\u5e94\u6027\u3002"}}
{"id": "2510.23664", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23664", "abs": "https://arxiv.org/abs/2510.23664", "authors": ["Eranga Bandara", "Ross Gore", "Xueping Liang", "Sachini Rajapakse", "Isurunima Kularathne", "Pramoda Karunarathna", "Peter Foytik", "Sachin Shetty", "Ravi Mukkamala", "Abdul Rahman", "Amin Hass", "Ng Wee Keong", "Kasun De Zoysa", "Aruna Withanage", "Nilaan Loganathan"], "title": "Agentsway -- Software Development Methodology for AI Agents-based Teams", "comment": null, "summary": "The emergence of Agentic AI is fundamentally transforming how software is\ndesigned, developed, and maintained. Traditional software development\nmethodologies such as Agile, Kanban, ShapeUp, etc, were originally designed for\nhuman-centric teams and are increasingly inadequate in environments where\nautonomous AI agents contribute to planning, coding, testing, and continuous\nlearning. To address this methodological gap, we present \"Agentsway\" a novel\nsoftware development framework designed for ecosystems where AI agents operate\nas first-class collaborators. Agentsway introduces a structured lifecycle\ncentered on human orchestration, and privacy-preserving collaboration among\nspecialized AI agents. The framework defines distinct roles for planning,\nprompting, coding, testing, and fine-tuning agents, each contributing to\niterative improvement and adaptive learning throughout the development process.\nBy integrating fine-tuned LLMs that leverage outputs and feedback from\ndifferent agents throughout the development cycle as part of a retrospective\nlearning process, Agentsway enhances domain-specific reasoning, and explainable\ndecision-making across the entire software development lifecycle. Responsible\nAI principles are further embedded across the agents through the coordinated\nuse of multiple fine-tuned LLMs and advanced reasoning models, ensuring\nbalanced, transparent, and accountable decision-making. This work advances\nsoftware engineering by formalizing agent-centric collaboration, integrating\nprivacy-by-design principles, and defining measurable metrics for productivity\nand trust. Agentsway represents a foundational step toward the next generation\nof AI-native, self-improving software development methodologies. To the best of\nour knowledge, this is the first research effort to introduce a dedicated\nmethodology explicitly designed for AI agent-based software engineering teams.", "AI": {"tldr": "Agentsway \u662f\u4e00\u79cd\u9762\u5411 AI \u667a\u80fd\u4f53\u534f\u4f5c\u7684\u65b0\u578b\u8f6f\u4ef6\u5f00\u53d1\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u4f5c\u4e3a\u6838\u5fc3\u53c2\u4e0e\u8005\uff0c\u5f15\u5165\u7ed3\u6784\u5316\u751f\u547d\u5468\u671f\u3001\u89d2\u8272\u5206\u5de5\u4e0e\u56de\u987e\u5f0f\u5b66\u4e60\u673a\u5236\uff0c\u4ee5\u63d0\u5347\u5f00\u53d1\u6548\u7387\u3001\u53ef\u89e3\u91ca\u6027\u4e0e\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u65b9\u6cd5\uff08\u5982\u654f\u6377\u3001\u770b\u677f\u7b49\uff09\u4e3a\u4eba\u7c7b\u56e2\u961f\u8bbe\u8ba1\uff0c\u96be\u4ee5\u9002\u5e94 AI \u667a\u80fd\u4f53\u53c2\u4e0e\u89c4\u5212\u3001\u7f16\u7801\u3001\u6d4b\u8bd5\u548c\u6301\u7eed\u5b66\u4e60\u7684\u65b0\u573a\u666f\uff0c\u4e9f\u9700\u4e00\u79cd\u4e13\u4e3a\u667a\u80fd\u4f53\u534f\u4f5c\u8bbe\u8ba1\u7684\u65b0\u65b9\u6cd5\u8bba\u3002", "method": "\u63d0\u51fa Agentsway \u6846\u67b6\uff0c\u5b9a\u4e49\u89c4\u5212\u3001\u63d0\u793a\u3001\u7f16\u7801\u3001\u6d4b\u8bd5\u548c\u5fae\u8c03\u7b49\u4e13\u7528\u667a\u80fd\u4f53\u89d2\u8272\uff0c\u901a\u8fc7\u4eba\u7c7b\u534f\u8c03\u3001\u9690\u79c1\u4fdd\u62a4\u534f\u4f5c\u4ee5\u53ca\u57fa\u4e8e\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u56de\u987e\u5b66\u4e60\u673a\u5236\uff0c\u5b9e\u73b0\u6574\u4e2a\u5f00\u53d1\u5468\u671f\u7684\u81ea\u9002\u5e94\u4f18\u5316\u3002", "result": "Agentsway \u5b9e\u73b0\u4e86\u9762\u5411\u667a\u80fd\u4f53\u7684\u534f\u4f5c\u7ed3\u6784\u5316\uff0c\u589e\u5f3a\u4e86\u9886\u57df\u63a8\u7406\u80fd\u529b\u4e0e\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u901a\u8fc7\u591a\u6a21\u578b\u534f\u540c\u5d4c\u5165\u8d1f\u8d23\u4efb AI \u539f\u5219\uff0c\u5efa\u7acb\u4e86\u53ef\u8861\u91cf\u7684\u751f\u4ea7\u529b\u4e0e\u4fe1\u4efb\u6307\u6807\u3002", "conclusion": "Agentsway \u662f\u9996\u4e2a\u4e13\u4e3a AI \u667a\u80fd\u4f53\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u8bbe\u8ba1\u7684\u65b9\u6cd5\u8bba\uff0c\u4e3a\u4e0b\u4e00\u4ee3 AI \u539f\u751f\u3001\u81ea\u8fdb\u5316\u7684\u8f6f\u4ef6\u5f00\u53d1\u8303\u5f0f\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.24175", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24175", "abs": "https://arxiv.org/abs/2510.24175", "authors": ["Nitin Shukla", "Alessandro Romeo", "Caterina Caravita", "Michael Redenti", "Radim Vavrik", "Lubomir Riha", "Andrea Mignone", "Marco Rossazza", "Stefano Truzzi", "Luca Tornatore", "Antonio Ragagnin", "Tiago Castro", "Geray S. Karademir", "Klaus Dolag", "Pranab J. Deka", "Fabio Bacchini", "Rostislav-Paul Wilhelm", "Daniele Gregori", "Elisabetta Boella"], "title": "Towards Exascale Computing for Astrophysical Simulation Leveraging the Leonardo EuroHPC System", "comment": null, "summary": "Developing and redesigning astrophysical, cosmological, and space plasma\nnumerical codes for existing and next-generation accelerators is critical for\nenabling large-scale simulations. To address these challenges, the SPACE Center\nof Excellence (SPACE-CoE) fosters collaboration between scientists, code\ndevelopers, and high-performance computing experts to optimize applications for\nthe exascale era. This paper presents our strategy and initial results on the\nLeonardo system at CINECA for three flagship codes, namely gPLUTO, OpenGadget3\nand iPIC3D, using profiling tools to analyze performance on single and multiple\nnodes. Preliminary tests show all three codes scale efficiently, reaching 80%\nscalability up to 1,024 GPUs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86SPACE-CoE\u5728Leonardo\u7cfb\u7edf\u4e0a\u5bf9gPLUTO\u3001OpenGadget3\u548ciPIC3D\u4e09\u4e2a\u5929\u4f53\u7269\u7406\u4e0e\u7b49\u79bb\u5b50\u4f53\u6a21\u62df\u4ee3\u7801\u8fdb\u884c\u6027\u80fd\u4f18\u5316\u7684\u7b56\u7565\u4e0e\u521d\u6b65\u6210\u679c\uff0c\u5c55\u793a\u4e86\u8fd9\u4e9b\u4ee3\u7801\u5728\u591a\u8fbe1,024\u4e2aGPU\u4e0a\u8fbe\u523080%\u7684\u9ad8\u6548\u6269\u5c55\u6027\u3002", "motivation": "\u4e3a\u5e94\u5bf9\u5728\u73b0\u6709\u53ca\u4e0b\u4e00\u4ee3\u52a0\u901f\u5668\u4e0a\u5f00\u53d1\u548c\u91cd\u6784\u5929\u4f53\u7269\u7406\u3001\u5b87\u5b99\u5b66\u548c\u7a7a\u95f4\u7b49\u79bb\u5b50\u4f53\u6570\u503c\u6a21\u62df\u4ee3\u7801\u7684\u6311\u6218\uff0c\u63a8\u52a8\u5927\u89c4\u6a21\u6a21\u62df\u5728exascale\u8d85\u7b97\u65f6\u4ee3\u7684\u5b9e\u73b0\u3002", "method": "\u901a\u8fc7SPACE-CoE\u8054\u5408\u79d1\u5b66\u5bb6\u3001\u4ee3\u7801\u5f00\u53d1\u8005\u4e0e\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e13\u5bb6\uff0c\u5229\u7528\u6027\u80fd\u5206\u6790\u5de5\u5177\u5728\u5355\u8282\u70b9\u548c\u591a\u8282\u70b9\u4e0a\u5bf9\u4e09\u4e2a\u65d7\u8230\u4ee3\u7801\uff08gPLUTO\u3001OpenGadget3\u3001iPIC3D\uff09\u5728CINECA\u7684Leonardo\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4f18\u5316\u4e0e\u6d4b\u8bd5\u3002", "result": "\u521d\u6b65\u6d4b\u8bd5\u8868\u660e\uff0c\u4e09\u4e2a\u4ee3\u7801\u5747\u8868\u73b0\u51fa\u826f\u597d\u7684\u6269\u5c55\u6027\uff0c\u5728\u591a\u8fbe1,024\u4e2aGPU\u4e0a\u53ef\u5b9e\u73b0\u9ad8\u8fbe80%\u7684\u5e76\u884c\u6548\u7387\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9a8c\u8bc1\u4e86\u5728exascale\u7cfb\u7edf\u4e0a\u9ad8\u6548\u8fd0\u884c\u590d\u6742\u5929\u4f53\u7269\u7406\u4e0e\u7b49\u79bb\u5b50\u4f53\u6a21\u62df\u4ee3\u7801\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u672a\u6765\u5927\u89c4\u6a21\u79d1\u5b66\u6a21\u62df\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.24611", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.24611", "abs": "https://arxiv.org/abs/2510.24611", "authors": ["Azadeh Pourkabirian", "Amir Masoud Rahmani", "Kai Li", "Wei Ni"], "title": "Strategic Task Offloading for Delay-Sensitive IoT Applications: A Game-Theory-Based Demand-Supply Mechanism with Participation Incentives", "comment": null, "summary": "Delay-sensitive Internet of Things (IoT) applications have drawn significant\nattention. Running many of these applications on IoT devices is challenging due\nto the limited processing resources of these devices and the need for real-time\nresponses. Task offloading can minimize latency by transferring computationally\nintensive tasks from IoT devices to resource-rich edge servers, ensuring delay\nand performance guarantees. In this paper, we develop a task-offloading\napproach for delay-sensitive IoT applications in edge computing environments.\nUnlike existing schemes, we model the task offloading problem as an economic\ndemand and supply model to achieve market balance. The proposed model avoids\nunder- and over-supply, ensuring the computational resources at edge servers\n(supply) are allocated in a manner that best meets the processing and\ncomputational needs of user devices (demand). Given the multi-agent nature of\ntask offloading involving users and service providers with different\npreferences and objectives, we design a game-theoretic framework using a\nVickrey-Clarke-Groves (VCG) auction. This framework analyzes agent interactions\nand decision-making processes. Additionally, we develop an incentive mechanism\nto encourage both parties to participate in the auction. The mechanism\nmaximizes user task offloading to edge servers and motivates edge servers to\nshare their computational resources, achieving profitability for both IoT users\nand edge servers. Simulations demonstrate our method maximizes social welfare,\nensures truthfulness, maintains market balance, and provides latency guarantees\nfor delay-sensitive IoT applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ecf\u6d4e\u4f9b\u9700\u6a21\u578b\u548cVCG\u62cd\u5356\u673a\u5236\u7684\u4efb\u52a1\u5378\u8f7d\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e2d\u4f18\u5316\u5ef6\u8fdf\u654f\u611f\u578b\u7269\u8054\u7f51\u5e94\u7528\u7684\u8d44\u6e90\u5206\u914d\uff0c\u5b9e\u73b0\u5e02\u573a\u5747\u8861\u3001\u771f\u5b9e\u6027\u548c\u793e\u4f1a\u798f\u5229\u6700\u5927\u5316\u3002", "motivation": "\u7531\u4e8e\u7269\u8054\u7f51\u8bbe\u5907\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u4e14\u9700\u6ee1\u8db3\u5b9e\u65f6\u54cd\u5e94\u9700\u6c42\uff0c\u4f20\u7edf\u4efb\u52a1\u5378\u8f7d\u65b9\u6848\u96be\u4ee5\u6709\u6548\u5e73\u8861\u8d44\u6e90\u4f9b\u9700\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u517c\u987e\u7528\u6237\u5ef6\u8fdf\u9700\u6c42\u4e0e\u8fb9\u7f18\u670d\u52a1\u5668\u8d44\u6e90\u4f9b\u7ed9\u7684\u65b0\u673a\u5236\u3002", "method": "\u5c06\u4efb\u52a1\u5378\u8f7d\u95ee\u9898\u5efa\u6a21\u4e3a\u7ecf\u6d4e\u4f9b\u9700\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8eVickrey-Clarke-Groves\uff08VCG\uff09\u62cd\u5356\u7684\u535a\u5f08\u8bba\u6846\u67b6\uff0c\u7ed3\u5408\u6fc0\u52b1\u673a\u5236\u534f\u8c03\u7528\u6237\u4e0e\u8fb9\u7f18\u670d\u52a1\u5668\u4e4b\u95f4\u7684\u8d44\u6e90\u5206\u914d\u4e0e\u53c2\u4e0e\u610f\u613f\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6700\u5927\u5316\u793e\u4f1a\u798f\u5229\u3001\u4fdd\u8bc1\u53c2\u4e0e\u8005\u7684\u771f\u5b9e\u6027\u3001\u7ef4\u6301\u5e02\u573a\u4f9b\u9700\u5e73\u8861\uff0c\u5e76\u4e3a\u5ef6\u8fdf\u654f\u611f\u578b\u7269\u8054\u7f51\u5e94\u7528\u63d0\u4f9b\u5ef6\u8fdf\u4fdd\u969c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4efb\u52a1\u5378\u8f7d\u65b9\u6cd5\u901a\u8fc7\u7ecf\u6d4e\u6a21\u578b\u4e0e\u535a\u5f08\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u8d44\u6e90\u4f9b\u9700\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u4e0e\u53c2\u4e0e\u65b9\u6536\u76ca\u3002"}}
{"id": "2510.23674", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.23674", "abs": "https://arxiv.org/abs/2510.23674", "authors": ["Bin Wang", "Hui Li", "AoFan Liu", "BoTao Yang", "Ao Yang", "YiLu Zhong", "Weixiang Huang", "Yanping Zhang", "Runhuai Huang", "Weimin Zeng"], "title": "RefleXGen:The unexamined code is not worth using", "comment": null, "summary": "Security in code generation remains a pivotal challenge when applying large\nlanguage models (LLMs). This paper introduces RefleXGen, an innovative method\nthat significantly enhances code security by integrating Retrieval-Augmented\nGeneration (RAG) techniques with guided self-reflection mechanisms inherent in\nLLMs. Unlike traditional approaches that rely on fine-tuning LLMs or developing\nspecialized secure code datasets - processes that can be resource-intensive -\nRefleXGen iteratively optimizes the code generation process through\nself-assessment and reflection without the need for extensive resources. Within\nthis framework, the model continuously accumulates and refines its knowledge\nbase, thereby progressively improving the security of the generated code.\nExperimental results demonstrate that RefleXGen substantially enhances code\nsecurity across multiple models, achieving a 13.6% improvement with GPT-3.5\nTurbo, a 6.7% improvement with GPT-4o, a 4.5% improvement with CodeQwen, and a\n5.8% improvement with Gemini. Our findings highlight that improving the quality\nof model self-reflection constitutes an effective and practical strategy for\nstrengthening the security of AI-generated code.", "AI": {"tldr": "RefleXGen \u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u53cd\u601d\u673a\u5236\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u65e0\u9700\u5fae\u8c03\u6216\u4e13\u7528\u6570\u636e\u96c6\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5b89\u5168\u6027\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u5982\u5fae\u8c03\u6a21\u578b\u6216\u6784\u5efa\u4e13\u7528\u5b89\u5168\u6570\u636e\u96c6\u6210\u672c\u9ad8\u6602\u3001\u8d44\u6e90\u5bc6\u96c6\u3002", "method": "RefleXGen \u901a\u8fc7\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8fed\u4ee3\u5f0f\u7684\u81ea\u8bc4\u4f30\u4e0e\u81ea\u53cd\u601d\uff0c\u7ed3\u5408 RAG \u6280\u672f\uff0c\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u4f18\u5316\u5e76\u79ef\u7d2f\u5b89\u5168\u77e5\u8bc6\uff0c\u4ece\u800c\u63d0\u5347\u4ee3\u7801\u5b89\u5168\u6027\u3002", "result": "\u5728\u591a\u4e2a\u4e3b\u6d41\u6a21\u578b\u4e0a\u9a8c\u8bc1\u6709\u6548\uff1aGPT-3.5 Turbo \u63d0\u5347 13.6%\uff0cGPT-4o \u63d0\u5347 6.7%\uff0cCodeQwen \u63d0\u5347 4.5%\uff0cGemini \u63d0\u5347 5.8%\u3002", "conclusion": "\u63d0\u5347\u6a21\u578b\u81ea\u53cd\u601d\u8d28\u91cf\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u7b56\u7565\uff0c\u53ef\u663e\u8457\u589e\u5f3a AI \u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2510.24205", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24205", "abs": "https://arxiv.org/abs/2510.24205", "authors": ["Telmo Ribeiro", "Jos\u00e9 Proen\u00e7a", "M\u00e1rio Florido"], "title": "CoMPSeT: A Framework for Comparing Multiparty Session Types", "comment": "In Proceedings EXPRESS/SOS 2025, arXiv:2510.23211", "summary": "Concurrent systems are often complex and difficult to design. Choreographic\nlanguages, such as Multiparty Session Types (MPST), allow the description of\nglobal protocols of interactions by capturing valid patterns of interactions\nbetween participants. Many variations of MPST exist, each one with its rather\nspecific features and idiosyncrasies. Here we propose a tool (CoMPSeT) that\nprovides clearer insights over different features in existing MPST. We select a\nrepresentative set of MPST examples and provide mechanisms to combine different\nfeatures and to animate and compare the semantics of concrete examples. CoMPSeT\nis open-source, compiled into JavaScript, and can be directly executed from any\nbrowser, becoming useful both for researchers who want to better understand the\nlandscape of MPST and for teachers who want to explain global choreographies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a CoMPSeT \u7684\u5f00\u6e90\u5de5\u5177\uff0c\u7528\u4e8e\u5206\u6790\u548c\u6bd4\u8f83\u591a\u79cd\u591a\u53c2\u4e0e\u65b9\u4f1a\u8bdd\u7c7b\u578b\uff08MPST\uff09\u7684\u7279\u6027\uff0c\u652f\u6301\u5728\u6d4f\u89c8\u5668\u4e2d\u76f4\u63a5\u8fd0\u884c\uff0c\u4fbf\u4e8e\u7814\u7a76\u4eba\u5458\u548c\u6559\u5e08\u7406\u89e3\u548c\u6559\u5b66\u5168\u5c40\u7f16\u6392\u534f\u8bae\u3002", "motivation": "\u591a\u53c2\u4e0e\u65b9\u4f1a\u8bdd\u7c7b\u578b\uff08MPST\uff09\u5b58\u5728\u4f17\u591a\u53d8\u4f53\uff0c\u5404\u81ea\u5177\u6709\u7279\u5b9a\u7279\u6027\u548c\u5dee\u5f02\uff0c\u5bfc\u81f4\u7406\u89e3\u548c\u6bd4\u8f83\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u5de5\u5177\u6765\u6e05\u6670\u5c55\u793a\u548c\u5bf9\u6bd4\u8fd9\u4e9b\u7279\u6027\u3002", "method": "\u4f5c\u8005\u9009\u53d6\u4e86\u4e00\u7ec4\u5177\u6709\u4ee3\u8868\u6027\u7684 MPST \u793a\u4f8b\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86 CoMPSeT \u5de5\u5177\uff0c\u8be5\u5de5\u5177\u652f\u6301\u7ec4\u5408\u4e0d\u540c\u7279\u6027\u3001\u52a8\u753b\u6f14\u793a\u53ca\u8bed\u4e49\u6bd4\u8f83\uff0c\u5e76\u4ee5 JavaScript \u7f16\u8bd1\uff0c\u53ef\u5728\u6d4f\u89c8\u5668\u4e2d\u8fd0\u884c\u3002", "result": "CoMPSeT \u80fd\u6709\u6548\u652f\u6301\u5bf9\u4e0d\u540c MPST \u7279\u6027\u7684\u7ec4\u5408\u3001\u52a8\u753b\u5316\u548c\u8bed\u4e49\u6bd4\u8f83\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u6559\u80b2\u8005\u63d0\u4f9b\u4e86\u76f4\u89c2\u7406\u89e3\u5168\u5c40\u7f16\u6392\u8bed\u8a00\u7684\u624b\u6bb5\u3002", "conclusion": "CoMPSeT \u4f5c\u4e3a\u4e00\u4e2a\u5f00\u6e90\u3001\u6613\u8bbf\u95ee\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u5398\u6e05 MPST \u7684\u591a\u6837\u5316\u7279\u6027\uff0c\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u4e0e\u6559\u5b66\u3002"}}
{"id": "2510.23893", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23893", "abs": "https://arxiv.org/abs/2510.23893", "authors": ["Rodrigo Falc\u00e3o", "Stefan Schweitzer", "Julien Siebert", "Emily Calvet", "Frank Elberzhager"], "title": "Evaluating the effectiveness of LLM-based interoperability", "comment": null, "summary": "Background: Systems of systems are becoming increasingly dynamic and\nheterogeneous, and this adds pressure on the long-standing challenge of\ninteroperability. Besides its technical aspect, interoperability has also an\neconomic side, as development time efforts are required to build the\ninteroperability artifacts. Objectives: With the recent advances in the field\nof large language models (LLMs), we aim at analyzing the effectiveness of\nLLM-based strategies to make systems interoperate autonomously, at runtime,\nwithout human intervention. Method: We selected 13 open source LLMs and curated\nfour versions of a dataset in the agricultural interoperability use case. We\nperformed three runs of each model with each version of the dataset, using two\ndifferent strategies. Then we compared the effectiveness of the models and the\nconsistency of their results across multiple runs. Results: qwen2.5-coder:32b\nwas the most effective model using both strategies DIRECT (average pass@1 >=\n0.99) and CODEGEN (average pass@1 >= 0.89) in three out of four dataset\nversions. In the fourth dataset version, which included an unit conversion, all\nmodels using the strategy DIRECT failed, whereas using CODEGEN\nqwen2.5-coder:32b succeeded with an average pass@1 = 0.75. Conclusion: Some\nLLMs can make systems interoperate autonomously. Further evaluation in\ndifferent domains is recommended, and further research on reliability\nstrategies should be conducted.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e8613\u4e2a\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u519c\u4e1a\u4e92\u64cd\u4f5c\u6027\u573a\u666f\u4e0b\u5b9e\u73b0\u7cfb\u7edf\u81ea\u4e3b\u4e92\u64cd\u4f5c\u7684\u80fd\u529b\uff0c\u53d1\u73b0qwen2.5-coder:32b\u5728\u591a\u6570\u6570\u636e\u96c6\u7248\u672c\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u5c24\u5176\u5728\u6d89\u53ca\u5355\u4f4d\u8f6c\u6362\u65f6CODEGEN\u7b56\u7565\u4f18\u4e8eDIRECT\u7b56\u7565\u3002", "motivation": "\u7cfb\u7edf\u4e4b\u7cfb\u7edf\u65e5\u76ca\u52a8\u6001\u548c\u5f02\u6784\uff0c\u5bf9\u4e92\u64cd\u4f5c\u6027\u63d0\u51fa\u66f4\u9ad8\u8981\u6c42\uff1b\u4f20\u7edf\u4e92\u64cd\u4f5c\u65b9\u6848\u9700\u5927\u91cf\u5f00\u53d1\u6295\u5165\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8fdb\u5c55\u4e3a\u5b9e\u73b0\u8fd0\u884c\u65f6\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u81ea\u4e3b\u4e92\u64cd\u4f5c\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u3002", "method": "\u9009\u53d613\u4e2a\u5f00\u6e90LLM\uff0c\u5728\u519c\u4e1a\u4e92\u64cd\u4f5c\u7528\u4f8b\u4e2d\u6784\u5efa\u56db\u4e2a\u7248\u672c\u7684\u6570\u636e\u96c6\uff0c\u91c7\u7528DIRECT\u548cCODEGEN\u4e24\u79cd\u7b56\u7565\uff0c\u5bf9\u6bcf\u4e2a\u6a21\u578b\u5728\u6bcf\u79cd\u6570\u636e\u96c6\u7248\u672c\u4e0a\u8fd0\u884c\u4e09\u6b21\uff0c\u8bc4\u4f30\u5176\u6548\u679c\u548c\u7ed3\u679c\u4e00\u81f4\u6027\u3002", "result": "qwen2.5-coder:32b\u5728\u4e09\u79cd\u6570\u636e\u96c6\u7248\u672c\u4e2d\u4f7f\u7528\u4e24\u79cd\u7b56\u7565\u5747\u53d6\u5f97\u9ad8\u6210\u529f\u7387\uff08DIRECT \u22650.99\uff0cCODEGEN \u22650.89\uff09\uff1b\u5728\u5305\u542b\u5355\u4f4d\u8f6c\u6362\u7684\u7b2c\u56db\u79cd\u6570\u636e\u96c6\u4e2d\uff0cDIRECT\u7b56\u7565\u5168\u90e8\u5931\u8d25\uff0c\u800cCODEGEN\u7b56\u7565\u4e0b\u8be5\u6a21\u578b\u4ecd\u4ee50.75\u7684\u5e73\u5747pass@1\u6210\u529f\u3002", "conclusion": "\u90e8\u5206\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u7cfb\u7edf\u95f4\u7684\u81ea\u4e3b\u4e92\u64cd\u4f5c\uff0c\u5efa\u8bae\u5728\u5176\u4ed6\u9886\u57df\u8fdb\u4e00\u6b65\u9a8c\u8bc1\uff0c\u5e76\u5f00\u5c55\u63d0\u5347\u53ef\u9760\u6027\u7684\u7b56\u7565\u7814\u7a76\u3002"}}
{"id": "2510.23970", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.23970", "abs": "https://arxiv.org/abs/2510.23970", "authors": ["Maria C. Borges", "Julian Legler", "Lucca Di Benedetto"], "title": "Validating Alerts in Cloud-Native Observability", "comment": "16th Symposium on Software Performance (SSP'25)", "summary": "Observability and alerting form the backbone of modern reliability\nengineering. Alerts help teams catch faults early before they turn into\nproduction outages and serve as first clues for troubleshooting. However,\ndesigning effective alerts is challenging. They need to strike a fine balance\nbetween catching issues early and minimizing false alarms. On top of this,\nalerts often cover uncommon faults, so the code is rarely executed and\ntherefore rarely checked. To address these challenges, several industry\npractitioners advocate for testing alerting code with the same rigor as\napplication code. Still, there's a lack of tools that support such systematic\ndesign and validation of alerts.\n  This paper introduces a new alerting extension for the observability\nexperimentation tool OXN. It lets engineers experiment with alerts early during\ndevelopment. With OXN, engineers can now tune rules at design time and\nroutinely validate the firing behavior of their alerts, avoiding future\nproblems at runtime.", "AI": {"tldr": "\u672c\u6587\u4e3a\u53ef\u89c2\u6d4b\u6027\u5b9e\u9a8c\u5de5\u5177 OXN \u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u544a\u8b66\u6269\u5c55\uff0c\u4f7f\u5de5\u7a0b\u5e08\u80fd\u5728\u5f00\u53d1\u65e9\u671f\u5bf9\u544a\u8b66\u89c4\u5219\u8fdb\u884c\u5b9e\u9a8c\u3001\u8c03\u4f18\u548c\u9a8c\u8bc1\uff0c\u4ece\u800c\u63d0\u5347\u544a\u8b66\u6709\u6548\u6027\u5e76\u51cf\u5c11\u8fd0\u884c\u65f6\u95ee\u9898\u3002", "motivation": "\u8bbe\u8ba1\u6709\u6548\u7684\u544a\u8b66\u673a\u5236\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u5728\u65e9\u671f\u53d1\u73b0\u95ee\u9898\u4e0e\u51cf\u5c11\u8bef\u62a5\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff1b\u540c\u65f6\uff0c\u7531\u4e8e\u544a\u8b66\u4ee3\u7801\u5f88\u5c11\u6267\u884c\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u9a8c\u8bc1\uff0c\u4e1a\u754c\u547c\u5401\u50cf\u5bf9\u5f85\u5e94\u7528\u4ee3\u7801\u4e00\u6837\u4e25\u683c\u6d4b\u8bd5\u544a\u8b66\u4ee3\u7801\uff0c\u4f46\u7f3a\u5c11\u76f8\u5e94\u5de5\u5177\u652f\u6301\u3002", "method": "\u5728\u53ef\u89c2\u6d4b\u6027\u5b9e\u9a8c\u5de5\u5177 OXN \u4e2d\u5f15\u5165\u65b0\u7684\u544a\u8b66\u6269\u5c55\uff0c\u5141\u8bb8\u5de5\u7a0b\u5e08\u5728\u5f00\u53d1\u9636\u6bb5\u5bf9\u544a\u8b66\u89c4\u5219\u8fdb\u884c\u5b9e\u9a8c\u3001\u8c03\u4f18\u548c\u5b9a\u671f\u9a8c\u8bc1\u5176\u89e6\u53d1\u884c\u4e3a\u3002", "result": "\u5de5\u7a0b\u5e08\u80fd\u591f\u5728\u8bbe\u8ba1\u9636\u6bb5\u5c31\u4f18\u5316\u544a\u8b66\u89c4\u5219\uff0c\u5e76\u6301\u7eed\u9a8c\u8bc1\u5176\u884c\u4e3a\uff0c\u4ece\u800c\u907f\u514d\u8fd0\u884c\u65f6\u51fa\u73b0\u544a\u8b66\u5931\u6548\u6216\u8bef\u62a5\u7b49\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u5c06\u544a\u8b66\u4ee3\u7801\u7eb3\u5165\u7cfb\u7edf\u5316\u5b9e\u9a8c\u4e0e\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u544a\u8b66\u7684\u53ef\u9760\u6027\u4e0e\u5b9e\u7528\u6027\uff0c\u586b\u8865\u4e86\u5f53\u524d\u5de5\u5177\u94fe\u7684\u7a7a\u767d\u3002"}}
{"id": "2510.24019", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24019", "abs": "https://arxiv.org/abs/2510.24019", "authors": ["Xing Xing", "Wei Wang", "Lipeng Ma", "Weidong Yang", "Junjie Zheng"], "title": "Lifecycle-Aware code generation: Leveraging Software Engineering Phases in LLMs", "comment": null, "summary": "Recent progress in large language models (LLMs) has advanced automatic code\ngeneration, yet most approaches rely on direct, single-step translation from\nproblem descriptions to code, disregarding structured software engineering\npractices. We introduce a lifecycle-aware framework that systematically\nincorporates intermediate artifacts such as requirements analysis, state\nmachine modeling, and pseudocode into both the training and inference stages.\nThis design aligns code generation with standard software development phases\nand enables more structured reasoning. Experiments show that lifecycle-level\nfine-tuning improves code correctness by up to 75% over the same model before\nfine-tuning, with performance gains compounding across intermediate stages.\nMulti-step inference consistently surpasses single-step generation,\ndemonstrating the effectiveness of intermediate scaffolding. Notably,\nopen-source LLMs, once fine-tuned under our framework, match or slightly\noutperform models pretrained on code. When applied to DeepSeek-Coder-1.3B, our\nframework yields relative CodeBLEU improvements of 34.3%, 20.0%, 11.2%, and\n22.3% over ChatGPT-3.5, ChatGPT-4o-mini, DeepSeek-R1, and LLaMA-8B,\nrespectively. Our pipeline also proves robust with up to 80\\% less training\ndata, confirming its resilience. Ablation studies further reveal that each\nintermediate artifact contributes distinctly to final code quality, with state\nmachine modeling yielding the most substantial impact. Our source code and\ndetailed experimental data are available at\nhttps://anonymous.4open.science/r/Lifecycle-Aware-3CCB.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u547d\u5468\u671f\u611f\u77e5\u7684\u4ee3\u7801\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u5f15\u5165\u9700\u6c42\u5206\u6790\u3001\u72b6\u6001\u673a\u5efa\u6a21\u548c\u4f2a\u4ee3\u7801\u7b49\u4e2d\u95f4\u4ea7\u7269\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u7684\u6b63\u786e\u6027\u548c\u7ed3\u6784\u5316\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u591a\u91c7\u7528\u4ece\u95ee\u9898\u63cf\u8ff0\u5230\u4ee3\u7801\u7684\u5355\u6b65\u76f4\u63a5\u7ffb\u8bd1\u65b9\u5f0f\uff0c\u5ffd\u7565\u4e86\u7ed3\u6784\u5316\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff0c\u9650\u5236\u4e86\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u751f\u547d\u5468\u671f\u611f\u77e5\u6846\u67b6\uff0c\u5728\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7cfb\u7edf\u6027\u5730\u5f15\u5165\u8f6f\u4ef6\u5f00\u53d1\u5404\u9636\u6bb5\u7684\u4e2d\u95f4\u4ea7\u7269\uff08\u5982\u9700\u6c42\u5206\u6790\u3001\u72b6\u6001\u673a\u5efa\u6a21\u3001\u4f2a\u4ee3\u7801\uff09\uff0c\u5b9e\u73b0\u591a\u9636\u6bb5\u7ed3\u6784\u5316\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u76f8\u540c\u6a21\u578b\u4e0a\u901a\u8fc7\u751f\u547d\u5468\u671f\u7ea7\u5fae\u8c03\u53ef\u5c06\u4ee3\u7801\u6b63\u786e\u7387\u63d0\u5347\u9ad8\u8fbe75%\uff1b\u5fae\u8c03\u540e\u7684\u5f00\u6e90\u6a21\u578b\u6027\u80fd\u5ab2\u7f8e\u751a\u81f3\u7565\u8d85\u4e13\u95e8\u9884\u8bad\u7ec3\u7684\u4ee3\u7801\u6a21\u578b\uff1b\u5728DeepSeek-Coder-1.3B\u4e0a\uff0cCodeBLEU\u6307\u6807\u663e\u8457\u4f18\u4e8e\u591a\u4e2a\u4e3b\u6d41\u6a21\u578b\uff1b\u4e14\u5728\u8bad\u7ec3\u6570\u636e\u51cf\u5c1180%\u65f6\u4ecd\u4fdd\u6301\u7a33\u5065\u6027\u80fd\u3002", "conclusion": "\u5f15\u5165\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684\u4e2d\u95f4\u4ea7\u7269\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u4e0e\u7ed3\u6784\u5316\u7a0b\u5ea6\uff0c\u72b6\u6001\u673a\u5efa\u6a21\u5bf9\u6700\u7ec8\u6027\u80fd\u8d21\u732e\u6700\u5927\uff0c\u8be5\u6846\u67b6\u5177\u6709\u9ad8\u6548\u3001\u9c81\u68d2\u548c\u5b9e\u7528\u6027\u5f3a\u7684\u7279\u70b9\u3002"}}
{"id": "2510.24142", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.24142", "abs": "https://arxiv.org/abs/2510.24142", "authors": ["Joran Leest", "Ilias Gerostathopoulos", "Patricia Lago", "Claudia Raibulet"], "title": "Monitoring and Observability of Machine Learning Systems: Current Practices and Gaps", "comment": null, "summary": "Production machine learning (ML) systems fail silently -- not with crashes,\nbut through wrong decisions. While observability is recognized as critical for\nML operations, there is a lack empirical evidence of what practitioners\nactually capture. This study presents empirical results on ML observability in\npractice through seven focus group sessions in several domains. We catalog the\ninformation practitioners systematically capture across ML systems and their\nenvironment and map how they use it to validate models, detect and diagnose\nfaults, and explain observed degradations. Finally, we identify gaps in current\npractice and outline implications for tooling design and research to establish\nML observability practices.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4e03\u4e2a\u8de8\u9886\u57df\u7684\u7126\u70b9\u5c0f\u7ec4\u4f1a\u8bae\uff0c\u8c03\u67e5\u4e86\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u7cfb\u7edf\u5728\u5b9e\u9645\u751f\u4ea7\u4e2d\u7684\u53ef\u89c2\u6d4b\u6027\u5b9e\u8df5\uff0c\u603b\u7ed3\u4e86\u4ece\u4e1a\u8005\u6355\u83b7\u7684\u4fe1\u606f\u7c7b\u578b\u53ca\u5176\u7528\u9014\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524d\u5b9e\u8df5\u4e2d\u7684\u4e0d\u8db3\u548c\u5bf9\u672a\u6765\u5de5\u5177\u4e0e\u7814\u7a76\u7684\u542f\u793a\u3002", "motivation": "\u751f\u4ea7\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5f80\u5f80\u4e0d\u4f1a\u5d29\u6e83\uff0c\u800c\u662f\u6084\u65e0\u58f0\u606f\u5730\u505a\u51fa\u9519\u8bef\u51b3\u7b56\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u7684\u53ef\u89c2\u6d4b\u6027\u624b\u6bb5\uff1b\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u5173\u4e8e\u4ece\u4e1a\u8005\u5b9e\u9645\u5982\u4f55\u5b9e\u73b0ML\u53ef\u89c2\u6d4b\u6027\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002", "method": "\u901a\u8fc7\u5728\u591a\u4e2a\u9886\u57df\u7ec4\u7ec7\u4e03\u573a\u7126\u70b9\u5c0f\u7ec4\u4f1a\u8bae\uff0c\u6536\u96c6\u5e76\u5206\u6790\u4ece\u4e1a\u8005\u5728ML\u7cfb\u7edf\u53ca\u5176\u73af\u5883\u4e2d\u7cfb\u7edf\u6027\u6355\u83b7\u7684\u4fe1\u606f\uff0c\u4ee5\u53ca\u4ed6\u4eec\u5982\u4f55\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u6a21\u578b\u9a8c\u8bc1\u3001\u6545\u969c\u68c0\u6d4b\u4e0e\u8bca\u65ad\u3001\u6027\u80fd\u9000\u5316\u89e3\u91ca\u3002", "result": "\u7814\u7a76\u6574\u7406\u4e86\u5b9e\u8df5\u4e2d\u5e38\u7528\u7684\u53ef\u89c2\u6d4b\u4fe1\u606f\u7c7b\u522b\uff0c\u63ed\u793a\u4e86\u5176\u5728\u6a21\u578b\u9a8c\u8bc1\u3001\u6545\u969c\u6392\u67e5\u548c\u6027\u80fd\u89e3\u91ca\u4e2d\u7684\u5177\u4f53\u5e94\u7528\uff0c\u5e76\u8bc6\u522b\u51fa\u73b0\u6709\u5b9e\u8df5\u4e2d\u7684\u5173\u952e\u7f3a\u53e3\u3002", "conclusion": "\u5f53\u524dML\u53ef\u89c2\u6d4b\u6027\u5b9e\u8df5\u5c1a\u4e0d\u5b8c\u5584\uff0c\u9700\u5728\u5de5\u5177\u8bbe\u8ba1\u548c\u7814\u7a76\u65b9\u5411\u4e0a\u8fdb\u4e00\u6b65\u53d1\u5c55\uff0c\u4ee5\u5efa\u7acb\u66f4\u7cfb\u7edf\u3001\u6709\u6548\u7684ML\u53ef\u89c2\u6d4b\u6027\u65b9\u6cd5\u3002"}}
{"id": "2510.24188", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.24188", "abs": "https://arxiv.org/abs/2510.24188", "authors": ["C\u00e9sar Santos", "Ermeson Andrade", "Roberto Natella"], "title": "Investigating Software Aging in LLM-Generated Software Systems", "comment": "Presented at the 17th International Workshop on Software Aging and\n  Rejuvenation (WoSAR), 2025", "summary": "Automatically generated software, especially code produced by Large Language\nModels (LLMs), is increasingly adopted to accelerate development and reduce\nmanual effort. However, little is known about the long-term reliability of such\nsystems under sustained execution. In this paper, we experimentally investigate\nthe phenomenon of software aging in applications generated by LLM-based tools.\nUsing the Bolt platform and standardized prompts from Baxbench, we generated\nfour service-oriented applications and subjected them to 50-hour load tests.\nResource usage, response time, and throughput were continuously monitored to\ndetect degradation patterns. The results reveal significant evidence of\nsoftware aging, including progressive memory growth, increased response time,\nand performance instability across all applications. Statistical analyzes\nconfirm these trends and highlight variability in the severity of aging\naccording to the type of application. Our findings show the need to consider\naging in automatically generated software and provide a foundation for future\nstudies on mitigation strategies and long-term reliability evaluation.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc750\u5c0f\u65f6\u8d1f\u8f7d\u6d4b\u8bd5\u53d1\u73b0\uff0c\u7531\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u7684\u670d\u52a1\u578b\u5e94\u7528\u666e\u904d\u5b58\u5728\u8f6f\u4ef6\u8001\u5316\u73b0\u8c61\uff0c\u8868\u73b0\u4e3a\u5185\u5b58\u6301\u7eed\u589e\u957f\u3001\u54cd\u5e94\u65f6\u95f4\u589e\u52a0\u548c\u6027\u80fd\u4e0d\u7a33\u5b9a\uff0c\u5f3a\u8c03\u9700\u91cd\u89c6\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u7684\u957f\u671f\u53ef\u9760\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5728\u957f\u671f\u8fd0\u884c\u4e0b\u7684\u53ef\u9760\u6027\u95ee\u9898\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\uff0c\u5c24\u5176\u662f\u8f6f\u4ef6\u8001\u5316\u73b0\u8c61\u7f3a\u4e4f\u5b9e\u8bc1\u5206\u6790\u3002", "method": "\u57fa\u4e8eBolt\u5e73\u53f0\u548cBaxbench\u6807\u51c6\u63d0\u793a\u751f\u6210\u56db\u4e2a\u670d\u52a1\u578b\u5e94\u7528\uff0c\u8fdb\u884c50\u5c0f\u65f6\u8d1f\u8f7d\u6d4b\u8bd5\uff0c\u6301\u7eed\u76d1\u63a7\u8d44\u6e90\u4f7f\u7528\u3001\u54cd\u5e94\u65f6\u95f4\u548c\u541e\u5410\u91cf\uff0c\u91c7\u7528\u7edf\u8ba1\u5206\u6790\u8bc6\u522b\u8001\u5316\u8d8b\u52bf\u3002", "result": "\u6240\u6709\u6d4b\u8bd5\u5e94\u7528\u5747\u8868\u73b0\u51fa\u663e\u8457\u7684\u8f6f\u4ef6\u8001\u5316\u8ff9\u8c61\uff0c\u5305\u62ec\u5185\u5b58\u6301\u7eed\u589e\u957f\u3001\u54cd\u5e94\u65f6\u95f4\u5ef6\u957f\u548c\u6027\u80fd\u4e0d\u7a33\u5b9a\uff0c\u4e14\u8001\u5316\u4e25\u91cd\u7a0b\u5ea6\u56e0\u5e94\u7528\u7c7b\u578b\u800c\u5f02\u3002", "conclusion": "\u81ea\u52a8\u751f\u6210\u8f6f\u4ef6\u5b58\u5728\u4e0d\u53ef\u5ffd\u89c6\u7684\u957f\u671f\u53ef\u9760\u6027\u98ce\u9669\uff0c\u9700\u5c06\u8f6f\u4ef6\u8001\u5316\u7eb3\u5165\u8003\u91cf\uff0c\u5e76\u4e3a\u672a\u6765\u5236\u5b9a\u7f13\u89e3\u7b56\u7565\u548c\u8bc4\u4f30\u65b9\u6cd5\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2510.24265", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.24265", "abs": "https://arxiv.org/abs/2510.24265", "authors": ["Sadia Afroz", "Zixuan Feng", "Katie Kimura", "Bianca Trinkenreich", "Igor Steinmacher", "Anita Sarma"], "title": "Developer Productivity with GenAI", "comment": null, "summary": "Generative AI (GenAI) tools are increasingly being adopted in software\ndevelopment as productivity aids. However, evidence regarding where and when\nthese tools actually enhance productivity is unclear. In this paper, we\ninvestigate how GenAI adoption affects different dimensions of developer\nproductivity. We surveyed 415 software practitioners to capture their\nperceptions of productivity changes associated with AI-assisted development\nusing the SPACE framework - Satisfaction and well-being, Performance, Activity,\nCommunication and collaboration, and Efficiency and flow. Our results,\ndisaggregated by frequency of AI usage, reveal limited overall productivity\nchange, highlighting the productivity paradox in which developers become faster\nbut do not necessarily create better software or feel more fulfilled.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e86415\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\uff0c\u53d1\u73b0\u751f\u6210\u5f0fAI\u5de5\u5177\u7684\u4f7f\u7528\u867d\u53ef\u80fd\u63d0\u5347\u5f00\u53d1\u901f\u5ea6\uff0c\u4f46\u5bf9\u6574\u4f53\u751f\u4ea7\u529b\uff08\u5982\u8f6f\u4ef6\u8d28\u91cf\u3001\u5f00\u53d1\u8005\u6ee1\u610f\u5ea6\u7b49\uff09\u7684\u63d0\u5347\u6709\u9650\uff0c\u4f53\u73b0\u4e86\u201c\u751f\u4ea7\u529b\u6096\u8bba\u201d\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0fAI\u5de5\u5177\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5176\u662f\u5426\u771f\u6b63\u63d0\u5347\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u5c1a\u4e0d\u660e\u786e\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u63a2\u7a76GenAI\u5bf9\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u4e0d\u540c\u7ef4\u5ea6\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u95ee\u5377\u8c03\u67e5415\u540d\u8f6f\u4ef6\u4ece\u4e1a\u8005\uff0c\u57fa\u4e8eSPACE\u6846\u67b6\uff08\u6ee1\u610f\u5ea6\u4e0e\u5e78\u798f\u611f\u3001\u7ee9\u6548\u3001\u6d3b\u52a8\u3001\u6c9f\u901a\u534f\u4f5c\u3001\u6548\u7387\u4e0e\u6d41\u7545\u611f\uff09\u8bc4\u4f30\u5176\u5bf9AI\u8f85\u52a9\u5f00\u53d1\u5e26\u6765\u7684\u751f\u4ea7\u529b\u53d8\u5316\u7684\u611f\u77e5\uff0c\u5e76\u6309AI\u4f7f\u7528\u9891\u7387\u8fdb\u884c\u5206\u7ec4\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u603b\u4f53\u751f\u4ea7\u529b\u53d8\u5316\u6709\u9650\uff1b\u9ad8\u9891\u4f7f\u7528AI\u7684\u5f00\u53d1\u8005\u867d\u5728\u6548\u7387\u4e0a\u6709\u6240\u63d0\u5347\uff0c\u4f46\u5728\u8f6f\u4ef6\u8d28\u91cf\u3001\u6ee1\u610f\u5ea6\u7b49\u65b9\u9762\u672a\u89c1\u663e\u8457\u6539\u5584\uff0c\u4f53\u73b0\u51fa\u201c\u751f\u4ea7\u529b\u6096\u8bba\u201d\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5de5\u5177\u867d\u80fd\u52a0\u5feb\u5f00\u53d1\u901f\u5ea6\uff0c\u4f46\u672a\u5fc5\u5e26\u6765\u5168\u9762\u7684\u751f\u4ea7\u529b\u63d0\u5347\uff0c\u5f00\u53d1\u8005\u5e76\u672a\u56e0\u6b64\u4ea7\u51fa\u66f4\u9ad8\u8d28\u91cf\u7684\u8f6f\u4ef6\u6216\u83b7\u5f97\u66f4\u9ad8\u7684\u804c\u4e1a\u6ee1\u8db3\u611f\u3002"}}
{"id": "2510.24358", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24358", "abs": "https://arxiv.org/abs/2510.24358", "authors": ["Lingyue Fu", "Bolun Zhang", "Hao Guan", "Yaoming Zhu", "Lin Qiu", "Weiwen Liu", "Xuezhi Cao", "Xunliang Cai", "Weinan Zhang", "Yong Yu"], "title": "Automatically Benchmarking LLM Code Agents through Agent-Driven Annotation and Evaluation", "comment": null, "summary": "Recent advances in code agents have enabled automated software development at\nthe project level, supported by large language models (LLMs) and widely adopted\ntools. However, existing benchmarks for code agent evaluation face two major\nlimitations: high annotation cost and expertise requirements, and rigid\nevaluation metrics that rely primarily on unit tests. To address these\nchallenges, we propose an agent-driven benchmark construction pipeline that\nleverages human supervision to efficiently generate diverse and challenging\nproject-level tasks. Based on this approach, we introduce PRDBench, a novel\nbenchmark comprising 50 real-world Python projects across 20 domains, each with\nstructured Product Requirement Document (PRD) requirements, comprehensive\nevaluation criteria, and reference implementations. PRDBench features rich data\nsources, high task complexity, and flexible metrics. We further employ an\nAgent-as-a-Judge paradigm to score agent outputs, enabling the evaluation of\nvarious test types beyond unit tests. Extensive experiments on PRDBench\ndemonstrate its effectiveness in assessing the capabilities of both code agents\nand evaluation agents, providing a scalable and robust framework for annotation\nand evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PRDBench\uff0c\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9ePython\u9879\u76ee\u7684\u65b0\u578b\u57fa\u51c6\uff0c\u901a\u8fc7\u7ed3\u5408\u4eba\u7c7b\u76d1\u7763\u4e0eAgent-as-a-Judge\u8303\u5f0f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4ee3\u7801\u667a\u80fd\u4f53\u8bc4\u4f30\u4e2d\u9ad8\u6807\u6ce8\u6210\u672c\u548c\u50f5\u5316\u6307\u6807\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u667a\u80fd\u4f53\u8bc4\u4f30\u57fa\u51c6\u5b58\u5728\u4e24\u5927\u5c40\u9650\uff1a\u4e00\u662f\u6807\u6ce8\u6210\u672c\u9ad8\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e8c\u662f\u8bc4\u4f30\u6307\u6807\u8fc7\u4e8e\u4f9d\u8d56\u5355\u5143\u6d4b\u8bd5\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7531\u667a\u80fd\u4f53\u9a71\u52a8\u7684\u57fa\u51c6\u6784\u5efa\u6d41\u7a0b\uff0c\u7ed3\u5408\u4eba\u7c7b\u76d1\u7763\u751f\u6210\u591a\u6837\u4e14\u5177\u6311\u6218\u6027\u7684\u9879\u76ee\u7ea7\u4efb\u52a1\uff0c\u5e76\u5f15\u5165Agent-as-a-Judge\u8303\u5f0f\u5bf9\u667a\u80fd\u4f53\u8f93\u51fa\u8fdb\u884c\u591a\u7ef4\u5ea6\u8bc4\u5206\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b50\u4e2a\u771f\u5b9ePython\u9879\u76ee\u3001\u8986\u76d620\u4e2a\u9886\u57df\u7684PRDBench\u57fa\u51c6\uff0c\u5177\u5907\u7ed3\u6784\u5316\u4ea7\u54c1\u9700\u6c42\u6587\u6863\u3001\u7efc\u5408\u8bc4\u4f30\u6807\u51c6\u548c\u53c2\u8003\u5b9e\u73b0\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u8bc4\u4f30\u4ee3\u7801\u667a\u80fd\u4f53\u548c\u8bc4\u4f30\u667a\u80fd\u4f53\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "PRDBench\u4e3a\u4ee3\u7801\u667a\u80fd\u4f53\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u9c81\u68d2\u4e14\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9879\u76ee\u7ea7\u8f6f\u4ef6\u5f00\u53d1\u81ea\u52a8\u5316\u8bc4\u4f30\u7684\u53ef\u884c\u6027\u4e0e\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.24367", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.24367", "abs": "https://arxiv.org/abs/2510.24367", "authors": ["Junda He", "Jieke Shi", "Terry Yue Zhuo", "Christoph Treude", "Jiamou Sun", "Zhenchang Xing", "Xiaoning Du", "David Lo"], "title": "LLM-as-a-Judge for Software Engineering: Literature Review, Vision, and the Road Ahead", "comment": null, "summary": "The rapid integration of Large Language Models (LLMs) into software\nengineering (SE) has revolutionized tasks like code generation, producing a\nmassive volume of software artifacts. This surge has exposed a critical\nbottleneck: the lack of scalable, reliable methods to evaluate these outputs.\nHuman evaluation is costly and time-consuming, while traditional automated\nmetrics like BLEU fail to capture nuanced quality aspects. In response, the\nLLM-as-a-Judge paradigm - using LLMs for automated evaluation - has emerged.\nThis approach leverages the advanced reasoning of LLMs, offering a path toward\nhuman-like nuance at automated scale. However, LLM-as-a-Judge research in SE is\nstill in its early stages. This forward-looking SE 2030 paper aims to steer the\ncommunity toward advancing LLM-as-a-Judge for evaluating LLM-generated software\nartifacts. We provide a literature review of existing SE studies, analyze their\nlimitations, identify key research gaps, and outline a detailed roadmap. We\nenvision these frameworks as reliable, robust, and scalable human surrogates\ncapable of consistent, multi-faceted artifact evaluation by 2030. Our work aims\nto foster research and adoption of LLM-as-a-Judge frameworks, ultimately\nimproving the scalability of software artifact evaluation.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u8bc4\u4f30\u8005\uff08LLM-as-a-Judge\uff09\u6765\u81ea\u52a8\u8bc4\u4ef7LLM\u751f\u6210\u7684\u8f6f\u4ef6\u5236\u54c1\uff0c\u6307\u51fa\u5f53\u524d\u7814\u7a76\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u52302030\u5e74\u5b9e\u73b0\u53ef\u9760\u3001\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u8bc4\u4f30\u6846\u67b6\u7684\u8def\u7ebf\u56fe\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4ea7\u751f\u4e86\u5927\u91cf\u4ee3\u7801\u7b49\u8f6f\u4ef6\u5236\u54c1\uff0c\u4f46\u7f3a\u4e4f\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002\u4eba\u5de5\u8bc4\u4f30\u6210\u672c\u9ad8\uff0c\u4f20\u7edf\u81ea\u52a8\u6307\u6807\uff08\u5982BLEU\uff09\u65e0\u6cd5\u6355\u6349\u8d28\u91cf\u7ec6\u8282\uff0c\u56e0\u6b64\u4e9f\u9700\u66f4\u667a\u80fd\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u624b\u6bb5\u3002", "method": "\u4f5c\u8005\u5bf9\u73b0\u6709\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u4e2dLLM-as-a-Judge\u76f8\u5173\u7814\u7a76\u8fdb\u884c\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u5176\u5c40\u9650\u6027\uff0c\u8bc6\u522b\u5173\u952e\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u53d1\u5c55\u7684\u8be6\u7ec6\u8def\u7ebf\u56fe\u3002", "result": "\u660e\u786e\u4e86\u5f53\u524dLLM-as-a-Judge\u5728\u8f6f\u4ef6\u5de5\u7a0b\u8bc4\u4f30\u4e2d\u7684\u7814\u7a76\u73b0\u72b6\u4e0e\u6311\u6218\uff0c\u4e3a\u6784\u5efa\u5177\u5907\u4eba\u7c7b\u8bc4\u4f30\u6c34\u5e73\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "conclusion": "LLM-as-a-Judge\u6709\u671b\u6210\u4e3a\u53ef\u9760\u3001\u9c81\u68d2\u548c\u53ef\u6269\u5c55\u7684\u4eba\u7c7b\u8bc4\u4f30\u66ff\u4ee3\u65b9\u6848\uff0c\u63a8\u52a8\u8f6f\u4ef6\u5236\u54c1\u8bc4\u4f30\u7684\u81ea\u52a8\u5316\u4e0e\u89c4\u6a21\u5316\uff0c\u4f5c\u8005\u547c\u5401\u793e\u533a\u52a0\u5f3a\u76f8\u5173\u7814\u7a76\u4e0e\u5e94\u7528\u3002"}}
{"id": "2510.24483", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.24483", "abs": "https://arxiv.org/abs/2510.24483", "authors": ["Michele Lanza"], "title": "The Divine Software Engineering Comedy -- Inferno: The Okinawa Files", "comment": null, "summary": "In June 2024 I co-organized the FUture of Software Engineering symposium in\nOkinawa, Japan. Me, Andrian Marcus, Takashi Kobayashi and Shinpei Hayashi were\ngeneral chairs, Nicole Novielli, Kevin Moran, Yutaro Kashiwa and Masanari Kondo\nwere program chairs, some members of my group, Carmen Armenti, Stefano\nCampanella, Roberto Minelli, were the tables, can't have a room with only\nchairs, after all. We invited a crowd of people to discuss what future software\nengineering has. FUSE became a 3-day marathon on whether there is actually a\nfuture at all for SE. This essay is a slightly dark take about what I saw at\nthat event, very loosely based on the discussions that took place, adding some\nhealthy sarcasm and cynicism, the intellectual salt and pepper I never seem to\nrun out of. I listened to the brilliant people who gathered to talk about where\nwe're headed, and distilled three nightmares headed in our direction: software\nmakers who don't know what they're doing, but get the job done anyway, a field\nmoving so fast it can't remember its own lessons, and technologies multiplying\nlike rabbits in Spring. So, let's start. The future, eh? The future of software\nengineering looks like a car crash in slow motion: you can see it coming but\nyou can't look away. The thing is...", "AI": {"tldr": "\u672c\u6587\u4ee5\u8bbd\u523a\u548c\u60b2\u89c2\u7684\u89c6\u89d2\uff0c\u603b\u7ed3\u4e862024\u5e746\u6708\u5728\u65e5\u672c\u51b2\u7ef3\u4e3e\u529e\u7684\u201c\u8f6f\u4ef6\u5de5\u7a0b\u7684\u672a\u6765\u201d\uff08FUSE\uff09\u7814\u8ba8\u4f1a\u4e2d\u7684\u6838\u5fc3\u8ba8\u8bba\uff0c\u63d0\u51fa\u8f6f\u4ef6\u5de5\u7a0b\u6b63\u9762\u4e34\u4e09\u5927\u201c\u5669\u68a6\u201d\uff1a\u4ece\u4e1a\u8005\u7f3a\u4e4f\u771f\u6b63\u7406\u89e3\u5374\u4ecd\u4ea4\u4ed8\u8f6f\u4ef6\u3001\u9886\u57df\u53d1\u5c55\u8fc7\u5feb\u5bfc\u81f4\u9057\u5fd8\u8fc7\u5f80\u7ecf\u9a8c\u3001\u4ee5\u53ca\u6280\u672f\u8fc7\u5ea6\u5feb\u901f\u7e41\u884d\u3002", "motivation": "\u4f5c\u8005\u53c2\u4e0e\u7ec4\u7ec7FUSE\u7814\u8ba8\u4f1a\u540e\uff0c\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\u611f\u5230\u5fe7\u8651\uff0c\u5e0c\u671b\u901a\u8fc7\u5e26\u6709\u8bbd\u523a\u548c\u6279\u5224\u6027\u7684\u53cd\u601d\uff0c\u63ed\u793a\u5f53\u524d\u9886\u57df\u4e2d\u5b58\u5728\u7684\u6df1\u5c42\u95ee\u9898\u3002", "method": "\u57fa\u4e8eFUSE\u7814\u8ba8\u4f1a\u4e2d\u7684\u89c2\u5bdf\u4e0e\u8ba8\u8bba\uff0c\u7ed3\u5408\u4e2a\u4eba\u89c1\u89e3\uff0c\u91c7\u7528\u8bbd\u523a\u4e0e\u6279\u5224\u6027\u6563\u6587\u7684\u5f62\u5f0f\uff0c\u63d0\u70bc\u51fa\u8f6f\u4ef6\u5de5\u7a0b\u9762\u4e34\u7684\u4e09\u5927\u6311\u6218\u3002", "result": "\u8bc6\u522b\u51fa\u8f6f\u4ef6\u5de5\u7a0b\u672a\u6765\u53d1\u5c55\u7684\u4e09\u5927\u201c\u5669\u68a6\u201d\uff1a1\uff09\u7f3a\u4e4f\u4e13\u4e1a\u7406\u89e3\u4f46\u80fd\u5b8c\u6210\u4efb\u52a1\u7684\u5f00\u53d1\u8005\uff1b2\uff09\u53d1\u5c55\u8fc7\u5feb\u800c\u5ffd\u89c6\u5386\u53f2\u6559\u8bad\u7684\u9886\u57df\uff1b3\uff09\u6280\u672f\u65e0\u8282\u5236\u5730\u5feb\u901f\u6269\u5f20\u3002", "conclusion": "\u8f6f\u4ef6\u5de5\u7a0b\u7684\u672a\u6765\u5982\u540c\u4e00\u573a\u7f13\u6162\u53d1\u751f\u7684\u8f66\u7978\uff0c\u867d\u53ef\u9884\u89c1\u5374\u96be\u4ee5\u56de\u907f\uff0c\u4e9f\u9700\u5bf9\u5f53\u524d\u8d8b\u52bf\u8fdb\u884c\u6df1\u523b\u53cd\u601d\u4e0e\u8c03\u6574\u3002"}}
