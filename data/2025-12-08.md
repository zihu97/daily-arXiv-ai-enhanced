<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 2]
- [cs.SE](#cs.SE) [Total: 21]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [FedGMR: Federated Learning with Gradual Model Restoration under Asynchrony and Model Heterogeneity](https://arxiv.org/abs/2512.05372)
*Chengjie Ma,Seungeun Oh,Jihong Park,Seong-Lyun Kim*

Main category: cs.DC

TL;DR: FedGMR通过渐进恢复子模型密度，提升带宽受限客户端在异步异构联邦学习中的参与效率与模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决带宽受限客户端因通信能力有限导致后期欠参数化、收敛慢、泛化差的问题。

Method: 提出渐进模型恢复机制（GMR）和掩码感知聚合规则，适配异步异构环境并提供收敛性保证。

Result: 在FEMNIST、CIFAR-10、ImageNet-100上实现更快收敛与更高准确率，尤其在高异构与非IID场景下表现突出。

Conclusion: FedGMR有效缩小异构客户端与全模型FL之间的性能差距，增强系统整体鲁棒性与效率。

Abstract: Federated learning (FL) holds strong potential for distributed machine learning, but in heterogeneous environments, Bandwidth-Constrained Clients (BCCs) often struggle to participate effectively due to limited communication capacity. Their small sub-models learn quickly at first but become under-parameterized in later stages, leading to slow convergence and degraded generalization. We propose FedGMR - Federated Learning with Gradual Model Restoration under Asynchrony and Model Heterogeneity. FedGMR progressively increases each client's sub-model density during training, enabling BCCs to remain effective contributors throughout the process. In addition, we develop a mask-aware aggregation rule tailored for asynchronous MHFL and provide convergence guarantees showing that aggregated error scales with the average sub-model density across clients and rounds, while GMR provably shrinks this gap toward full-model FL. Extensive experiments on FEMNIST, CIFAR-10, and ImageNet-100 demonstrate that FedGMR achieves faster convergence and higher accuracy, especially under high heterogeneity and non-IID settings.

</details>


### [2] [Are Bus-Mounted Edge Servers Feasible?](https://arxiv.org/abs/2512.05543)
*Xuezhi Li,Jiancong He,Ming Xie,Xuyang Chen,Le Chang,Li Jiang,Gui Gui*

Main category: cs.DC

TL;DR: 本文研究了基于公交车的边缘服务器在车联网中的可行性，通过真实数据验证其覆盖能力和需求响应效果。


<details>
  <summary>Details</summary>
Motivation: 固定边缘服务器难以应对车联网用户时空动态性，需引入移动计算资源提升弹性。

Method: 结合上海公交、出租车和电信数据集分析覆盖范围，构建数学模型并设计贪心算法选择最优公交车部署边缘服务器。

Result: 仿真结果表明该方法在预算和容量限制下有效提升需求点覆盖率，适应动态用户需求。

Conclusion: 城市车联网中部署公交车载边缘服务器具有可行性、效益性和应用价值。

Abstract: Placement of edge servers is the prerequisite of provisioning edge computing services for Internet of Vehicles (IoV). Fixed-site edge servers at Road Side Units (RSUs) or base stations are able to offer basic service coverage for end users, i.e., vehicles on road. However, the server locations and capacity are fixed after deployment, rendering their inefficiency in handling spationtemporal user dynamics. Mobile servers such as buses, on the other hand, have the potential of adding computation elasticity to such system. To this end, this paper studies the feasibility of bus-mounted edge servers based on real traces. First, we investigate the coverage of the buses and base stations using the Shanghai bus/taxi/Telecom datasets, which shows a great potential of bus-based edge servers as they cover a great portion of geographic area and demand points. Next, we build a mathematical model and design a simple greedy heuristic algorithm to select a limited number of buses that maximizes the coverage of demand points, i.e., with a limited purchase budget. We perform trace-driven simulations to verify the performance of the proposed bus selection algorithm. The results show that our approach effectively handles the dynamic user demand under realistic constraints such as server capacity and purchase quantity. Thus, we claim: bus-mounted edge servers for vehicular networks in urban areas are feasible, beneficial, and valuable.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Model Gateway: Model Management Platform for Model-Driven Drug Discovery](https://arxiv.org/abs/2512.05462)
*Yan-Shiun Wu,Nathan A. Morin*

Main category: cs.SE

TL;DR: Model Gateway 是一个用于药物发现流程中管理机器学习和科学计算模型的平台，支持LLM智能体与生成式AI工具，实现高效、零失败率的大规模模型调用与管理。


<details>
  <summary>Details</summary>
Motivation: 加速药物研发流程，通过整合LLM智能体与生成式AI提升MLOps基础设施能力。

Method: 构建包含控制面板、管理工具与API服务的平台，支持动态共识模型、异步执行、结果追踪等功能。

Result: 在超过1万并发客户端调用模型时实现0%失败率。

Conclusion: Model Gateway 是推动模型驱动型药物发现的关键组件，具备显著加速新药开发的潜力。

Abstract: This paper presents the Model Gateway, a management platform for managing machine learning (ML) and scientific computational models in the drug discovery pipeline. The platform supports Large Language Model (LLM) Agents and Generative AI-based tools to perform ML model management tasks in our Machine Learning operations (MLOps) pipelines, such as the dynamic consensus model, a model that aggregates several scientific computational models, registration and management, retrieving model information, asynchronous submission/execution of models, and receiving results once the model complete executions. The platform includes a Model Owner Control Panel, Platform Admin Tools, and Model Gateway API service for interacting with the platform and tracking model execution. The platform achieves a 0% failure rate when testing scaling beyond 10k simultaneous application clients consume models. The Model Gateway is a fundamental part of our model-driven drug discovery pipeline. It has the potential to significantly accelerate the development of new drugs with the maturity of our MLOps infrastructure and the integration of LLM Agents and Generative AI tools.

</details>


### [4] [Metronome: Differentiated Delay Scheduling for Serverless Functions](https://arxiv.org/abs/2512.05703)
*Zhuangbin Chen,Juzheng Zheng,Zibin Zheng*

Main category: cs.SE

TL;DR: Metronome 是一种针对无服务器环境的差异化延迟调度框架，通过预测机制优化函数执行位置，显著降低平均执行时间并保障 SLA。


<details>
  <summary>Details</summary>
Motivation: 无服务器函数的动态性和事件驱动特性使调度优化困难，传统基于规则的延迟调度在异构执行时间和复杂局部性模式下效果不佳。

Method: 提出 Metronome 框架，利用在线随机森林回归模型预测函数在不同节点的执行时间，实现局部性感知的智能延迟决策。

Result: 在 OpenLambda 上实现，相比基线方法，平均执行时间减少 64.88%-95.83%，高并发下仍保持性能优势且满足 SLA。

Conclusion: Metronome 有效应对无服务器环境中的调度挑战，为数据与基础设施局部性提供自适应解决方案，提升整体执行效率。

Abstract: Function-as-a-Service (FaaS) computing is an emerging cloud computing paradigm for its ease-of-management and elasticity. However, optimizing scheduling for serverless functions remains challenging due to their dynamic and event-driven nature. While data locality has been proven effective in traditional cluster computing systems through delay scheduling, its application in serverless platforms remains largely unexplored. In this paper, we systematically evaluate existing delay scheduling methods in serverless environments and identify three key observations: 1) delay scheduling benefits vary significantly based on function input characteristics; 2) serverless computing exhibits more complex locality patterns than cluster computing systems, encompassing both data locality and infrastructure locality; and 3) heterogeneous function execution times make rule-based delay thresholds ineffective. Based on these insights, we propose Metronome, a differentiated delay scheduling framework that employs predictive mechanisms to identify optimal locality-aware nodes for individual functions. Metronome leverages an online Random Forest Regression model to forecast function execution times across various nodes, enabling informed delay decisions while preventing SLA violations. Our implementation on OpenLambda shows that Metronome significantly outperforms baselines, achieving 64.88%-95.83% reduction in mean execution time for functions, while maintaining performance advantages under increased concurrency levels and ensuring SLA compliance.

</details>


### [5] [Stellis: A Strategy Language for Purifying Separation Logic Entailments](https://arxiv.org/abs/2512.05159)
*Zhiyi Wang,Xiwei Wu,Yi Fang,Chengtao Li,Hongyi Zhong,Lihan Xie,Qinxiang Cao,Zhenjiang Hu*

Main category: cs.SE

TL;DR: Stellis是一种用于简化分离逻辑蕴含的策略语言，通过灵活匹配和动作描述实现高效自动化，并在基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 规则方法在自动化分离逻辑蕴含证明时缺乏对策略的充分描述能力，难以处理内存布局对齐与消除等复杂场景。

Method: 提出Stellis策略语言，结合强大的匹配机制与灵活动作描述，支持广泛策略编码；设计算法生成策略的正确性条件，并基于机械化定理实现自动化证明。

Result: 在229个基准测试用例中，使用5个库和98种策略，系统自动净化了95.6%（219/229）的蕴含关系。

Conclusion: Stellis在保持灵活性与易用性的同时，显著提升了分离逻辑蕴含自动化的效率与实用性。

Abstract: Automatically proving separation logic entailments is a fundamental challenge in verification. While rule-based methods rely on separation logic rules (lemmas) for automation, these rule statements are insufficient for describing automation strategies, which usually involve the alignment and elimination of corresponding memory layouts in specific scenarios. To overcome this limitation, we propose Stellis, a strategy language for purifying separation logic entailments, i.e., removing all spatial formulas to reduce the entailment to a simpler pure entailment. Stellis features a powerful matching mechanism and a flexible action description, enabling the straightforward encoding of a wide range of strategies. To ensure strategy soundness, we introduce an algorithm that generates a soundness condition for each strategy, thereby reducing the soundness of each strategy to the correctness of its soundness condition. Furthermore, based on a mechanized reduction soundness theorem, our prototype implementation generates correctness proofs for the overall automation. We evaluate our system on a benchmark of 229 entailments collected from verification of standard linked data structures and the memory module of a microkernel, and the evaluation results demonstrate that, with such flexibility and convenience provided, our system is also highly effective, which automatically purifies 95.6% (219 out of 229) of the entailments using 5 libraries with 98 strategies.

</details>


### [6] [Towards A Cultural Intelligence and Values Inferences Quality Benchmark for Community Values and Common Knowledge](https://arxiv.org/abs/2512.05176)
*Brittany Johnson,Erin Reddick,Angela D. R. Smith*

Main category: cs.SE

TL;DR: 本文提出CIVIQ基准，旨在通过复制KorNAT方法，提升LLM对美国多元文化社区价值观的对齐能力。


<details>
  <summary>Details</summary>
Motivation: 当前通用LLM偏向西方主流叙事，难以满足多元文化协作创新需求，亟需支持文化对齐的评估工具。

Method: 复制韩国KorNAT基准构建流程，在美国语境下开发聚焦社区价值观与常识对齐的CIVIQ基准。

Result: 成功构建CIVIQ基准，为AI技术文化对齐研究与实践奠定基础。

Conclusion: CIVIQ填补了美国多元文化背景下LLM文化对齐评估工具的空白，推动更具包容性的AI发展。

Abstract: Large language models (LLMs) have emerged as a powerful technology, and thus, we have seen widespread adoption and use on software engineering teams. Most often, LLMs are designed as "general purpose" technologies meant to represent the general population. Unfortunately, this often means alignment with predominantly Western Caucasian narratives and misalignment with other cultures and populations that engage in collaborative innovation. In response to this misalignment, there have been recent efforts centered on the development of "culturally-informed" LLMs, such as ChatBlackGPT, that are capable of better aligning with historically marginalized experiences and perspectives. Despite this progress, there has been little effort aimed at supporting our ability to develop and evaluate culturally-informed LLMs. A recent effort proposed an approach for developing a national alignment benchmark that emphasizes alignment with national social values and common knowledge. However, given the range of cultural identities present in the United States (U.S.), a national alignment benchmark is an ineffective goal for broader representation. To help fill this gap in this US context, we propose a replication study that translates the process used to develop KorNAT, a Korean National LLM alignment benchmark, to develop CIVIQ, a Cultural Intelligence and Values Inference Quality benchmark centered on alignment with community social values and common knowledge. Our work provides a critical foundation for research and development aimed at cultural alignment of AI technologies in practice.

</details>


### [7] [A Survey of Bugs in AI-Generated Code](https://arxiv.org/abs/2512.05239)
*Ruofan Gao,Amjed Tahir,Peng Liang,Teo Susnjak,Foutse Khomh*

Main category: cs.SE

TL;DR: 本文系统分析AI生成代码中的缺陷与错误，提供分类、分布及修复策略，为未来模型改进和质量评估提供参考。


<details>
  <summary>Details</summary>
Motivation: AI生成代码广泛使用但存在质量问题，目前缺乏系统性总结，亟需全面梳理错误类型、分布及修复方法。

Method: 系统综述现有文献，对AI生成代码中的缺陷进行分类、模式识别，并分析不同模型间的相关性及修复策略。

Result: 明确了AI生成代码中缺陷的性质、类型分布及其与模型的相关性，并总结了可行的修复与缓解策略。

Conclusion: 本研究为提升AI代码生成模型质量及建立评估体系提供了理论基础和实践指导。

Abstract: Developers are widely using AI code-generation models, aiming to increase productivity and efficiency. However, there are also quality concerns regarding the AI-generated code. The generated code is produced by models trained on publicly available code, which are known to contain bugs and quality issues. Those issues can cause trust and maintenance challenges during the development process. Several quality issues associated with AI-generated code have been reported, including bugs and defects. However, these findings are often scattered and lack a systematic summary. A comprehensive review is currently lacking to reveal the types and distribution of these errors, possible remediation strategies, as well as their correlation with the specific models. In this paper, we systematically analyze the existing AI-generated code literature to establish an overall understanding of bugs and defects in generated code, providing a reference for future model improvement and quality assessment. We aim to understand the nature and extent of bugs in AI-generated code, and provide a classification of bug types and patterns present in code generated by different models. We also discuss possible fixes and mitigation strategies adopted to eliminate bugs from the generated code.

</details>


### [8] [Learning to Code with Context: A Study-Based Approach](https://arxiv.org/abs/2512.05242)
*Uwe M. Borghoff,Mark Minas,Jannis Schopp*

Main category: cs.SE

TL;DR: 本文探讨了在软件工程教育中整合生成式AI工具的方法，通过学生开发游戏的项目研究AI在不同开发阶段的应用效果与挑战，并分析了一个基于RAG的本地部署LLM助手如何提供上下文感知支持。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI工具的兴起，软件工程教育需适应变化，帮助学生掌握传统开发方法的同时学会负责任地使用AI技术。

Method: 通过大学编程项目中的用户研究，观察学生在游戏开发中使用生成式AI的情况，并构建基于RAG的本地LLM助手进行上下文支持与行为分析。

Result: 研究识别了AI工具最有效的任务类型、学生遇到的挑战，并展示了上下文感知AI助手在教育项目中的潜力与局限。

Conclusion: 上下文感知的AI支持能深化软件工程教育中AI工具的整合，为未来课程设计提供实践依据。

Abstract: The rapid emergence of generative AI tools is transforming the way software is developed. Consequently, software engineering education must adapt to ensure that students not only learn traditional development methods but also understand how to meaningfully and responsibly use these new technologies. In particular, project-based courses offer an effective environment to explore and evaluate the integration of AI assistance into real-world development practices. This paper presents our approach and a user study conducted within a university programming project in which students collaboratively developed computer games. The study investigates how participants used generative AI tools throughout different phases of the software development process, identifies the types of tasks where such tools were most effective, and analyzes the challenges students encountered. Building on these insights, we further examine a repository-aware, locally deployed large language model (LLM) assistant designed to provide project-contextualized support. The system employs Retrieval-Augmented Generation (RAG) to ground responses in relevant documentation and source code, enabling qualitative analysis of model behavior, parameter sensitivity, and common failure modes. The findings deepen our understanding of context-aware AI support in educational software projects and inform future integration of AI-based assistance into software engineering curricula.

</details>


### [9] [Engagement in Code Review: Emotional, Behavioral, and Cognitive Dimensions in Peer vs. LLM Interactions](https://arxiv.org/abs/2512.05309)
*Adam Alami,Nathan Cassee,Thiago Rocha Silva,Elda Paja,Neil A. Ernst*

Main category: cs.SE

TL;DR: 该研究通过两阶段定性分析，探讨了软件工程师在LLM辅助代码审查与人工同行审查中的情感调节、行为参与及反馈采纳差异。


<details>
  <summary>Details</summary>
Motivation: 理解LLM如何影响代码审查这一社会技术实践中的情感与认知过程，优化人机协作模式。

Method: 对20名软件工程师进行两阶段访谈与观察，第一阶段聚焦人工审查的情感反应，第二阶段引入LLM并探测其反馈特性对行为的影响。

Result: 发现LLM辅助审查降低情感成本与自我调节需求，当反馈符合认知预期时更易被采纳；参与重心从情绪管理转向认知负荷管理。

Conclusion: AI应作为支持性伙伴，减轻认知与情感负担，同时保留人类问责制与同行评审的社会意义。

Abstract: Code review is a socio-technical practice, yet how software engineers engage in Large Language Model (LLM)-assisted code reviews compared to human peer-led reviews is less understood. We report a two-phase qualitative study with 20 software engineers to understand this. In Phase I, participants exchanged peer reviews and were interviewed about their affective responses and engagement decisions. In Phase II, we introduced a new prompt matching engineers' preferences and probed how characteristics shaped their reactions. We develop an integrative account linking emotional self-regulation to behavioral engagement and resolution. We identify self-regulation strategies that engineers use to regulate their emotions in response to negative feedback: reframing, dialogic regulation, avoidance, and defensiveness. Engagement proceeds through social calibration; engineers align their responses and behaviors to the relational climate and team norms. Trajectories to resolution, in the case of peer-led review, vary by locus (solo/dyad/team) and an internal sense-making process. With the LLM-assisted review, emotional costs and the need for self-regulation seem lower. When LLM feedback aligned with engineers' cognitive expectations, participants reported reduced processing effort and a potentially higher tendency to adopt. We show that LLM-assisted review redirects engagement from emotion management to cognitive load management. We contribute an integrative model of engagement that links emotional self-regulation to behavioral engagement and resolution, showing how affective and cognitive processes influence feedback adoption in peer-led and LLM-assisted code reviews. We conclude that AI is best positioned as a supportive partner to reduce cognitive and emotional load while preserving human accountability and the social meaning of peer review and similar socio-technical activities.

</details>


### [10] [WhatsCode: Large-Scale GenAI Deployment for Developer Efficiency at WhatsApp](https://arxiv.org/abs/2512.05314)
*Ke Mao,Timotej Kapus,Cons T Åhs,Matteo Marescotti,Daniel Ip,Ákos Hajdu,Sopot Cela,Aparup Banerjee*

Main category: cs.SE

TL;DR: WhatsCode系统在WhatsApp大规模工业环境中成功部署，通过人机协作模式显著提升隐私验证覆盖率与代码自动化处理效率，证明组织因素与技术能力同等重要。


<details>
  <summary>Details</summary>
Motivation: 填补AI辅助开发工具在合规性要求高的大型工业环境中的学术研究空白，探索其实际部署效果与影响因素。

Method: 部署并迭代WhatsCode这一领域专用AI开发系统，集成到WhatsApp的端到端功能开发与DevOps流程中，分析25个月内的量化指标与协作模式。

Result: 隐私验证覆盖率提升3.5倍至53%，生成超3000项被接受的代码变更，bug分诊精度达86%，识别出两类稳定人机协作模式：一键部署（60%）与指挥修订（40%）。

Conclusion: 在合规敏感的大规模企业环境中，有效的人机协作而非完全自动化，才是驱动可持续业务影响的关键；组织因素如所有权模型和风险管理与技术能力同等决定AI部署成败。

Abstract: The deployment of AI-assisted development tools in compliance-relevant, large-scale industrial environments represents significant gaps in academic literature, despite growing industry adoption. We report on the industrial deployment of WhatsCode, a domain-specific AI development system that supports WhatsApp (serving over 2 billion users) and processes millions of lines of code across multiple platforms. Over 25 months (2023-2025), WhatsCode evolved from targeted privacy automation to autonomous agentic workflows integrated with end-to-end feature development and DevOps processes.
  WhatsCode achieved substantial quantifiable impact, improving automated privacy verification coverage 3.5x from 15% to 53%, identifying privacy requirements, and generating over 3,000 accepted code changes with acceptance rates ranging from 9% to 100% across different automation domains. The system committed 692 automated refactor/fix changes, 711 framework adoptions, 141 feature development assists and maintained 86% precision in bug triage. Our study identifies two stable human-AI collaboration patterns that emerged from production deployment: one-click rollout for high-confidence changes (60% of cases) and commandeer-revise for complex decisions (40%). We demonstrate that organizational factors, such as ownership models, adoption dynamics, and risk management, are as decisive as technical capabilities for enterprise-scale AI success. The findings provide evidence-based guidance for large-scale AI tool deployment in compliance-relevant environments, showing that effective human-AI collaboration, not full automation, drives sustainable business impact.

</details>


### [11] [Invisible Load: Uncovering the Challenges of Neurodivergent Women in Software Engineering](https://arxiv.org/abs/2512.05350)
*Munazza Zaib,Wei Wang,Dulaji Hidellaarachchi,Isma Farah Siddiqui*

Main category: cs.SE

TL;DR: 本文提出一种结合InclusiveMag与GenderMag的混合方法，旨在系统研究软件工程领域中神经多样性女性所面临的独特挑战，并推动包容性实践。


<details>
  <summary>Details</summary>
Motivation: 神经多样性女性在软件工程中面临性别偏见与神经差异交织的障碍，现有研究缺乏对此群体的系统关注。

Method: 采用三阶段混合方法：文献综述梳理挑战、构建人物画像与分析流程、通过协作工作坊应用方法。

Result: 初步文献综述归纳出认知、社交、组织、结构与职业发展五大类挑战，为后续开发包容性分析工具奠定基础。

Conclusion: 该研究为支持神经多样性女性在软件工程中的包容性变革提供理论与方法基础。

Abstract: Neurodivergent women in Software Engineering (SE) encounter distinctive challenges at the intersection of gender bias and neurological differences. To the best of our knowledge, no prior work in SE research has systematically examined this group, despite increasing recognition of neurodiversity in the workplace. Underdiagnosis, masking, and male-centric workplace cultures continue to exacerbate barriers that contribute to stress, burnout, and attrition. In response, we propose a hybrid methodological approach that integrates InclusiveMag's inclusivity framework with the GenderMag walkthrough process, tailored to the context of neurodivergent women in SE. The overarching design unfolds across three stages, scoping through literature review, deriving personas and analytic processes, and applying the method in collaborative workshops. We present a targeted literature review that synthesize challenges into cognitive, social, organizational, structural and career progression challenges neurodivergent women face in SE, including how under/late diagnosis and masking intensify exclusion. These findings lay the groundwork for subsequent stages that will develop and apply inclusive analytic methods to support actionable change.

</details>


### [12] [Legacy Modernization with AI -- Mainframe modernization](https://arxiv.org/abs/2512.05375)
*Sunil Khemka,Arunava Majumdar*

Main category: cs.SE

TL;DR: AI助力传统主机系统现代化，实现灵活、可扩展的智能架构转型。


<details>
  <summary>Details</summary>
Motivation: 传统主机系统维护成本高、技能短缺且难以与云系统集成，亟需现代化改造。

Method: 采用AI驱动策略，如自动化代码重构、智能数据迁移和预测性维护，结合机器学习分析代码、优化效率并自动化测试部署。

Result: 企业成功迁移到微服务、容器化和混合云平台，提升运营效率、减少停机时间并增强系统韧性。

Conclusion: AI是推动主机现代化和企业可持续数字化转型的关键催化剂。

Abstract: Artificial Intelligence-assisted legacy modernization is essential in changing the stalwart mainframe systems of the past into flexible, scalable, and smart architecture. While mainframes are generally dependable, they can be difficult to maintain due to their high maintenance costs, the shortage of skills, and the problems in integrating them with cloud-based systems. By adopting AI-driven modernization strategies such as automated code refactoring, migration of data using smart tools, and predictive maintenance, companies can easily move to microservices, containerized environments, and hybrid cloud platforms. Machine learning models have the capability to go through legacy codebases, figure out efficiency opportunities, and carry out automated testing and deployment. Besides that, AI improves the organization's operational efficiency by generating the insights that can be used to level the workload and detect the anomalies. The coupling of the two is not only about saving the core business logic but also about enabling quicker innovation, less downtime, and enhanced system resilience. Therefore, the use of AI in mainframe modernization is a catalyst for digital transformation and enterprise growth that is sustainable over time.

</details>


### [13] [Fuzzing the brain: Automated stress testing for the safety of ML-driven neurostimulation](https://arxiv.org/abs/2512.05383)
*Mara Downing,Matthew Peng,Jacob Granley,Michael Beyeler,Tevfik Bultan*

Main category: cs.SE

TL;DR: 本文提出一种基于模糊测试的系统方法，用于检测机器学习驱动神经刺激系统中的不安全刺激模式。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在神经假体中广泛应用，但其输出直接作用于神经组织时可能带来新的安全风险，亟需系统性评估方法。

Method: 采用覆盖引导的模糊测试技术，通过扰动输入并跟踪输出是否违反电生理安全限制，结合覆盖率指标评估模型安全性。

Result: 该方法成功识别视网膜与皮层刺激编码器中多种超出安全限值的刺激模式，并支持跨架构和训练策略的可解释比较。

Conclusion: 将安全性从训练启发式转化为可测量属性，为下一代神经接口提供实证基准、监管准备与伦理保障基础。

Abstract: Objective: Machine learning (ML) models are increasingly used to generate electrical stimulation patterns in neuroprosthetic devices such as visual prostheses. While these models promise precise and personalized control, they also introduce new safety risks when model outputs are delivered directly to neural tissue. We propose a systematic, quantitative approach to detect and characterize unsafe stimulation patterns in ML-driven neurostimulation systems. Approach: We adapt an automated software testing technique known as coverage-guided fuzzing to the domain of neural stimulation. Here, fuzzing performs stress testing by perturbing model inputs and tracking whether resulting stimulation violates biophysical limits on charge density, instantaneous current, or electrode co-activation. The framework treats encoders as black boxes and steers exploration with coverage metrics that quantify how broadly test cases span the space of possible outputs and violation types. Main results: Applied to deep stimulus encoders for the retina and cortex, the method systematically reveals diverse stimulation regimes that exceed established safety limits. Two violation-output coverage metrics identify the highest number and diversity of unsafe outputs, enabling interpretable comparisons across architectures and training strategies. Significance: Violation-focused fuzzing reframes safety assessment as an empirical, reproducible process. By transforming safety from a training heuristic into a measurable property of the deployed model, it establishes a foundation for evidence-based benchmarking, regulatory readiness, and ethical assurance in next-generation neural interfaces.

</details>


### [14] [Bita: A Conversational Assistant for Fairness Testing](https://arxiv.org/abs/2512.05428)
*Keeryn Johnson,Cleyton Magalhaes,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: Bita是一个对话式助手，帮助软件测试人员检测AI系统中的偏见并生成公平性测试方案。


<details>
  <summary>Details</summary>
Motivation: 现有公平性测试工具难以使用且缺乏对实际工作流的支持。

Method: 结合大语言模型与检索增强生成技术，基于精选的公平性文献提供响应。

Result: 验证表明Bita能有效支持真实AI系统的公平性测试任务。

Conclusion: Bita为工业实践提供了易用、系统且实用的公平性测试工具。

Abstract: Bias in AI systems can lead to unfair and discriminatory outcomes, especially when left untested before deployment. Although fairness testing aims to identify and mitigate such bias, existing tools are often difficult to use, requiring advanced expertise and offering limited support for real-world workflows. To address this, we introduce Bita, a conversational assistant designed to help software testers detect potential sources of bias, evaluate test plans through a fairness lens, and generate fairness-oriented exploratory testing charters. Bita integrates a large language model with retrieval-augmented generation, grounding its responses in curated fairness literature. Our validation demonstrates how Bita supports fairness testing tasks on real-world AI systems, providing structured, reproducible evidence of its utility. In summary, our work contributes a practical tool that operationalizes fairness testing in a way that is accessible, systematic, and directly applicable to industrial practice.

</details>


### [15] [Everything is Context: Agentic File System Abstraction for Context Engineering](https://arxiv.org/abs/2512.05470)
*Xiwei Xu,Robert Mao,Quan Bai,Xuewu Gu,Yechao Li,Liming Zhu*

Main category: cs.SE

TL;DR: 本文提出了一种基于文件系统抽象的上下文工程架构，以支持可验证、可维护且适用于工业场景的生成式AI系统。


<details>
  <summary>Details</summary>
Motivation: 现有上下文工程技术碎片化，缺乏可追溯性和问责机制，亟需统一架构支持可信推理。

Method: 借鉴Unix‘一切皆文件’理念，构建持久化、可治理的上下文管理框架AIGNE，包含构造器、加载器与评估器三阶段流水线。

Result: 通过带记忆体的智能体和GitHub助手两个实例，验证了架构在开发者与工业环境中的可行性与实用性。

Conclusion: 该架构为人机协同的生成式AI系统提供了可复用、以人类为中心的可信基础。

Abstract: Generative AI (GenAI) has reshaped software system design by introducing foundation models as pre-trained subsystems that redefine architectures and operations. The emerging challenge is no longer model fine-tuning but context engineering-how systems capture, structure, and govern external knowledge, memory, tools, and human input to enable trustworthy reasoning. Existing practices such as prompt engineering, retrieval-augmented generation (RAG), and tool integration remain fragmented, producing transient artefacts that limit traceability and accountability. This paper proposes a file-system abstraction for context engineering, inspired by the Unix notion that 'everything is a file'. The abstraction offers a persistent, governed infrastructure for managing heterogeneous context artefacts through uniform mounting, metadata, and access control. Implemented within the open-source AIGNE framework, the architecture realises a verifiable context-engineering pipeline, comprising the Context Constructor, Loader, and Evaluator, that assembles, delivers, and validates context under token constraints. As GenAI becomes an active collaborator in decision support, humans play a central role as curators, verifiers, and co-reasoners. The proposed architecture establishes a reusable foundation for accountable and human-centred AI co-work, demonstrated through two exemplars: an agent with memory and an MCP-based GitHub assistant. The implementation within the AIGNE framework demonstrates how the architecture can be operationalised in developer and industrial settings, supporting verifiable, maintainable, and industry-ready GenAI systems.

</details>


### [16] [A Hybrid Approach for EMF Code Generation:Code Templates Meet Large Language Models](https://arxiv.org/abs/2512.05498)
*Xiao He,Ru Chen,Zeqing Zhang,Yanling Wang,Qiuyan Dong*

Main category: cs.SE

TL;DR: iEcoreGen结合EMF模板生成与LLM补全能力，提升代码生成正确率与灵活性。


<details>
  <summary>Details</summary>
Motivation: 解决纯模板方法僵化与纯LLM方法易出错的问题，探索模型驱动开发与大语言模型协同的潜力。

Method: 分解需求生成操作规范，用EMF模板生成初始Java代码并序列化为文档字符串，再由LLM补全未实现方法。

Result: 在20个任务中优于纯LLM基线（pass@k），编译成功率相当；消融实验验证各组件贡献。

Conclusion: LLM增强的模型驱动开发是实现高效软件自动化的可行方向。

Abstract: Template-based and LLM-based code generation are both key enablers of automated software development. The former provides correctness guarantees but are rigid for complex requirements, whereas LLMs offer high flexibility at the risk of producing faulty code.This paper proposes iEcoreGen, a hybrid approach that integrates Eclipse Modeling Framework (EMF) and LLMs. In EMF, an Ecore model defines a system structure and acts as a blueprint for code-generation.iEcoreGen decomposes requirements to derive operation specifications, uses EMF's template-based generator to produce initial Java code, and serializes specifications into docstrings. LLMs are then invoked to complete and fix unimplemented methods. We assessed iEcoreGen on twenty code-generation tasks across five LLMs. It surpasses LLM-only baselines on pass@k and performs on par with them on compilation@k. An ablation study clarified the contribution of each component of iEcoreGen. Overall, the findings indicate that LLM-enhanced model-driven development is a promising path toward more efficient software automation.

</details>


### [17] [Generative AI in Simulation-Based Test Environments for Large-Scale Cyber-Physical Systems: An Industrial Study](https://arxiv.org/abs/2512.05507)
*Masoud Sadrnezhaad,José Antonio Hernández López,Torvald Mårtensson,Daniel Varro*

Main category: cs.SE

TL;DR: 本文探讨生成式AI在大规模信息物理系统仿真测试中的应用潜力与挑战，提出未来研究方向以促进产学研合作。


<details>
  <summary>Details</summary>
Motivation: 当前大规模信息物理系统的仿真测试依赖复杂模型与资源，而生成式AI虽在软件测试中展现潜力，但在该领域尚未充分探索。

Method: 通过跨公司研讨会收集六家机构工程师的实践经验，归纳挑战并制定研究议程。

Result: 识别出三大高优先级研究方向：AI生成场景与环境模型、CI/CD管道中的仿真器与AI集成、生成式AI的可信度问题。

Conclusion: 生成式AI具显著潜力，但需解决现存挑战，方能负责任地应用于仿真测试，推动产学研协作发展。

Abstract: Quality assurance for large-scale cyber-physical systems relies on sophisticated test activities using complex test environments investigated with the help of numerous types of simulators. As these systems grow, extensive resources are required to develop and maintain simulation models of hardware and software components, as well as physical environments. Meanwhile, recent advances in generative AI have led to tools that can produce executable test cases for software systems, offering potential benefits such as reducing manual efforts or increasing test coverage. However, the application of generative AI techniques to simulation-based testing of large-scale cyber-physical systems remains underexplored. To better understand this gap, this study captures practitioners' perspectives on leveraging generative AI, based on a cross-company workshop with six organizations. Our contribution is twofold: (1) detailed, experience-based insights into challenges faced by engineers, and (2) a research agenda comprising three high-priority directions: (a) AI-generated scenarios and environment models, (b) simulators and AI in CI/CD pipelines, and (c) trustworthiness in generative AI for simulation. While participants acknowledged substantial potential, they also highlighted unresolved challenges. By detailing these issues, the paper aims to guide future academia-industry collaboration towards the responsible adoption of generative AI in simulation-based testing.

</details>


### [18] [From Challenge to Change: Design Principles for AI Transformations](https://arxiv.org/abs/2512.05533)
*Theocharis Tavantzis,Stefano Lambiase,Daniel Russo,Robert Feldt*

Main category: cs.SE

TL;DR: 本文提出一个以行为软件工程为基础的人本框架，帮助软件工程组织在早期AI采用阶段应对挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注AI的技术层面，缺乏对团队适应与信任等人类中心问题的深入探讨。

Method: 通过文献综述、访谈主题分析构建框架，并结合问卷调查（N=105）与专家研讨会（N=4）进行验证。

Result: 框架包含九个维度，调查发现‘技能提升’与‘AI战略设计’最受重视，但人本保障措施仍较薄弱。

Conclusion: 该框架为AI早期采用提供实用路线图，并指明未来人本AI在软件工程中的研究方向。

Abstract: The rapid rise of Artificial Intelligence (AI) is reshaping Software Engineering (SE), creating new opportunities while introducing human-centered challenges. Although prior work notes behavioral and other non-technical factors in AI integration, most studies still emphasize technical concerns and offer limited insight into how teams adapt to and trust AI. This paper proposes a Behavioral Software Engineering (BSE)-informed, human-centric framework to support SE organizations during early AI adoption. Using a mixed-methods approach, we built and refined the framework through a literature review of organizational change models and thematic analysis of interview data, producing concrete, actionable steps. The framework comprises nine dimensions: AI Strategy Design, AI Strategy Evaluation, Collaboration, Communication, Governance and Ethics, Leadership, Organizational Culture, Organizational Dynamics, and Up-skilling, each supported by design principles and actions. To gather preliminary practitioner input, we conducted a survey (N=105) and two expert workshops (N=4). Survey results show that Up-skilling (15.2%) and AI Strategy Design (15.1%) received the highest $100-method allocations, underscoring their perceived importance in early AI initiatives. Findings indicate that organizations currently prioritize procedural elements such as strategy design, while human-centered guardrails remain less developed. Workshop feedback reinforced these patterns and emphasized the need to ground the framework in real-world practice. By identifying key behavioral dimensions and offering actionable guidance, this work provides a pragmatic roadmap for navigating the socio-technical complexity of early AI adoption and highlights future research directions for human-centric AI in SE.

</details>


### [19] [Automated Code Review Assignments: An Alternative Perspective of Code Ownership on GitHub](https://arxiv.org/abs/2512.05551)
*Jai Lal Lulla,Raula Gaikovina Kula,Christoph Treude*

Main category: cs.SE

TL;DR: 本研究首次大规模分析GitHub的CODEOWNERS功能，发现其能提升代码审查效率与责任分配，增强开源项目的安全性与治理能力。


<details>
  <summary>Details</summary>
Motivation: 随着软件供应链攻击增加，需强化代码所有权机制以保障项目质量与安全。

Method: 分析84.4万次PR、190万条评论及200万次审查，追踪10,287名代码所有者行为，并采用RDD分析审查动态变化。

Result: CODEOWNERS用户遵守规则，协作行为类似传统所有权指标，且随时间推移提升PR流程效率；采用该机制后，审查责任从核心开发者分散。

Conclusion: CODEOWNERS是提升软件治理与韧性的有效但未被充分利用的工具，建议项目采纳以优化安全、问责与工作流效率。

Abstract: Code ownership is central to ensuring accountability and maintaining quality in large-scale software development. Yet, as external threats such as software supply chain attacks on project health and quality assurance increase, mechanisms for assigning and enforcing responsibility have become increasingly critical. In 2017, GitHub introduced the CODEOWNERS feature, which automatically designates reviewers for specific files to strengthen accountability and protect critical parts of the codebase. Despite its potential, little is known about how CODEOWNERS is actually adopted and practiced. We present the first large-scale empirical study of CODEOWNERS usage across over 844,000 pull requests with 1.9 million comments and over 2 million reviews. We identify 10,287 code owners to track their review activities. Results indicate that codeowners tend to adhere the rules specified in the CODEOWNERS file, exhibit similar collaborative behaviours to traditional metrics of ownership, but tend to contribute to a smoother and faster PR workflow over time. Finally, using regression discontinuity design (RDD) analysis, we find that repositories adopting CODEOWNERS experience shifts in review dynamics, as ownership redistributes review responsibilities away from core developers. Our results position CODEOWNERS as a promising yet underutilized mechanism for improving software governance and resilience. We discuss how projects can leverage this alternative ownership method as a perspective to enhance security, accountability, and workflow efficiency in open-source development.

</details>


### [20] [Executing Discrete/Continuous Declarative Process Specifications via Complex Event Processing](https://arxiv.org/abs/2512.05653)
*Stefan Schönig,Leo Poss,Fabrizio Maria Maggi*

Main category: cs.SE

TL;DR: 本文提出一种基于复杂事件处理的三层架构，用于实时执行和强制实施混合声明性模型，从而弥合规范与操作控制之间的差距。


<details>
  <summary>Details</summary>
Motivation: 传统BPM无法整合物理信息环境中的连续传感器数据，现有方法仅限于监控和事后合规检查。

Method: 引入基于CEP的执行架构，将STL启发的谓词集成到执行流程中，实现实时触发活动并依据传感器行为强制执行流程边界。

Result: 该架构成功支持混合声明性模型的实时执行与动态控制。

Conclusion: 本研究填补了混合声明性规范与实际运行控制之间的空白，为智能流程管理提供新方向。

Abstract: Traditional Business Process Management (BPM) focuses on discrete events and fails to incorporate critical continuous sensor data in cyber-physical environments. Hybrid declarative specifications, utilizing Signal Temporal Logic (STL), address this limitation by allowing constraints over both discrete events and real-valued signals. However, existing work has been limited to monitoring and post-hoc conformance checking. This paper introduces a novel Complex Event Processing (CEP)-based execution architecture that enables the real-time execution and enforcement of hybrid declarative models. Our three-layer approach integrates STL-inspired predicates into the execution flow, allowing the system to actively trigger activities and enforce process boundaries based on continuous sensor behavior. This approach bridges the gap between hybrid specification and operational control.

</details>


### [21] [MicroRacer: Detecting Concurrency Bugs for Cloud Service Systems](https://arxiv.org/abs/2512.05716)
*Zhiling Deng,Juepeng Wang,Zhuangbin Chen*

Main category: cs.SE

TL;DR: MicroRacer 是一种非侵入式自动化框架，用于检测微服务环境中的并发错误，通过动态插桩收集运行时数据并分析操作间的先后关系与资源访问模式。


<details>
  <summary>Details</summary>
Motivation: 现有并发错误检测方法因侵入性强且难以应对微服务架构复杂性而效果有限，亟需更优解决方案。

Method: 动态插桩常用库以收集运行时轨迹数据，分析操作的 happened-before 关系与资源访问模式，并通过三阶段验证流程确认并发错误。

Result: 在开源微服务基准测试中，MicroRacer 能高效准确地检测并定位复现的工业级并发错误。

Conclusion: MicroRacer 为微服务系统提供了一种实用、非侵入且高效的并发错误检测方案，显著提升云服务可靠性。

Abstract: Modern cloud applications delivering global services are often built on distributed systems with a microservice architecture. In such systems, end-to-end user requests traverse multiple different services and machines, exhibiting intricate interactions. Consequently, cloud service systems are vulnerable to concurrency bugs, which pose significant challenges to their reliability. Existing methods for concurrency bug detection often fall short due to their intrusive nature and inability to handle the architectural complexities of microservices. To address these limitations, we propose MicroRacer, a non-intrusive and automated framework for detecting concurrency bugs in such environments. By dynamically instrumenting widely-used libraries at runtime, MicroRacer collects detailed trace data without modifying the application code. Such data are utilized to analyze the happened-before relationship and resource access patterns of common operations within service systems. Based on this information, MicroRacer identifies suspicious concurrent operations and employs a three-stage validation process to test and confirm concurrency bugs. Experiments on open-source microservice benchmarks with replicated industrial bugs demonstrate MicroRacer's effectiveness and efficiency in accurately detecting and pinpointing concurrency issues.

</details>


### [22] [Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models](https://arxiv.org/abs/2512.05887)
*Sairam Vaidya,Marcel Böhme,Loris D'Antoni*

Main category: cs.SE

TL;DR: Germinator 是一种针对可扩展编译器的方言无关且高效的模糊测试工具，结合语法与大语言模型自动生成多样化种子输入，显著提升覆盖率并发现大量未知漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有测试方法难以兼顾方言无关性与针对性，导致可扩展编译器生态中低资源方言缺乏有效自动化测试手段。

Method: 从方言规范自动提取语法约束，结合预训练大语言模型生成覆盖全面的初始种子，再驱动覆盖率引导的模糊测试。

Result: 在6个MLIR项目、91种方言上评估，Germinator使行覆盖率提升10-120%，发现88个新漏洞（40个已确认），其中23个来自此前无自动化测试的方言。

Conclusion: 该方法实现了对异构方言生态高效、可控、无需人工干预的大规模自动化测试，填补了低资源方言的测试空白。

Abstract: Modern extensible compiler frameworks-such as MLIR-enable rapid creation of domain-specific language dialects. This flexibility, however, makes correctness harder to ensure as the same extensibility that accelerates development also complicates maintaining the testing infrastructure. Extensible languages require automated test generation that is both dialect-agnostic (works across dialects without manual adaptation) and dialect-effective (targets dialect-specific features to find bugs). Existing approaches typically sacrifice one of these goals by either requiring manually constructed seed corpora for each dialect, or by failing to be effective. We present a dialect-agnostic and dialect-effective grammar-based and coverage-guided fuzzing approach for extensible compilers that combines two key insights from existing work: (i) the grammars of dialects, which already encode the structural and type constraints, can often be extracted automatically from the dialect specification; and (ii) these grammars can be used in combination with pre-trained large language models to automatically generate representative and diverse seed inputs from the full dialect space without requiring any manual input or training data. These seeds can then be used to bootstrap coverage-guided fuzzers. We built this approach into a tool, Germinator. When evaluated on six MLIR projects spanning 91 dialects, Germinator generated seeds improve line coverage by 10-120% over grammar-based baselines. We compare against grammar-based baselines because they are the only class of existing automatic seed generators that can be applied uniformly across MLIR's heterogeneous dialect ecosystem. Germinator discovers 88 previously unknown bugs (40 confirmed), including 23 in dialects with no prior automated test generators, demonstrating effective and controllable testing of low-resource dialects at scale.

</details>


### [23] [Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures](https://arxiv.org/abs/2512.05908)
*Amirkia Rafiei Oskooei,S. Selcan Yukcu,Mehmet Cevheri Bozoglan,Mehmet S. Aktas*

Main category: cs.SE

TL;DR: 通过将代码库转换为自然语言摘要并执行NL-to-NL搜索，本方法在多仓库微服务架构中实现了高效且可解释的缺陷定位。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言缺陷报告与代码之间的语义鸿沟、LLM上下文限制及需先识别正确仓库的问题。

Method: 构建文件、目录和仓库层级的上下文感知自然语言摘要，采用两阶段搜索：先路由到相关仓库，再自上而下定位缺陷。

Result: 在含46个仓库和110万行代码的DNext系统上，Pass@10达0.82，MRR达0.50，显著优于检索基线和GitHub Copilot等RAG系统。

Conclusion: 工程化自然语言表示比原始源码更适用于可扩展缺陷定位，并提供可解释路径以增强企业AI工具的可信度。

Abstract: Bug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code, LLM context limitations, and the need to first identify the correct repository. We propose reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval. Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories. Evaluated on DNext, an industrial system with 46 repositories and 1.1M lines of code, our method achieves Pass@10 of 0.82 and MRR of 0.50, significantly outperforming retrieval baselines and agentic RAG systems like GitHub Copilot and Cursor. This work demonstrates that engineered natural language representations can be more effective than raw source code for scalable bug localization, providing an interpretable repository -> directory -> file search path, which is vital for building trust in enterprise AI tools by providing essential transparency.

</details>
