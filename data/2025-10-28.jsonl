{"id": "2510.21745", "categories": ["cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.21745", "abs": "https://arxiv.org/abs/2510.21745", "authors": ["Eashan Wadhwa", "Shanker Shreejith"], "title": "Simopt-Power: Leveraging Simulation Metadata for Low-Power Design Synthesis", "comment": null, "summary": "Excessive switching activity is a primary contributor to dynamic power\ndissipation in modern FPGAs, where fine-grained configurability amplifies\nsignal toggling and associated capacitance. Conventional low-power techniques\n-- gating, clock-domain partitioning, and placement-aware netlist rewrites -\neither require intrusive design changes or offer diminishing returns as device\ndensities grow. In this work, we present Simopt-power, a simulator-driven\noptimisation framework that leverages simulation analysis to identify and\nselectively reconfigure high-toggle paths. By feeding activity profiles back\ninto a lightweight transformation pass, Simopt-power judiciously inserts\nduplicate truth table logic using Shannon Decomposition principle and relocates\ncritical nets, thereby attenuating unnecessary transitions without perturbing\nfunctional behaviour. We evaluated this framework on open-source RTLLM\nbenchmark, with Simopt-power achieves an average switching-induced power\nreduction of ~9\\% while incurring only ~9\\% additional LUT-equivalent resources\nfor arithmetic designs. These results demonstrate that coupling simulation\ninsights with targeted optimisations can yield a reduced dynamic power,\noffering a practical path toward using simulation metadata in the FPGA-CAD\nflow."}
{"id": "2510.22087", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22087", "abs": "https://arxiv.org/abs/2510.22087", "authors": ["Shvetank Prakash", "Andrew Cheng", "Arya Tschand", "Mark Mazumder", "Varun Gohil", "Jeffrey Ma", "Jason Yik", "Zishen Wan", "Jessica Quaye", "Elisavet Lydia Alvanaki", "Avinash Kumar", "Chandrashis Mazumdar", "Tuhin Khare", "Alexander Ingare", "Ikechukwu Uchendu", "Radhika Ghosal", "Abhishek Tyagi", "Chenyu Wang", "Andrea Mattia Garavagno", "Sarah Gu", "Alice Guo", "Grace Hur", "Luca Carloni", "Tushar Krishna", "Ankita Nayak", "Amir Yazdanbakhsh", "Vijay Janapa Reddi"], "title": "QuArch: A Benchmark for Evaluating LLM Reasoning in Computer Architecture", "comment": null, "summary": "The field of computer architecture, which bridges high-level software\nabstractions and low-level hardware implementations, remains absent from\ncurrent large language model (LLM) evaluations. To this end, we present QuArch\n(pronounced 'quark'), the first benchmark designed to facilitate the\ndevelopment and evaluation of LLM knowledge and reasoning capabilities\nspecifically in computer architecture. QuArch provides a comprehensive\ncollection of 2,671 expert-validated question-answer (QA) pairs covering\nvarious aspects of computer architecture, including processor design, memory\nsystems, and interconnection networks. Our evaluation reveals that while\nfrontier models possess domain-specific knowledge, they struggle with skills\nthat require higher-order thinking in computer architecture. Frontier model\naccuracies vary widely (from 34% to 72%) on these advanced questions,\nhighlighting persistent gaps in architectural reasoning across analysis,\ndesign, and implementation QAs. By holistically assessing fundamental skills,\nQuArch provides a foundation for building and measuring LLM capabilities that\ncan accelerate innovation in computing systems. With over 140 contributors from\n40 institutions, this benchmark represents a community effort to set the\nstandard for architectural reasoning in LLM evaluation."}
{"id": "2510.22627", "categories": ["cs.AR", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.22627", "abs": "https://arxiv.org/abs/2510.22627", "authors": ["Mohd Faisal Khan", "Mukul Lokhande", "Santosh Kumar Vishvakarma"], "title": "RAMAN: Resource-efficient ApproxiMate Posit Processing for Algorithm-Hardware Co-desigN", "comment": "39th International Conference on VLSI Design and 25th International\n  Conference on Embedded Systems (VLSI-D), Pune, India", "summary": "Edge-AI applications still face considerable challenges in enhancing\ncomputational efficiency in resource-constrained environments. This work\npresents RAMAN, a resource-efficient and approximate posit(8,2)-based\nMultiply-Accumulate (MAC) architecture designed to improve hardware efficiency\nwithin bandwidth limitations. The proposed REAP (Resource-Efficient Approximate\nPosit) MAC engine, which is at the core of RAMAN, uses approximation in the\nposit multiplier to achieve significant area and power reductions with an\nimpact on accuracy. To support diverse AI workloads, this MAC unit is\nincorporated in a scalable Vector Execution Unit (VEU), which permits hardware\nreuse and parallelism among deep neural network layers. Furthermore, we propose\nan algorithm-hardware co-design framework incorporating approximation-aware\ntraining to evaluate the impact of hardware-level approximation on\napplication-level performance. Empirical validation on FPGA and ASIC platforms\nshows that the proposed REAP MAC achieves up to 46% in LUT savings and 35.66%\narea, 31.28% power reduction, respectively, over the baseline Posit Dot-Product\nUnit (PDPU) design, while maintaining high accuracy (98.45%) for handwritten\ndigit recognition. RAMAN demonstrates a promising trade-off between hardware\nefficiency and learning performance, making it suitable for next-generation\nedge intelligence."}
{"id": "2510.22674", "categories": ["cs.AR", "cs.IT", "eess.IV", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.22674", "abs": "https://arxiv.org/abs/2510.22674", "authors": ["L. Hemanth Krishna", "Srinivasu Bodapati", "Sreehari Veeramachaneni", "BhaskaraRao Jammu", "Noor Mahammad Sk"], "title": "Approximate Signed Multiplier with Sign-Focused Compressor for Edge Detection Applications", "comment": "15 pages", "summary": "This paper presents an approximate signed multiplier architecture that\nincorporates a sign-focused compressor, specifically designed for edge\ndetection applications in machine learning and signal processing. The\nmultiplier incorporates two types of sign-focused compressors: A + B + C + 1\nand A + B + C + D + 1. Both exact and approximate compressor designs are\nutilized, with a focus on efficiently handling constant value \"1\" and negative\npartial products, which frequently appear in the partial product matrices of\nsigned multipliers. To further enhance efficiency, the lower N - 1 columns of\nthe partial product matrix are truncated, followed by an error compensation\nmechanism. Experimental results show that the proposed 8-bit approximate\nmultiplier achieves a 29.21% reduction in power delay product (PDP) and a\n14.39% reduction in power compared to the best of existing multipliers. The\nproposed multiplier is integrated into a custom convolution layer and performs\nedge detection, demonstrating its practical utility in real-world applications."}
{"id": "2510.21902", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21902", "abs": "https://arxiv.org/abs/2510.21902", "authors": ["Timothé Boulet", "Xavier Hinaut", "Clément Moulin-Frier"], "title": "Software Engineering Agents for Embodied Controller Generation : A Study in Minigrid Environments", "comment": "10 pages, 7 figures", "summary": "Software Engineering Agents (SWE-Agents) have proven effective for\ntraditional software engineering tasks with accessible codebases, but their\nperformance for embodied tasks requiring well-designed information discovery\nremains unexplored. We present the first extended evaluation of SWE-Agents on\ncontroller generation for embodied tasks, adapting Mini-SWE-Agent (MSWEA) to\nsolve 20 diverse embodied tasks from the Minigrid environment. Our experiments\ncompare agent performance across different information access conditions: with\nand without environment source code access, and with varying capabilities for\ninteractive exploration. We quantify how different information access levels\naffect SWE-Agent performance for embodied tasks and analyze the relative\nimportance of static code analysis versus dynamic exploration for task solving.\nThis work establishes controller generation for embodied tasks as a crucial\nevaluation domain for SWE-Agents and provides baseline results for future\nresearch in efficient reasoning systems."}
{"id": "2510.21865", "categories": ["cs.PF", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.21865", "abs": "https://arxiv.org/abs/2510.21865", "authors": ["F. I. Qowy"], "title": "Prefetching Cache Optimization Using Graph Neural Networks: A Modular Framework and Conceptual Analysis", "comment": null, "summary": "Caching and prefetching techniques are fundamental to modern computing,\nserving to bridge the growing performance gap between processors and memory.\nTraditional prefetching strategies are often limited by their reliance on\npredefined heuristics or simplified statistical models, which fail to capture\nthe complex, non-linear dependencies in modern data access patterns. This paper\nintroduces a modular framework leveraging Graph Neural Networks (GNNs) to model\nand predict access patterns within graph-structured data, focusing on web\nnavigation and hierarchical file systems. The toolchain consists of: a route\nmapper for extracting structural information, a graph constructor for creating\ngraph representations, a walk session generator for simulating user behaviors,\nand a gnn prefetch module for training and inference. We provide a detailed\nconceptual analysis showing how GNN-based approaches can outperform\nconventional methods by learning intricate dependencies. This work offers both\ntheoretical foundations and a practical, replicable pipeline for future\nresearch in graph-driven systems optimization."}
{"id": "2510.22108", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22108", "abs": "https://arxiv.org/abs/2510.22108", "authors": ["Xinyue Liang", "Hui Kang", "Junwei Che", "Jiahui Li", "Geng Sun", "Qingqing Wu", "Jiacheng Wang", "Dusit Niyato"], "title": "STAR-RIS-assisted Collaborative Beamforming for Low-altitude Wireless Networks", "comment": "13 pages, 9 figures, submitted to IEEE Transactions on Communications", "summary": "While low-altitude wireless networks (LAWNs) based on uncrewed aerial\nvehicles (UAVs) offer high mobility, flexibility, and coverage for urban\ncommunications, they face severe signal attenuation in dense environments due\nto obstructions. To address this critical issue, we consider introducing\ncollaborative beamforming (CB) of UAVs and omnidirectional reconfigurable\nbeamforming (ORB) of simultaneous transmitting and reflecting reconfigurable\nintelligent surfaces (STAR-RIS) to enhance the signal quality and\ndirectionality. On this basis, we formulate a joint rate and energy\noptimization problem (JREOP) to maximize the transmission rate of the overall\nsystem, while minimizing the energy consumption of the UAV swarm. Due to the\nnon-convex and NP-hard nature of JREOP, we propose a heterogeneous multi-agent\ncollaborative dynamic (HMCD) optimization framework, which has two core\ncomponents. The first component is a simulated annealing (SA)-based STAR-RIS\ncontrol method, which dynamically optimizes reflection and transmission\ncoefficients to enhance signal propagation. The second component is an improved\nmulti-agent deep reinforcement learning (MADRL) control method, which\nincorporates a self-attention evaluation mechanism to capture interactions\nbetween UAVs and an adaptive velocity transition mechanism to enhance training\nstability. Simulation results demonstrate that HMCD outperforms various\nbaselines in terms of convergence speed, average transmission rate, and energy\nconsumption. Further analysis reveals that the average transmission rate of the\noverall system scales positively with both UAV count and STAR-RIS element\nnumbers."}
{"id": "2510.21738", "categories": ["cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.21738", "abs": "https://arxiv.org/abs/2510.21738", "authors": ["Yifan Bai", "Shruti Kotpalliwar", "Christoforos Kanellakis", "George Nikolakopoulos"], "title": "Collaborative Task Assignment, Sequencing and Multi-agent Path-finding", "comment": null, "summary": "In this article, we address the problem of collaborative task assignment,\nsequencing, and multi-agent pathfinding (TSPF), where a team of agents must\nvisit a set of task locations without collisions while minimizing flowtime.\nTSPF incorporates agent-task compatibility constraints and ensures that all\ntasks are completed. We propose a Conflict-Based Search with Task Sequencing\n(CBS-TS), an optimal and complete algorithm that alternates between finding new\ntask sequences and resolving conflicts in the paths of current sequences.\nCBS-TS uses a mixed-integer linear program (MILP) to optimize task sequencing\nand employs Conflict-Based Search (CBS) with Multi-Label A* (MLA*) for\ncollision-free path planning within a search forest. By invoking MILP for the\nnext-best sequence only when needed, CBS-TS efficiently limits the search\nspace, enhancing computational efficiency while maintaining optimality. We\ncompare the performance of our CBS-TS against Conflict-based Steiner Search\n(CBSS), a baseline method that, with minor modifications, can address the TSPF\nproblem. Experimental results demonstrate that CBS-TS outperforms CBSS in most\ntesting scenarios, achieving higher success rates and consistently optimal\nsolutions, whereas CBSS achieves near-optimal solutions in some cases. The\nsupplementary video is available at https://youtu.be/QT8BYgvefmU."}
{"id": "2510.21903", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21903", "abs": "https://arxiv.org/abs/2510.21903", "authors": ["Xuhui Zhou", "Valerie Chen", "Zora Zhiruo Wang", "Graham Neubig", "Maarten Sap", "Xingyao Wang"], "title": "TOM-SWE: User Mental Modeling For Software Engineering Agents", "comment": null, "summary": "Recent advances in coding agents have made them capable of planning, editing,\nrunning, and testing complex code bases. Despite their growing ability in\ncoding tasks, these systems still struggle to infer and track user intent,\nespecially when instructions are underspecified or context-dependent. To bridge\nthis gap, we introduce ToM-SWE, a dual-agent architecture that pairs a primary\nsoftware-engineering (SWE) agent with a lightweight theory-of-mind (ToM)\npartner agent dedicated to modeling the user's mental state. The ToM agent\ninfers user goals, constraints, and preferences from instructions and\ninteraction history, maintains a \\textbf{persistent memory} of the user, and\nprovides user-related suggestions to the SWE agent. In two software engineering\nbenchmarks (ambiguous SWE-bench and stateful SWE-bench), ToM-SWE improves task\nsuccess rates and user satisfaction. Notably, on the stateful SWE benchmark, a\nnewly introduced evaluation that provides agents with a user simulator along\nwith previous interaction histories, ToM-SWE achieves a substantially higher\ntask success rate of 59.7\\% compared to 18.1\\% for OpenHands, a\nstate-of-the-art SWE agent. Furthermore, in a three-week study with\nprofessional developers using ToM-SWE in their daily work, participants found\nit useful 86\\% of the time, underscoring the value of stateful user modeling\nfor practical coding agents."}
{"id": "2510.22909", "categories": ["cs.DC", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.22909", "abs": "https://arxiv.org/abs/2510.22909", "authors": ["Zongshun Zhang", "Ibrahim Matta"], "title": "Rethinking Inference Placement for Deep Learning across Edge and Cloud Platforms: A Multi-Objective Optimization Perspective and Future Directions", "comment": null, "summary": "Edge intelligent applications like VR/AR and language model based chatbots\nhave become widespread with the rapid expansion of IoT and mobile devices.\nHowever, constrained edge devices often cannot serve the increasingly large and\ncomplex deep learning (DL) models. To mitigate these challenges, researchers\nhave proposed optimizing and offloading partitions of DL models among user\ndevices, edge servers, and the cloud. In this setting, users can take advantage\nof different services to support their intelligent applications. For example,\nedge resources offer low response latency. In contrast, cloud platforms provide\nlow monetary cost computation resources for computation-intensive workloads.\nHowever, communication between DL model partitions can introduce transmission\nbottlenecks and pose risks of data leakage. Recent research aims to balance\naccuracy, computation delay, transmission delay, and privacy concerns. They\naddress these issues with model compression, model distillation, transmission\ncompression, and model architecture adaptations, including internal\nclassifiers. This survey contextualizes the state-of-the-art model offloading\nmethods and model adaptation techniques by studying their implication to a\nmulti-objective optimization comprising inference latency, data privacy, and\nresource monetary cost."}
{"id": "2510.22117", "categories": ["cs.NI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22117", "abs": "https://arxiv.org/abs/2510.22117", "authors": ["Jiahui Li", "Xinyue Liang", "Geng Sun", "Hui Kang", "Jiacheng Wang", "Dusit Niyato", "Shiwen Mao", "Abbas Jamalipour"], "title": "When UAV Swarm Meets IRS: Collaborative Secure Communications in Low-altitude Wireless Networks", "comment": "13 pages, 7 figures, submitted to IEEE Journal on Selected Areas in\n  Communications", "summary": "Low-altitude wireless networks (LAWNs) represent a promising architecture\nthat integrates unmanned aerial vehicles (UAVs) as aerial nodes to provide\nenhanced coverage, reliability, and throughput for diverse applications.\nHowever, these networks face significant security vulnerabilities from both\nknown and potential unknown eavesdroppers, which may threaten data\nconfidentiality and system integrity. To solve this critical issue, we propose\na novel secure communication framework for LAWNs where the selected UAVs within\na swarm function as a virtual antenna array (VAA), complemented by intelligent\nreflecting surface (IRS) to create a robust defense against eavesdropping\nattacks. Specifically, we formulate a multi-objective optimization problem that\nsimultaneously maximizes the secrecy rate while minimizing the maximum sidelobe\nlevel and total energy consumption, requiring joint optimization of UAV\nexcitation current weights, flight trajectories, and IRS phase shifts. This\nproblem presents significant difficulties due to the dynamic nature of the\nsystem and heterogeneous components. Thus, we first transform the problem into\na heterogeneous Markov decision process (MDP). Then, we propose a heterogeneous\nmulti-agent control approach (HMCA) that integrates a dedicated IRS control\npolicy with a multi-agent soft actor-critic framework for UAV control, which\nenables coordinated operation across heterogeneous network elements. Simulation\nresults show that the proposed HMCA achieves superior performance compared to\nbaseline approaches in terms of secrecy rate improvement, sidelobe suppression,\nand energy efficiency. Furthermore, we find that the collaborative and passive\nbeamforming synergy between VAA and IRS creates robust security guarantees when\nthe number of UAVs increases."}
{"id": "2510.21965", "categories": ["cs.MA", "I.6.0"], "pdf": "https://arxiv.org/pdf/2510.21965", "abs": "https://arxiv.org/abs/2510.21965", "authors": ["Jennifer Shi", "Christopher K. Frantz", "Christian Kimmich", "Saba Siddiki", "Atrisha Sarkar"], "title": "LLM-augmented empirical game theoretic simulation for social-ecological systems", "comment": null, "summary": "Designing institutions for social-ecological systems requires models that\ncapture heterogeneity, uncertainty, and strategic interaction. Multiple\nmodeling approaches have emerged to meet this challenge, including empirical\ngame-theoretic analysis (EGTA), which merges ABM's scale and diversity with\ngame-theoretic models' formal equilibrium analysis. The newly popular class of\nLLM-driven simulations provides yet another approach, and it is not clear how\nthese approaches can be integrated with one another, nor whether the resulting\nsimulations produce a plausible range of behaviours for real-world\nsocial-ecological governance. To address this gap, we compare four\nLLM-augmented frameworks: procedural ABMs, generative ABMs, LLM-EGTA, and\nexpert guided LLM-EGTA, and evaluate them on a real-world case study of\nirrigation and fishing in the Amu Darya basin under centralized and\ndecentralized governance. Our results show: first, procedural ABMs, generative\nABMs, and LLM-augmented EGTA models produce strikingly different patterns of\ncollective behaviour, highlighting the value of methodological diversity.\nSecond, inducing behaviour through system prompts in LLMs is less effective\nthan shaping behaviour through parameterized payoffs in an expert-guided\nEGTA-based model."}
{"id": "2510.21933", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21933", "abs": "https://arxiv.org/abs/2510.21933", "authors": ["Joao Correia", "Daniel Coutinho", "Marco Castelluccio", "Caio Barbosa", "Rafael de Mello", "Anita Sarma", "Alessandro Garcia", "Marco Gerosa", "Igor Steinmacher"], "title": "A Comparison of Conversational Models and Humans in Answering Technical Questions: the Firefox Case", "comment": "13 pages", "summary": "The use of Large Language Models (LLMs) to support tasks in software\ndevelopment has steadily increased over recent years. From assisting developers\nin coding activities to providing conversational agents that answer newcomers'\nquestions. In collaboration with the Mozilla Foundation, this study evaluates\nthe effectiveness of Retrieval-Augmented Generation (RAG) in assisting\ndevelopers within the Mozilla Firefox project. We conducted an empirical\nanalysis comparing responses from human developers, a standard GPT model, and a\nGPT model enhanced with RAG, using real queries from Mozilla's developer chat\nrooms. To ensure a rigorous evaluation, Mozilla experts assessed the responses\nbased on helpfulness, comprehensiveness, and conciseness. The results show that\nRAG-assisted responses were more comprehensive than human developers (62.50% to\n54.17%) and almost as helpful (75.00% to 79.17%), suggesting RAG's potential to\nenhance developer assistance. However, the RAG responses were not as concise\nand often verbose. The results show the potential to apply RAG-based tools to\nOpen Source Software (OSS) to minimize the load to core maintainers without\nlosing answer quality. Toning down retrieval mechanisms and making responses\neven shorter in the future would enhance developer assistance in massive\nprojects like Mozilla Firefox."}
{"id": "2510.22133", "categories": ["cs.NI", "cs.CR", "cs.LG", "C.2.0; I.5.4; K.6.5"], "pdf": "https://arxiv.org/pdf/2510.22133", "abs": "https://arxiv.org/abs/2510.22133", "authors": ["Eduardo Fabricio Gomes Trindade", "Felipe Silveira de Almeida", "Gioliano de Oliveira Braga", "Rafael Pimenta de Mattos Paixão", "Pedro Henrique dos Santos Rocha", "Lourenco Alves Pereira Jr"], "title": "HandPass: A Wi-Fi CSI Palm Authentication Approach for Access Control", "comment": "9 pages, 4 figures, 3 tables", "summary": "Wi-Fi Channel State Information (CSI) has been extensively studied for\nsensing activities. However, its practical application in user authentication\nstill needs to be explored. This study presents a novel approach to biometric\nauthentication using Wi-Fi Channel State Information (CSI) data for palm\nrecognition. The research delves into utilizing a Raspberry Pi encased in a\ncustom-built box with antenna power reduced to 1dBm, which was used to capture\nCSI data from the right hands of 20 participants (10 men and 10 women). The\ndataset was normalized using MinMax scaling to ensure uniformity and accuracy.\nBy focusing on biophysical aspects such as hand size, shape, angular spread\nbetween fingers, and finger phalanx lengths, among other characteristics, the\nstudy explores how these features affect electromagnetic signals, which are\nthen reflected in Wi-Fi CSI, allowing for precise user identification. Five\nclassification algorithms were evaluated, with the Random Forest classifier\nachieving an average F1-Score of 99.82\\% using 10-fold cross-validation.\nAmplitude and Phase data were used, with each capture session recording\napproximately 1000 packets per second in five 5-second intervals for each User.\nThis high accuracy highlights the potential of Wi-Fi CSI in developing robust\nand reliable user authentication systems based on palm biometric data."}
{"id": "2510.22222", "categories": ["cs.MA", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.22222", "abs": "https://arxiv.org/abs/2510.22222", "authors": ["Yumeng Shi", "Zhongliang Yang", "Yisi Wang", "Linna Zhou"], "title": "CreditXAI: A Multi-Agent System for Explainable Corporate Credit Rating", "comment": "8 pages, 2 figures", "summary": "In the domain of corporate credit rating, traditional deep learning methods\nhave improved predictive accuracy but still suffer from the inherent\n'black-box' problem and limited interpretability. While incorporating\nnon-financial information enriches the data and provides partial\ninterpretability, the models still lack hierarchical reasoning mechanisms,\nlimiting their comprehensive analytical capabilities. To address these\nchallenges, we propose CreditXAI, a Multi-Agent System (MAS) framework that\nsimulates the collaborative decision-making process of professional credit\nanalysts. The framework focuses on business, financial, and governance risk\ndimensions to generate consistent and interpretable credit assessments.\nExperimental results demonstrate that multi-agent collaboration improves\npredictive accuracy by more than 7% over the best single-agent baseline,\nconfirming its significant synergistic advantage in corporate credit risk\nevaluation. This study provides a new technical pathway to build intelligent\nand interpretable credit rating models."}
{"id": "2510.22309", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.22309", "abs": "https://arxiv.org/abs/2510.22309", "authors": ["Tanvir Kaur", "Ashish Saxena"], "title": "When Agents are Powerful: Black Hole Search in Time-Varying Graphs", "comment": null, "summary": "A black hole is a harmful node in a graph that destroys any resource entering\nit, making its identification a critical task. In the \\emph{Black Hole Search\n(BHS)} problem, a team of agents operates on a graph $G$ with the objective\nthat at least one agent must survive and correctly identify an edge incident to\nthe black hole. Prior work has addressed BHS in arbitrary dynamic graphs under\nthe restrictive \\emph{face-to-face} communication, where agents can exchange\ninformation only when co-located. This constraint significantly increases the\nnumber of agents required to solve the problem. In this work, we strengthen the\ncapabilities of agents in two ways: (i) granting them \\emph{global\ncommunication}, enabling interaction regardless of location, and (ii) equipping\nthem with \\emph{1-hop visibility}, allowing each agent to observe its immediate\nneighborhood. These enhancements lead to more efficient solutions for the BHS\nproblem in dynamic graphs."}
{"id": "2510.21966", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21966", "abs": "https://arxiv.org/abs/2510.21966", "authors": ["Musengamana Jean de Dieu", "Ruiyin Li", "Peng Liang", "Mojtaba Shahin", "Muhammad Waseem", "Arif Ali Khan", "Bangchao Wang", "Mst Shamima Aktar"], "title": "ArchISMiner: A Framework for Automatic Mining of Architectural Issue-Solution Pairs from Online Developer Communities", "comment": "42 pages, 14 images, 6 tables, Manuscript submitted to a Journal\n  (2025)", "summary": "Stack Overflow (SO), a leading online community forum, is a rich source of\nsoftware development knowledge. However, locating architectural knowledge, such\nas architectural solutions remains challenging due to the overwhelming volume\nof unstructured content and fragmented discussions. Developers must manually\nsift through posts to find relevant architectural insights, which is\ntime-consuming and error-prone. This study introduces ArchISMiner, a framework\nfor mining architectural knowledge from SO. The framework comprises two\ncomplementary components: ArchPI and ArchISPE. ArchPI trains and evaluates\nmultiple models, including conventional ML/DL models, Pre-trained Language\nModels (PLMs), and Large Language Models (LLMs), and selects the\nbest-performing model to automatically identify Architecture-Related Posts\n(ARPs) among programming-related discussions. ArchISPE employs an indirect\nsupervised approach that leverages diverse features, including BERT embeddings\nand local TextCNN features, to extract architectural issue-solution pairs. Our\nevaluation shows that the best model in ArchPI achieves an F1-score of 0.960 in\nARP detection, and ArchISPE outperforms baselines in both SE and NLP fields,\nachieving F1-scores of 0.883 for architectural issues and 0.894 for solutions.\nA user study further validated the quality (e.g., relevance and usefulness) of\nthe identified ARPs and the extracted issue-solution pairs. Moreover, we\napplied ArchISMiner to three additional forums, releasing a dataset of over 18K\narchitectural issue-solution pairs. Overall, ArchISMiner can help architects\nand developers identify ARPs and extract succinct, relevant, and useful\narchitectural knowledge from developer communities more accurately and\nefficiently. The replication package of this study has been provided at\nhttps://github.com/JeanMusenga/ArchISPE"}
{"id": "2510.22247", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.22247", "abs": "https://arxiv.org/abs/2510.22247", "authors": ["Tianming Lan"], "title": "Space-Air-Ground Integrated Networks for 6G Mobile Communications", "comment": "8 pages, 5 figures", "summary": "After the industrialization of 5G cellular communications, 6G has\nincreasingly become a research hotspot in the academia. Space-Air-Ground\nIntegrated Network (SAGIN) is a key supporting technology for 6G because of its\nadvantages such as high-speed transmission and expanded coverage. This paper\nsummarizes the motivation to develop the SAGIN-assisted 6G first and introduces\nthe current situation of SAGIN. We then try to discuss the design concept of\nthe SAGIN-assisted 6G, and list the problem and challenges. Moreover, we\npropose an architecture of the SAGIN-assisted 6G and identify a series of key\ntechnologies that are needed in different layers. Finally, in order for readers\nto better understand our hierarchical architecture, we use a case study\ndiscussing the congestion problem in the Integrated layer."}
{"id": "2510.22235", "categories": ["cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22235", "abs": "https://arxiv.org/abs/2510.22235", "authors": ["Yixiao Nie", "Yang Zhang", "Yingjie Jin", "Zhepeng Wang", "Xiu Li", "Xiang Li"], "title": "CGoT: A Novel Inference Mechanism for Embodied Multi-Agent Systems Using Composable Graphs of Thoughts", "comment": null, "summary": "The integration of self-driving cars and service robots is becoming\nincreasingly prevalent across a wide array of fields, playing a crucial and\nexpanding role in both industrial applications and everyday life. In parallel,\nthe rapid advancements in Large Language Models (LLMs) have garnered\nsubstantial attention and interest within the research community. This paper\nintroduces a novel vehicle-robot system that leverages the strengths of both\nautonomous vehicles and service robots. In our proposed system, two autonomous\nego-vehicles transports service robots to locations within an office park,\nwhere they perform a series of tasks. The study explores the feasibility and\npotential benefits of incorporating LLMs into this system, with the aim of\nenhancing operational efficiency and maximizing the potential of the\ncooperative mechanisms between the vehicles and the robots. This paper proposes\na novel inference mechanism which is called CGOT toward this type of system\nwhere an agent can carry another agent. Experimental results are presented to\nvalidate the performance of the proposed method."}
{"id": "2510.22434", "categories": ["cs.DC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.22434", "abs": "https://arxiv.org/abs/2510.22434", "authors": ["Prajyot Pyati", "Navjot Kaur", "Saswata Jana", "Adri Bhattacharya", "Partha Sarathi Mandal"], "title": "Separation of Unconscious Robots with Obstructed Visibility", "comment": null, "summary": "We study a recently introduced \\textit{unconscious} mobile robot model, where\neach robot is associated with a \\textit{color}, which is visible to other\nrobots but not to itself. The robots are autonomous, anonymous, oblivious and\nsilent, operating in the Euclidean plane under the conventional\n\\textit{Look-Compute-Move} cycle. A primary task in this model is the\n\\textit{separation problem}, where unconscious robots sharing the same color\nmust separate from others, forming recognizable geometric shapes such as\ncircles, points, or lines. All prior works model the robots as\n\\textit{transparent}, enabling each to know the positions and colors of all\nother robots. In contrast, we model the robots as \\textit{opaque}, where a\nrobot can obstruct the visibility of two other robots, if it lies on the line\nsegment between them. Under this obstructed visibility, we consider a variant\nof the separation problem in which robots, starting from any arbitrary initial\nconfiguration, are required to separate into concentric semicircles. We present\na collision-free algorithm that solves the separation problem under a\nsemi-synchronous scheduler in $O(n)$ epochs, where $n$ is the number of robots.\nThe robots agree on one coordinate axis but have no knowledge of $n$."}
{"id": "2510.21993", "categories": ["cs.SE", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.21993", "abs": "https://arxiv.org/abs/2510.21993", "authors": ["Yupeng Qi", "Ran Xu", "Xu Chu"], "title": "FeaGPT: an End-to-End agentic-AI for Finite Element Analysis", "comment": null, "summary": "Large language models (LLMs) are establishing new paradigms for engineering\napplications by enabling natural language control of complex computational\nworkflows. This paper introduces FeaGPT, the first framework to achieve\ncomplete geometry-mesh-simulation workflows through conversational interfaces.\nUnlike existing tools that automate individual FEA components, FeaGPT\nimplements a fully integrated Geometry-Mesh-Simulation-Analysis (GMSA) pipeline\nthat transforms engineering specifications into validated computational results\nwithout manual intervention. The system interprets engineering intent,\nautomatically generates physics-aware adaptive meshes, configures complete FEA\nsimulations with proper boundary condition inference, and performs\nmulti-objective analysis through closed-loop iteration.\n  Experimental validation confirms complete end-to-end automation capability.\nIndustrial turbocharger cases (7-blade compressor and 12-blade turbine at\n\\SI{110000}{rpm}) demonstrate the system successfully transforms natural\nlanguage specifications into validated CalculiX simulations, producing\nphysically realistic results for rotating machinery analysis. Additional\nvalidation through 432 NACA airfoil configurations confirms scalability for\nparametric design exploration. These results demonstrate that natural language\ninterfaces can effectively democratize access to advanced computational\nengineering tools while preserving analytical rigor."}
{"id": "2510.22397", "categories": ["cs.NI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22397", "abs": "https://arxiv.org/abs/2510.22397", "authors": ["Satyandra Guthula", "Jaber Daneshamooz", "Charles Fleming", "Ashish Kundu", "Walter Willinger", "Arpit Gupta"], "title": "NetBurst: Event-Centric Forecasting of Bursty, Intermittent Time Series", "comment": null, "summary": "Forecasting on widely used benchmark time series data (e.g., ETT,\nElectricity, Taxi, and Exchange Rate, etc.) has favored smooth, seasonal\nseries, but network telemetry time series -- traffic measurements at service,\nIP, or subnet granularity -- are instead highly bursty and intermittent, with\nheavy-tailed bursts and highly variable inactive periods. These properties\nplace the latter in the statistical regimes made famous and popularized more\nthan 20 years ago by B.~Mandelbrot. Yet forecasting such time series with\nmodern-day AI architectures remains underexplored. We introduce NetBurst, an\nevent-centric framework that reformulates forecasting as predicting when bursts\noccur and how large they are, using quantile-based codebooks and dual\nautoregressors. Across large-scale sets of production network telemetry time\nseries and compared to strong baselines, such as Chronos, NetBurst reduces Mean\nAverage Scaled Error (MASE) by 13--605x on service-level time series while\npreserving burstiness and producing embeddings that cluster 5x more cleanly\nthan Chronos. In effect, our work highlights the benefits that modern AI can\nreap from leveraging Mandelbrot's pioneering studies for forecasting in bursty,\nintermittent, and heavy-tailed regimes, where its operational value for\nhigh-stakes decision making is of paramount interest."}
{"id": "2510.22320", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2510.22320", "abs": "https://arxiv.org/abs/2510.22320", "authors": ["Yanqing Fu", "Chenrun Wang", "Chao Huang", "Zhuping Wang"], "title": "IFS: Information Flow Structure for Multi-agent Ad Hoc System", "comment": null, "summary": "Multi-agent ad hoc systems are dynamic collaborative systems in which\nmultiple autonomous agents must cooperate with both known and unknown teammates\nin open environments, without relying on pre-coordinated strategies. These\nsystems operate under conditions of uncertainty and partial observability,\nwhere team composition, agent behaviors, and environmental factors may change\nduring execution. Through an analysis of information flow in such systems, we\nidentify two key limitations in existing research: insufficient information\nflow and limited information processing capacity. To address these issues, we\npropose an information flow structure for multi-agent ad hoc systems (IFS),\nwhich tackles these challenges from the perspectives of communication and\ninformation fusion. Experimental results in StarCraft II demonstrate that IFS\nsignificantly improves both information flow and processing capacity, while\nexhibiting strong generalization capabilities and outperforming baseline\nmethods in complex ad hoc teamwork scenarios."}
{"id": "2510.22909", "categories": ["cs.DC", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.22909", "abs": "https://arxiv.org/abs/2510.22909", "authors": ["Zongshun Zhang", "Ibrahim Matta"], "title": "Rethinking Inference Placement for Deep Learning across Edge and Cloud Platforms: A Multi-Objective Optimization Perspective and Future Directions", "comment": null, "summary": "Edge intelligent applications like VR/AR and language model based chatbots\nhave become widespread with the rapid expansion of IoT and mobile devices.\nHowever, constrained edge devices often cannot serve the increasingly large and\ncomplex deep learning (DL) models. To mitigate these challenges, researchers\nhave proposed optimizing and offloading partitions of DL models among user\ndevices, edge servers, and the cloud. In this setting, users can take advantage\nof different services to support their intelligent applications. For example,\nedge resources offer low response latency. In contrast, cloud platforms provide\nlow monetary cost computation resources for computation-intensive workloads.\nHowever, communication between DL model partitions can introduce transmission\nbottlenecks and pose risks of data leakage. Recent research aims to balance\naccuracy, computation delay, transmission delay, and privacy concerns. They\naddress these issues with model compression, model distillation, transmission\ncompression, and model architecture adaptations, including internal\nclassifiers. This survey contextualizes the state-of-the-art model offloading\nmethods and model adaptation techniques by studying their implication to a\nmulti-objective optimization comprising inference latency, data privacy, and\nresource monetary cost."}
{"id": "2510.22003", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22003", "abs": "https://arxiv.org/abs/2510.22003", "authors": ["Stefan Julian Kooy", "Jean Paul Sebastian Piest", "Rob Henk Bemthuis"], "title": "Impact and Implications of Generative AI for Enterprise Architects in Agile Environments: A Systematic Literature Review", "comment": "17 pages, 1 figure, 5 tables; to appear in Enterprise Design,\n  Operations, and Computing. EDOC 2025 Workshops, Lecture Notes in Business\n  Information Processing (LNBIP), Springer, 2025. Part of 29th International\n  Conference on Enterprise Design, Operations, and Computing (EDOC)", "summary": "Generative AI (GenAI) is reshaping enterprise architecture work in agile\nsoftware organizations, yet evidence on its effects remains scattered. We\nreport a systematic literature review (SLR), following established SLR\nprotocols of Kitchenham and PRISMA, of 1,697 records, yielding 33 studies\nacross enterprise, solution, domain, business, and IT architect roles. GenAI\nmost consistently supports (i) design ideation and trade-off exploration; (ii)\nrapid creation and refinement of artifacts (e.g., code, models, documentation);\nand (iii) architectural decision support and knowledge retrieval. Reported\nrisks include opacity and bias, contextually incorrect outputs leading to\nrework, privacy and compliance concerns, and social loafing. We also identify\nemerging skills and competencies, including prompt engineering, model\nevaluation, and professional oversight, and organizational enablers around\nreadiness and adaptive governance. The review contributes with (1) a mapping of\nGenAI use cases and risks in agile architecting, (2) implications for\ncapability building and governance, and (3) an initial research agenda on\nhuman-AI collaboration in architecture. Overall, the findings inform\nresponsible adoption of GenAI that accelerates digital transformation while\nsafeguarding architectural integrity."}
{"id": "2510.22461", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.22461", "abs": "https://arxiv.org/abs/2510.22461", "authors": ["Josue Abreu", "Paul Bergeron", "Sandhya Aneja"], "title": "Should BBR be the default TCP Congestion Control Protocol?", "comment": null, "summary": "In this research, we investigate the feasibility of adopting the Bottleneck\nBandwidth and Round-trip propagation time (BBR) protocol as the default\ncongestion control mechanism for TCP. Our central question is whether BBR,\nparticularly its latest iterations, BBRv2 and BBRv3, can outperform traditional\nTCP variants such as Reno and Cubic across diverse networking environments. We\nevaluated performance trade-offs in Internet, data center, Ethernet, wireless,\nand satellite networks, comparing BBR against protocols including DCTCP, DCQCN,\nTIMELY, HPCC, Swift, and congestion control schemes designed for low-Earth\norbit satellite networks, using both experiments and previous studies. Our\nfindings show that BBR consistently achieves high throughput across all\nenvironments, with especially strong performance and fairness in scenarios\ninvolving homogeneous BBR flows or high bandwidth Internet paths. Experiments\nwith Google and other websites over a 100~Mbps home network further confirm\nBBR's superior performance and its ability to co-exist with Cubic flows. In\nanother experiment on the Marist campus (1--10~Gbps network), we observed its\nlatency characteristics compared to Cubic. Moreover, a controlled evaluation\nbetween protocols reveals that BBR achieves the highest throughput ($\\approx\n905$~Mbps) but introduces higher latency ($\\approx 0.79$~ms) and jitter\n($\\approx 4.2$~ms). In contrast, Reno and Cubic deliver balanced performance\nwith lower latency and moderate jitter. Vegas prioritizes minimal latency and\njitter at the cost of reduced throughput. These results demonstrate the\nstrength of BBR to handle bulk transfers and bandwidth-intensive applications.\nHowever, they also emphasize the significance of workload-driven protocol\nselection in latency-sensitive environments."}
{"id": "2510.22422", "categories": ["cs.MA", "cs.AI", "cs.CY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.22422", "abs": "https://arxiv.org/abs/2510.22422", "authors": ["Ariel Flint", "Luca Maria Aiello", "Romualdo Pastor-Satorras", "Andrea Baronchelli"], "title": "Group size effects and collective misalignment in LLM multi-agent systems", "comment": null, "summary": "Multi-agent systems of large language models (LLMs) are rapidly expanding\nacross domains, introducing dynamics not captured by single-agent evaluations.\nYet, existing work has mostly contrasted the behavior of a single agent with\nthat of a collective of fixed size, leaving open a central question: how does\ngroup size shape dynamics? Here, we move beyond this dichotomy and\nsystematically explore outcomes across the full range of group sizes. We focus\non multi-agent misalignment, building on recent evidence that interacting LLMs\nplaying a simple coordination game can generate collective biases absent in\nindividual models. First, we show that collective bias is a deeper phenomenon\nthan previously assessed: interaction can amplify individual biases, introduce\nnew ones, or override model-level preferences. Second, we demonstrate that\ngroup size affects the dynamics in a non-linear way, revealing model-dependent\ndynamical regimes. Finally, we develop a mean-field analytical approach and\nshow that, above a critical population size, simulations converge to\ndeterministic predictions that expose the basins of attraction of competing\nequilibria. These findings establish group size as a key driver of multi-agent\ndynamics and highlight the need to consider population-level effects when\ndeploying LLM-based systems at scale."}
{"id": "2510.23503", "categories": ["cs.DC", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23503", "abs": "https://arxiv.org/abs/2510.23503", "authors": ["Fatemeh Zahra Safaeipour", "Jacob Chakareski", "Morteza Hashemi"], "title": "Bayes-Split-Edge: Bayesian Optimization for Constrained Collaborative Inference in Wireless Edge Systems", "comment": null, "summary": "Mobile edge devices (e.g., AR/VR headsets) typically need to complete timely\ninference tasks while operating with limited on-board computing and energy\nresources. In this paper, we investigate the problem of collaborative inference\nin wireless edge networks, where energy-constrained edge devices aim to\ncomplete inference tasks within given deadlines. These tasks are carried out\nusing neural networks, and the edge device seeks to optimize inference\nperformance under energy and delay constraints. The inference process can be\nsplit between the edge device and an edge server, thereby achieving\ncollaborative inference over wireless networks. We formulate an inference\nutility optimization problem subject to energy and delay constraints, and\npropose a novel solution called Bayes-Split-Edge, which leverages Bayesian\noptimization for collaborative split inference over wireless edge networks. Our\nsolution jointly optimizes the transmission power and the neural network split\npoint. The Bayes-Split-Edge framework incorporates a novel hybrid acquisition\nfunction that balances inference task utility, sample efficiency, and\nconstraint violation penalties. We evaluate our approach using the VGG19 model\non the ImageNet-Mini dataset, and Resnet101 on Tiny-ImageNet, and real-world\nmMobile wireless channel datasets. Numerical results demonstrate that\nBayes-Split-Edge achieves up to 2.4x reduction in evaluation cost compared to\nstandard Bayesian optimization and achieves near-linear convergence. It also\noutperforms several baselines, including CMA-ES, DIRECT, exhaustive search, and\nProximal Policy Optimization (PPO), while matching exhaustive search\nperformance under tight constraints. These results confirm that the proposed\nframework provides a sample-efficient solution requiring maximum 20 function\nevaluations and constraint-aware optimization for wireless split inference in\nedge computing systems."}
{"id": "2510.22210", "categories": ["cs.SE", "cs.AI", "D.2.5"], "pdf": "https://arxiv.org/pdf/2510.22210", "abs": "https://arxiv.org/abs/2510.22210", "authors": ["Gwihwan Go", "Quan Zhang", "Chijin Zhou", "Zhao Wei", "Yu Jiang"], "title": "LSPRAG: LSP-Guided RAG for Language-Agnostic Real-Time Unit Test Generation", "comment": "13pages, 6 figures", "summary": "Automated unit test generation is essential for robust software development,\nyet existing approaches struggle to generalize across multiple programming\nlanguages and operate within real-time development. While Large Language Models\n(LLMs) offer a promising solution, their ability to generate high coverage test\ncode depends on prompting a concise context of the focal method. Current\nsolutions, such as Retrieval-Augmented Generation, either rely on imprecise\nsimilarity-based searches or demand the creation of costly, language-specific\nstatic analysis pipelines. To address this gap, we present LSPRAG, a framework\nfor concise-context retrieval tailored for real-time, language-agnostic unit\ntest generation. LSPRAG leverages off-the-shelf Language Server Protocol (LSP)\nback-ends to supply LLMs with precise symbol definitions and references in real\ntime. By reusing mature LSP servers, LSPRAG provides an LLM with language-aware\ncontext retrieval, requiring minimal per-language engineering effort. We\nevaluated LSPRAG on open-source projects spanning Java, Go, and Python.\nCompared to the best performance of baselines, LSPRAG increased line coverage\nby up to 174.55% for Golang, 213.31% for Java, and 31.57% for Python."}
{"id": "2510.22773", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.22773", "abs": "https://arxiv.org/abs/2510.22773", "authors": ["Simon Scherrer", "Adrian Perrig", "Stefan Schmid"], "title": "A Control-Theoretic Perspective on BBR/CUBIC Congestion-Control Competition", "comment": "Accepted at the International Symposium on Computer Performance,\n  Modeling, Measurements and Evaluation (PERFORMANCE) 2025", "summary": "To understand the fairness properties of the BBR congestion-control algorithm\n(CCA), previous research has analyzed BBR behavior with a variety of models.\nHowever, previous model-based work suffers from a trade-off between accuracy\nand interpretability: While dynamic fluid models generate highly accurate\npredictions through simulation, the causes of their predictions cannot be\neasily understood. In contrast, steady-state models predict CCA behavior in a\nmanner that is intuitively understandable, but often less accurate. This\ntrade-off is especially consequential when analyzing the competition between\nBBR and traditional loss-based CCAs, as this competition often suffers from\ninstability, i.e., sending-rate oscillation. Steady-state models cannot predict\nthis instability at all, and fluid-model simulation cannot yield analytical\nresults regarding preconditions and severity of the oscillation. To overcome\nthis trade-off, we extend the recent dynamic fluid model of BBR by means of\ncontrol theory. Based on this control-theoretic analysis, we derive\nquantitative conditions for BBR/CUBIC oscillation, identify network settings\nthat are susceptible to instability, and find that these conditions are\nfrequently satisfied by practical networks. Our analysis illuminates the\nfairness implications of BBR/CUBIC oscillation, namely by deriving and\nexperimentally validating fairness bounds that reflect the extreme rate\ndistributions during oscillation. In summary, our analysis shows that BBR/CUBIC\noscillation is frequent and harms BBR fairness, but can be remedied by means of\nour control-theoretic framework."}
{"id": "2510.22431", "categories": ["cs.MA", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.22431", "abs": "https://arxiv.org/abs/2510.22431", "authors": ["Zheng Wei", "Mingchen Li", "Zeqian Zhang", "Ruibin Yuan", "Pan Hui", "Huamin Qu", "James Evans", "Maneesh Agrawala", "Anyi Rao"], "title": "Hollywood Town: Long-Video Generation via Cross-Modal Multi-Agent Orchestration", "comment": null, "summary": "Recent advancements in multi-agent systems have demonstrated significant\npotential for enhancing creative task performance, such as long video\ngeneration. This study introduces three innovations to improve multi-agent\ncollaboration. First, we propose OmniAgent, a hierarchical, graph-based\nmulti-agent framework for long video generation that leverages a\nfilm-production-inspired architecture to enable modular specialization and\nscalable inter-agent collaboration. Second, inspired by context engineering, we\npropose hypergraph nodes that enable temporary group discussions among agents\nlacking sufficient context, reducing individual memory requirements while\nensuring adequate contextual information. Third, we transition from directed\nacyclic graphs (DAGs) to directed cyclic graphs with limited retries, allowing\nagents to reflect and refine outputs iteratively, thereby improving earlier\nstages through feedback from subsequent nodes. These contributions lay the\ngroundwork for developing more robust multi-agent systems in creative tasks."}
{"id": "2510.21745", "categories": ["cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.21745", "abs": "https://arxiv.org/abs/2510.21745", "authors": ["Eashan Wadhwa", "Shanker Shreejith"], "title": "Simopt-Power: Leveraging Simulation Metadata for Low-Power Design Synthesis", "comment": null, "summary": "Excessive switching activity is a primary contributor to dynamic power\ndissipation in modern FPGAs, where fine-grained configurability amplifies\nsignal toggling and associated capacitance. Conventional low-power techniques\n-- gating, clock-domain partitioning, and placement-aware netlist rewrites -\neither require intrusive design changes or offer diminishing returns as device\ndensities grow. In this work, we present Simopt-power, a simulator-driven\noptimisation framework that leverages simulation analysis to identify and\nselectively reconfigure high-toggle paths. By feeding activity profiles back\ninto a lightweight transformation pass, Simopt-power judiciously inserts\nduplicate truth table logic using Shannon Decomposition principle and relocates\ncritical nets, thereby attenuating unnecessary transitions without perturbing\nfunctional behaviour. We evaluated this framework on open-source RTLLM\nbenchmark, with Simopt-power achieves an average switching-induced power\nreduction of ~9\\% while incurring only ~9\\% additional LUT-equivalent resources\nfor arithmetic designs. These results demonstrate that coupling simulation\ninsights with targeted optimisations can yield a reduced dynamic power,\noffering a practical path toward using simulation metadata in the FPGA-CAD\nflow."}
{"id": "2510.22224", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.LO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.22224", "abs": "https://arxiv.org/abs/2510.22224", "authors": ["Guan-Yan Yang", "Farn Wang"], "title": "Taming Silent Failures: A Framework for Verifiable AI Reliability", "comment": "This preprint has been accepted by IEEE Reliability Magazine. 10\n  pages, 3 figures", "summary": "The integration of Artificial Intelligence (AI) into safety-critical systems\nintroduces a new reliability paradigm: silent failures, where AI produces\nconfident but incorrect outputs that can be dangerous. This paper introduces\nthe Formal Assurance and Monitoring Environment (FAME), a novel framework that\nconfronts this challenge. FAME synergizes the mathematical rigor of offline\nformal synthesis with the vigilance of online runtime monitoring to create a\nverifiable safety net around opaque AI components. We demonstrate its efficacy\nin an autonomous vehicle perception system, where FAME successfully detected\n93.5% of critical safety violations that were otherwise silent. By\ncontextualizing our framework within the ISO 26262 and ISO/PAS 8800 standards,\nwe provide reliability engineers with a practical, certifiable pathway for\ndeploying trustworthy AI. FAME represents a crucial shift from accepting\nprobabilistic performance to enforcing provable safety in next-generation\nsystems."}
{"id": "2510.23152", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.23152", "abs": "https://arxiv.org/abs/2510.23152", "authors": ["Alexis Delplace", "Samer Lahoud", "Kinda Khawam"], "title": "Exploring LR-FHSS Modulation for Enhanced IoT Connectivity: A Measurement Campaign", "comment": "Accepted for publication in the 2025 IEEE 102nd Vehicular Technology\n  Conference (VTC2025-Fall). 7 pages, 8 figures", "summary": "This paper presents the first comprehensive real-world measurement campaign\ncomparing LR-FHSS and LoRa modulations within LoRaWAN networks in urban\nenvironments. Conducted in Halifax, Canada, the campaign used a LoRaWAN\nplatform capable of operating both modulations in the FCC-regulated US915 band.\nReal-world measurements are crucial for capturing the effects of urban topology\nand signal propagation challenges, which are difficult to fully replicate in\nsimulations. Results show that LR-FHSS can achieve up to a 20% improvement in\nPacket Reception Rate (PRR) over traditional LoRa in dense urban areas.\nAdditionally, the study investigated path loss and Received Signal Strength\nIndicator (RSSI), finding that LR-FHSS achieved a minimum RSSI of -138 dBm\ncompared to LoRa's -120 dBm. The findings demonstrate that the introduction of\nLR-FHSS enhances communication robustness and reliability under regulatory\nlimitations and suggest promising applications in LoRaWAN networks."}
{"id": "2510.22477", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22477", "abs": "https://arxiv.org/abs/2510.22477", "authors": ["Yijia Fan", "Jusheng Zhang", "Jing Yang", "Keze Wang"], "title": "Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence Policy Optimization", "comment": null, "summary": "To combat the prohibitive communication costs of ``free-for-all\" multi-agent\nsystems (MAS), we introduce \\textbf{Agent-GSPO}, a framework that directly\noptimizes for token economy using sequence-level reinforcement learning.\nAgent-GSPO leverages the stable and memory-efficient Group Sequence Policy\nOptimization (GSPO) algorithm to train agents on a communication-aware reward\nthat explicitly penalizes verbosity. Across seven reasoning benchmarks,\nAgent-GSPO not only achieves new state-of-the-art performance but does so with\na fraction of the token consumption of existing methods. By fostering emergent\nstrategies like ``strategic silence,\" our approach provides a practical\nblueprint for developing scalable and economically viable multi-agent systems."}
{"id": "2510.22986", "categories": ["cs.SE", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.22986", "abs": "https://arxiv.org/abs/2510.22986", "authors": ["Junjie Huang", "Minghua He", "Jinyang Liu", "Yintong Huo", "Domenico Bianculli", "Michael R. Lyu"], "title": "CodeAD: Synthesize Code of Rules for Log-based Anomaly Detection with LLMs", "comment": null, "summary": "Log-based anomaly detection (LogAD) is critical for maintaining the\nreliability and availability of large-scale online service systems. While\nmachine learning, deep learning, and large language models (LLMs)-based methods\nhave advanced the LogAD, they often suffer from limited interpretability, high\ninference costs, and extensive preprocessing requirements, limiting their\npracticality for real-time, high-volume log analysis. In contrast, rule-based\nsystems offer efficiency and transparency, but require significant manual\neffort and are difficult to scale across diverse and evolving environments. In\nthis paper, We present CodeAD, a novel framework that automatically synthesizes\nlightweight Python rule functions for LogAD using LLMs. CodeAD introduces a\nhierarchical clustering and anchor-grounded sampling strategy to construct\nrepresentative contrastive log windows, enabling LLMs to discern discriminative\nanomaly patterns. To ensure robustness and generalizability, CodeAD employs an\nagentic workflow that iteratively generates, tests, repairs, and refines the\nrules until it meets correctness and abstraction requirements. The synthesized\nrules are interpretable, lightweight, and directly executable on raw logs,\nsupporting efficient and transparent online anomaly detection. Our\ncomprehensive experiments on three public datasets (BGL, Hadoop, Thunderbird)\ndemonstrate that CodeAD achieves an average absolute improvement of 3.6% F1\nscore over the state-of-the-art baselines, while processing large datasets up\nto 4x faster and at a fraction of the cost (total LLM invocation cost under 4\nUSD per dataset). These results highlight CodeAD as a practical and scalable\nsolution for online monitoring systems, enabling interpretable, efficient, and\nautomated LogAD in real-world environment."}
{"id": "2510.22249", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22249", "abs": "https://arxiv.org/abs/2510.22249", "authors": ["Ibuki Nakamura", "Yutaro Kashiwa", "Bin Lin", "Hajimu Iida"], "title": "Understanding Self-Admitted Technical Debt in Test Code: An Empirical Study", "comment": null, "summary": "Developers often opt for easier but non-optimal implementation to meet\ndeadlines or create rapid prototypes, leading to additional effort known as\ntechnical debt to improve the code later. Oftentimes, developers explicitly\ndocument the technical debt in code comments, referred to as Self-Admitted\nTechnical Debt (SATD). Numerous researchers have investigated the impact of\nSATD on different aspects of software quality and development processes.\nHowever, most of these studies focus on SATD in production code, often\noverlooking SATD in the test code or assuming that it shares similar\ncharacteristics with SATD in production code. In fact, a significant amount of\nSATD is also present in the test code, with many instances not fitting into\nexisting categories for the production code. This study aims to fill this gap\nand disclose the nature of SATD in the test code by examining its distribution\nand types. Moreover, the relation between its presence and test quality is also\nanalyzed. Our empirical study, involving 17,766 SATD comments (14,987 from\nproduction code, 2,779 from test code) collected from 50 repositories,\ndemonstrates that while SATD widely exists in test code, it is not directly\nassociated with test smells. Our study also presents comprehensive categories\nof SATD types in the test code, and machine learning models are developed to\nautomatically classify SATD comments based on their types for easier\nmanagement. Our results show that the CodeBERT-based model outperforms other\nmachine learning models in terms of recall and F1-score. However, the\nperformance varies on different types of SATD."}
{"id": "2510.23465", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.23465", "abs": "https://arxiv.org/abs/2510.23465", "authors": ["Abdul Saboor", "Zhuangzhuang Cui", "Achiel Colpaert", "Evgenii Vinogradov", "Wout Joseph", "Sofie Pollin"], "title": "Trajectory-Aware Air-to-Ground Channel Characterization for Low-Altitude UAVs Using MaMIMO Measurements", "comment": "Submitted to IEEE Transactions on Vehicular Technology (IEEE TVT)", "summary": "This paper presents a comprehensive measurement-based trajectory-aware\ncharacterization of low-altitude Air-to-Ground (A2G) channels in a suburban\nenvironment. A 64-element Massive Multi-Input Multi-Output (MaMIMO) array was\nused to capture channels for three trajectories of an Uncrewed Aerial Vehicle\n(UAV), including two horizontal zig-zag flights at fixed altitudes and one\nvertical ascent, chosen to emulate AUE operations and to induce controlled\nazimuth and elevation sweeps for analyzing geometry-dependent propagation\ndynamics. We examine large-scale power variations and their correlation with\ngeometric features, such as elevation, azimuth, and 3D distance, followed by an\nanalysis of fading behavior through distribution fitting and Rician K-factor\nestimation. Furthermore, temporal non-stationarity is quantified using the\nCorrelation Matrix Distance (CMD), and angular stationarity spans are utilized\nto demonstrate how channel characteristics change with the movement of the UAV.\nWe also analyze Spectral Efficiency (SE) in relation to K-factor and Root Mean\nSquare (RMS) delay spread, highlighting their combined influence on link\nperformance. The results show that the elevation angle is the strongest\npredictor of the received power, with a correlation of more than 0.77 for each\ntrajectory, while the Nakagami model best fits the small-scale fading. The\nK-factor increases from approximately 5 dB at low altitudes to over 15 dB at\nhigher elevations, indicating stronger LoS dominance. Non-stationarity patterns\nare highly trajectory- and geometry-dependent, with azimuth most affected in\nhorizontal flights and elevation during vertical flight. These findings offer\nvaluable insights for modeling and improving UAV communication channels in 6G\nNon-Terrestrial Networks (NTNs)."}
{"id": "2510.22986", "categories": ["cs.SE", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.22986", "abs": "https://arxiv.org/abs/2510.22986", "authors": ["Junjie Huang", "Minghua He", "Jinyang Liu", "Yintong Huo", "Domenico Bianculli", "Michael R. Lyu"], "title": "CodeAD: Synthesize Code of Rules for Log-based Anomaly Detection with LLMs", "comment": null, "summary": "Log-based anomaly detection (LogAD) is critical for maintaining the\nreliability and availability of large-scale online service systems. While\nmachine learning, deep learning, and large language models (LLMs)-based methods\nhave advanced the LogAD, they often suffer from limited interpretability, high\ninference costs, and extensive preprocessing requirements, limiting their\npracticality for real-time, high-volume log analysis. In contrast, rule-based\nsystems offer efficiency and transparency, but require significant manual\neffort and are difficult to scale across diverse and evolving environments. In\nthis paper, We present CodeAD, a novel framework that automatically synthesizes\nlightweight Python rule functions for LogAD using LLMs. CodeAD introduces a\nhierarchical clustering and anchor-grounded sampling strategy to construct\nrepresentative contrastive log windows, enabling LLMs to discern discriminative\nanomaly patterns. To ensure robustness and generalizability, CodeAD employs an\nagentic workflow that iteratively generates, tests, repairs, and refines the\nrules until it meets correctness and abstraction requirements. The synthesized\nrules are interpretable, lightweight, and directly executable on raw logs,\nsupporting efficient and transparent online anomaly detection. Our\ncomprehensive experiments on three public datasets (BGL, Hadoop, Thunderbird)\ndemonstrate that CodeAD achieves an average absolute improvement of 3.6% F1\nscore over the state-of-the-art baselines, while processing large datasets up\nto 4x faster and at a fraction of the cost (total LLM invocation cost under 4\nUSD per dataset). These results highlight CodeAD as a practical and scalable\nsolution for online monitoring systems, enabling interpretable, efficient, and\nautomated LogAD in real-world environment."}
{"id": "2510.22254", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22254", "abs": "https://arxiv.org/abs/2510.22254", "authors": ["Eric W. Bridgeford", "Iain Campbell", "Zijao Chen", "Zhicheng Lin", "Harrison Ritz", "Joachim Vandekerckhove", "Russell A. Poldrack"], "title": "Ten Simple Rules for AI-Assisted Coding in Science", "comment": "9 pages of content; 1 table; 1 page appendix", "summary": "While AI coding tools have demonstrated potential to accelerate software\ndevelopment, their use in scientific computing raises critical questions about\ncode quality and scientific validity. In this paper, we provide ten practical\nrules for AI-assisted coding that balance leveraging capabilities of AI with\nmaintaining scientific and methodological rigor. We address how AI can be\nleveraged strategically throughout the development cycle with four key themes:\nproblem preparation and understanding, managing context and interaction,\ntesting and validation, and code quality assurance and iterative improvement.\nThese principles serve to emphasize maintaining human agency in coding\ndecisions, establishing robust validation procedures, and preserving the domain\nexpertise essential for methodologically sound research. These rules are\nintended to help researchers harness AI's transformative potential for faster\nsoftware development while ensuring that their code meets the standards of\nreliability, reproducibility, and scientific validity that research integrity\ndemands."}
{"id": "2510.23510", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.23510", "abs": "https://arxiv.org/abs/2510.23510", "authors": ["Shakthivelu Janardhanan", "Ritanshi Agarwal", "Wolfgang Kellerer", "Carmen Mas-Machuca"], "title": "How to build a sovereign network? -- A proposal to measure network sovereignty", "comment": null, "summary": "Network sovereignty is a network operator's ability to reduce the dependency\non component manufacturers to minimize the impact of manufacturer failures.\nNetwork operators now face new design challenges to increase network\nsovereignty and avoid vendor lock-in problems because a high dependency on a\nmanufacturer corresponds to low survivability if that manufacturer is\nunavailable. The main contribution of this work is the proposal of a novel\nmetric to measure network sovereignty, the Cut Set Coloring (CSC) score. Based\non the CSC core metric CSC-ILP, our Integer Linear Program formulation is\npresented to maximize network sovereignty. We compare CSC-ILP's performance\nwith state of the art manufacturer assignment strategies."}
{"id": "2510.22318", "categories": ["cs.SE", "cs.AI", "K.3.2, D.2.5"], "pdf": "https://arxiv.org/pdf/2510.22318", "abs": "https://arxiv.org/abs/2510.22318", "authors": ["Tuan-Phong Ngo", "Bao-Ngoc Duong", "Tuan-Anh Hoang", "Joshua Dwight", "Ushik Shrestha Khwakhali"], "title": "Harnessing the Power of Large Language Models for Software Testing Education: A Focus on ISTQB Syllabus", "comment": "7 pages, 3 figures, 3 tables", "summary": "Software testing is a critical component in the software engineering field\nand is important for software engineering education. Thus, it is vital for\nacademia to continuously improve and update educational methods to reflect the\ncurrent state of the field. The International Software Testing Qualifications\nBoard (ISTQB) certification framework is globally recognized and widely adopted\nin industry and academia. However, ISTQB-based learning has been rarely applied\nwith recent generative artificial intelligence advances. Despite the growing\ncapabilities of large language models (LLMs), ISTQB-based learning and\ninstruction with LLMs have not been thoroughly explored. This paper explores\nand evaluates how LLMs can complement the ISTQB framework for higher education.\nThe findings present four key contributions: (i) the creation of a\ncomprehensive ISTQB-aligned dataset spanning over a decade, consisting of 28\nsample exams and 1,145 questions; (ii) the development of a domain-optimized\nprompt that enhances LLM precision and explanation quality on ISTQB tasks;\n(iii) a systematic evaluation of state-of-the-art LLMs on this dataset; and\n(iv) actionable insights and recommendations for integrating LLMs into software\ntesting education. These findings highlight the promise of LLMs in supporting\nISTQB certification preparation and offer a foundation for their broader use in\nsoftware engineering at higher education."}
{"id": "2510.22338", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22338", "abs": "https://arxiv.org/abs/2510.22338", "authors": ["Aritra Mitra", "Srijoni Majumdar", "Anamitra Mukhopadhyay", "Partha Pratim Das", "Paul D Clough", "Partha Pratim Chakrabarti"], "title": "Operationalizing Large Language Models with Design-Aware Contexts for Code Comment Generation", "comment": null, "summary": "Comments are very useful to the flow of code development. With the increasing\ncommonality of code, novice coders have been creating a significant amount of\ncodebases. Due to lack of commenting standards, their comments are often\nuseless, and increase the time taken to further maintain codes. This study\nintends to find the usefulness of large language models (LLMs) in these cases\nto generate potentially better comments. This study focuses on the feasibility\nof design documents as a context for the LLMs to generate more useful comments,\nas design documents are often used by maintainers to understand code when\ncomments do not suffice."}
{"id": "2510.22409", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22409", "abs": "https://arxiv.org/abs/2510.22409", "authors": ["Shahidul Islam", "Md Nahidul Islam Opu", "Shaowei Wang", "Shaiful Chowdhury"], "title": "A First Look at the Self-Admitted Technical Debt in Test Code: Taxonomy and Detection", "comment": null, "summary": "Self-admitted technical debt (SATD) refers to comments in which developers\nexplicitly acknowledge code issues, workarounds, or suboptimal solutions. SATD\nis known to significantly increase software maintenance effort. While extensive\nresearch has examined SATD in source code, its presence and impact in test code\nhave received no focused attention, leaving a significant gap in our\nunderstanding of how SATD manifests in testing contexts.\n  This study, the first of its kind, investigates SATD in test code by manually\nanalyzing 50,000 comments randomly sampled from 1.6 million comments across\n1,000 open-source Java projects. From this sample, after manual analysis and\nfiltering, we identified 615 SATD comments and classified them into 15 distinct\ncategories, building a taxonomy of test code SATD. To investigate whether test\ncode SATD can be detected automatically, we evaluated existing SATD detection\ntools, as well as both open-source and proprietary LLMs. Among the existing\ntools, MAT performed the best, albeit with moderate recall. To our surprise,\nboth open-source and proprietary LLMs exhibited poor detection accuracy,\nprimarily due to low precision. These results indicate that neither existing\napproaches nor current LLMs can reliably detect SATD in test code.\n  Overall, this work provides the first large-scale analysis of SATD in test\ncode, a nuanced understanding of its types, and the limitations of current SATD\ndetection methods. Our findings lay the groundwork for future research on test\ncode-specific SATD."}
{"id": "2510.22457", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22457", "abs": "https://arxiv.org/abs/2510.22457", "authors": ["Shalini Chakraborty", "Sebastian Baltes"], "title": "A Multifaceted View on Discrimination in Software Development Careers", "comment": "11 pages, 1 figure, 5 tables", "summary": "Conversations around diversity and inclusion in software engineering often\nfocus on gender and racial disparities. However, the State of the Developer\nNation 2025 survey with 8,717 participants revealed that other forms of\ndiscrimination are similarly prevalent but receive considerably less attention.\nThis includes discrimination based on age, political perspective, disabilities,\nor cognitive differences such as neurodivergence. We conducted a secondary\nanalysis of 800 open-ended survey responses to examine patterns of perceived\ndiscrimination, as well as related challenges and negative impacts. Our study\ncovers multiple identity facets, including age, gender, race, and disability.\nWe found that age- and gender-related discrimination was the most frequently\nreported workplace issue, but discrimination based on political and religious\nviews emerged as further notable concerns. Most of the participants who\nidentified as female cited gender as the primary source of discrimination,\noften accompanied by intersectional factors such as race, political views, age,\nor sexual orientation. Discrimination related to caregiving responsibilities\nwas reported by all gender identities. Regarding the negative impacts of\nworkplace issues, many participants described modifying their appearance or\nbehavior in response to gender biases. Gender also appeared to influence\nbroader career challenges, as women and non-binary respondents reported\nexperiencing almost all workplace issues at higher rates, particularly\ndiscrimination (35%) and mental health challenges (62%). Our goal is to raise\nawareness in the research community that discrimination in software development\nis multifaceted, and to encourage researchers to select and assess relevant\nfacets beyond age and gender when designing software engineering studies."}
{"id": "2510.22530", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22530", "abs": "https://arxiv.org/abs/2510.22530", "authors": ["Sungmin Kang", "Sumi Yun", "Jingun Hong", "Shin Yoo", "Gabin An"], "title": "Finding the Needle in the Crash Stack: Industrial-Scale Crash Root Cause Localization with AutoCrashFL", "comment": "11 pages, 8 figures, under review", "summary": "Fault Localization (FL) aims to identify root causes of program failures. FL\ntypically targets failures observed from test executions, and as such, often\ninvolves dynamic analyses to improve accuracy, such as coverage profiling or\nmutation testing. However, for large industrial software, measuring coverage\nfor every execution is prohibitively expensive, making the use of such\ntechniques difficult. To address these issues and apply FL in an industrial\nsetting, this paper proposes AutoCrashFL, an LLM agent for the localization of\ncrashes that only requires the crashdump from the Program Under Test (PUT) and\naccess to the repository of the corresponding source code. We evaluate\nAutoCrashFL against real-world crashes of SAP HANA, an industrial software\nproject consisting of more than 35 million lines of code. Experiments reveal\nthat AutoCrashFL is more effective in localization, as it identified 30%\ncrashes at the top, compared to 17% achieved by the baseline. Through thorough\nanalysis, we find that AutoCrashFL has attractive practical properties: it is\nrelatively more effective for complex bugs, and it can indicate confidence in\nits results. Overall, these results show the practicality of LLM agent\ndeployment on an industrial scale."}
{"id": "2510.22613", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22613", "abs": "https://arxiv.org/abs/2510.22613", "authors": ["Songhan Zhang", "Aoyang Fang", "Yifan Yang", "Ruiyi Cheng", "Xiaoying Tang", "Pinjia He"], "title": "DynaCausal: Dynamic Causality-Aware Root Cause Analysis for Distributed Microservices", "comment": null, "summary": "Cloud-native microservices enable rapid iteration and scalable deployment but\nalso create complex, fast-evolving dependencies that challenge reliable\ndiagnosis. Existing root cause analysis (RCA) approaches, even with multi-modal\nfusion of logs, traces, and metrics, remain limited in capturing dynamic\nbehaviors and shifting service relationships. Three critical challenges\npersist: (i) inadequate modeling of cascading fault propagation, (ii)\nvulnerability to noise interference and concept drift in normal service\nbehavior, and (iii) over-reliance on service deviation intensity that obscures\ntrue root causes. To address these challenges, we propose DynaCausal, a dynamic\ncausality-aware framework for RCA in distributed microservice systems.\nDynaCausal unifies multi-modal dynamic signals to capture time-varying\nspatio-temporal dependencies through interaction-aware representation learning.\nIt further introduces a dynamic contrastive mechanism to disentangle true fault\nindicators from contextual noise and adopts a causal-prioritized pairwise\nranking objective to explicitly optimize causal attribution. Comprehensive\nevaluations on public benchmarks demonstrate that DynaCausal consistently\nsurpasses state-of-the-art methods, attaining an average AC@1 of 0.63 with\nabsolute gains from 0.25 to 0.46, and delivering both accurate and\ninterpretable diagnoses in highly dynamic microservice environments."}
{"id": "2510.22614", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22614", "abs": "https://arxiv.org/abs/2510.22614", "authors": ["Roham Koohestani", "Agnia Sergeyuk", "David Gros", "Claudio Spiess", "Sergey Titov", "Prem Devanbu", "Maliheh Izadi"], "title": "Does In-IDE Calibration of Large Language Models work at Scale?", "comment": "Under Review", "summary": "The introduction of large language models into integrated development\nenvironments (IDEs) is revolutionizing software engineering, yet it poses\nchallenges to the usefulness and reliability of Artificial\nIntelligence-generated code. Post-hoc calibration of internal model confidences\naims to align probabilities with an acceptability measure. Prior work suggests\ncalibration can improve alignment, but at-scale evidence is limited. In this\nwork, we investigate the feasibility of applying calibration of code models to\nan in-IDE context. We study two aspects of the problem: (1) the technical\nmethod for implementing confidence calibration and improving the reliability of\ncode generation models, and (2) the human-centered design principles for\neffectively communicating reliability signal to developers. First, we develop a\nscalable and flexible calibration framework which can be used to obtain\ncalibration weights for open-source models using any dataset, and evaluate\nwhether calibrators improve the alignment between model confidence and\ndeveloper acceptance behavior. Through a large-scale analysis of over 24\nmillion real-world developer interactions across multiple programming\nlanguages, we find that a general, post-hoc calibration model based on\nPlatt-scaling does not, on average, improve the reliability of model confidence\nsignals. We also find that while dynamically personalizing calibration to\nindividual users can be effective, its effectiveness is highly dependent on the\nvolume of user interaction data. Second, we conduct a multi-phase design study\nwith 3 expert designers and 153 professional developers, combining\nscenario-based design, semi-structured interviews, and survey validation,\nrevealing a clear preference for presenting reliability signals via\nnon-numerical, color-coded indicators within the in-editor code generation\nworkflow."}
{"id": "2510.22787", "categories": ["cs.SE", "cs.AI", "68T07", "I.2.11; I.2.7; I.2.8"], "pdf": "https://arxiv.org/pdf/2510.22787", "abs": "https://arxiv.org/abs/2510.22787", "authors": ["Kamil Szczepanik", "Jarosław A. Chudziak"], "title": "Collaborative LLM Agents for C4 Software Architecture Design Automation", "comment": "This paper has been accepted for the upcoming 59th Hawaii\n  International Conference on System Sciences (HICSS-59), 2026, Hawaii, USA.\n  The final published version will appear in the official conference\n  proceedings", "summary": "Software architecture design is a fundamental part of creating every software\nsystem. Despite its importance, producing a C4 software architecture model, the\npreferred notation for such architecture, remains manual and time-consuming. We\nintroduce an LLM-based multi-agent system that automates this task by\nsimulating a dialogue between role-specific experts who analyze requirements\nand generate the Context, Container, and Component views of the C4 model.\nQuality is assessed with a hybrid evaluation framework: deterministic checks\nfor structural and syntactic integrity and C4 rule consistency, plus semantic\nand qualitative scoring via an LLM-as-a-Judge approach. Tested on five\ncanonical system briefs, the workflow demonstrates fast C4 model creation,\nsustains high compilation success, and delivers semantic fidelity. A comparison\nof four state-of-the-art LLMs shows different strengths relevant to\narchitectural design. This study contributes to automated software architecture\ndesign and its evaluation methods."}
{"id": "2510.22815", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22815", "abs": "https://arxiv.org/abs/2510.22815", "authors": ["Vasudev Vikram", "Yuvraj Agarwal", "Rohan Padhye"], "title": "On the Freshness of Pinned Dependencies in Maven", "comment": null, "summary": "Library dependencies in software ecosystems play a crucial role in the\ndevelopment of software. As newer releases of these libraries are published,\ndevelopers may opt to pin their dependencies to a particular version. While\npinning may have benefits in ensuring reproducible builds and avoiding breaking\nchanges, it bears larger risks in using outdated dependencies that may contain\nbugs and security vulnerabilities. To understand the frequency and consequences\nof dependency pinning, we first define the concepts of stale and fresh pins,\nwhich are distinguished based on how outdated the dependency is relative to the\nrelease date of the project. We conduct an empirical study to show that over\n60% of consumers of popular Maven libraries contain stale pins to their\ndependencies, with some outdated versions over a year old. These pinned\nversions often miss out on security fixes; we find that 10% of all dependency\nupgrades in our dataset to the latest minor or patch version would reduce\nsecurity vulnerabilities.\n  We prototype an approach called Pin-Freshener that can encourage developers\nto freshen their pins by leveraging the insight that crowdsourced tests of peer\nprojects can provide additional signal for the safety of an upgrade. Running\nPin-Freshener on dependency upgrades shows that just 1-5 additional test suites\ncan provide 35-100% more coverage of a dependency, compared to that of a single\nconsumer test suite. Our evaluation on real-world pins to the top 500 popular\nlibraries in Maven shows that Pin-Freshener can provide an additional signal of\nat least 5 passing crowdsourced test suites to over 3,000 consumers to safely\nperform an upgrade that reduces security vulnerabilities. Pin-Freshener can\nprovide practical confidence to developers by offering additional signal beyond\ntheir own test suites, representing an improvement over current practices."}
{"id": "2510.22986", "categories": ["cs.SE", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.22986", "abs": "https://arxiv.org/abs/2510.22986", "authors": ["Junjie Huang", "Minghua He", "Jinyang Liu", "Yintong Huo", "Domenico Bianculli", "Michael R. Lyu"], "title": "CodeAD: Synthesize Code of Rules for Log-based Anomaly Detection with LLMs", "comment": null, "summary": "Log-based anomaly detection (LogAD) is critical for maintaining the\nreliability and availability of large-scale online service systems. While\nmachine learning, deep learning, and large language models (LLMs)-based methods\nhave advanced the LogAD, they often suffer from limited interpretability, high\ninference costs, and extensive preprocessing requirements, limiting their\npracticality for real-time, high-volume log analysis. In contrast, rule-based\nsystems offer efficiency and transparency, but require significant manual\neffort and are difficult to scale across diverse and evolving environments. In\nthis paper, We present CodeAD, a novel framework that automatically synthesizes\nlightweight Python rule functions for LogAD using LLMs. CodeAD introduces a\nhierarchical clustering and anchor-grounded sampling strategy to construct\nrepresentative contrastive log windows, enabling LLMs to discern discriminative\nanomaly patterns. To ensure robustness and generalizability, CodeAD employs an\nagentic workflow that iteratively generates, tests, repairs, and refines the\nrules until it meets correctness and abstraction requirements. The synthesized\nrules are interpretable, lightweight, and directly executable on raw logs,\nsupporting efficient and transparent online anomaly detection. Our\ncomprehensive experiments on three public datasets (BGL, Hadoop, Thunderbird)\ndemonstrate that CodeAD achieves an average absolute improvement of 3.6% F1\nscore over the state-of-the-art baselines, while processing large datasets up\nto 4x faster and at a fraction of the cost (total LLM invocation cost under 4\nUSD per dataset). These results highlight CodeAD as a practical and scalable\nsolution for online monitoring systems, enabling interpretable, efficient, and\nautomated LogAD in real-world environment."}
{"id": "2510.23010", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.23010", "abs": "https://arxiv.org/abs/2510.23010", "authors": ["Ming-Tung Shen", "Yuh-Jzer Joung"], "title": "TALM: Dynamic Tree-Structured Multi-Agent Framework with Long-Term Memory for Scalable Code Generation", "comment": null, "summary": "Agentic code generation requires large language models (LLMs) capable of\ncomplex context management and multi-step reasoning. Prior multi-agent\nframeworks attempt to address these challenges through collaboration, yet they\noften suffer from rigid workflows and high reasoning recovery costs. To\novercome these limitations, we propose TALM (Tree-Structured Multi-Agent\nFramework with Long-Term Memory), a dynamic framework that integrates\nstructured task decomposition, localized re-reasoning, and long-term memory\nmechanisms. TALM employs an extensible tree-based collaboration structure. The\nparent-child relationships, when combined with a divide-and-conquer strategy,\nenhance reasoning flexibility and enable efficient error correction across\ndiverse task scopes. Furthermore, a long-term memory module enables semantic\nquerying and integration of prior knowledge, supporting implicit\nself-improvement through experience reuse. Experimental results on HumanEval,\nBigCodeBench, and ClassEval benchmarks demonstrate that TALM consistently\ndelivers strong reasoning performance and high token efficiency, highlighting\nits robustness and practical utility in complex code generation tasks."}
{"id": "2510.23055", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.23055", "abs": "https://arxiv.org/abs/2510.23055", "authors": ["Manjeshwar Aniruddh Mallya", "Alessio Ferrari", "Mohammad Amin Zadenoori", "Jacek Dąbrowski"], "title": "From Online User Feedback to Requirements: Evaluating Large Language Models for Classification and Specification Tasks", "comment": null, "summary": "[Context and Motivation] Online user feedback provides valuable information\nto support requirements engineering (RE). However, analyzing online user\nfeedback is challenging due to its large volume and noise. Large language\nmodels (LLMs) show strong potential to automate this process and outperform\nprevious techniques. They can also enable new tasks, such as generating\nrequirements specifications.\n  [Question-Problem] Despite their potential, the use of LLMs to analyze user\nfeedback for RE remains underexplored. Existing studies offer limited empirical\nevidence, lack thorough evaluation, and rarely provide replication packages,\nundermining validity and reproducibility.\n  [Principal Idea-Results] We evaluate five lightweight open-source LLMs on\nthree RE tasks: user request classification, NFR classification, and\nrequirements specification generation. Classification performance was measured\non two feedback datasets, and specification quality via human evaluation. LLMs\nachieved moderate-to-high classification accuracy (F1 ~ 0.47-0.68) and\nmoderately high specification quality (mean ~ 3/5).\n  [Contributions] We newly explore lightweight LLMs for feedback-driven\nrequirements development. Our contributions are: (i) an empirical evaluation of\nlightweight LLMs on three RE tasks, (ii) a replication package, and (iii)\ninsights into their capabilities and limitations for RE."}
{"id": "2510.23068", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.23068", "abs": "https://arxiv.org/abs/2510.23068", "authors": ["Ella Dodor", "Cristina V. Lopes"], "title": "Checkstyle+: Reducing Technical Debt Through The Use of Linters with LLMs", "comment": "11 pages, 9 figures, tool link:\n  https://github.com/ellacodee/CheckstylePlus", "summary": "Good code style improves program readability, maintainability, and\ncollaboration, and is an integral component of software quality. Developers,\nhowever, often cut corners when following style rules, leading to the wide\nadoption of tools such as linters in professional software development\nprojects. Traditional linters like Checkstyle operate using rigid, rule-based\nmechanisms that effectively detect many surface-level violations. However, in\nmost programming languages, there is a subset of style rules that require a\nmore nuanced understanding of code, and fall outside the scope of such static\nanalysis. In this paper, we propose Checkstyle+, a hybrid approach that\naugments Checkstyle with large language model (LLM) capabilities, to identify\nstyle violations that elude the conventional rule-based analysis. Checkstyle+\nis evaluated on a sample of 380 Java code files, drawn from a broader dataset\nof 30,800 real-world Java programs sourced from accepted Codeforces\nsubmissions. The results show that Checkstyle+ achieves superior performance\nover standard Checkstyle in detecting violations of the semantically nuanced\nrules."}
{"id": "2510.23350", "categories": ["cs.SE", "D.2.1; D.2.4; D.2.5"], "pdf": "https://arxiv.org/pdf/2510.23350", "abs": "https://arxiv.org/abs/2510.23350", "authors": ["Alcino Cunha", "Nuno Macedo"], "title": "Validating Formal Specifications with LLM-generated Test Cases", "comment": null, "summary": "Validation is a central activity when developing formal specifications.\nSimilarly to coding, a possible validation technique is to define upfront test\ncases or scenarios that a future specification should satisfy or not.\nUnfortunately, specifying such test cases is burdensome and error prone, which\ncould cause users to skip this validation task. This paper reports the results\nof an empirical evaluation of using pre-trained large language models (LLMs) to\nautomate the generation of test cases from natural language requirements. In\nparticular, we focus on test cases for structural requirements of simple domain\nmodels formalized in the Alloy specification language. Our evaluation focuses\non the state-of-art GPT-5 model, but results from other closed- and open-source\nLLMs are also reported. The results show that, in this context, GPT-5 is\nalready quite effective at generating positive (and negative) test cases that\nare syntactically correct and that satisfy (or not) the given requirement, and\nthat can detect many wrong specifications written by humans."}
{"id": "2510.23389", "categories": ["cs.SE", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23389", "abs": "https://arxiv.org/abs/2510.23389", "authors": ["Edoardo Manino", "Bruno Farias", "Rafael Sá Menezes", "Fedor Shmarov", "Lucas C. Cordeiro"], "title": "Floating-Point Neural Network Verification at the Software Level", "comment": "Pre-print before submission to peer review", "summary": "The behaviour of neural network components must be proven correct before\ndeployment in safety-critical systems. Unfortunately, existing neural network\nverification techniques cannot certify the absence of faults at the software\nlevel. In this paper, we show how to specify and verify that neural networks\nare safe, by explicitly reasoning about their floating-point implementation. In\ndoing so, we construct NeuroCodeBench 2.0, a benchmark comprising 912 neural\nnetwork verification examples that cover activation functions, common layers,\nand full neural networks of up to 170K parameters. Our verification suite is\nwritten in plain C and is compatible with the format of the International\nCompetition on Software Verification (SV-COMP). Thanks to it, we can conduct\nthe first rigorous evaluation of eight state-of-the-art software verifiers on\nneural network code. The results show that existing automated verification\ntools can correctly solve an average of 11% of our benchmark, while producing\naround 3% incorrect verdicts. At the same time, a historical analysis reveals\nthat the release of our benchmark has already had a significantly positive\nimpact on the latter."}
{"id": "2510.23528", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.23528", "abs": "https://arxiv.org/abs/2510.23528", "authors": ["Joran Leest", "Ilias Gerostathopoulos", "Patricia Lago", "Claudia Raibulet"], "title": "Tracing Distribution Shifts with Causal System Maps", "comment": null, "summary": "Monitoring machine learning (ML) systems is hard, with standard practice\nfocusing on detecting distribution shifts rather than their causes. Root-cause\nanalysis often relies on manual tracing to determine whether a shift is caused\nby software faults, data-quality issues, or natural change. We propose ML\nSystem Maps -- causal maps that, through layered views, make explicit the\npropagation paths between the environment and the ML system's internals,\nenabling systematic attribution of distribution shifts. We outline the approach\nand a research agenda for its development and evaluation."}
{"id": "2510.21865", "categories": ["cs.PF", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.21865", "abs": "https://arxiv.org/abs/2510.21865", "authors": ["F. I. Qowy"], "title": "Prefetching Cache Optimization Using Graph Neural Networks: A Modular Framework and Conceptual Analysis", "comment": null, "summary": "Caching and prefetching techniques are fundamental to modern computing,\nserving to bridge the growing performance gap between processors and memory.\nTraditional prefetching strategies are often limited by their reliance on\npredefined heuristics or simplified statistical models, which fail to capture\nthe complex, non-linear dependencies in modern data access patterns. This paper\nintroduces a modular framework leveraging Graph Neural Networks (GNNs) to model\nand predict access patterns within graph-structured data, focusing on web\nnavigation and hierarchical file systems. The toolchain consists of: a route\nmapper for extracting structural information, a graph constructor for creating\ngraph representations, a walk session generator for simulating user behaviors,\nand a gnn prefetch module for training and inference. We provide a detailed\nconceptual analysis showing how GNN-based approaches can outperform\nconventional methods by learning intricate dependencies. This work offers both\ntheoretical foundations and a practical, replicable pipeline for future\nresearch in graph-driven systems optimization."}
{"id": "2510.22087", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22087", "abs": "https://arxiv.org/abs/2510.22087", "authors": ["Shvetank Prakash", "Andrew Cheng", "Arya Tschand", "Mark Mazumder", "Varun Gohil", "Jeffrey Ma", "Jason Yik", "Zishen Wan", "Jessica Quaye", "Elisavet Lydia Alvanaki", "Avinash Kumar", "Chandrashis Mazumdar", "Tuhin Khare", "Alexander Ingare", "Ikechukwu Uchendu", "Radhika Ghosal", "Abhishek Tyagi", "Chenyu Wang", "Andrea Mattia Garavagno", "Sarah Gu", "Alice Guo", "Grace Hur", "Luca Carloni", "Tushar Krishna", "Ankita Nayak", "Amir Yazdanbakhsh", "Vijay Janapa Reddi"], "title": "QuArch: A Benchmark for Evaluating LLM Reasoning in Computer Architecture", "comment": null, "summary": "The field of computer architecture, which bridges high-level software\nabstractions and low-level hardware implementations, remains absent from\ncurrent large language model (LLM) evaluations. To this end, we present QuArch\n(pronounced 'quark'), the first benchmark designed to facilitate the\ndevelopment and evaluation of LLM knowledge and reasoning capabilities\nspecifically in computer architecture. QuArch provides a comprehensive\ncollection of 2,671 expert-validated question-answer (QA) pairs covering\nvarious aspects of computer architecture, including processor design, memory\nsystems, and interconnection networks. Our evaluation reveals that while\nfrontier models possess domain-specific knowledge, they struggle with skills\nthat require higher-order thinking in computer architecture. Frontier model\naccuracies vary widely (from 34% to 72%) on these advanced questions,\nhighlighting persistent gaps in architectural reasoning across analysis,\ndesign, and implementation QAs. By holistically assessing fundamental skills,\nQuArch provides a foundation for building and measuring LLM capabilities that\ncan accelerate innovation in computing systems. With over 140 contributors from\n40 institutions, this benchmark represents a community effort to set the\nstandard for architectural reasoning in LLM evaluation."}
