<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 2]
- [cs.SE](#cs.SE) [Total: 22]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.MA](#cs.MA) [Total: 7]
- [cs.DC](#cs.DC) [Total: 3]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [RAMAN: Resource-efficient ApproxiMate Posit Processing for Algorithm-Hardware Co-desigN](https://arxiv.org/abs/2510.22627)
*Mohd Faisal Khan,Mukul Lokhande,Santosh Kumar Vishvakarma*

Main category: cs.AR

TL;DR: 本文提出了RAMAN，一种基于近似posit(8,2)的资源高效乘累加（MAC）架构，通过在乘法器中引入近似计算，在保持高准确率的同时显著降低面积与功耗，适用于边缘AI场景。


<details>
  <summary>Details</summary>
Motivation: 边缘AI应用在资源受限环境中面临计算效率低下的挑战，亟需兼顾硬件效率与模型精度的解决方案。

Method: 提出REAP MAC引擎，结合近似posit乘法器，并将其集成到可扩展的向量执行单元（VEU）中；同时采用算法-硬件协同设计框架，引入近似感知训练以评估硬件近似对应用性能的影响。

Result: 在FPGA和ASIC平台上验证表明，相比基线PDPU设计，REAP MAC最多节省46% LUT、35.66%面积和31.28%功耗，同时在手写数字识别任务中保持98.45%的高准确率。

Conclusion: RAMAN在硬件效率与学习性能之间实现了良好权衡，适用于下一代边缘智能系统。

Abstract: Edge-AI applications still face considerable challenges in enhancing
computational efficiency in resource-constrained environments. This work
presents RAMAN, a resource-efficient and approximate posit(8,2)-based
Multiply-Accumulate (MAC) architecture designed to improve hardware efficiency
within bandwidth limitations. The proposed REAP (Resource-Efficient Approximate
Posit) MAC engine, which is at the core of RAMAN, uses approximation in the
posit multiplier to achieve significant area and power reductions with an
impact on accuracy. To support diverse AI workloads, this MAC unit is
incorporated in a scalable Vector Execution Unit (VEU), which permits hardware
reuse and parallelism among deep neural network layers. Furthermore, we propose
an algorithm-hardware co-design framework incorporating approximation-aware
training to evaluate the impact of hardware-level approximation on
application-level performance. Empirical validation on FPGA and ASIC platforms
shows that the proposed REAP MAC achieves up to 46% in LUT savings and 35.66%
area, 31.28% power reduction, respectively, over the baseline Posit Dot-Product
Unit (PDPU) design, while maintaining high accuracy (98.45%) for handwritten
digit recognition. RAMAN demonstrates a promising trade-off between hardware
efficiency and learning performance, making it suitable for next-generation
edge intelligence.

</details>


### [2] [Approximate Signed Multiplier with Sign-Focused Compressor for Edge Detection Applications](https://arxiv.org/abs/2510.22674)
*L. Hemanth Krishna,Srinivasu Bodapati,Sreehari Veeramachaneni,BhaskaraRao Jammu,Noor Mahammad Sk*

Main category: cs.AR

TL;DR: 本文提出一种面向边缘检测应用的近似有符号乘法器架构，通过引入处理符号和常数“1”的专用压缩器，并结合低位截断与误差补偿机制，在保持功能的同时显著降低功耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 在机器学习和信号处理的边缘检测任务中，传统有符号乘法器在处理负数和常数“1”时效率较低，且功耗较高。因此，亟需一种能高效处理这些特性的低功耗近似乘法器。

Method: 提出两种符号聚焦压缩器（A+B+C+1 和 A+B+C+D+1），结合精确与近似设计，高效处理有符号乘法中的负部分积和常数“1”；同时对部分积矩阵的低N-1位列进行截断，并引入误差补偿机制。

Result: 所提出的8位近似乘法器相比现有最优乘法器，功耗延迟积（PDP）降低29.21%，功耗降低14.39%；并成功集成到自定义卷积层中实现边缘检测。

Conclusion: 该近似有符号乘法器在保证边缘检测性能的同时显著提升了能效，适用于资源受限的边缘计算场景。

Abstract: This paper presents an approximate signed multiplier architecture that
incorporates a sign-focused compressor, specifically designed for edge
detection applications in machine learning and signal processing. The
multiplier incorporates two types of sign-focused compressors: A + B + C + 1
and A + B + C + D + 1. Both exact and approximate compressor designs are
utilized, with a focus on efficiently handling constant value "1" and negative
partial products, which frequently appear in the partial product matrices of
signed multipliers. To further enhance efficiency, the lower N - 1 columns of
the partial product matrix are truncated, followed by an error compensation
mechanism. Experimental results show that the proposed 8-bit approximate
multiplier achieves a 29.21% reduction in power delay product (PDP) and a
14.39% reduction in power compared to the best of existing multipliers. The
proposed multiplier is integrated into a custom convolution layer and performs
edge detection, demonstrating its practical utility in real-world applications.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Software Engineering Agents for Embodied Controller Generation : A Study in Minigrid Environments](https://arxiv.org/abs/2510.21902)
*Timothé Boulet,Xavier Hinaut,Clément Moulin-Frier*

Main category: cs.SE

TL;DR: 本文首次评估了软件工程智能体（SWE-Agents）在具身任务控制器生成中的表现，通过在Minigrid环境中测试Mini-SWE-Agent在不同信息获取条件下的性能，揭示了静态代码分析与动态探索对任务解决的相对重要性。


<details>
  <summary>Details</summary>
Motivation: 现有SWE-Agents在传统软件工程任务中表现良好，但在需要有效信息发现的具身任务中的能力尚未被探索，因此需要建立新的评估范式。

Method: 将Mini-SWE-Agent适配到Minigrid环境中的20个多样化具身任务，比较其在有无环境源代码访问权限以及不同交互探索能力下的表现。

Result: 实验量化了不同信息访问级别对SWE-Agent在具身任务中性能的影响，并分析了静态代码分析与动态探索在任务解决中的相对重要性。

Conclusion: 具身任务的控制器生成是评估SWE-Agents的重要新领域，本研究为此提供了基线结果，有助于推动高效推理系统的研究。

Abstract: Software Engineering Agents (SWE-Agents) have proven effective for
traditional software engineering tasks with accessible codebases, but their
performance for embodied tasks requiring well-designed information discovery
remains unexplored. We present the first extended evaluation of SWE-Agents on
controller generation for embodied tasks, adapting Mini-SWE-Agent (MSWEA) to
solve 20 diverse embodied tasks from the Minigrid environment. Our experiments
compare agent performance across different information access conditions: with
and without environment source code access, and with varying capabilities for
interactive exploration. We quantify how different information access levels
affect SWE-Agent performance for embodied tasks and analyze the relative
importance of static code analysis versus dynamic exploration for task solving.
This work establishes controller generation for embodied tasks as a crucial
evaluation domain for SWE-Agents and provides baseline results for future
research in efficient reasoning systems.

</details>


### [4] [TOM-SWE: User Mental Modeling For Software Engineering Agents](https://arxiv.org/abs/2510.21903)
*Xuhui Zhou,Valerie Chen,Zora Zhiruo Wang,Graham Neubig,Maarten Sap,Xingyao Wang*

Main category: cs.SE

TL;DR: ToM-SWE is a dual-agent system that enhances coding agents’ ability to understand and respond to user intent by incorporating a lightweight theory-of-mind (ToM) agent that models the user’s goals, preferences, and context through persistent memory, significantly improving task success and user satisfaction in software engineering tasks.


<details>
  <summary>Details</summary>
Motivation: Current coding agents struggle to infer and track user intent, especially when instructions are ambiguous or context-dependent, limiting their effectiveness in real-world software development scenarios.

Method: The authors propose ToM-SWE, a dual-agent architecture consisting of a primary software engineering (SWE) agent and a lightweight theory-of-mind (ToM) agent. The ToM agent interprets user instructions and interaction history to maintain a persistent memory of user goals, constraints, and preferences, and provides contextual suggestions to the SWE agent.

Result: ToM-SWE achieves a 59.7% task success rate on the stateful SWE-bench, significantly outperforming OpenHands (18.1%). In a three-week user study with professional developers, participants found ToM-SWE useful 86% of the time.

Conclusion: Incorporating a theory-of-mind component with persistent user modeling substantially improves coding agents’ performance and user satisfaction, highlighting the importance of stateful, user-aware design in practical software engineering AI systems.

Abstract: Recent advances in coding agents have made them capable of planning, editing,
running, and testing complex code bases. Despite their growing ability in
coding tasks, these systems still struggle to infer and track user intent,
especially when instructions are underspecified or context-dependent. To bridge
this gap, we introduce ToM-SWE, a dual-agent architecture that pairs a primary
software-engineering (SWE) agent with a lightweight theory-of-mind (ToM)
partner agent dedicated to modeling the user's mental state. The ToM agent
infers user goals, constraints, and preferences from instructions and
interaction history, maintains a \textbf{persistent memory} of the user, and
provides user-related suggestions to the SWE agent. In two software engineering
benchmarks (ambiguous SWE-bench and stateful SWE-bench), ToM-SWE improves task
success rates and user satisfaction. Notably, on the stateful SWE benchmark, a
newly introduced evaluation that provides agents with a user simulator along
with previous interaction histories, ToM-SWE achieves a substantially higher
task success rate of 59.7\% compared to 18.1\% for OpenHands, a
state-of-the-art SWE agent. Furthermore, in a three-week study with
professional developers using ToM-SWE in their daily work, participants found
it useful 86\% of the time, underscoring the value of stateful user modeling
for practical coding agents.

</details>


### [5] [A Comparison of Conversational Models and Humans in Answering Technical Questions: the Firefox Case](https://arxiv.org/abs/2510.21933)
*Joao Correia,Daniel Coutinho,Marco Castelluccio,Caio Barbosa,Rafael de Mello,Anita Sarma,Alessandro Garcia,Marco Gerosa,Igor Steinmacher*

Main category: cs.SE

TL;DR: 本研究评估了检索增强生成（RAG）在Mozilla Firefox项目中辅助开发者的有效性，发现RAG生成的回答比人类开发者更全面，几乎同样有帮助，但较为冗长。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLM）在软件开发中的应用日益广泛，研究旨在探索RAG技术能否有效辅助开源项目（如Mozilla Firefox）中的开发者，减轻核心维护者负担。

Method: 研究通过实证分析，比较人类开发者、标准GPT模型和RAG增强GPT模型对Mozilla开发者聊天室真实问题的回答，由Mozilla专家从有用性、全面性和简洁性三方面进行评估。

Result: RAG辅助的回答在全面性上优于人类（62.50% vs 54.17%），在有用性上接近人类（75.00% vs 79.17%），但在简洁性方面表现较差，常显得冗长。

Conclusion: RAG在开源软件项目中具有提升开发者支持的潜力，未来可通过优化检索机制和缩短回答长度，进一步提高其在大型项目中的实用性。

Abstract: The use of Large Language Models (LLMs) to support tasks in software
development has steadily increased over recent years. From assisting developers
in coding activities to providing conversational agents that answer newcomers'
questions. In collaboration with the Mozilla Foundation, this study evaluates
the effectiveness of Retrieval-Augmented Generation (RAG) in assisting
developers within the Mozilla Firefox project. We conducted an empirical
analysis comparing responses from human developers, a standard GPT model, and a
GPT model enhanced with RAG, using real queries from Mozilla's developer chat
rooms. To ensure a rigorous evaluation, Mozilla experts assessed the responses
based on helpfulness, comprehensiveness, and conciseness. The results show that
RAG-assisted responses were more comprehensive than human developers (62.50% to
54.17%) and almost as helpful (75.00% to 79.17%), suggesting RAG's potential to
enhance developer assistance. However, the RAG responses were not as concise
and often verbose. The results show the potential to apply RAG-based tools to
Open Source Software (OSS) to minimize the load to core maintainers without
losing answer quality. Toning down retrieval mechanisms and making responses
even shorter in the future would enhance developer assistance in massive
projects like Mozilla Firefox.

</details>


### [6] [FeaGPT: an End-to-End agentic-AI for Finite Element Analysis](https://arxiv.org/abs/2510.21993)
*Yupeng Qi,Ran Xu,Xu Chu*

Main category: cs.SE

TL;DR: 本文提出了FeaGPT，首个通过自然语言对话实现完整几何-网格-仿真-分析（GMSA）工作流的框架，无需人工干预即可将工程需求转化为经过验证的有限元仿真结果。


<details>
  <summary>Details</summary>
Motivation: 现有工具仅能自动化有限元分析（FEA）的个别组件，缺乏端到端的集成能力；本文旨在通过自然语言接口实现全自动、完整的FEA工作流，降低高级计算工程工具的使用门槛。

Method: FeaGPT构建了一个集成的GMSA流水线，能够理解工程意图、自动生成物理感知的自适应网格、自动配置边界条件完整的FEA仿真，并通过闭环迭代进行多目标分析。

Result: 在工业级涡轮增压器案例（7叶片压缩机和12叶片涡轮，110000 rpm）中成功生成经验证的CalculiX仿真结果；并通过432种NACA翼型配置验证了其在参数化设计探索中的可扩展性。

Conclusion: 自然语言接口能够有效实现计算工程工具的民主化，在保持分析严谨性的同时，实现从自然语言到完整仿真的端到端自动化。

Abstract: Large language models (LLMs) are establishing new paradigms for engineering
applications by enabling natural language control of complex computational
workflows. This paper introduces FeaGPT, the first framework to achieve
complete geometry-mesh-simulation workflows through conversational interfaces.
Unlike existing tools that automate individual FEA components, FeaGPT
implements a fully integrated Geometry-Mesh-Simulation-Analysis (GMSA) pipeline
that transforms engineering specifications into validated computational results
without manual intervention. The system interprets engineering intent,
automatically generates physics-aware adaptive meshes, configures complete FEA
simulations with proper boundary condition inference, and performs
multi-objective analysis through closed-loop iteration.
  Experimental validation confirms complete end-to-end automation capability.
Industrial turbocharger cases (7-blade compressor and 12-blade turbine at
\SI{110000}{rpm}) demonstrate the system successfully transforms natural
language specifications into validated CalculiX simulations, producing
physically realistic results for rotating machinery analysis. Additional
validation through 432 NACA airfoil configurations confirms scalability for
parametric design exploration. These results demonstrate that natural language
interfaces can effectively democratize access to advanced computational
engineering tools while preserving analytical rigor.

</details>


### [7] [LSPRAG: LSP-Guided RAG for Language-Agnostic Real-Time Unit Test Generation](https://arxiv.org/abs/2510.22210)
*Gwihwan Go,Quan Zhang,Chijin Zhou,Zhao Wei,Yu Jiang*

Main category: cs.SE

TL;DR: 本文提出LSPRAG框架，利用现成的语言服务器协议（LSP）后端为大语言模型（LLM）提供精准的代码上下文，实现实时、跨语言的单元测试生成，在Java、Go和Python项目中显著提升行覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有自动化单元测试生成方法难以在多种编程语言间泛化，且无法满足实时开发需求；而当前基于检索增强生成（RAG）的方法要么依赖不精确的相似性搜索，要么需要构建昂贵的语言特定静态分析流水线。

Method: LSPRAG利用现成的语言服务器协议（LSP）后端，在实时开发中为LLM提供精确的符号定义与引用信息，从而实现语言无关、低工程成本的上下文检索。

Result: 在Java、Go和Python的开源项目评估中，LSPRAG相比最佳基线方法，分别提升了213.31%、174.55%和31.57%的行覆盖率。

Conclusion: LSPRAG通过复用成熟的LSP服务器，有效解决了跨语言、实时单元测试生成中的上下文检索难题，显著提高了测试覆盖率，同时大幅降低了每种语言所需的工程投入。

Abstract: Automated unit test generation is essential for robust software development,
yet existing approaches struggle to generalize across multiple programming
languages and operate within real-time development. While Large Language Models
(LLMs) offer a promising solution, their ability to generate high coverage test
code depends on prompting a concise context of the focal method. Current
solutions, such as Retrieval-Augmented Generation, either rely on imprecise
similarity-based searches or demand the creation of costly, language-specific
static analysis pipelines. To address this gap, we present LSPRAG, a framework
for concise-context retrieval tailored for real-time, language-agnostic unit
test generation. LSPRAG leverages off-the-shelf Language Server Protocol (LSP)
back-ends to supply LLMs with precise symbol definitions and references in real
time. By reusing mature LSP servers, LSPRAG provides an LLM with language-aware
context retrieval, requiring minimal per-language engineering effort. We
evaluated LSPRAG on open-source projects spanning Java, Go, and Python.
Compared to the best performance of baselines, LSPRAG increased line coverage
by up to 174.55% for Golang, 213.31% for Java, and 31.57% for Python.

</details>


### [8] [Taming Silent Failures: A Framework for Verifiable AI Reliability](https://arxiv.org/abs/2510.22224)
*Guan-Yan Yang,Farn Wang*

Main category: cs.SE

TL;DR: 本文提出FAME框架，结合离线形式化综合与在线运行时监控，有效检测AI在安全关键系统中的“静默故障”，并在自动驾驶感知系统中验证其有效性，为可信AI部署提供符合ISO标准的可认证路径。


<details>
  <summary>Details</summary>
Motivation: AI在安全关键系统中的应用带来了“静默故障”风险——即AI输出自信但错误的结果，可能引发严重安全隐患。现有方法难以对此类故障进行有效检测与防范，亟需一种兼顾严谨性与实用性的安全保障机制。

Method: 提出FAME（Formal Assurance and Monitoring Environment）框架，融合离线形式化综合的数学严谨性与在线运行时监控的实时警觉性，围绕黑盒AI组件构建可验证的安全保障机制，并结合ISO 26262与ISO/PAS 8800标准进行设计。

Result: 在自动驾驶感知系统中，FAME成功检测出93.5%原本难以察觉的关键安全违规事件，验证了其对AI静默故障的高效识别能力。

Conclusion: FAME为安全关键系统中可信AI的部署提供了一条可认证、可验证的实用路径，标志着从依赖概率性能向实现可证明安全性的范式转变。

Abstract: The integration of Artificial Intelligence (AI) into safety-critical systems
introduces a new reliability paradigm: silent failures, where AI produces
confident but incorrect outputs that can be dangerous. This paper introduces
the Formal Assurance and Monitoring Environment (FAME), a novel framework that
confronts this challenge. FAME synergizes the mathematical rigor of offline
formal synthesis with the vigilance of online runtime monitoring to create a
verifiable safety net around opaque AI components. We demonstrate its efficacy
in an autonomous vehicle perception system, where FAME successfully detected
93.5% of critical safety violations that were otherwise silent. By
contextualizing our framework within the ISO 26262 and ISO/PAS 8800 standards,
we provide reliability engineers with a practical, certifiable pathway for
deploying trustworthy AI. FAME represents a crucial shift from accepting
probabilistic performance to enforcing provable safety in next-generation
systems.

</details>


### [9] [CodeAD: Synthesize Code of Rules for Log-based Anomaly Detection with LLMs](https://arxiv.org/abs/2510.22986)
*Junjie Huang,Minghua He,Jinyang Liu,Yintong Huo,Domenico Bianculli,Michael R. Lyu*

Main category: cs.SE

TL;DR: CodeAD 是一个利用大语言模型（LLMs）自动生成轻量级、可解释 Python 规则函数的日志异常检测框架，通过层次聚类与锚点采样构建对比日志窗口，并采用智能体工作流迭代优化规则，在多个数据集上优于现有方法，兼具高效性、低成本与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习、深度学习和大语言模型的日志异常检测方法存在可解释性差、推理成本高和预处理复杂等问题，而传统规则系统虽高效透明却依赖大量人工且难以扩展。因此，亟需一种兼顾自动化、可解释性、效率与泛化能力的新方法。

Method: CodeAD 框架结合 LLM 自动生成轻量级 Python 规则函数。其核心包括：1）层次聚类与锚点采样策略构建代表性对比日志窗口；2）基于智能体的工作流，对规则进行迭代生成、测试、修复与优化，确保规则正确性与抽象性；3）直接在原始日志上执行生成的规则，实现高效在线检测。

Result: 在 BGL、Hadoop 和 Thunderbird 三个公开数据集上的实验表明，CodeAD 相比当前最优基线平均 F1 分数提升 3.6%，处理速度最高快 4 倍，且每个数据集的 LLM 调用总成本低于 4 美元。

Conclusion: CodeAD 提供了一种实用、可扩展且自动化的日志异常检测方案，兼具可解释性、高效性与低成本，适用于真实环境中的在线监控系统。

Abstract: Log-based anomaly detection (LogAD) is critical for maintaining the
reliability and availability of large-scale online service systems. While
machine learning, deep learning, and large language models (LLMs)-based methods
have advanced the LogAD, they often suffer from limited interpretability, high
inference costs, and extensive preprocessing requirements, limiting their
practicality for real-time, high-volume log analysis. In contrast, rule-based
systems offer efficiency and transparency, but require significant manual
effort and are difficult to scale across diverse and evolving environments. In
this paper, We present CodeAD, a novel framework that automatically synthesizes
lightweight Python rule functions for LogAD using LLMs. CodeAD introduces a
hierarchical clustering and anchor-grounded sampling strategy to construct
representative contrastive log windows, enabling LLMs to discern discriminative
anomaly patterns. To ensure robustness and generalizability, CodeAD employs an
agentic workflow that iteratively generates, tests, repairs, and refines the
rules until it meets correctness and abstraction requirements. The synthesized
rules are interpretable, lightweight, and directly executable on raw logs,
supporting efficient and transparent online anomaly detection. Our
comprehensive experiments on three public datasets (BGL, Hadoop, Thunderbird)
demonstrate that CodeAD achieves an average absolute improvement of 3.6% F1
score over the state-of-the-art baselines, while processing large datasets up
to 4x faster and at a fraction of the cost (total LLM invocation cost under 4
USD per dataset). These results highlight CodeAD as a practical and scalable
solution for online monitoring systems, enabling interpretable, efficient, and
automated LogAD in real-world environment.

</details>


### [10] [Understanding Self-Admitted Technical Debt in Test Code: An Empirical Study](https://arxiv.org/abs/2510.22249)
*Ibuki Nakamura,Yutaro Kashiwa,Bin Lin,Hajimu Iida*

Main category: cs.SE

TL;DR: 该研究揭示了测试代码中自承认技术债务（SATD）的分布与类型，发现其广泛存在但与测试异味无直接关联，并构建了基于CodeBERT的分类模型以自动识别SATD类型。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注生产代码中的SATD，忽视了测试代码中的SATD，且假设两者特性相似；然而测试代码中存在大量不符合现有分类的SATD，亟需系统性研究。

Method: 通过从50个代码仓库中收集17,766条SATD注释（含2,779条测试代码），分析其分布、类型及与测试质量的关系，并构建机器学习模型（特别是CodeBERT）对SATD类型进行自动分类。

Result: 测试代码中存在大量SATD，但与测试异味无显著关联；研究提出了测试代码SATD的完整分类体系，且CodeBERT模型在召回率和F1分数上优于其他模型，但对不同类型SATD的分类效果存在差异。

Conclusion: 测试代码中的SATD具有独特性，不能简单套用生产代码的分类；自动分类模型（如CodeBERT）有助于SATD管理，但需针对不同类型进一步优化。

Abstract: Developers often opt for easier but non-optimal implementation to meet
deadlines or create rapid prototypes, leading to additional effort known as
technical debt to improve the code later. Oftentimes, developers explicitly
document the technical debt in code comments, referred to as Self-Admitted
Technical Debt (SATD). Numerous researchers have investigated the impact of
SATD on different aspects of software quality and development processes.
However, most of these studies focus on SATD in production code, often
overlooking SATD in the test code or assuming that it shares similar
characteristics with SATD in production code. In fact, a significant amount of
SATD is also present in the test code, with many instances not fitting into
existing categories for the production code. This study aims to fill this gap
and disclose the nature of SATD in the test code by examining its distribution
and types. Moreover, the relation between its presence and test quality is also
analyzed. Our empirical study, involving 17,766 SATD comments (14,987 from
production code, 2,779 from test code) collected from 50 repositories,
demonstrates that while SATD widely exists in test code, it is not directly
associated with test smells. Our study also presents comprehensive categories
of SATD types in the test code, and machine learning models are developed to
automatically classify SATD comments based on their types for easier
management. Our results show that the CodeBERT-based model outperforms other
machine learning models in terms of recall and F1-score. However, the
performance varies on different types of SATD.

</details>


### [11] [Ten Simple Rules for AI-Assisted Coding in Science](https://arxiv.org/abs/2510.22254)
*Eric W. Bridgeford,Iain Campbell,Zijao Chen,Zhicheng Lin,Harrison Ritz,Joachim Vandekerckhove,Russell A. Poldrack*

Main category: cs.SE

TL;DR: 本文提出了十条实用规则，指导科研人员在科学计算中合理使用AI编码工具，在提升开发效率的同时确保代码的可靠性、可复现性和科学有效性。


<details>
  <summary>Details</summary>
Motivation: AI编码工具虽能加速软件开发，但在科学计算中可能影响代码质量和科研结果的科学性，因此需要制定兼顾AI能力与科研严谨性的使用准则。

Method: 作者围绕问题准备与理解、上下文与交互管理、测试与验证、代码质量保障与迭代改进四个主题，提出十条AI辅助编码的实践规则。

Result: 所提出的规则强调保持人类在编码决策中的主导权、建立稳健的验证流程，并保留对科研方法至关重要的领域专业知识。

Conclusion: 这些规则有助于研究人员在利用AI提升开发效率的同时，确保其代码符合科研诚信所要求的可靠性、可复现性和科学有效性标准。

Abstract: While AI coding tools have demonstrated potential to accelerate software
development, their use in scientific computing raises critical questions about
code quality and scientific validity. In this paper, we provide ten practical
rules for AI-assisted coding that balance leveraging capabilities of AI with
maintaining scientific and methodological rigor. We address how AI can be
leveraged strategically throughout the development cycle with four key themes:
problem preparation and understanding, managing context and interaction,
testing and validation, and code quality assurance and iterative improvement.
These principles serve to emphasize maintaining human agency in coding
decisions, establishing robust validation procedures, and preserving the domain
expertise essential for methodologically sound research. These rules are
intended to help researchers harness AI's transformative potential for faster
software development while ensuring that their code meets the standards of
reliability, reproducibility, and scientific validity that research integrity
demands.

</details>


### [12] [Harnessing the Power of Large Language Models for Software Testing Education: A Focus on ISTQB Syllabus](https://arxiv.org/abs/2510.22318)
*Tuan-Phong Ngo,Bao-Ngoc Duong,Tuan-Anh Hoang,Joshua Dwight,Ushik Shrestha Khwakhali*

Main category: cs.SE

TL;DR: 本文探讨了大语言模型（LLMs）如何辅助ISTQB软件测试认证框架在高等教育中的应用，构建了包含十余年28套样题的ISTQB数据集，优化了领域专用提示词，系统评估了主流LLMs性能，并提出了将LLMs融入软件测试教育的实用建议。


<details>
  <summary>Details</summary>
Motivation: 尽管ISTQB认证在业界和学术界广泛应用，但其与最新生成式人工智能（尤其是大语言模型）的结合尚未被充分探索。为提升软件测试教育质量，有必要研究LLMs如何支持ISTQB学习与教学。

Method: 构建覆盖十余年、包含28套样题和1,145道题目的ISTQB对齐数据集；设计领域优化提示以提升LLMs在ISTQB任务中的准确性和解释质量；系统评估当前主流LLMs在该数据集上的表现；基于结果提出教育整合建议。

Result: 研究实现了四个关键成果：（i）构建了全面的ISTQB数据集；（ii）开发了提升LLM性能的专用提示；（iii）对多个先进LLM进行了系统评估；（iv）提出了将LLMs融入软件测试教育的具体建议。

Conclusion: 大语言模型在支持ISTQB认证准备方面展现出显著潜力，本研究为LLMs在高等教育中更广泛地应用于软件工程教学奠定了基础。

Abstract: Software testing is a critical component in the software engineering field
and is important for software engineering education. Thus, it is vital for
academia to continuously improve and update educational methods to reflect the
current state of the field. The International Software Testing Qualifications
Board (ISTQB) certification framework is globally recognized and widely adopted
in industry and academia. However, ISTQB-based learning has been rarely applied
with recent generative artificial intelligence advances. Despite the growing
capabilities of large language models (LLMs), ISTQB-based learning and
instruction with LLMs have not been thoroughly explored. This paper explores
and evaluates how LLMs can complement the ISTQB framework for higher education.
The findings present four key contributions: (i) the creation of a
comprehensive ISTQB-aligned dataset spanning over a decade, consisting of 28
sample exams and 1,145 questions; (ii) the development of a domain-optimized
prompt that enhances LLM precision and explanation quality on ISTQB tasks;
(iii) a systematic evaluation of state-of-the-art LLMs on this dataset; and
(iv) actionable insights and recommendations for integrating LLMs into software
testing education. These findings highlight the promise of LLMs in supporting
ISTQB certification preparation and offer a foundation for their broader use in
software engineering at higher education.

</details>


### [13] [Operationalizing Large Language Models with Design-Aware Contexts for Code Comment Generation](https://arxiv.org/abs/2510.22338)
*Aritra Mitra,Srijoni Majumdar,Anamitra Mukhopadhyay,Partha Pratim Das,Paul D Clough,Partha Pratim Chakrabarti*

Main category: cs.SE

TL;DR: 本文探讨利用大语言模型（LLMs）结合设计文档作为上下文，以生成比新手开发者所写更有用的代码注释。


<details>
  <summary>Details</summary>
Motivation: 新手开发者编写的代码注释常常缺乏标准且无用，增加了代码维护成本；而维护者常依赖设计文档理解代码，因此研究尝试利用设计文档作为上下文提升LLM生成注释的质量。

Method: 研究评估大语言模型在以设计文档为上下文的情况下生成代码注释的可行性与效果。

Result: 尚未提供具体实验结果，但研究聚焦于验证设计文档能否有效提升LLM生成注释的有用性。

Conclusion: 利用设计文档作为上下文，大语言模型有望生成更高质量、对维护更有帮助的代码注释。

Abstract: Comments are very useful to the flow of code development. With the increasing
commonality of code, novice coders have been creating a significant amount of
codebases. Due to lack of commenting standards, their comments are often
useless, and increase the time taken to further maintain codes. This study
intends to find the usefulness of large language models (LLMs) in these cases
to generate potentially better comments. This study focuses on the feasibility
of design documents as a context for the LLMs to generate more useful comments,
as design documents are often used by maintainers to understand code when
comments do not suffice.

</details>


### [14] [A First Look at the Self-Admitted Technical Debt in Test Code: Taxonomy and Detection](https://arxiv.org/abs/2510.22409)
*Shahidul Islam,Md Nahidul Islam Opu,Shaowei Wang,Shaiful Chowdhury*

Main category: cs.SE

TL;DR: 本文首次大规模研究了测试代码中的自认技术债务（SATD），通过对1000个开源Java项目中的5万条评论进行人工分析，识别出615条SATD并构建了包含15类的分类体系；评估现有检测工具和大语言模型发现，它们在测试代码SATD检测上表现不佳，表明当前方法尚不可靠。


<details>
  <summary>Details</summary>
Motivation: 尽管源代码中的自认技术债务（SATD）已被广泛研究，但其在测试代码中的存在形式与影响尚未得到关注，导致对测试上下文中SATD的理解存在显著空白。

Method: 从1000个开源Java项目的160万条评论中随机抽取5万条，经人工分析和筛选识别出615条SATD评论，并将其分类构建测试代码SATD分类体系；同时评估了现有SATD检测工具及开源与闭源大语言模型（LLMs）在该任务上的表现。

Result: 识别出15类测试代码SATD；现有工具中MAT表现最佳但召回率一般；开源与闭源LLMs均因精确率低而检测效果差，表明当前方法无法可靠检测测试代码中的SATD。

Conclusion: 本研究首次系统揭示了测试代码中SATD的类型与特征，并指出当前检测方法的局限性，为未来针对测试代码的SATD研究奠定了基础。

Abstract: Self-admitted technical debt (SATD) refers to comments in which developers
explicitly acknowledge code issues, workarounds, or suboptimal solutions. SATD
is known to significantly increase software maintenance effort. While extensive
research has examined SATD in source code, its presence and impact in test code
have received no focused attention, leaving a significant gap in our
understanding of how SATD manifests in testing contexts.
  This study, the first of its kind, investigates SATD in test code by manually
analyzing 50,000 comments randomly sampled from 1.6 million comments across
1,000 open-source Java projects. From this sample, after manual analysis and
filtering, we identified 615 SATD comments and classified them into 15 distinct
categories, building a taxonomy of test code SATD. To investigate whether test
code SATD can be detected automatically, we evaluated existing SATD detection
tools, as well as both open-source and proprietary LLMs. Among the existing
tools, MAT performed the best, albeit with moderate recall. To our surprise,
both open-source and proprietary LLMs exhibited poor detection accuracy,
primarily due to low precision. These results indicate that neither existing
approaches nor current LLMs can reliably detect SATD in test code.
  Overall, this work provides the first large-scale analysis of SATD in test
code, a nuanced understanding of its types, and the limitations of current SATD
detection methods. Our findings lay the groundwork for future research on test
code-specific SATD.

</details>


### [15] [A Multifaceted View on Discrimination in Software Development Careers](https://arxiv.org/abs/2510.22457)
*Shalini Chakraborty,Sebastian Baltes*

Main category: cs.SE

TL;DR: 该研究通过对800份开发者调查的开放式回答进行二次分析，揭示了软件工程领域中除性别和种族外，年龄、政治观点、宗教信仰、残障及神经多样性等多维度歧视同样普遍，且常以交叉形式出现，尤其对女性和非二元性别者影响显著，呼吁研究者在设计研究时纳入更广泛的多样性维度。


<details>
  <summary>Details</summary>
Motivation: 当前软件工程领域关于多样性和包容性的讨论多集中于性别和种族差异，而其他形式的歧视（如年龄、政治观点、残障、神经多样性等）虽同样普遍却未受足够关注。作者旨在揭示这些被忽视的歧视维度及其交叉影响，提升研究社区对歧视多面性的认识。

Method: 对“2025年开发者国家状况”调查中800份开放式回答进行二次分析，识别受访者感知到的歧视模式、相关挑战及负面影响，涵盖年龄、性别、种族、残障等多个身份维度。

Result: 研究发现年龄和性别相关的歧视最为常见，政治和宗教观点歧视也较突出；女性受访者普遍将性别视为主要歧视来源，并常与其他身份因素（如种族、政治观点、年龄、性取向）交叉出现；所有性别身份均报告了因照护责任遭受歧视；女性和非二元性别者在各类职场问题（尤其是歧视35%和心理健康挑战62%）中报告率更高；许多人因性别偏见而调整外貌或行为。

Conclusion: 软件开发中的歧视具有多维性和交叉性，研究者在设计软件工程研究时应超越传统的年龄与性别范畴，纳入更多相关身份维度，以更全面地理解和应对职场不平等问题。

Abstract: Conversations around diversity and inclusion in software engineering often
focus on gender and racial disparities. However, the State of the Developer
Nation 2025 survey with 8,717 participants revealed that other forms of
discrimination are similarly prevalent but receive considerably less attention.
This includes discrimination based on age, political perspective, disabilities,
or cognitive differences such as neurodivergence. We conducted a secondary
analysis of 800 open-ended survey responses to examine patterns of perceived
discrimination, as well as related challenges and negative impacts. Our study
covers multiple identity facets, including age, gender, race, and disability.
We found that age- and gender-related discrimination was the most frequently
reported workplace issue, but discrimination based on political and religious
views emerged as further notable concerns. Most of the participants who
identified as female cited gender as the primary source of discrimination,
often accompanied by intersectional factors such as race, political views, age,
or sexual orientation. Discrimination related to caregiving responsibilities
was reported by all gender identities. Regarding the negative impacts of
workplace issues, many participants described modifying their appearance or
behavior in response to gender biases. Gender also appeared to influence
broader career challenges, as women and non-binary respondents reported
experiencing almost all workplace issues at higher rates, particularly
discrimination (35%) and mental health challenges (62%). Our goal is to raise
awareness in the research community that discrimination in software development
is multifaceted, and to encourage researchers to select and assess relevant
facets beyond age and gender when designing software engineering studies.

</details>


### [16] [DynaCausal: Dynamic Causality-Aware Root Cause Analysis for Distributed Microservices](https://arxiv.org/abs/2510.22613)
*Songhan Zhang,Aoyang Fang,Yifan Yang,Ruiyi Cheng,Xiaoying Tang,Pinjia He*

Main category: cs.SE

TL;DR: 本文提出DynaCausal框架，通过融合多模态动态信号、引入动态对比机制和因果优先排序目标，显著提升云原生微服务系统中根因分析的准确性与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有根因分析方法在捕捉微服务系统中动态行为和变化的服务关系方面存在不足，难以有效应对级联故障传播、噪声干扰与概念漂移以及对服务偏离强度的过度依赖等问题。

Method: DynaCausal统一多模态动态信号，通过交互感知的表征学习捕获时空依赖关系；引入动态对比机制分离真实故障信号与噪声；采用因果优先的成对排序目标优化因果归因。

Result: 在公开基准上的实验表明，DynaCausal在AC@1指标上平均达到0.63，相比现有最优方法提升0.25至0.46，能提供准确且可解释的诊断结果。

Conclusion: DynaCausal有效解决了微服务系统中动态环境下根因分析的关键挑战，显著优于现有方法，在准确性和可解释性方面均表现优异。

Abstract: Cloud-native microservices enable rapid iteration and scalable deployment but
also create complex, fast-evolving dependencies that challenge reliable
diagnosis. Existing root cause analysis (RCA) approaches, even with multi-modal
fusion of logs, traces, and metrics, remain limited in capturing dynamic
behaviors and shifting service relationships. Three critical challenges
persist: (i) inadequate modeling of cascading fault propagation, (ii)
vulnerability to noise interference and concept drift in normal service
behavior, and (iii) over-reliance on service deviation intensity that obscures
true root causes. To address these challenges, we propose DynaCausal, a dynamic
causality-aware framework for RCA in distributed microservice systems.
DynaCausal unifies multi-modal dynamic signals to capture time-varying
spatio-temporal dependencies through interaction-aware representation learning.
It further introduces a dynamic contrastive mechanism to disentangle true fault
indicators from contextual noise and adopts a causal-prioritized pairwise
ranking objective to explicitly optimize causal attribution. Comprehensive
evaluations on public benchmarks demonstrate that DynaCausal consistently
surpasses state-of-the-art methods, attaining an average AC@1 of 0.63 with
absolute gains from 0.25 to 0.46, and delivering both accurate and
interpretable diagnoses in highly dynamic microservice environments.

</details>


### [17] [Does In-IDE Calibration of Large Language Models work at Scale?](https://arxiv.org/abs/2510.22614)
*Roham Koohestani,Agnia Sergeyuk,David Gros,Claudio Spiess,Sergey Titov,Prem Devanbu,Maliheh Izadi*

Main category: cs.SE

TL;DR: 本文研究了在集成开发环境（IDE）中对代码生成大模型进行后验置信度校准的可行性，发现通用的Platt缩放校准方法平均而言并未提升模型置信度与开发者接受行为之间的一致性，但个性化校准在用户交互数据充足时有效；同时通过设计研究发现开发者更偏好在编辑器中使用非数值的颜色编码来展示可靠性信号。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在IDE中的应用虽推动了软件工程的发展，但其生成代码的可靠性与实用性面临挑战。现有研究表明置信度校准可能改善模型输出与可接受性之间的一致性，但缺乏大规模实证支持，且如何向开发者有效传达可靠性信息尚不明确。

Method: 研究分为两部分：一是构建可扩展的校准框架，利用Platt缩放等后验方法对开源模型进行校准，并基于2400万条真实开发者交互数据评估校准效果；二是通过多阶段设计研究（包括场景设计、半结构化访谈和问卷验证），与3名设计师和153名专业开发者合作，探索可靠性信号的最佳呈现方式。

Result: 通用的Platt缩放校准方法平均未能提升模型置信度与开发者接受行为的一致性；个性化校准在用户交互数据量大时有效，但效果高度依赖数据量；开发者普遍偏好在代码生成流程中使用非数值的颜色编码来传达可靠性信号。

Conclusion: 在IDE中对代码生成模型进行通用后验校准未必有效，个性化校准需足够用户数据支持；向开发者传达可靠性信息时，应采用非数值、颜色编码等符合人机交互原则的设计方式。

Abstract: The introduction of large language models into integrated development
environments (IDEs) is revolutionizing software engineering, yet it poses
challenges to the usefulness and reliability of Artificial
Intelligence-generated code. Post-hoc calibration of internal model confidences
aims to align probabilities with an acceptability measure. Prior work suggests
calibration can improve alignment, but at-scale evidence is limited. In this
work, we investigate the feasibility of applying calibration of code models to
an in-IDE context. We study two aspects of the problem: (1) the technical
method for implementing confidence calibration and improving the reliability of
code generation models, and (2) the human-centered design principles for
effectively communicating reliability signal to developers. First, we develop a
scalable and flexible calibration framework which can be used to obtain
calibration weights for open-source models using any dataset, and evaluate
whether calibrators improve the alignment between model confidence and
developer acceptance behavior. Through a large-scale analysis of over 24
million real-world developer interactions across multiple programming
languages, we find that a general, post-hoc calibration model based on
Platt-scaling does not, on average, improve the reliability of model confidence
signals. We also find that while dynamically personalizing calibration to
individual users can be effective, its effectiveness is highly dependent on the
volume of user interaction data. Second, we conduct a multi-phase design study
with 3 expert designers and 153 professional developers, combining
scenario-based design, semi-structured interviews, and survey validation,
revealing a clear preference for presenting reliability signals via
non-numerical, color-coded indicators within the in-editor code generation
workflow.

</details>


### [18] [Collaborative LLM Agents for C4 Software Architecture Design Automation](https://arxiv.org/abs/2510.22787)
*Kamil Szczepanik,Jarosław A. Chudziak*

Main category: cs.SE

TL;DR: 本文提出了一种基于大语言模型（LLM）的多智能体系统，通过模拟领域专家之间的对话，自动生成符合C4规范的软件架构模型（包括Context、Container和Component视图），并采用结合确定性规则检查与LLM评分的混合评估框架验证其质量，在五个典型系统需求上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: C4软件架构模型虽被广泛采用，但其构建过程仍依赖人工，费时费力；因此需要一种自动化方法来提升效率与一致性。

Method: 构建一个多智能体系统，利用多个角色特定的LLM专家协同分析需求，并生成C4模型的三个层级视图；同时设计混合评估框架，结合结构/语法规则检查与LLM作为评判者的语义质量评分。

Result: 在五个标准系统需求上，该方法能快速生成C4模型，保持高编译成功率，并在语义保真度方面表现良好；不同LLM在架构设计任务中展现出各自优势。

Conclusion: 本研究推动了软件架构设计的自动化，并为相关生成结果的质量评估提供了新方法。

Abstract: Software architecture design is a fundamental part of creating every software
system. Despite its importance, producing a C4 software architecture model, the
preferred notation for such architecture, remains manual and time-consuming. We
introduce an LLM-based multi-agent system that automates this task by
simulating a dialogue between role-specific experts who analyze requirements
and generate the Context, Container, and Component views of the C4 model.
Quality is assessed with a hybrid evaluation framework: deterministic checks
for structural and syntactic integrity and C4 rule consistency, plus semantic
and qualitative scoring via an LLM-as-a-Judge approach. Tested on five
canonical system briefs, the workflow demonstrates fast C4 model creation,
sustains high compilation success, and delivers semantic fidelity. A comparison
of four state-of-the-art LLMs shows different strengths relevant to
architectural design. This study contributes to automated software architecture
design and its evaluation methods.

</details>


### [19] [On the Freshness of Pinned Dependencies in Maven](https://arxiv.org/abs/2510.22815)
*Vasudev Vikram,Yuvraj Agarwal,Rohan Padhye*

Main category: cs.SE

TL;DR: 该论文研究了软件生态系统中依赖固定（pinning）现象的普遍性及其风险，发现超过60%的Maven库使用者存在过时依赖固定，其中部分版本已过期一年以上，并可能遗漏安全修复。作者提出名为Pin-Freshener的原型方法，利用同行项目的众包测试来增强开发者对升级安全性的信心，实验表明该方法能显著提升测试覆盖率，并为超过3000个使用者提供安全升级的额外依据。


<details>
  <summary>Details</summary>
Motivation: 依赖固定虽有助于构建可复现性和避免破坏性变更，但可能导致使用含漏洞或缺陷的过时版本。作者旨在量化依赖固定现象的普遍性与风险，并探索如何安全地鼓励开发者更新依赖。

Method: 定义“过时固定”（stale pins）与“新鲜固定”（fresh pins）的概念；对Maven生态系统中流行库的依赖使用情况进行实证分析；提出Pin-Freshener方法，利用众包测试（来自其他项目）评估依赖升级的安全性，并在真实世界数据上评估其效果。

Result: 研究发现60%以上的Maven库使用者存在过时依赖固定，10%的依赖升级可减少安全漏洞；Pin-Freshener仅需1-5个额外测试套件即可提升35%-100%的依赖覆盖率，在前500个流行库中为3000多个使用者提供了至少5个通过的众包测试信号，支持其安全升级。

Conclusion: 依赖固定普遍存在且带来安全隐患，而Pin-Freshener通过引入众包测试信号，能有效增强开发者对依赖升级的信心，是一种优于当前实践的实用方法。

Abstract: Library dependencies in software ecosystems play a crucial role in the
development of software. As newer releases of these libraries are published,
developers may opt to pin their dependencies to a particular version. While
pinning may have benefits in ensuring reproducible builds and avoiding breaking
changes, it bears larger risks in using outdated dependencies that may contain
bugs and security vulnerabilities. To understand the frequency and consequences
of dependency pinning, we first define the concepts of stale and fresh pins,
which are distinguished based on how outdated the dependency is relative to the
release date of the project. We conduct an empirical study to show that over
60% of consumers of popular Maven libraries contain stale pins to their
dependencies, with some outdated versions over a year old. These pinned
versions often miss out on security fixes; we find that 10% of all dependency
upgrades in our dataset to the latest minor or patch version would reduce
security vulnerabilities.
  We prototype an approach called Pin-Freshener that can encourage developers
to freshen their pins by leveraging the insight that crowdsourced tests of peer
projects can provide additional signal for the safety of an upgrade. Running
Pin-Freshener on dependency upgrades shows that just 1-5 additional test suites
can provide 35-100% more coverage of a dependency, compared to that of a single
consumer test suite. Our evaluation on real-world pins to the top 500 popular
libraries in Maven shows that Pin-Freshener can provide an additional signal of
at least 5 passing crowdsourced test suites to over 3,000 consumers to safely
perform an upgrade that reduces security vulnerabilities. Pin-Freshener can
provide practical confidence to developers by offering additional signal beyond
their own test suites, representing an improvement over current practices.

</details>


### [20] [TALM: Dynamic Tree-Structured Multi-Agent Framework with Long-Term Memory for Scalable Code Generation](https://arxiv.org/abs/2510.23010)
*Ming-Tung Shen,Yuh-Jzer Joung*

Main category: cs.SE

TL;DR: 本文提出了TALM，一种结合树状多智能体结构与长期记忆机制的动态框架，用于提升复杂代码生成任务中的推理能力与效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于多智能体的代码生成框架存在工作流僵化和推理恢复成本高的问题，难以有效支持复杂上下文管理和多步推理。

Method: TALM采用可扩展的树状协作结构，结合分治策略实现灵活推理与高效错误修正，并引入长期记忆模块以支持语义查询和经验复用。

Result: 在HumanEval、BigCodeBench和ClassEval基准测试中，TALM展现出优异的推理性能和高token效率。

Conclusion: TALM通过结构化任务分解、局部重推理和长期记忆机制，在复杂代码生成任务中具有强鲁棒性和实用价值。

Abstract: Agentic code generation requires large language models (LLMs) capable of
complex context management and multi-step reasoning. Prior multi-agent
frameworks attempt to address these challenges through collaboration, yet they
often suffer from rigid workflows and high reasoning recovery costs. To
overcome these limitations, we propose TALM (Tree-Structured Multi-Agent
Framework with Long-Term Memory), a dynamic framework that integrates
structured task decomposition, localized re-reasoning, and long-term memory
mechanisms. TALM employs an extensible tree-based collaboration structure. The
parent-child relationships, when combined with a divide-and-conquer strategy,
enhance reasoning flexibility and enable efficient error correction across
diverse task scopes. Furthermore, a long-term memory module enables semantic
querying and integration of prior knowledge, supporting implicit
self-improvement through experience reuse. Experimental results on HumanEval,
BigCodeBench, and ClassEval benchmarks demonstrate that TALM consistently
delivers strong reasoning performance and high token efficiency, highlighting
its robustness and practical utility in complex code generation tasks.

</details>


### [21] [From Online User Feedback to Requirements: Evaluating Large Language Models for Classification and Specification Tasks](https://arxiv.org/abs/2510.23055)
*Manjeshwar Aniruddh Mallya,Alessio Ferrari,Mohammad Amin Zadenoori,Jacek Dąbrowski*

Main category: cs.SE

TL;DR: 本文评估了五种轻量级开源大语言模型（LLMs）在需求工程（RE）中的三项任务上的表现：用户请求分类、非功能性需求（NFR）分类和需求规格生成，结果表明LLMs在分类任务中表现中等至较高（F1值约0.47–0.68），在需求规格生成方面也达到中等偏上质量（平均约3/5），并提供了可复现的实验包和实践洞见。


<details>
  <summary>Details</summary>
Motivation: 在线用户反馈对需求工程具有重要价值，但其体量大、噪声多，分析困难。尽管大语言模型（LLMs）在自动化处理和新任务（如生成需求规格）方面展现出潜力，但目前在需求工程中应用LLMs的研究仍不足，缺乏充分的实证证据、严谨评估和可复现性支持。

Method: 作者在三个需求工程任务上评估了五种轻量级开源LLMs：用户请求分类、非功能性需求分类和需求规格生成。分类任务在两个用户反馈数据集上进行，性能通过F1分数衡量；需求规格质量则通过人工评估打分。

Result: LLMs在分类任务中取得了中等至较高的准确率（F1值约为0.47–0.68），在需求规格生成任务中获得中等偏上的质量评分（平均约为3/5）。

Conclusion: 轻量级开源大语言模型在反馈驱动的需求工程任务中具备实用潜力，但仍有局限。本研究不仅提供了实证评估和可复现包，还为未来在需求工程中应用LLMs提供了有价值的见解。

Abstract: [Context and Motivation] Online user feedback provides valuable information
to support requirements engineering (RE). However, analyzing online user
feedback is challenging due to its large volume and noise. Large language
models (LLMs) show strong potential to automate this process and outperform
previous techniques. They can also enable new tasks, such as generating
requirements specifications.
  [Question-Problem] Despite their potential, the use of LLMs to analyze user
feedback for RE remains underexplored. Existing studies offer limited empirical
evidence, lack thorough evaluation, and rarely provide replication packages,
undermining validity and reproducibility.
  [Principal Idea-Results] We evaluate five lightweight open-source LLMs on
three RE tasks: user request classification, NFR classification, and
requirements specification generation. Classification performance was measured
on two feedback datasets, and specification quality via human evaluation. LLMs
achieved moderate-to-high classification accuracy (F1 ~ 0.47-0.68) and
moderately high specification quality (mean ~ 3/5).
  [Contributions] We newly explore lightweight LLMs for feedback-driven
requirements development. Our contributions are: (i) an empirical evaluation of
lightweight LLMs on three RE tasks, (ii) a replication package, and (iii)
insights into their capabilities and limitations for RE.

</details>


### [22] [Checkstyle+: Reducing Technical Debt Through The Use of Linters with LLMs](https://arxiv.org/abs/2510.23068)
*Ella Dodor,Cristina V. Lopes*

Main category: cs.SE

TL;DR: 本文提出Checkstyle+，一种结合传统规则检查器Checkstyle与大语言模型（LLM）的混合方法，用于检测传统静态分析难以捕捉的语义层面代码风格违规，在380个真实Java代码文件上验证其优于标准Checkstyle。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的代码风格检查工具（如Checkstyle）难以处理需要语义理解的风格规则，而这类规则在实际开发中普遍存在，因此需要更智能的方法来提升检测能力。

Method: 提出Checkstyle+，将大语言模型（LLM）与Checkstyle结合，利用LLM对代码语义的理解能力，识别传统规则引擎无法覆盖的风格违规。

Result: 在从30,800个Codeforces提交中抽取的380个Java文件上进行评估，Checkstyle+在检测语义复杂的风格违规方面表现优于标准Checkstyle。

Conclusion: 结合大语言模型的混合方法能有效弥补传统静态分析工具在代码风格检查中的不足，提升对语义层面风格违规的检测能力。

Abstract: Good code style improves program readability, maintainability, and
collaboration, and is an integral component of software quality. Developers,
however, often cut corners when following style rules, leading to the wide
adoption of tools such as linters in professional software development
projects. Traditional linters like Checkstyle operate using rigid, rule-based
mechanisms that effectively detect many surface-level violations. However, in
most programming languages, there is a subset of style rules that require a
more nuanced understanding of code, and fall outside the scope of such static
analysis. In this paper, we propose Checkstyle+, a hybrid approach that
augments Checkstyle with large language model (LLM) capabilities, to identify
style violations that elude the conventional rule-based analysis. Checkstyle+
is evaluated on a sample of 380 Java code files, drawn from a broader dataset
of 30,800 real-world Java programs sourced from accepted Codeforces
submissions. The results show that Checkstyle+ achieves superior performance
over standard Checkstyle in detecting violations of the semantically nuanced
rules.

</details>


### [23] [Validating Formal Specifications with LLM-generated Test Cases](https://arxiv.org/abs/2510.23350)
*Alcino Cunha,Nuno Macedo*

Main category: cs.SE

TL;DR: 本文评估了使用预训练大语言模型（特别是GPT-5）从自然语言需求自动生成Alloy形式化规约的测试用例的效果，结果表明GPT-5能高效生成语法正确且符合（或不符合）需求的正负测试用例，并能有效检测人为编写的错误规约。


<details>
  <summary>Details</summary>
Motivation: 形式化规约开发中的验证任务（如编写测试用例）繁琐且易错，导致用户可能跳过该步骤；因此需要自动化方法减轻负担。

Method: 利用预训练大语言模型（以GPT-5为主，也包括其他闭源和开源模型）从自然语言描述的结构化需求中自动生成适用于Alloy语言的正负测试用例，并进行实证评估。

Result: GPT-5在生成语法正确、满足或不满足给定需求的测试用例方面表现良好，且能有效识别人工编写的错误规约。

Conclusion: 大语言模型（尤其是GPT-5）在自动化生成形式化规约测试用例方面已具备实用潜力，有助于提升验证效率和质量。

Abstract: Validation is a central activity when developing formal specifications.
Similarly to coding, a possible validation technique is to define upfront test
cases or scenarios that a future specification should satisfy or not.
Unfortunately, specifying such test cases is burdensome and error prone, which
could cause users to skip this validation task. This paper reports the results
of an empirical evaluation of using pre-trained large language models (LLMs) to
automate the generation of test cases from natural language requirements. In
particular, we focus on test cases for structural requirements of simple domain
models formalized in the Alloy specification language. Our evaluation focuses
on the state-of-art GPT-5 model, but results from other closed- and open-source
LLMs are also reported. The results show that, in this context, GPT-5 is
already quite effective at generating positive (and negative) test cases that
are syntactically correct and that satisfy (or not) the given requirement, and
that can detect many wrong specifications written by humans.

</details>


### [24] [Tracing Distribution Shifts with Causal System Maps](https://arxiv.org/abs/2510.23528)
*Joran Leest,Ilias Gerostathopoulos,Patricia Lago,Claudia Raibulet*

Main category: cs.SE

TL;DR: 本文提出ML系统图（ML System Maps）——一种通过分层视图显式展示环境与机器学习系统内部之间传播路径的因果图，用于系统性地归因分布偏移，替代传统依赖人工追溯的方法。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习系统的监控主要关注检测分布偏移，而非其根本原因；根因分析通常依赖人工追溯，效率低下且易出错。

Method: 提出ML系统图，通过构建环境与ML系统内部组件之间的因果传播路径，以分层视图形式支持对分布偏移的系统性归因。

Result: 文章勾勒了该方法的实现路径和未来研究议程，尚未提供实证结果。

Conclusion: ML系统图有望提升对分布偏移原因的系统性理解和自动化诊断能力，为ML系统监控提供新方向。

Abstract: Monitoring machine learning (ML) systems is hard, with standard practice
focusing on detecting distribution shifts rather than their causes. Root-cause
analysis often relies on manual tracing to determine whether a shift is caused
by software faults, data-quality issues, or natural change. We propose ML
System Maps -- causal maps that, through layered views, make explicit the
propagation paths between the environment and the ML system's internals,
enabling systematic attribution of distribution shifts. We outline the approach
and a research agenda for its development and evaluation.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [25] [HandPass: A Wi-Fi CSI Palm Authentication Approach for Access Control](https://arxiv.org/abs/2510.22133)
*Eduardo Fabricio Gomes Trindade,Felipe Silveira de Almeida,Gioliano de Oliveira Braga,Rafael Pimenta de Mattos Paixão,Pedro Henrique dos Santos Rocha,Lourenco Alves Pereira Jr*

Main category: cs.NI

TL;DR: 本文提出一种基于Wi-Fi信道状态信息（CSI）的掌纹生物识别认证方法，利用树莓派采集20名参与者手掌的CSI数据，结合手掌生理特征（如尺寸、形状、手指角度等）对电磁信号的影响，通过随机森林分类器实现了99.82%的平均F1分数，验证了Wi-Fi CSI在掌纹认证中的高准确性和应用潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管Wi-Fi CSI已被广泛用于感知任务，但其在用户身份认证中的实际应用仍待深入探索。本研究旨在利用CSI数据实现基于手掌生物特征的高精度身份认证。

Method: 研究使用天线功率降至1dBm的树莓派设备，采集20名参与者右手的CSI数据；对数据进行MinMax归一化处理，并提取手掌尺寸、形状、手指夹角及指骨长度等生物物理特征；采用五种分类算法进行评估，其中随机森林在10折交叉验证下表现最优；每次采集包含五个5秒间隔，每秒约1000个数据包，同时使用幅度和相位信息。

Result: 随机森林分类器在10折交叉验证中达到了99.82%的平均F1分数，表明基于Wi-Fi CSI的掌纹识别具有极高的识别准确率。

Conclusion: 该研究验证了Wi-Fi CSI在掌纹生物识别认证中的可行性与高效性，为构建稳健可靠的无接触身份认证系统提供了新思路。

Abstract: Wi-Fi Channel State Information (CSI) has been extensively studied for
sensing activities. However, its practical application in user authentication
still needs to be explored. This study presents a novel approach to biometric
authentication using Wi-Fi Channel State Information (CSI) data for palm
recognition. The research delves into utilizing a Raspberry Pi encased in a
custom-built box with antenna power reduced to 1dBm, which was used to capture
CSI data from the right hands of 20 participants (10 men and 10 women). The
dataset was normalized using MinMax scaling to ensure uniformity and accuracy.
By focusing on biophysical aspects such as hand size, shape, angular spread
between fingers, and finger phalanx lengths, among other characteristics, the
study explores how these features affect electromagnetic signals, which are
then reflected in Wi-Fi CSI, allowing for precise user identification. Five
classification algorithms were evaluated, with the Random Forest classifier
achieving an average F1-Score of 99.82\% using 10-fold cross-validation.
Amplitude and Phase data were used, with each capture session recording
approximately 1000 packets per second in five 5-second intervals for each User.
This high accuracy highlights the potential of Wi-Fi CSI in developing robust
and reliable user authentication systems based on palm biometric data.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [26] [Collaborative Task Assignment, Sequencing and Multi-agent Path-finding](https://arxiv.org/abs/2510.21738)
*Yifan Bai,Shruti Kotpalliwar,Christoforos Kanellakis,George Nikolakopoulos*

Main category: cs.MA

TL;DR: 本文提出了一种用于协同任务分配、排序与多智能体路径规划（TSPF）问题的最优完备算法CBS-TS，该算法结合混合整数线性规划（MILP）与基于冲突的搜索（CBS），在保证解最优性的同时提升了计算效率，并在多数实验场景中优于基线方法CBSS。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中任务分配、任务排序与无冲突路径规划联合优化的问题，同时考虑智能体与任务的兼容性约束，并最小化总流程时间（flowtime）。

Method: 提出CBS-TS算法，交替进行任务序列优化与路径冲突消解：使用MILP优化任务序列，利用CBS结合多标签A*（MLA*）在搜索森林中生成无碰撞路径，并仅在必要时调用MILP以限制搜索空间。

Result: 实验表明，CBS-TS在大多数测试场景中优于CBSS，具有更高的成功率并始终获得最优解，而CBSS仅在部分情况下获得近似最优解。

Conclusion: CBS-TS是一种高效、最优且完备的TSPF问题求解方法，在兼顾任务兼容性与无碰撞路径规划的同时，显著优于现有基线方法。

Abstract: In this article, we address the problem of collaborative task assignment,
sequencing, and multi-agent pathfinding (TSPF), where a team of agents must
visit a set of task locations without collisions while minimizing flowtime.
TSPF incorporates agent-task compatibility constraints and ensures that all
tasks are completed. We propose a Conflict-Based Search with Task Sequencing
(CBS-TS), an optimal and complete algorithm that alternates between finding new
task sequences and resolving conflicts in the paths of current sequences.
CBS-TS uses a mixed-integer linear program (MILP) to optimize task sequencing
and employs Conflict-Based Search (CBS) with Multi-Label A* (MLA*) for
collision-free path planning within a search forest. By invoking MILP for the
next-best sequence only when needed, CBS-TS efficiently limits the search
space, enhancing computational efficiency while maintaining optimality. We
compare the performance of our CBS-TS against Conflict-based Steiner Search
(CBSS), a baseline method that, with minor modifications, can address the TSPF
problem. Experimental results demonstrate that CBS-TS outperforms CBSS in most
testing scenarios, achieving higher success rates and consistently optimal
solutions, whereas CBSS achieves near-optimal solutions in some cases. The
supplementary video is available at https://youtu.be/QT8BYgvefmU.

</details>


### [27] [LLM-augmented empirical game theoretic simulation for social-ecological systems](https://arxiv.org/abs/2510.21965)
*Jennifer Shi,Christopher K. Frantz,Christian Kimmich,Saba Siddiki,Atrisha Sarkar*

Main category: cs.MA

TL;DR: 本文比较了四种结合大语言模型（LLM）的建模框架（程序化ABM、生成式ABM、LLM-EGTA和专家引导的LLM-EGTA），用于模拟阿姆河流域灌溉与渔业治理中的集体行为，发现不同方法产生显著不同的行为模式，且基于专家引导的EGTA模型在行为塑造上优于仅依赖系统提示的LLM方法。


<details>
  <summary>Details</summary>
Motivation: 为社会-生态系统设计制度需要能够捕捉异质性、不确定性和策略互动的模型，而当前多种建模方法（如EGTA和LLM驱动模拟）之间的整合方式及其现实行为合理性尚不明确。

Method: 通过在阿姆河流域灌溉与渔业的真实案例中，比较四种LLM增强的建模框架（程序化ABM、生成式ABM、LLM-EGTA、专家引导LLM-EGTA），在集中式与分权式治理下评估其表现。

Result: 1）不同建模框架产生显著不同的集体行为模式；2）通过参数化收益在专家引导的EGTA模型中塑造行为，比仅依赖LLM系统提示更有效。

Conclusion: 方法多样性对理解社会-生态治理至关重要，而将专家知识嵌入博弈结构的LLM-EGTA模型在行为真实性方面更具优势。

Abstract: Designing institutions for social-ecological systems requires models that
capture heterogeneity, uncertainty, and strategic interaction. Multiple
modeling approaches have emerged to meet this challenge, including empirical
game-theoretic analysis (EGTA), which merges ABM's scale and diversity with
game-theoretic models' formal equilibrium analysis. The newly popular class of
LLM-driven simulations provides yet another approach, and it is not clear how
these approaches can be integrated with one another, nor whether the resulting
simulations produce a plausible range of behaviours for real-world
social-ecological governance. To address this gap, we compare four
LLM-augmented frameworks: procedural ABMs, generative ABMs, LLM-EGTA, and
expert guided LLM-EGTA, and evaluate them on a real-world case study of
irrigation and fishing in the Amu Darya basin under centralized and
decentralized governance. Our results show: first, procedural ABMs, generative
ABMs, and LLM-augmented EGTA models produce strikingly different patterns of
collective behaviour, highlighting the value of methodological diversity.
Second, inducing behaviour through system prompts in LLMs is less effective
than shaping behaviour through parameterized payoffs in an expert-guided
EGTA-based model.

</details>


### [28] [CreditXAI: A Multi-Agent System for Explainable Corporate Credit Rating](https://arxiv.org/abs/2510.22222)
*Yumeng Shi,Zhongliang Yang,Yisi Wang,Linna Zhou*

Main category: cs.MA

TL;DR: 本文提出CreditXAI，一种基于多智能体系统的可解释信用评级框架，通过模拟专业分析师的协作决策过程，在提升预测准确率的同时增强模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在企业信用评级中存在“黑箱”问题和可解释性不足，即使引入非财务信息，仍缺乏层次化推理机制，限制了综合分析能力。

Method: 构建一个多智能体系统（MAS）框架CreditXAI，聚焦业务、财务和治理三大风险维度，模拟专业信用分析师的协同决策过程。

Result: 实验表明，多智能体协作相比最优单智能体基线，预测准确率提升超过7%，展现出显著的协同优势。

Conclusion: 该研究为企业信用评级提供了一条构建智能且可解释模型的新技术路径。

Abstract: In the domain of corporate credit rating, traditional deep learning methods
have improved predictive accuracy but still suffer from the inherent
'black-box' problem and limited interpretability. While incorporating
non-financial information enriches the data and provides partial
interpretability, the models still lack hierarchical reasoning mechanisms,
limiting their comprehensive analytical capabilities. To address these
challenges, we propose CreditXAI, a Multi-Agent System (MAS) framework that
simulates the collaborative decision-making process of professional credit
analysts. The framework focuses on business, financial, and governance risk
dimensions to generate consistent and interpretable credit assessments.
Experimental results demonstrate that multi-agent collaboration improves
predictive accuracy by more than 7% over the best single-agent baseline,
confirming its significant synergistic advantage in corporate credit risk
evaluation. This study provides a new technical pathway to build intelligent
and interpretable credit rating models.

</details>


### [29] [IFS: Information Flow Structure for Multi-agent Ad Hoc System](https://arxiv.org/abs/2510.22320)
*Yanqing Fu,Chenrun Wang,Chao Huang,Zhuping Wang*

Main category: cs.MA

TL;DR: 本文提出了一种用于多智能体即兴协作系统的信息流结构（IFS），通过改进通信与信息融合，显著提升了系统的信息流动与处理能力，在StarCraft II实验中表现出优越的泛化能力和协作性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究在多智能体即兴协作系统中存在信息流不足和信息处理能力有限的问题，尤其在开放、动态、部分可观测的环境中，团队组成和行为不断变化，亟需更有效的信息管理机制。

Method: 提出一种信息流结构（IFS），从通信和信息融合两个角度优化多智能体系统中的信息流动与处理能力。

Result: 在StarCraft II环境中的实验表明，IFS显著提升了信息流效率和处理能力，具备良好的泛化性，并在复杂即兴协作场景中优于基线方法。

Conclusion: 所提出的IFS框架有效解决了多智能体即兴协作系统中的关键信息瓶颈问题，为提升开放环境下多智能体协作性能提供了新思路。

Abstract: Multi-agent ad hoc systems are dynamic collaborative systems in which
multiple autonomous agents must cooperate with both known and unknown teammates
in open environments, without relying on pre-coordinated strategies. These
systems operate under conditions of uncertainty and partial observability,
where team composition, agent behaviors, and environmental factors may change
during execution. Through an analysis of information flow in such systems, we
identify two key limitations in existing research: insufficient information
flow and limited information processing capacity. To address these issues, we
propose an information flow structure for multi-agent ad hoc systems (IFS),
which tackles these challenges from the perspectives of communication and
information fusion. Experimental results in StarCraft II demonstrate that IFS
significantly improves both information flow and processing capacity, while
exhibiting strong generalization capabilities and outperforming baseline
methods in complex ad hoc teamwork scenarios.

</details>


### [30] [Group size effects and collective misalignment in LLM multi-agent systems](https://arxiv.org/abs/2510.22422)
*Ariel Flint,Luca Maria Aiello,Romualdo Pastor-Satorras,Andrea Baronchelli*

Main category: cs.MA

TL;DR: 该论文系统研究了基于大语言模型（LLM）的多智能体系统中群体规模对集体行为动态的影响，发现群体规模是非线性地塑造集体偏见的关键因素，并提出平均场方法揭示其在临界规模之上的确定性动态。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要对比单智能体与固定规模群体的行为，忽略了群体规模如何系统性地影响多智能体动态，尤其是集体偏见的形成机制。

Method: 作者在简单协调博弈中模拟不同规模的LLM多智能体交互，分析集体偏见的产生与变化，并构建平均场理论模型以预测大规模下的系统行为。

Result: 研究发现：（1）交互可放大、引入或覆盖个体偏见；（2）群体规模对动态的影响是非线性的，且依赖于模型；（3）超过临界规模后，系统行为趋于确定性，可通过平均场模型预测。

Conclusion: 群体规模是驱动多智能体系统动态的关键变量，在大规模部署基于LLM的系统时必须考虑群体层面的效应。

Abstract: Multi-agent systems of large language models (LLMs) are rapidly expanding
across domains, introducing dynamics not captured by single-agent evaluations.
Yet, existing work has mostly contrasted the behavior of a single agent with
that of a collective of fixed size, leaving open a central question: how does
group size shape dynamics? Here, we move beyond this dichotomy and
systematically explore outcomes across the full range of group sizes. We focus
on multi-agent misalignment, building on recent evidence that interacting LLMs
playing a simple coordination game can generate collective biases absent in
individual models. First, we show that collective bias is a deeper phenomenon
than previously assessed: interaction can amplify individual biases, introduce
new ones, or override model-level preferences. Second, we demonstrate that
group size affects the dynamics in a non-linear way, revealing model-dependent
dynamical regimes. Finally, we develop a mean-field analytical approach and
show that, above a critical population size, simulations converge to
deterministic predictions that expose the basins of attraction of competing
equilibria. These findings establish group size as a key driver of multi-agent
dynamics and highlight the need to consider population-level effects when
deploying LLM-based systems at scale.

</details>


### [31] [Hollywood Town: Long-Video Generation via Cross-Modal Multi-Agent Orchestration](https://arxiv.org/abs/2510.22431)
*Zheng Wei,Mingchen Li,Zeqian Zhang,Ruibin Yuan,Pan Hui,Huamin Qu,James Evans,Maneesh Agrawala,Anyi Rao*

Main category: cs.MA

TL;DR: 本文提出OmniAgent框架，通过类电影制作的层级图结构、超图节点上下文共享机制以及带有限重试的有向循环图，提升多智能体在长视频生成等创造性任务中的协作能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于多智能体系统在执行创造性任务（如长视频生成）时，存在协作效率低、上下文信息不足及缺乏迭代优化机制等问题，亟需更高效、可扩展且具备反思能力的多智能体架构。

Method: 提出OmniAgent框架：1）采用受电影制作启发的层级图结构实现模块化分工；2）引入超图节点支持临时群组讨论以共享上下文；3）将传统有向无环图升级为带有限重试机制的有向循环图，支持智能体迭代优化输出。

Result: 所提方法有效降低了单个智能体的记忆负担，增强了上下文信息的传递与利用，并通过反馈机制提升了整体生成质量，为多智能体在创造性任务中的应用提供了新思路。

Conclusion: OmniAgent框架通过结构创新和协作机制优化，显著提升了多智能体系统在长视频生成等复杂创造性任务中的性能与可扩展性，为未来研究奠定基础。

Abstract: Recent advancements in multi-agent systems have demonstrated significant
potential for enhancing creative task performance, such as long video
generation. This study introduces three innovations to improve multi-agent
collaboration. First, we propose OmniAgent, a hierarchical, graph-based
multi-agent framework for long video generation that leverages a
film-production-inspired architecture to enable modular specialization and
scalable inter-agent collaboration. Second, inspired by context engineering, we
propose hypergraph nodes that enable temporary group discussions among agents
lacking sufficient context, reducing individual memory requirements while
ensuring adequate contextual information. Third, we transition from directed
acyclic graphs (DAGs) to directed cyclic graphs with limited retries, allowing
agents to reflect and refine outputs iteratively, thereby improving earlier
stages through feedback from subsequent nodes. These contributions lay the
groundwork for developing more robust multi-agent systems in creative tasks.

</details>


### [32] [Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence Policy Optimization](https://arxiv.org/abs/2510.22477)
*Yijia Fan,Jusheng Zhang,Jing Yang,Keze Wang*

Main category: cs.MA

TL;DR: Agent-GSPO 是一种通过序列级强化学习优化通信开销的多智能体框架，显著减少令牌使用并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有“自由通信”多智能体系统存在高昂的通信成本问题，亟需一种能兼顾性能与通信效率的新方法。

Method: 提出 Agent-GSPO 框架，采用稳定且内存高效的组序列策略优化（GSPO）算法，在奖励函数中显式惩罚冗余通信，从而优化令牌使用。

Result: 在七个推理基准上，Agent-GSPO 以远低于现有方法的令牌消耗实现了新的最先进性能，并涌现出“策略性沉默”等高效通信策略。

Conclusion: Agent-GSPO 为构建可扩展且经济高效的多智能体系统提供了实用方案。

Abstract: To combat the prohibitive communication costs of ``free-for-all" multi-agent
systems (MAS), we introduce \textbf{Agent-GSPO}, a framework that directly
optimizes for token economy using sequence-level reinforcement learning.
Agent-GSPO leverages the stable and memory-efficient Group Sequence Policy
Optimization (GSPO) algorithm to train agents on a communication-aware reward
that explicitly penalizes verbosity. Across seven reasoning benchmarks,
Agent-GSPO not only achieves new state-of-the-art performance but does so with
a fraction of the token consumption of existing methods. By fostering emergent
strategies like ``strategic silence," our approach provides a practical
blueprint for developing scalable and economically viable multi-agent systems.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [33] [Rethinking Inference Placement for Deep Learning across Edge and Cloud Platforms: A Multi-Objective Optimization Perspective and Future Directions](https://arxiv.org/abs/2510.22909)
*Zongshun Zhang,Ibrahim Matta*

Main category: cs.DC

TL;DR: 该综述探讨了在边缘计算环境中，如何通过模型卸载与模型自适应技术，在推理延迟、数据隐私和资源成本之间实现多目标优化。


<details>
  <summary>Details</summary>
Motivation: 边缘智能应用（如VR/AR和基于大语言模型的聊天机器人）日益普及，但受限的边缘设备难以承载日益庞大复杂的深度学习模型，亟需在设备、边缘服务器与云之间高效分配模型计算任务。

Method: 综述并分析了当前主流的模型卸载方法和模型自适应技术，包括模型压缩、知识蒸馏、传输压缩及带内部分类器的架构调整，并将其置于推理延迟、数据隐私和资源成本的多目标优化框架下进行评估。

Result: 现有研究在平衡准确率、计算延迟、传输延迟和隐私风险方面取得进展，通过多种技术手段缓解通信瓶颈与数据泄露问题。

Conclusion: 未来工作需进一步优化多目标权衡机制，以支持更高效、安全且经济的边缘智能应用部署。

Abstract: Edge intelligent applications like VR/AR and language model based chatbots
have become widespread with the rapid expansion of IoT and mobile devices.
However, constrained edge devices often cannot serve the increasingly large and
complex deep learning (DL) models. To mitigate these challenges, researchers
have proposed optimizing and offloading partitions of DL models among user
devices, edge servers, and the cloud. In this setting, users can take advantage
of different services to support their intelligent applications. For example,
edge resources offer low response latency. In contrast, cloud platforms provide
low monetary cost computation resources for computation-intensive workloads.
However, communication between DL model partitions can introduce transmission
bottlenecks and pose risks of data leakage. Recent research aims to balance
accuracy, computation delay, transmission delay, and privacy concerns. They
address these issues with model compression, model distillation, transmission
compression, and model architecture adaptations, including internal
classifiers. This survey contextualizes the state-of-the-art model offloading
methods and model adaptation techniques by studying their implication to a
multi-objective optimization comprising inference latency, data privacy, and
resource monetary cost.

</details>


### [34] [When Agents are Powerful: Black Hole Search in Time-Varying Graphs](https://arxiv.org/abs/2510.22309)
*Tanvir Kaur,Ashish Saxena*

Main category: cs.DC

TL;DR: 本文研究动态图中的黑洞搜索（BHS）问题，通过赋予智能体全局通信能力和1跳可见性，显著提升了搜索效率。


<details>
  <summary>Details</summary>
Motivation: 在动态图中，传统基于面对面通信模型的黑洞搜索需要大量智能体，效率低下；本文旨在通过增强智能体能力来降低资源需求并提高效率。

Method: 为智能体引入两种增强能力：(i) 全局通信，使智能体无论位置均可交换信息；(ii) 1跳可见性，使其能观察邻近节点状态。

Result: 所提出的方法在动态图中实现了更高效的黑洞搜索，减少了所需智能体数量并提升了问题求解效率。

Conclusion: 通过增强智能体的通信与感知能力，可在动态图中更高效地解决黑洞搜索问题，为相关分布式计算任务提供新思路。

Abstract: A black hole is a harmful node in a graph that destroys any resource entering
it, making its identification a critical task. In the \emph{Black Hole Search
(BHS)} problem, a team of agents operates on a graph $G$ with the objective
that at least one agent must survive and correctly identify an edge incident to
the black hole. Prior work has addressed BHS in arbitrary dynamic graphs under
the restrictive \emph{face-to-face} communication, where agents can exchange
information only when co-located. This constraint significantly increases the
number of agents required to solve the problem. In this work, we strengthen the
capabilities of agents in two ways: (i) granting them \emph{global
communication}, enabling interaction regardless of location, and (ii) equipping
them with \emph{1-hop visibility}, allowing each agent to observe its immediate
neighborhood. These enhancements lead to more efficient solutions for the BHS
problem in dynamic graphs.

</details>


### [35] [Separation of Unconscious Robots with Obstructed Visibility](https://arxiv.org/abs/2510.22434)
*Prajyot Pyati,Navjot Kaur,Saswata Jana,Adri Bhattacharya,Partha Sarathi Mandal*

Main category: cs.DC

TL;DR: 本文研究了在不透明机器人模型下，无意识移动机器人如何在受阻可见性条件下通过半同步调度实现同心半圆分离的问题，并提出了一种在$O(n)$轮内完成该任务的无碰撞算法。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设机器人是透明的，即每个机器人都能观测到所有其他机器人的位置和颜色。然而，现实中机器人可能是不透明的，会遮挡视线。因此，本文旨在探索在更贴近现实的不透明模型下，如何解决无意识机器人的分离问题。

Method: 作者提出了一种无碰撞算法，适用于半同步调度环境，机器人仅需共享一个坐标轴方向，无需知道总数量$n$，并在受阻可见性条件下实现同心半圆的分离。

Result: 该算法能够在$O(n)$个周期内成功将无意识、不透明的机器人从任意初始配置分离成同心半圆结构。

Conclusion: 本文首次在不透明机器人模型下解决了无意识机器人的分离问题，展示了即使在受阻可见性和有限感知能力下，仍可高效实现特定几何构型的形成。

Abstract: We study a recently introduced \textit{unconscious} mobile robot model, where
each robot is associated with a \textit{color}, which is visible to other
robots but not to itself. The robots are autonomous, anonymous, oblivious and
silent, operating in the Euclidean plane under the conventional
\textit{Look-Compute-Move} cycle. A primary task in this model is the
\textit{separation problem}, where unconscious robots sharing the same color
must separate from others, forming recognizable geometric shapes such as
circles, points, or lines. All prior works model the robots as
\textit{transparent}, enabling each to know the positions and colors of all
other robots. In contrast, we model the robots as \textit{opaque}, where a
robot can obstruct the visibility of two other robots, if it lies on the line
segment between them. Under this obstructed visibility, we consider a variant
of the separation problem in which robots, starting from any arbitrary initial
configuration, are required to separate into concentric semicircles. We present
a collision-free algorithm that solves the separation problem under a
semi-synchronous scheduler in $O(n)$ epochs, where $n$ is the number of robots.
The robots agree on one coordinate axis but have no knowledge of $n$.

</details>
