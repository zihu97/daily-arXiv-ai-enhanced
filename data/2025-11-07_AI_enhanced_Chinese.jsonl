{"id": "2511.03875", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03875", "abs": "https://arxiv.org/abs/2511.03875", "authors": ["Julian Frattini", "Hans-Martin Heyn", "Robert Feldt", "Richard Torkar"], "title": "Tutorial Debriefing: Applied Statistical Causal Inference in Requirements Engineering", "comment": null, "summary": "As any scientific discipline, the software engineering (SE) research\ncommunity strives to contribute to the betterment of the target population of\nour research: software producers and consumers. We will only achieve this\nbetterment if we manage to transfer the knowledge acquired during research into\npractice. This transferal of knowledge may come in the form of tools,\nprocesses, and guidelines for software developers. However, the value of these\ncontributions hinges on the assumption that applying them causes an improvement\nof the development process, user experience, or other performance metrics. Such\na promise requires evidence of causal relationships between an exposure or\nintervention (i.e., the contributed tool, process or guideline) and an outcome\n(i.e., performance metrics). A straight-forward approach to obtaining this\nevidence is via controlled experiments in which a sample of a population is\nrandomly divided into a group exposed to the new tool, process, or guideline,\nand a control group. However, such randomized control trials may not be\nlegally, ethically, or logistically feasible. In these cases, we need a\nreliable process for statistical causal inference (SCI) from observational\ndata.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u56e0\u679c\u63a8\u65ad\u5c06\u7814\u7a76\u6210\u679c\u6709\u6548\u8f6c\u5316\u4e3a\u5b9e\u8df5\uff0c\u5c24\u5176\u5728\u65e0\u6cd5\u8fdb\u884c\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u65f6\uff0c\u5f3a\u8c03\u5229\u7528\u89c2\u5bdf\u6027\u6570\u636e\u8fdb\u884c\u7edf\u8ba1\u56e0\u679c\u63a8\u65ad\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u65e8\u5728\u6539\u5584\u8f6f\u4ef6\u5f00\u53d1\u8005\u4e0e\u7528\u6237\u7684\u5b9e\u8df5\u548c\u4f53\u9a8c\uff0c\u4f46\u5176\u6210\u679c\uff08\u5982\u5de5\u5177\u3001\u6d41\u7a0b\u3001\u6307\u5357\uff09\u7684\u4ef7\u503c\u4f9d\u8d56\u4e8e\u80fd\u5426\u8bc1\u660e\u5176\u5bf9\u6027\u80fd\u6307\u6807\u5177\u6709\u56e0\u679c\u6548\u5e94\u3002\u7136\u800c\uff0c\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u5e38\u56e0\u6cd5\u5f8b\u3001\u4f26\u7406\u6216\u5b9e\u9645\u9650\u5236\u4e0d\u53ef\u884c\uff0c\u56e0\u6b64\u9700\u8981\u53ef\u9760\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5728\u65e0\u6cd5\u5f00\u5c55\u968f\u673a\u5bf9\u7167\u8bd5\u9a8c\u7684\u60c5\u51b5\u4e0b\uff0c\u91c7\u7528\u57fa\u4e8e\u89c2\u5bdf\u6027\u6570\u636e\u7684\u7edf\u8ba1\u56e0\u679c\u63a8\u65ad\uff08SCI\uff09\u65b9\u6cd5\u6765\u9a8c\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u5e72\u9884\u63aa\u65bd\u7684\u6709\u6548\u6027\u3002", "result": "\u6587\u7ae0\u6307\u51fa\u7edf\u8ba1\u56e0\u679c\u63a8\u65ad\u53ef\u4f5c\u4e3a\u8bc4\u4f30\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u5e72\u9884\u6548\u679c\u7684\u53ef\u884c\u4e14\u53ef\u9760\u7684\u65b9\u6cd5\uff0c\u4e3a\u77e5\u8bc6\u8f6c\u5316\u63d0\u4f9b\u5b9e\u8bc1\u57fa\u7840\u3002", "conclusion": "\u4e3a\u4e86\u786e\u4fdd\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u6210\u679c\u771f\u6b63\u6709\u76ca\u4e8e\u5b9e\u8df5\uff0c\u7814\u7a76\u8005\u5e94\u91cd\u89c6\u5e76\u5e94\u7528\u7edf\u8ba1\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u5c24\u5176\u662f\u5728\u65e0\u6cd5\u8fdb\u884c\u968f\u673a\u5b9e\u9a8c\u7684\u60c5\u5883\u4e0b\u3002"}}
{"id": "2511.03925", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03925", "abs": "https://arxiv.org/abs/2511.03925", "authors": ["Nikta Akbarpour", "Mahdieh Sadat Benis", "Fatemeh Hendijani Fard", "Ali Ouni", "Mohamed Aymen Saied"], "title": "Collaborative Agents for Automated Program Repair in Ruby", "comment": null, "summary": "Automated Program Repair (APR) has advanced rapidly with Large Language\nModels (LLMs), but most existing methods remain computationally expensive, and\nfocused on a small set of languages. Ruby, despite its widespread use in web\ndevelopment and the persistent challenges faced by its developers, has received\nlittle attention in APR research. In this paper, we introduce RAMP, a novel\nlightweight framework that formulates program repair as a feedback-driven,\niterative process for Ruby. RAMP employs a team of collaborative agents that\ngenerate targeted tests, reflect on errors, and refine candidate fixes until a\ncorrect solution is found. Unlike prior approaches, RAMP is designed to avoid\nreliance on large multilingual repair databases or costly fine-tuning, instead\noperating directly on Ruby through lightweight prompting and test-driven\nfeedback. Evaluation on the XCodeEval benchmark shows that RAMP achieves a\npass@1 of 67% on Ruby, outper-forming prior approaches. RAMP converges quickly\nwithin five iterations, and ablation studies confirm that test generation and\nself-reflection are key drivers of its performance. Further analysis shows that\nRAMP is particularly effective at repairing wrong answers, compilation errors,\nand runtime errors. Our approach provides new insights into multi-agent repair\nstrategies, and establishes a foundation for extending LLM-based debugging\ntools to under-studied languages.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RAMP\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8eRuby\u8bed\u8a00\u7684\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6d4b\u8bd5\u9a71\u52a8\u7684\u53cd\u9988\u673a\u5236\u8fed\u4ee3\u4f18\u5316\u4fee\u590d\u65b9\u6848\uff0c\u5728XCodeEval\u57fa\u51c6\u4e0a\u4ee567%\u7684pass@1\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u4e3b\u8981\u805a\u7126\u4e8e\u5c11\u6570\u7f16\u7a0b\u8bed\u8a00\uff0c\u800c\u5e7f\u6cdb\u7528\u4e8eWeb\u5f00\u53d1\u7684Ruby\u8bed\u8a00\u5728APR\u7814\u7a76\u4e2d\u88ab\u5ffd\u89c6\u3002", "method": "RAMP\u91c7\u7528\u534f\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7\u751f\u6210\u9488\u5bf9\u6027\u6d4b\u8bd5\u3001\u9519\u8bef\u53cd\u601d\u548c\u5019\u9009\u4fee\u590d\u8fed\u4ee3\u4f18\u5316\uff0c\u65e0\u9700\u4f9d\u8d56\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u4fee\u590d\u6570\u636e\u5e93\u6216\u6602\u8d35\u5fae\u8c03\uff0c\u4ec5\u4f9d\u9760\u8f7b\u91cf\u7ea7\u63d0\u793a\u548c\u6d4b\u8bd5\u53cd\u9988\u76f4\u63a5\u4f5c\u7528\u4e8eRuby\u4ee3\u7801\u3002", "result": "\u5728XCodeEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRAMP\u5728Ruby\u4efb\u52a1\u4e0a\u8fbe\u523067%\u7684pass@1\u51c6\u786e\u7387\uff0c\u901a\u5e38\u5728\u4e94\u6b21\u8fed\u4ee3\u5185\u6536\u655b\uff1b\u6d88\u878d\u5b9e\u9a8c\u8bc1\u660e\u6d4b\u8bd5\u751f\u6210\u4e0e\u81ea\u6211\u53cd\u601d\u662f\u6027\u80fd\u5173\u952e\uff1b\u8be5\u65b9\u6cd5\u5bf9\u9519\u8bef\u7b54\u6848\u3001\u7f16\u8bd1\u9519\u8bef\u548c\u8fd0\u884c\u65f6\u9519\u8bef\u5c24\u4e3a\u6709\u6548\u3002", "conclusion": "RAMP\u4e3a\u591a\u667a\u80fd\u4f53\u4fee\u590d\u7b56\u7565\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5e76\u4e3a\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u8c03\u8bd5\u5de5\u5177\u6269\u5c55\u5230\u7814\u7a76\u8f83\u5c11\u7684\u8bed\u8a00\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.03934", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03934", "abs": "https://arxiv.org/abs/2511.03934", "authors": ["Athma Narayanan", "Mahesh Subedar", "Omesh Tickoo"], "title": "PEFA-AI: Advancing Open-source LLMs for RTL generation using Progressive Error Feedback Agentic-AI", "comment": "Appeared in the Design Automation Conference (DAC) 2025, Workshop\n  Poster on June 22, 2025", "summary": "We present an agentic flow consisting of multiple agents that combine\nspecialized LLMs and hardware simulation tools to collaboratively complete the\ncomplex task of Register Transfer Level (RTL) generation without human\nintervention. A key feature of the proposed flow is the progressive error\nfeedback system of agents (PEFA), a self-correcting mechanism that leverages\niterative error feedback to progressively increase the complexity of the\napproach. The generated RTL includes checks for compilation, functional\ncorrectness, and synthesizable constructs. To validate this adaptive approach\nto code generation, benchmarking is performed using two opensource natural\nlanguage-to-RTL datasets. We demonstrate the benefits of the proposed approach\nimplemented on an open source agentic framework, using both open- and\nclosed-source LLMs, effectively bridging the performance gap between them.\nCompared to previously published methods, our approach sets a new benchmark,\nproviding state-of-the-art pass rates while being efficient in token counts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u534f\u540c\u6d41\u7a0b\uff0c\u7ed3\u5408\u4e13\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u786c\u4ef6\u4eff\u771f\u5de5\u5177\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u9519\u8bef\u53cd\u9988\u673a\u5236\uff08PEFA\uff09\u81ea\u52a8\u751f\u6210\u53ef\u7efc\u5408\u3001\u529f\u80fd\u6b63\u786e\u7684\u5bc4\u5b58\u5668\u4f20\u8f93\u7ea7\uff08RTL\uff09\u4ee3\u7801\uff0c\u5728\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u5f53\u524d\u6700\u4f18\u7684RTL\u751f\u6210\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u81ea\u7136\u8bed\u8a00\u5230RTL\u7684\u81ea\u52a8\u8f6c\u6362\u65b9\u6cd5\u5728\u529f\u80fd\u6b63\u786e\u6027\u3001\u53ef\u7efc\u5408\u6027\u53ca\u81ea\u52a8\u5316\u7a0b\u5ea6\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u81ea\u6211\u7ea0\u9519\u3001\u9ad8\u6548\u4e14\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u7684\u751f\u6210\u6d41\u7a0b\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u96c6\u6210\u4e13\u7528LLM\u4e0e\u786c\u4ef6\u4eff\u771f\u5de5\u5177\uff0c\u5e76\u5f15\u5165\u6e10\u8fdb\u5f0f\u9519\u8bef\u53cd\u9988\u7cfb\u7edf\uff08PEFA\uff09\uff0c\u901a\u8fc7\u8fed\u4ee3\u53cd\u9988\u9010\u6b65\u63d0\u5347\u751f\u6210\u590d\u6742\u5ea6\uff0c\u786e\u4fdd\u751f\u6210\u7684RTL\u901a\u8fc7\u7f16\u8bd1\u3001\u529f\u80fd\u9a8c\u8bc1\u548c\u53ef\u7efc\u5408\u6027\u68c0\u67e5\u3002", "result": "\u5728\u4e24\u4e2a\u5f00\u6e90NL-to-RTL\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u8fbe\u5230\u6700\u9ad8\u7684\u901a\u8fc7\u7387\uff0c\u540c\u65f6\u5728token\u4f7f\u7528\u6548\u7387\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u7f29\u5c0f\u4e86\u5f00\u6e90\u4e0e\u95ed\u6e90LLM\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8ePEFA\u7684\u591a\u667a\u80fd\u4f53\u6d41\u7a0b\u4e3aRTL\u81ea\u52a8\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u9760\u4e14\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u8868\u4e86\u8be5\u9886\u57df\u7684\u65b0\u524d\u6cbf\u3002"}}
{"id": "2511.04012", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04012", "abs": "https://arxiv.org/abs/2511.04012", "authors": ["Yongxi Chen", "Lei Chen"], "title": "PSD2Code: Automated Front-End Code Generation from Design Files via Multimodal Large Language Models", "comment": null, "summary": "Design-to-code generation has emerged as a promising approach to bridge the\ngap between design prototypes and deployable frontend code. However, existing\nmethods often suffer from structural inconsistencies, asset misalignment, and\nlimited production readiness. This paper presents PSD2Code, a novel multi-modal\napproach that leverages PSD file parsing and asset alignment to generate\nproduction-ready React+SCSS code. Our method introduces a ParseAlignGenerate\npipeline that extracts hierarchical structures, layer properties, and metadata\nfrom PSD files, providing large language models with precise spatial\nrelationships and semantic groupings for frontend code generation. The system\nemploys a constraint-based alignment strategy that ensures consistency between\ngenerated elements and design resources, while a structured prompt construction\nenhances controllability and code quality. Comprehensive evaluation\ndemonstrates significant improvements over existing methods across multiple\nmetrics including code similarity, visual fidelity, and production readiness.\nThe method exhibits strong model independence across different large language\nmodels, validating the effectiveness of integrating structured design\ninformation with multimodal large language models for industrial-grade code\ngeneration, marking an important step toward design-driven automated frontend\ndevelopment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPSD2Code\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u6001\u7684\u4ecePSD\u8bbe\u8ba1\u7a3f\u751f\u6210\u751f\u4ea7\u7ea7React+SCSS\u4ee3\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7Parse-Align-Generate\u6d41\u7a0b\u663e\u8457\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u4e0e\u89c6\u89c9\u4fdd\u771f\u5ea6\u3002", "motivation": "\u73b0\u6709\u8bbe\u8ba1\u5230\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u5e38\u5b58\u5728\u7ed3\u6784\u4e0d\u4e00\u81f4\u3001\u8d44\u6e90\u9519\u4f4d\u548c\u7f3a\u4e4f\u751f\u4ea7\u5c31\u7eea\u6027\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u66f4\u53ef\u9760\u4e14\u5de5\u4e1a\u53ef\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faParseAlignGenerate\u6d41\u6c34\u7ebf\uff0c\u4ecePSD\u6587\u4ef6\u4e2d\u63d0\u53d6\u5c42\u7ea7\u7ed3\u6784\u3001\u56fe\u5c42\u5c5e\u6027\u548c\u5143\u6570\u636e\uff0c\u7ed3\u5408\u7ea6\u675f\u5bf9\u9f50\u7b56\u7565\u4e0e\u7ed3\u6784\u5316\u63d0\u793a\uff0c\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u9ad8\u4fdd\u771f\u3001\u53ef\u90e8\u7f72\u7684\u524d\u7aef\u4ee3\u7801\u3002", "result": "\u5728\u4ee3\u7801\u76f8\u4f3c\u6027\u3001\u89c6\u89c9\u4fdd\u771f\u5ea6\u548c\u751f\u4ea7\u5c31\u7eea\u6027\u7b49\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u5728\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6a21\u578b\u65e0\u5173\u6027\u3002", "conclusion": "\u5c06\u7ed3\u6784\u5316\u8bbe\u8ba1\u4fe1\u606f\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u80fd\u6709\u6548\u5b9e\u73b0\u5de5\u4e1a\u7ea7\u524d\u7aef\u4ee3\u7801\u81ea\u52a8\u751f\u6210\uff0c\u63a8\u52a8\u8bbe\u8ba1\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u524d\u7aef\u5f00\u53d1\u3002"}}
{"id": "2511.03944", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.03944", "abs": "https://arxiv.org/abs/2511.03944", "authors": ["Tong Zhang", "Vikram Sharma Mailthody", "Fei Sun", "Linsen Ma", "Chris J. Newburn", "Teresa Zhang", "Yang Liu", "Jiangpeng Li", "Hao Zhong", "Wen-Mei Hwu"], "title": "From Minutes to Seconds: Redefining the Five-Minute Rule for AI-Era Memory Hierarchies", "comment": "13 pages, 10 figures", "summary": "In 1987, Jim Gray and Gianfranco Putzolu introduced the five-minute rule, a\nsimple, storage-memory-economics-based heuristic for deciding when data should\nlive in DRAM rather than on storage. Subsequent revisits to the rule largely\nretained that economics-only view, leaving host costs, feasibility limits, and\nworkload behavior out of scope. This paper revisits the rule from first\nprinciples, integrating host costs, DRAM bandwidth/capacity, and\nphysics-grounded models of SSD performance and cost, and then embedding these\nelements in a constraint- and workload-aware framework that yields actionable\nprovisioning guidance. We show that, for modern AI platforms, especially\nGPU-centric hosts paired with ultra-high-IOPS SSDs engineered for fine-grained\nrandom access, the DRAM-to-flash caching threshold collapses from minutes to a\nfew seconds. This shift reframes NAND flash memory as an active data tier and\nexposes a broad research space across the hardware-software stack. We further\nintroduce MQSim-Next, a calibrated SSD simulator that supports validation and\nsensitivity analysis and facilitates future architectural and system research.\nFinally, we present two concrete case studies that showcase the software system\ndesign space opened by such memory hierarchy paradigm shift. Overall, we turn a\nclassical heuristic into an actionable, feasibility-aware analysis and\nprovisioning framework and set the stage for further research on AI-era memory\nhierarchy.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u7ecf\u5178\u7684\u4e94\u5206\u949f\u89c4\u5219\uff0c\u7ed3\u5408\u73b0\u4ee3AI\u5e73\u53f0\u7684\u786c\u4ef6\u7279\u6027\uff08\u5982GPU\u4e3b\u673a\u548c\u9ad8\u6027\u80fdSSD\uff09\uff0c\u63d0\u51faDRAM\u4e0e\u95ea\u5b58\u4e4b\u95f4\u7684\u7f13\u5b58\u9608\u503c\u5df2\u4ece\u5206\u949f\u7ea7\u7f29\u77ed\u81f3\u79d2\u7ea7\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u8003\u8651\u6210\u672c\u3001\u6027\u80fd\u7ea6\u675f\u548c\u5de5\u4f5c\u8d1f\u8f7d\u7684\u53ef\u884c\u6027\u611f\u77e5\u5206\u6790\u6846\u67b6\u3002", "motivation": "\u539f\u59cb\u7684\u4e94\u5206\u949f\u89c4\u5219\u4ec5\u57fa\u4e8e\u5b58\u50a8\u4e0e\u5185\u5b58\u7684\u7ecf\u6d4e\u6027\uff0c\u5ffd\u7565\u4e86\u4e3b\u673a\u6210\u672c\u3001DRAM\u5e26\u5bbd/\u5bb9\u91cf\u9650\u5236\u3001SSD\u7269\u7406\u6027\u80fd\u6a21\u578b\u4ee5\u53ca\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\uff0c\u96be\u4ee5\u9002\u7528\u4e8e\u73b0\u4ee3AI\u7cfb\u7edf\u3002", "method": "\u4ece\u7b2c\u4e00\u6027\u539f\u7406\u51fa\u53d1\uff0c\u6574\u5408\u4e3b\u673a\u6210\u672c\u3001DRAM\u5e26\u5bbd\u4e0e\u5bb9\u91cf\u3001\u57fa\u4e8e\u7269\u7406\u7684SSD\u6027\u80fd\u4e0e\u6210\u672c\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u5d4c\u5165\u4e00\u4e2a\u8003\u8651\u7ea6\u675f\u6761\u4ef6\u548c\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5206\u6790\u6846\u67b6\uff1b\u540c\u65f6\u5f00\u53d1\u4e86\u6821\u51c6\u540e\u7684SSD\u6a21\u62df\u5668MQSim-Next\u4ee5\u652f\u6301\u9a8c\u8bc1\u4e0e\u654f\u611f\u6027\u5206\u6790\u3002", "result": "\u53d1\u73b0\u5bf9\u4e8e\u73b0\u4ee3AI\u5e73\u53f0\uff0c\u5c24\u5176\u662f\u914d\u5907\u8d85\u9ad8IOPS SSD\u7684GPU\u4e2d\u5fc3\u5316\u4e3b\u673a\uff0cDRAM\u5230\u95ea\u5b58\u7684\u7f13\u5b58\u9608\u503c\u7f29\u77ed\u81f3\u51e0\u79d2\uff1b\u5e76\u5c55\u793a\u4e86\u4e24\u4e2a\u8f6f\u4ef6\u7cfb\u7edf\u8bbe\u8ba1\u6848\u4f8b\uff0c\u8bf4\u660e\u8be5\u8303\u5f0f\u8f6c\u53d8\u5e26\u6765\u7684\u65b0\u8bbe\u8ba1\u7a7a\u95f4\u3002", "conclusion": "\u5c06\u7ecf\u5178\u7684\u4e94\u5206\u949f\u89c4\u5219\u8f6c\u5316\u4e3a\u4e00\u4e2a\u53ef\u884c\u3001\u53ef\u64cd\u4f5c\u7684\u5206\u6790\u4e0e\u914d\u7f6e\u6846\u67b6\uff0c\u4e3aAI\u65f6\u4ee3\u5185\u5b58\u5c42\u6b21\u7ed3\u6784\u7684\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.03866", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.03866", "abs": "https://arxiv.org/abs/2511.03866", "authors": ["Arijit Bhattacharjee", "Ali TehraniJamsaz", "Le Chen", "Niranjan Hasabnis", "Mihai Capota", "Nesreen Ahmed", "Ali Jannesari"], "title": "OMPILOT: Harnessing Transformer Models for Auto Parallelization to Shared Memory Computing Paradigms", "comment": null, "summary": "Recent advances in large language models (LLMs) have significantly\naccelerated progress in code translation, enabling more accurate and efficient\ntransformation across programming languages. While originally developed for\nnatural language processing, LLMs have shown strong capabilities in modeling\nprogramming language syntax and semantics, outperforming traditional rule-based\nsystems in both accuracy and flexibility. These models have streamlined\ncross-language conversion, reduced development overhead, and accelerated legacy\ncode migration. In this paper, we introduce OMPILOT, a novel domain-specific\nencoder-decoder transformer tailored for translating C++ code into OpenMP,\nenabling effective shared-memory parallelization. OMPILOT leverages custom\npre-training objectives that incorporate the semantics of parallel constructs\nand combines both unsupervised and supervised learning strategies to improve\ncode translation robustness. Unlike previous work that focused primarily on\nloop-level transformations, OMPILOT operates at the function level to capture a\nwider semantic context. To evaluate our approach, we propose OMPBLEU, a novel\ncomposite metric specifically crafted to assess the correctness and quality of\nOpenMP parallel constructs, addressing limitations in conventional translation\nmetrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86OMPILOT\uff0c\u4e00\u79cd\u4e13\u7528\u4e8e\u5c06C++\u4ee3\u7801\u7ffb\u8bd1\u4e3aOpenMP\u5e76\u884c\u4ee3\u7801\u7684\u9886\u57df\u7279\u5b9a\u7f16\u7801\u5668-\u89e3\u7801\u5668Transformer\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u65b0\u8bc4\u4f30\u6307\u6807OMPBLEU\u3002", "motivation": "\u4f20\u7edf\u89c4\u5219\u7cfb\u7edf\u5728\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\u4e0d\u8db3\uff0c\u800c\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u867d\u6709\u8fdb\u5c55\uff0c\u4f46\u5728\u51fd\u6570\u7ea7\u5e76\u884c\u8bed\u4e49\u5efa\u6a21\u548cOpenMP\u7279\u5b9a\u6784\u9020\u8bc4\u4f30\u65b9\u9762\u4ecd\u6709\u5c40\u9650\u3002", "method": "OMPILOT\u91c7\u7528\u5b9a\u5236\u7684\u9884\u8bad\u7ec3\u76ee\u6807\u878d\u5408\u5e76\u884c\u6784\u9020\u8bed\u4e49\uff0c\u7ed3\u5408\u65e0\u76d1\u7763\u4e0e\u76d1\u7763\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u51fd\u6570\u7ea7\u522b\u8fdb\u884c\u4ee3\u7801\u7ffb\u8bd1\uff1b\u540c\u65f6\u63d0\u51faOMPBLEU\u6307\u6807\u8bc4\u4f30OpenMP\u7ffb\u8bd1\u8d28\u91cf\u3002", "result": "OMPILOT\u80fd\u6709\u6548\u5b9e\u73b0C++\u5230OpenMP\u7684\u51fd\u6570\u7ea7\u7ffb\u8bd1\uff0c\u63d0\u5347\u5e76\u884c\u5316\u51c6\u786e\u6027\u4e0e\u9c81\u68d2\u6027\uff0cOMPBLEU\u6307\u6807\u66f4\u8d34\u5408OpenMP\u6784\u9020\u7684\u8bc4\u4f30\u9700\u6c42\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86\u9886\u57df\u7279\u5b9a\u5927\u6a21\u578b\u5728\u4ee3\u7801\u5e76\u884c\u5316\u7ffb\u8bd1\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u4e3a\u4e13\u7528\u7ffb\u8bd1\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u5efa\u6a21\u8303\u5f0f\u4e0e\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2511.03761", "categories": ["cs.MA", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.03761", "abs": "https://arxiv.org/abs/2511.03761", "authors": ["Umut \u00c7al\u0131ky\u0131lmaz", "Nitin Nayak", "Jinghua Groppe", "Sven Groppe"], "title": "OptiMA: A Transaction-Based Framework with Throughput Optimization for Very Complex Multi-Agent Systems", "comment": null, "summary": "In recent years, the research of multi-agent systems has taken a direction to\nexplore larger and more complex models to fulfill sophisticated tasks. We point\nout two possible pitfalls that might be caused by increasing complexity;\nsusceptibilities to faults, and performance bottlenecks. To prevent the former\nthreat, we propose a transaction-based framework to design very complex\nmulti-agent systems (VCMAS). To address the second threat, we offer to\nintegrate transaction scheduling into the proposed framework. We implemented\nboth of these ideas to develop the OptiMA framework and show that it is able to\nfacilitate the execution of VCMAS with more than a hundred agents. We also\ndemonstrate the effect of transaction scheduling on such a system by showing\nimprovements up to more than 16\\%. Furthermore, we also performed a theoretical\nanalysis on the transaction scheduling problem and provided practical tools\nthat can be used for future research on it.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u590d\u6742\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08VCMAS\uff09\u5728\u89c4\u6a21\u6269\u5927\u65f6\u53ef\u80fd\u51fa\u73b0\u7684\u5bb9\u9519\u6027\u5dee\u548c\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8b\u52a1\u7684\u6846\u67b6OptiMA\uff0c\u5e76\u5f15\u5165\u4e8b\u52a1\u8c03\u5ea6\u673a\u5236\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u53ef\u652f\u6301\u4e0a\u767e\u4e2a\u667a\u80fd\u4f53\u8fd0\u884c\uff0c\u4e14\u8c03\u5ea6\u7b56\u7565\u5e26\u6765\u8d85\u8fc716%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u968f\u7740\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6a21\u578b\u65e5\u76ca\u590d\u6742\uff0c\u7cfb\u7edf\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u5bf9\u6545\u969c\u7684\u654f\u611f\u6027\u589e\u52a0\u4ee5\u53ca\u6027\u80fd\u74f6\u9888\u3002\u4e3a\u5e94\u5bf9\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u65b0\u7684\u8bbe\u8ba1\u6846\u67b6\u4ee5\u589e\u5f3a\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e8b\u52a1\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u6846\u67b6\uff08OptiMA\uff09\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u96c6\u6210\u4e86\u4e8b\u52a1\u8c03\u5ea6\u673a\u5236\uff0c\u4ee5\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u4e0e\u53ef\u9760\u6027\u3002", "result": "OptiMA\u6846\u67b6\u6210\u529f\u652f\u6301\u4e86\u5305\u542b\u4e0a\u767e\u4e2a\u667a\u80fd\u4f53\u7684\u590d\u6742\u7cfb\u7edf\u8fd0\u884c\uff0c\u4e8b\u52a1\u8c03\u5ea6\u5e26\u6765\u4e86\u6700\u9ad8\u8d85\u8fc716%\u7684\u6027\u80fd\u63d0\u5347\uff1b\u540c\u65f6\u4f5c\u8005\u8fd8\u5bf9\u8c03\u5ea6\u95ee\u9898\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u4f9b\u540e\u7eed\u7814\u7a76\u4f7f\u7528\u3002", "conclusion": "\u57fa\u4e8e\u4e8b\u52a1\u7684\u8bbe\u8ba1\u65b9\u6cd5\u7ed3\u5408\u4e8b\u52a1\u8c03\u5ea6\u80fd\u6709\u6548\u5e94\u5bf9\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5bb9\u9519\u6027\u4e0e\u6027\u80fd\u6311\u6218\uff0c\u4e3a\u672a\u6765\u590d\u6742\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7814\u7a76\u4e0e\u5b9e\u73b0\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u548c\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2511.04014", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04014", "abs": "https://arxiv.org/abs/2511.04014", "authors": ["Hao Zhu", "Jia Li", "Cuiyun Gao", "Jiaru Qian", "Yihong Dong", "Huanyu Liu", "Lecheng Wang", "Ziliang Wang", "Xiaolong Hu", "Ge Li"], "title": "Specification-Guided Vulnerability Detection with Large Language Models", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable progress in code\nunderstanding tasks. However, they demonstrate limited performance in\nvulnerability detection and struggle to distinguish vulnerable code from\npatched code. We argue that LLMs lack understanding of security specifications\n-- the expectations about how code should behave to remain safe. When code\nbehavior differs from these expectations, it becomes a potential vulnerability.\nHowever, such knowledge is rarely explicit in training data, leaving models\nunable to reason about security flaws. We propose VulInstruct, a\nspecification-guided approach that systematically extracts security\nspecifications from historical vulnerabilities to detect new ones. VulInstruct\nconstructs a specification knowledge base from two perspectives: (i) General\nspecifications from high-quality patches across projects, capturing fundamental\nsafe behaviors; and (ii) Domain-specific specifications from repeated\nviolations in particular repositories relevant to the target code. VulInstruct\nretrieves relevant past cases and specifications, enabling LLMs to reason about\nexpected safe behaviors rather than relying on surface patterns. We evaluate\nVulInstruct under strict criteria requiring both correct predictions and valid\nreasoning. On PrimeVul, VulInstruct achieves 45.0% F1-score (32.7% improvement)\nand 37.7% recall (50.8% improvement) compared to baselines, while uniquely\ndetecting 24.3% of vulnerabilities -- 2.4x more than any baseline. In pair-wise\nevaluation, VulInstruct achieves 32.3% relative improvement. VulInstruct also\ndiscovered a previously unknown high-severity vulnerability (CVE-2025-56538) in\nproduction code, demonstrating practical value for real-world vulnerability\ndiscovery. All code and supplementary materials are available at\nhttps://github.com/zhuhaopku/VulInstruct-temp.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faVulInstruct\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u5386\u53f2\u6f0f\u6d1e\u4e2d\u63d0\u53d6\u5b89\u5168\u89c4\u8303\uff08\u5305\u62ec\u901a\u7528\u89c4\u8303\u548c\u9886\u57df\u7279\u5b9a\u89c4\u8303\uff09\uff0c\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u53d1\u73b0\u4e86\u4e00\u4e2a\u65b0\u7684\u9ad8\u5371\u6f0f\u6d1e\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u96be\u4ee5\u533a\u5206\u6f0f\u6d1e\u4ee3\u7801\u4e0e\u4fee\u590d\u540e\u7684\u4ee3\u7801\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u5bf9\u5b89\u5168\u89c4\u8303\uff08\u5373\u4ee3\u7801\u5e94\u5982\u4f55\u884c\u4e3a\u4ee5\u4fdd\u6301\u5b89\u5168\uff09\u7684\u7406\u89e3\uff0c\u800c\u8fd9\u7c7b\u77e5\u8bc6\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u901a\u5e38\u672a\u663e\u5f0f\u4f53\u73b0\u3002", "method": "VulInstruct\u662f\u4e00\u79cd\u57fa\u4e8e\u5b89\u5168\u89c4\u8303\u5f15\u5bfc\u7684\u65b9\u6cd5\uff0c\u4ece\u4e24\u4e2a\u89d2\u5ea6\u6784\u5efa\u89c4\u8303\u77e5\u8bc6\u5e93\uff1a(i) \u8de8\u9879\u76ee\u7684\u9ad8\u8d28\u91cf\u8865\u4e01\u4e2d\u63d0\u53d6\u901a\u7528\u5b89\u5168\u89c4\u8303\uff1b(ii) \u4ece\u76ee\u6807\u4ee3\u7801\u76f8\u5173\u4ed3\u5e93\u4e2d\u91cd\u590d\u51fa\u73b0\u7684\u8fdd\u89c4\u6a21\u5f0f\u4e2d\u63d0\u53d6\u9886\u57df\u7279\u5b9a\u89c4\u8303\u3002\u8be5\u65b9\u6cd5\u68c0\u7d22\u76f8\u5173\u5386\u53f2\u6848\u4f8b\u548c\u89c4\u8303\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u57fa\u4e8e\u9884\u671f\u7684\u5b89\u5168\u884c\u4e3a\u8fdb\u884c\u63a8\u7406\uff0c\u800c\u975e\u4f9d\u8d56\u8868\u9762\u6a21\u5f0f\u3002", "result": "\u5728PrimeVul\u6570\u636e\u96c6\u4e0a\uff0cVulInstruct\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5F1\u5206\u6570\u63d0\u534732.7%\uff08\u8fbe45.0%\uff09\uff0c\u53ec\u56de\u7387\u63d0\u534750.8%\uff08\u8fbe37.7%\uff09\uff0c\u5e76\u80fd\u72ec\u68c0\u51fa24.3%\u7684\u6f0f\u6d1e\uff08\u662f\u6700\u4f73\u57fa\u7ebf\u76842.4\u500d\uff09\uff1b\u5728\u6210\u5bf9\u8bc4\u4f30\u4e2d\u76f8\u5bf9\u63d0\u534732.3%\uff1b\u6b64\u5916\u8fd8\u53d1\u73b0\u4e86\u4e00\u4e2a\u65b0\u7684\u9ad8\u5371\u6f0f\u6d1eCVE-2025-56538\u3002", "conclusion": "VulInstruct\u901a\u8fc7\u5f15\u5165\u5b89\u5168\u89c4\u8303\u77e5\u8bc6\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6f0f\u6d1e\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.03844", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03844", "abs": "https://arxiv.org/abs/2511.03844", "authors": ["Yuran Ding", "Xinwei Chen", "Xiaofan Zhang", "Zongwei Zhou"], "title": "ASAP: an Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training", "comment": "This work has been accepted to Workshop on ML for Systems at NeurIPS\n  2025", "summary": "Optimizing large-language model (LLM) training on distributed domain-specific\naccelerator systems presents significant challenges due to its complex\noptimization space. Existing optimization methods, however, rely on\ntime-consuming manual tuning or resource-intensive black-box searches, which\nstruggle to keep pace with the rapidly evolving LLM domain, leading to slow\ndevelopment and underutilized resources. To address this, we introduce ASAP, an\nAgentic Solution to Auto-optimize Performance of Large-Scale LLM Training. It\nis a multi-agent system, featuring Coordinator, Analyzer, and Proposal agents,\nwhich integrates LLM reasoning with insights from performance profiling tools,\nroofline analysis, and a knowledge base of best practices and successful past\noptimizations from human experts. Our proposed design can automate the\ndiagnosis of performance bottlenecks and recommend optimized sharding\nconfigurations with reasoning, thus effectively improving the efficiency of\ndistributed LLM training. Experiments have shown that the ASAP-generated\nsharding configurations can contribute up to 28% training step time reduction\nand 1.43 times throughput improvement. When combined with additional\noptimization from human experts, throughput can be further increased to 2.58\ntimes. The proposed ASAP promises to provide a scalable and explainable\nmethodology for AI-assisted performance engineering in large-scale LLM\ntraining.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ASAP\uff0c\u4e00\u79cd\u7528\u4e8e\u81ea\u52a8\u4f18\u5316\u5927\u89c4\u6a21\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bad\u7ec3\u6027\u80fd\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408LLM\u63a8\u7406\u3001\u6027\u80fd\u5206\u6790\u5de5\u5177\u548c\u4e13\u5bb6\u77e5\u8bc6\uff0c\u5b9e\u73b0\u5bf9\u5206\u5e03\u5f0f\u8bad\u7ec3\u4e2d\u5206\u7247\u914d\u7f6e\u7684\u81ea\u52a8\u8bca\u65ad\u4e0e\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u73b0\u6709LLM\u8bad\u7ec3\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u8017\u65f6\u7684\u624b\u52a8\u8c03\u4f18\u6216\u8d44\u6e90\u5bc6\u96c6\u578b\u7684\u9ed1\u76d2\u641c\u7d22\uff0c\u96be\u4ee5\u9002\u5e94\u5feb\u901f\u53d1\u5c55\u7684LLM\u9886\u57df\uff0c\u5bfc\u81f4\u5f00\u53d1\u7f13\u6162\u548c\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u3002", "method": "\u63d0\u51faASAP\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5305\u542bCoordinator\u3001Analyzer\u548cProposal\u4e09\u4e2a\u667a\u80fd\u4f53\uff0c\u878d\u5408LLM\u63a8\u7406\u80fd\u529b\u3001\u6027\u80fd\u5256\u6790\u5de5\u5177\u3001roofline\u5206\u6790\u4ee5\u53ca\u4e13\u5bb6\u6700\u4f73\u5b9e\u8df5\u77e5\u8bc6\u5e93\uff0c\u81ea\u52a8\u8bca\u65ad\u6027\u80fd\u74f6\u9888\u5e76\u63a8\u8350\u5e26\u89e3\u91ca\u7684\u4f18\u5316\u5206\u7247\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cASAP\u751f\u6210\u7684\u5206\u7247\u914d\u7f6e\u53ef\u51cf\u5c11\u6700\u591a28%\u7684\u8bad\u7ec3\u6b65\u65f6\uff0c\u5e76\u63d0\u53471.43\u500d\u541e\u5410\u91cf\uff1b\u82e5\u7ed3\u5408\u4eba\u5de5\u8fdb\u4e00\u6b65\u4f18\u5316\uff0c\u541e\u5410\u91cf\u53ef\u8fbe2.58\u500d\u3002", "conclusion": "ASAP\u4e3a\u5927\u89c4\u6a21LLM\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684AI\u8f85\u52a9\u6027\u80fd\u5de5\u7a0b\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u5206\u5e03\u5f0f\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2511.03941", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03941", "abs": "https://arxiv.org/abs/2511.03941", "authors": ["Fabio Diniz Rossi"], "title": "Stochastic Modeling for Energy-Efficient Edge Infrastructure", "comment": "8 pages, 4 figures, 3 tables", "summary": "Edge Computing enables low-latency processing for real-time applications but\nintroduces challenges in power management due to the distributed nature of edge\ndevices and their limited energy resources. This paper proposes a stochastic\nmodeling approach using Markov Chains to analyze power state transitions in\nEdge Computing. By deriving steady-state probabilities and evaluating energy\nconsumption, we demonstrate the benefits of AI-driven predictive power scaling\nover conventional reactive methods. Monte Carlo simulations validate the model,\nshowing strong alignment between theoretical and empirical results. Sensitivity\nanalysis highlights how varying transition probabilities affect power\nefficiency, confirming that predictive scaling minimizes unnecessary\ntransitions and improves overall system responsiveness. Our findings suggest\nthat AI-based power management strategies significantly enhance energy\nefficiency by anticipating workload demands and optimizing state transitions.\nExperimental results indicate that AI-based power management optimizes workload\ndistribution across heterogeneous edge nodes, reducing energy consumption\ndisparities between devices, improving overall efficiency, and enhancing\nadaptive power coordination in multi-node environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u94fe\u7684\u968f\u673a\u5efa\u6a21\u65b9\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u7684\u7535\u6e90\u72b6\u6001\u8f6c\u6362\uff0c\u5e76\u901a\u8fc7AI\u9a71\u52a8\u7684\u9884\u6d4b\u6027\u529f\u8017\u8c03\u8282\u7b56\u7565\u63d0\u5347\u80fd\u6548\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u867d\u652f\u6301\u4f4e\u5ef6\u8fdf\u5b9e\u65f6\u5e94\u7528\uff0c\u4f46\u5176\u8bbe\u5907\u5206\u5e03\u5e7f\u3001\u80fd\u6e90\u6709\u9650\uff0c\u5e26\u6765\u7535\u6e90\u7ba1\u7406\u6311\u6218\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u7684\u80fd\u8017\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u9a6c\u5c14\u53ef\u592b\u94fe\u5bf9\u8fb9\u7f18\u8bbe\u5907\u7684\u7535\u6e90\u72b6\u6001\u8f6c\u6362\u8fdb\u884c\u5efa\u6a21\uff0c\u63a8\u5bfc\u7a33\u6001\u6982\u7387\u5e76\u8bc4\u4f30\u80fd\u8017\uff1b\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u4eff\u771f\u4e0e\u654f\u611f\u6027\u5206\u6790\u9a8c\u8bc1\u6a21\u578b\uff0c\u5e76\u6bd4\u8f83AI\u9884\u6d4b\u6027\u8c03\u8282\u80fd\u8017\u4e0e\u4f20\u7edf\u53cd\u5e94\u5f0f\u65b9\u6cd5\u7684\u6548\u679c\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u7406\u8bba\u4e0e\u5b9e\u8bc1\u9ad8\u5ea6\u4e00\u81f4\uff1bAI\u9884\u6d4b\u6027\u7535\u6e90\u7ba1\u7406\u80fd\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u72b6\u6001\u5207\u6362\uff0c\u4f18\u5316\u5f02\u6784\u8fb9\u7f18\u8282\u70b9\u95f4\u7684\u5de5\u4f5c\u8d1f\u8f7d\u5206\u914d\uff0c\u964d\u4f4e\u8bbe\u5907\u95f4\u80fd\u8017\u5dee\u5f02\uff0c\u63d0\u5347\u6574\u4f53\u80fd\u6548\u4e0e\u7cfb\u7edf\u54cd\u5e94\u80fd\u529b\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u9884\u6d4b\u6027\u7535\u6e90\u7ba1\u7406\u7b56\u7565\u80fd\u663e\u8457\u63d0\u5347\u8fb9\u7f18\u8ba1\u7b97\u73af\u5883\u4e0b\u7684\u80fd\u6e90\u6548\u7387\u548c\u81ea\u9002\u5e94\u534f\u8c03\u80fd\u529b\u3002"}}
{"id": "2511.04023", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04023", "abs": "https://arxiv.org/abs/2511.04023", "authors": ["Shiyin Lin"], "title": "LLM-Driven Adaptive Source-Sink Identification and False Positive Mitigation for Static Analysis", "comment": null, "summary": "Static analysis is effective for discovering software vulnerabilities but\nnotoriously suffers from incomplete source--sink specifications and excessive\nfalse positives (FPs). We present \\textsc{AdaTaint}, an LLM-driven taint\nanalysis framework that adaptively infers source/sink specifications and\nfilters spurious alerts through neuro-symbolic reasoning. Unlike LLM-only\ndetectors, \\textsc{AdaTaint} grounds model suggestions in program facts and\nconstraint validation, ensuring both adaptability and determinism.\n  We evaluate \\textsc{AdaTaint} on Juliet 1.3, SV-COMP-style C benchmarks, and\nthree large real-world projects. Results show that \\textsc{AdaTaint} reduces\nfalse positives by \\textbf{43.7\\%} on average and improves recall by\n\\textbf{11.2\\%} compared to state-of-the-art baselines (CodeQL, Joern, and\nLLM-only pipelines), while maintaining competitive runtime overhead. These\nfindings demonstrate that combining LLM inference with symbolic validation\noffers a practical path toward more accurate and reliable static vulnerability\nanalysis.", "AI": {"tldr": "AdaTaint \u662f\u4e00\u4e2a\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u7b26\u53f7\u9a8c\u8bc1\u7684\u6c61\u70b9\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u81ea\u9002\u5e94\u63a8\u65ad\u6e90/\u6c47\u89c4\u8303\u5e76\u8fc7\u6ee4\u8bef\u62a5\uff0c\u5728\u4fdd\u6301\u8fd0\u884c\u5f00\u9500\u53ef\u63a7\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u9759\u6001\u5206\u6790\u4e2d\u7684\u5047\u9633\u6027\u7387\u5e76\u63d0\u5347\u53ec\u56de\u7387\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u5206\u6790\u5728\u53d1\u73b0\u8f6f\u4ef6\u6f0f\u6d1e\u65f6\u53d7\u9650\u4e8e\u4e0d\u5b8c\u6574\u7684\u6e90-\u6c47\u89c4\u8303\u548c\u5927\u91cf\u8bef\u62a5\uff0c\u73b0\u6709\u7eafLLM\u65b9\u6cd5\u7f3a\u4e4f\u786e\u5b9a\u6027\u548c\u7a0b\u5e8f\u4e8b\u5b9e\u4f9d\u636e\u3002", "method": "\u63d0\u51fa AdaTaint \u6846\u67b6\uff0c\u5229\u7528 LLM \u81ea\u9002\u5e94\u63a8\u65ad\u6e90/\u6c47\u89c4\u8303\uff0c\u5e76\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u63a8\u7406\u5c06\u6a21\u578b\u5efa\u8bae\u4e0e\u7a0b\u5e8f\u4e8b\u5b9e\u53ca\u7ea6\u675f\u9a8c\u8bc1\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u517c\u5177\u9002\u5e94\u6027\u4e0e\u786e\u5b9a\u6027\u7684\u6c61\u70b9\u5206\u6790\u3002", "result": "\u5728 Juliet 1.3\u3001SV-COMP \u98ce\u683c C \u57fa\u51c6\u548c\u4e09\u4e2a\u5927\u578b\u771f\u5b9e\u9879\u76ee\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAdaTaint \u76f8\u6bd4 CodeQL\u3001Joern \u548c\u7eaf LLM \u65b9\u6cd5\uff0c\u5e73\u5747\u51cf\u5c11 43.7% \u7684\u5047\u9633\u6027\uff0c\u53ec\u56de\u7387\u63d0\u5347 11.2%\uff0c\u4e14\u8fd0\u884c\u65f6\u5f00\u9500\u53ef\u63a7\u3002", "conclusion": "\u5c06 LLM \u63a8\u7406\u4e0e\u7b26\u53f7\u9a8c\u8bc1\u76f8\u7ed3\u5408\uff0c\u662f\u5b9e\u73b0\u66f4\u51c6\u786e\u3001\u53ef\u9760\u9759\u6001\u6f0f\u6d1e\u5206\u6790\u7684\u6709\u6548\u8def\u5f84\u3002"}}
{"id": "2511.04104", "categories": ["cs.AR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.04104", "abs": "https://arxiv.org/abs/2511.04104", "authors": ["Chao Guo", "Jiahe Xu", "Moshe Zukerman"], "title": "Disaggregated Architectures and the Redesign of Data Center Ecosystems: Scheduling, Pooling, and Infrastructure Trade-offs", "comment": null, "summary": "Hardware disaggregation seeks to transform Data Center (DC) resources from\ntraditional server fleets into unified resource pools. Despite existing\nchallenges that may hinder its full realization, significant progress has been\nmade in both industry and academia. In this article, we provide an overview of\nthe motivations and recent advancements in hardware disaggregation. We further\ndiscuss the research challenges and opportunities associated with disaggregated\narchitectures, focusing on aspects that have received limited attention. We\nargue that hardware disaggregation has the potential to reshape the entire DC\necosystem, impacting application design, resource scheduling, hardware\nconfiguration, cooling, and power system optimization. Additionally, we present\na numerical study to illustrate several key aspects of these challenges.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6570\u636e\u4e2d\u5fc3\u786c\u4ef6\u89e3\u8026\u7684\u52a8\u673a\u4e0e\u6700\u65b0\u8fdb\u5c55\uff0c\u63a2\u8ba8\u5176\u5bf9\u6574\u4e2a\u6570\u636e\u4e2d\u5fc3\u751f\u6001\u7cfb\u7edf\uff08\u5305\u62ec\u5e94\u7528\u8bbe\u8ba1\u3001\u8d44\u6e90\u8c03\u5ea6\u3001\u786c\u4ef6\u914d\u7f6e\u3001\u51b7\u5374\u548c\u4f9b\u7535\u4f18\u5316\uff09\u7684\u6f5c\u5728\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u7814\u7a76\u63ed\u793a\u76f8\u5173\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u6570\u636e\u4e2d\u5fc3\u670d\u52a1\u5668\u67b6\u6784\u5b58\u5728\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u3001\u6269\u5c55\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u786c\u4ef6\u89e3\u8026\u65e8\u5728\u5c06\u8ba1\u7b97\u3001\u5b58\u50a8\u3001\u5185\u5b58\u7b49\u8d44\u6e90\u6c60\u5316\uff0c\u63d0\u5347\u7075\u6d3b\u6027\u4e0e\u6548\u7387\uff0c\u4ece\u800c\u91cd\u5851\u6570\u636e\u4e2d\u5fc3\u751f\u6001\u3002", "method": "\u6587\u7ae0\u901a\u8fc7\u7efc\u8ff0\u73b0\u6709\u7814\u7a76\u4e0e\u5de5\u4e1a\u5b9e\u8df5\uff0c\u5206\u6790\u786c\u4ef6\u89e3\u8026\u67b6\u6784\u7684\u5173\u952e\u6280\u672f\u4e0e\u6311\u6218\uff0c\u5e76\u8f85\u4ee5\u6570\u503c\u7814\u7a76\u6765\u91cf\u5316\u548c\u8bf4\u660e\u82e5\u5e72\u6838\u5fc3\u95ee\u9898\u3002", "result": "\u7814\u7a76\u8868\u660e\u786c\u4ef6\u89e3\u8026\u5728\u8d44\u6e90\u5229\u7528\u3001\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u548c\u80fd\u6548\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u4f46\u5176\u5b9e\u9645\u90e8\u7f72\u4ecd\u9762\u4e34\u4e92\u8fde\u5ef6\u8fdf\u3001\u7ba1\u7406\u590d\u6742\u6027\u7b49\u6311\u6218\u3002", "conclusion": "\u786c\u4ef6\u89e3\u8026\u6709\u671b\u6df1\u523b\u6539\u53d8\u6570\u636e\u4e2d\u5fc3\u7684\u8bbe\u8ba1\u4e0e\u8fd0\u8425\u65b9\u5f0f\uff0c\u5c3d\u7ba1\u5c1a\u5b58\u6280\u672f\u969c\u788d\uff0c\u4f46\u5176\u5e26\u6765\u7684\u7cfb\u7edf\u7ea7\u4f18\u5316\u673a\u4f1a\u503c\u5f97\u6301\u7eed\u6df1\u5165\u7814\u7a76\u3002"}}
{"id": "2511.03958", "categories": ["cs.MA", "cs.CL", "cs.HC", "I.2.11; I.2.6; K.3.1"], "pdf": "https://arxiv.org/pdf/2511.03958", "abs": "https://arxiv.org/abs/2511.03958", "authors": ["Kia Karbasi", "Kevin Hong", "Mohammad Amin Samadi", "Gregory Pottie"], "title": "Multi-Agent Collaborative Framework For Math Problem Generation", "comment": "Published in the Proceedings of the 18th International Conference on\n  Educational Data Mining, 6 pages, 5 figures", "summary": "Automatic question generation (AQG) for mathematics education remains an\nelusive goal for Intelligent Tutoring Systems and educators. While pre-trained\ntransformer-based language models have significantly advanced natural language\ngeneration, they often struggle to precisely control problem complexity and\ncognitive demands. In this paper, we introduce a collaborative multi-agent\nframework as a novel method of incorporating inference-time computation into\nAQG. This approach leverages multiple agents that iteratively refine generated\nquestion-answer pairs to better balance complexity and cognitive demand. We\nevaluate the generated questions on five meta-evaluation criteria: relevance,\nimportance, clarity, difficulty matching, answerability, to assess the system's\nability to control the required complexity and quality of the questions.\nPreliminary evaluations show that this collaborative multi-agent framework\nelevates the quality of generated educational content by fostering a more\nnuanced balance between cognitive challenge and clarity. These promising\noutcomes suggest that integrating collaborative multi-agent workflows can yield\nmore controlled, pedagogically valuable content that can help advance automated\neducational content generation and adaptive learning environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u81ea\u52a8\u6570\u5b66\u95ee\u9898\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u8ba1\u7b97\u52a8\u6001\u8c03\u6574\u95ee\u9898\u7684\u8ba4\u77e5\u96be\u5ea6\u4e0e\u6e05\u6670\u5ea6\uff0c\u5728\u591a\u9879\u5143\u8bc4\u4f30\u6307\u6807\u4e0a\u5c55\u73b0\u51fa\u66f4\u4f18\u7684\u6559\u80b2\u5185\u5bb9\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u751f\u6210\u6570\u5b66\u6559\u80b2\u95ee\u9898\u65f6\u96be\u4ee5\u7cbe\u786e\u63a7\u5236\u95ee\u9898\u590d\u6742\u5ea6\u548c\u8ba4\u77e5\u9700\u6c42\uff0c\u9650\u5236\u4e86\u5176\u5728\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u534f\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5728\u63a8\u7406\u9636\u6bb5\u901a\u8fc7\u591a\u4e2a\u667a\u80fd\u4f53\u8fed\u4ee3\u4f18\u5316\u751f\u6210\u7684\u95ee\u9898-\u7b54\u6848\u5bf9\uff0c\u4ee5\u5e73\u8861\u95ee\u9898\u7684\u590d\u6742\u6027\u4e0e\u8ba4\u77e5\u8981\u6c42\u3002", "result": "\u5728\u76f8\u5173\u6027\u3001\u91cd\u8981\u6027\u3001\u6e05\u6670\u5ea6\u3001\u96be\u5ea6\u5339\u914d\u548c\u53ef\u7b54\u6027\u4e94\u4e2a\u5143\u8bc4\u4f30\u6807\u51c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u95ee\u9898\u8d28\u91cf\u663e\u8457\u63d0\u5347\uff0c\u5b9e\u73b0\u4e86\u8ba4\u77e5\u6311\u6218\u4e0e\u6e05\u6670\u5ea6\u4e4b\u95f4\u7684\u66f4\u597d\u5e73\u8861\u3002", "conclusion": "\u534f\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u80fd\u751f\u6210\u66f4\u5177\u6559\u5b66\u4ef7\u503c\u3001\u53ef\u63a7\u6027\u66f4\u5f3a\u7684\u6559\u80b2\u5185\u5bb9\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u81ea\u52a8\u5316\u6559\u80b2\u5185\u5bb9\u751f\u6210\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u73af\u5883\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.04268", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.04268", "abs": "https://arxiv.org/abs/2511.04268", "authors": ["Iker Mart\u00edn-\u00c1lvarez", "Jos\u00e9 I. Aliaga", "Maribel Castillo", "Sergio Iserte"], "title": "Parallel Spawning Strategies for Dynamic-Aware MPI Applications", "comment": "10 pages, 1 Table, 6 Figures, 8 Equations, 2 Listings", "summary": "Dynamic resource management is an increasingly important capability of High\nPerformance Computing systems, as it enables jobs to adjust their resource\nallocation at runtime. This capability has been shown to reduce workload\nmakespan, substantially decrease job waiting times and improve overall system\nutilization. In this context, malleability refers to the ability of\napplications to adapt to new resource allocations during execution. Although\nbeneficial, malleability incurs significant reconfiguration costs, making the\nreduction of these costs an important research topic.\n  Some existing methods for MPI applications respawn the entire application,\nwhich is an expensive solution that avoids the reuse of original processes.\nOther MPI methods reuse them, but fail to fully release unneeded processes when\nshrinking, since some ranks within the same communicator remain active across\nnodes, preventing the application from returning those nodes to the system.\nThis work overcomes both limitations by proposing a novel parallel spawning\nstrategy, in which all processes cooperate in spawning before redistribution,\nthereby reducing execution time. Additionally, it removes shrinkage\nlimitations, allowing better adaptation of parallel systems to workload and\nreducing their makespan. As a result, it preserves competitive expansion times\nwith at most a $1.25\\times$ overhead, while enabling fast shrink operations\nthat reduce their cost by at least $20\\times$. This strategy has been validated\non both homogeneous and heterogeneous systems and can also be applied in\nshared-resource environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5e76\u884c\u542f\u52a8\u7b56\u7565\uff0c\u901a\u8fc7\u6240\u6709\u8fdb\u7a0b\u5728\u91cd\u5206\u914d\u524d\u534f\u4f5c\u542f\u52a8\uff0c\u663e\u8457\u964d\u4f4eMPI\u5e94\u7528\u5728\u52a8\u6001\u8d44\u6e90\u8c03\u6574\uff08\u5c24\u5176\u662f\u6536\u7f29\uff09\u65f6\u7684\u5f00\u9500\uff0c\u5728\u4fdd\u6301\u6269\u5c55\u6027\u80fd\u7684\u540c\u65f6\u5c06\u6536\u7f29\u6210\u672c\u964d\u4f4e\u81f3\u5c1120\u500d\u3002", "motivation": "\u52a8\u6001\u8d44\u6e90\u7ba1\u7406\u5bf9\u9ad8\u6027\u80fd\u8ba1\u7b97\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709MPI\u5e94\u7528\u7684\u53ef\u5851\u6027\u65b9\u6cd5\u5b58\u5728\u91cd\u914d\u7f6e\u6210\u672c\u9ad8\u3001\u65e0\u6cd5\u6709\u6548\u91ca\u653e\u8282\u70b9\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u5e76\u884c\u542f\u52a8\u7b56\u7565\uff1a\u6240\u6709\u8fdb\u7a0b\u5728\u8d44\u6e90\u91cd\u5206\u914d\u524d\u534f\u540c\u53c2\u4e0e\u542f\u52a8\u8fc7\u7a0b\uff0c\u5e76\u6539\u8fdb\u6536\u7f29\u673a\u5236\u4ee5\u5f7b\u5e95\u91ca\u653e\u4e0d\u518d\u9700\u8981\u7684\u8282\u70b9\u3002", "result": "\u8be5\u7b56\u7565\u5728\u6269\u5c55\u65f6\u6700\u591a\u4ec5\u67091.25\u500d\u5f00\u9500\uff0c\u540c\u65f6\u5c06\u6536\u7f29\u64cd\u4f5c\u7684\u6210\u672c\u964d\u4f4e\u81f3\u5c1120\u500d\uff0c\u5e76\u5728\u540c\u6784\u4e0e\u5f02\u6784\u7cfb\u7edf\u53ca\u5171\u4eab\u8d44\u6e90\u73af\u5883\u4e2d\u5747\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u514b\u670d\u4e86\u73b0\u6709MPI\u53ef\u5851\u6027\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u6001\u8d44\u6e90\u8c03\u6574\u6548\u7387\uff0c\u6709\u52a9\u4e8e\u51cf\u5c11\u4f5c\u4e1a\u7b49\u5f85\u65f6\u95f4\u548c\u7cfb\u7edf\u6574\u4f53\u5b8c\u5de5\u65f6\u95f4\u3002"}}
{"id": "2511.04064", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04064", "abs": "https://arxiv.org/abs/2511.04064", "authors": ["Zhengran Zeng", "Yixin Li", "Rui Xie", "Wei Ye", "Shikun Zhang"], "title": "Benchmarking and Studying the LLM-based Agent System in End-to-End Software Development", "comment": null, "summary": "The development of LLM-based autonomous agents for end-to-end software\ndevelopment represents a significant paradigm shift in software engineering.\nHowever, the scientific evaluation of these systems is hampered by significant\nchallenges, including overly simplistic benchmarks and the difficulty of\nconducting fair comparisons between different agent architectures due to\nconfounding implementation variables. To address these limitations, we first\nconstruct a challenging and dynamically curated E2EDevBench to simulate\nrealistic development scenarios. Second, we propose a hybrid evaluation\nframework that combines test-case-based functional assessment with\nfine-grained, LLM-based requirement verification. Using this framework, we\nconduct a controlled empirical study on three representative agent\narchitectures implemented upon a unified foundation to isolate the impact of\nworkflow design. Our findings reveal that state-of-the-art agents can fulfill\napproximately 50\\% of requirements on \\bench{}, but their success is critically\ndependent on the architectural strategy for task decomposition and\ncollaboration. Furthermore, our analysis indicates that the primary bottleneck\nis the omission of requirements and inadequate self-verification. This work\nprovides the community with a more realistic benchmark, a comprehensive\nevaluation framework, and crucial insights into the current capabilities and\ncore challenges of software development agents, guiding future research toward\nenhancing requirement comprehension and planning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u66f4\u5177\u6311\u6218\u6027\u7684\u7aef\u5230\u7aef\u8f6f\u4ef6\u5f00\u53d1\u57fa\u51c6E2EDevBench\u548c\u4e00\u4e2a\u7ed3\u5408\u6d4b\u8bd5\u7528\u4f8b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u9700\u6c42\u9a8c\u8bc1\u7684\u6df7\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u63a7\u5236\u53d8\u91cf\u5b9e\u9a8c\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u7684\u667a\u80fd\u4f53\u4ec5\u80fd\u5b8c\u6210\u7ea650%\u7684\u9700\u6c42\uff0c\u5176\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u4efb\u52a1\u5206\u89e3\u4e0e\u534f\u4f5c\u67b6\u6784\uff0c\u5e76\u6307\u51fa\u9700\u6c42\u9057\u6f0f\u548c\u81ea\u6211\u9a8c\u8bc1\u4e0d\u8db3\u662f\u4e3b\u8981\u74f6\u9888\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u81ea\u4e3b\u8f6f\u4ef6\u5f00\u53d1\u667a\u80fd\u4f53\u7f3a\u4e4f\u79d1\u5b66\u8bc4\u4f30\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u8fc7\u4e8e\u7b80\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u53ca\u4e0d\u540c\u667a\u80fd\u4f53\u67b6\u6784\u4e4b\u95f4\u56e0\u5b9e\u73b0\u5dee\u5f02\u5bfc\u81f4\u7684\u4e0d\u516c\u5e73\u6bd4\u8f83\u3002", "method": "\u6784\u5efa\u52a8\u6001\u7ef4\u62a4\u3001\u8d34\u8fd1\u771f\u5b9e\u573a\u666f\u7684E2EDevBench\u57fa\u51c6\uff1b\u63d0\u51fa\u878d\u5408\u6d4b\u8bd5\u7528\u4f8b\u529f\u80fd\u8bc4\u4f30\u4e0e\u7ec6\u7c92\u5ea6LLM\u9700\u6c42\u9a8c\u8bc1\u7684\u6df7\u5408\u8bc4\u4f30\u6846\u67b6\uff1b\u5728\u7edf\u4e00\u57fa\u7840\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e09\u79cd\u4ee3\u8868\u6027\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5f00\u5c55\u63a7\u5236\u53d8\u91cf\u5b9e\u8bc1\u7814\u7a76\u4ee5\u9694\u79bb\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u7684\u5f71\u54cd\u3002", "result": "\u6700\u5148\u8fdb\u7684\u667a\u80fd\u4f53\u5728E2EDevBench\u4e0a\u4ec5\u80fd\u6ee1\u8db3\u7ea650%\u7684\u9700\u6c42\uff1b\u4efb\u52a1\u5206\u89e3\u4e0e\u534f\u4f5c\u67b6\u6784\u5bf9\u6027\u80fd\u5f71\u54cd\u663e\u8457\uff1b\u4e3b\u8981\u5931\u8d25\u539f\u56e0\u5728\u4e8e\u9700\u6c42\u9057\u6f0f\u548c\u81ea\u6211\u9a8c\u8bc1\u80fd\u529b\u4e0d\u8db3\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u7684\u57fa\u51c6\u3001\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u5bf9\u5f53\u524d\u8f6f\u4ef6\u5f00\u53d1\u667a\u80fd\u4f53\u80fd\u529b\u4e0e\u6838\u5fc3\u6311\u6218\u7684\u5173\u952e\u6d1e\u5bdf\uff0c\u4e3a\u672a\u6765\u63d0\u5347\u9700\u6c42\u7406\u89e3\u4e0e\u89c4\u5212\u80fd\u529b\u7684\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2511.04321", "categories": ["cs.AR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04321", "abs": "https://arxiv.org/abs/2511.04321", "authors": ["Yuanpeng Zhang", "Xing Hu", "Xi Chen", "Zhihang Yuan", "Cong Li", "Jingchen Zhu", "Zhao Wang", "Chenguang Zhang", "Xin Si", "Wei Gao", "Qiang Wu", "Runsheng Wang", "Guangyu Sun"], "title": "AIM: Software and Hardware Co-design for Architecture-level IR-drop Mitigation in High-performance PIM", "comment": "18 pages, 22 figures, accepted by ISCA 2025", "summary": "SRAM Processing-in-Memory (PIM) has emerged as the most promising\nimplementation for high-performance PIM, delivering superior computing density,\nenergy efficiency, and computational precision. However, the pursuit of higher\nperformance necessitates more complex circuit designs and increased operating\nfrequencies, which exacerbate IR-drop issues. Severe IR-drop can significantly\ndegrade chip performance and even threaten reliability. Conventional\ncircuit-level IR-drop mitigation methods, such as back-end optimizations, are\nresource-intensive and often compromise power, performance, and area (PPA). To\naddress these challenges, we propose AIM, comprehensive software and hardware\nco-design for architecture-level IR-drop mitigation in high-performance PIM.\nInitially, leveraging the bit-serial and in-situ dataflow processing properties\nof PIM, we introduce Rtog and HR, which establish a direct correlation between\nPIM workloads and IR-drop. Building on this foundation, we propose LHR and WDS,\nenabling extensive exploration of architecture-level IR-drop mitigation while\nmaintaining computational accuracy through software optimization. Subsequently,\nwe develop IR-Booster, a dynamic adjustment mechanism that integrates\nsoftware-level HR information with hardware-based IR-drop monitoring to adapt\nthe V-f pairs of the PIM macro, achieving enhanced energy efficiency and\nperformance. Finally, we propose the HR-aware task mapping method, bridging\nsoftware and hardware designs to achieve optimal improvement. Post-layout\nsimulation results on a 7nm 256-TOPS PIM chip demonstrate that AIM achieves up\nto 69.2% IR-drop mitigation, resulting in 2.29x energy efficiency improvement\nand 1.152x speedup.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAIM\uff0c\u4e00\u79cd\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u7684\u67b6\u6784\u7ea7IR-drop\u7f13\u89e3\u65b9\u6848\uff0c\u7528\u4e8e\u9ad8\u6027\u80fdSRAM\u5b58\u5185\u8ba1\u7b97\uff08PIM\uff09\u82af\u7247\u3002\u901a\u8fc7\u5efa\u7acb\u5de5\u4f5c\u8d1f\u8f7d\u4e0eIR-drop\u4e4b\u95f4\u7684\u5173\u8054\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u8f6f\u4ef6\u4f18\u5316\u4e0e\u786c\u4ef6\u52a8\u6001\u8c03\u8282\u673a\u5236\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4eIR-drop\uff0c\u63d0\u5347\u80fd\u6548\u4e0e\u6027\u80fd\u3002", "motivation": "\u9ad8\u6027\u80fdSRAM PIM\u56e0\u590d\u6742\u7535\u8def\u548c\u9ad8\u9891\u7387\u8fd0\u884c\u5bfc\u81f4\u4e25\u91cd\u7684IR-drop\u95ee\u9898\uff0c\u4f20\u7edf\u540e\u7aef\u7535\u8def\u7ea7\u7f13\u89e3\u65b9\u6cd5\u4ee3\u4ef7\u9ad8\u6602\u4e14\u727a\u7272PPA\uff08\u529f\u8017\u3001\u6027\u80fd\u3001\u9762\u79ef\uff09\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u67b6\u6784\u7ea7\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faAIM\u6846\u67b6\uff1a\u9996\u5148\u57fa\u4e8ePIM\u7684\u4f4d\u4e32\u884c\u548c\u539f\u4f4d\u6570\u636e\u6d41\u7279\u6027\uff0c\u5f15\u5165Rtog\u548cHR\u6307\u6807\u4ee5\u91cf\u5316\u5de5\u4f5c\u8d1f\u8f7d\u4e0eIR-drop\u7684\u5173\u7cfb\uff1b\u7136\u540e\u63d0\u51faLHR\u548cWDS\u8fdb\u884c\u8f6f\u4ef6\u5c42\u9762\u7684\u67b6\u6784\u7ea7IR-drop\u4f18\u5316\uff1b\u63a5\u7740\u5f00\u53d1IR-Booster\u673a\u5236\uff0c\u878d\u5408\u8f6f\u4ef6HR\u4fe1\u606f\u4e0e\u786c\u4ef6IR\u76d1\u6d4b\uff0c\u52a8\u6001\u8c03\u6574PIM\u5b8f\u7684\u7535\u538b-\u9891\u7387\u5bf9\uff1b\u6700\u540e\u8bbe\u8ba1HR\u611f\u77e5\u7684\u4efb\u52a1\u6620\u5c04\u7b56\u7565\uff0c\u5b9e\u73b0\u8f6f\u786c\u4ef6\u534f\u540c\u4f18\u5316\u3002", "result": "\u57287nm\u5de5\u827a\u3001256-TOPS\u7684PIM\u82af\u7247\u4e0a\u8fdb\u884c\u540e\u4eff\u771f\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793aAIM\u6700\u591a\u53ef\u964d\u4f4e69.2%\u7684IR-drop\uff0c\u5e26\u67652.29\u500d\u7684\u80fd\u6548\u63d0\u5347\u548c1.152\u500d\u7684\u6027\u80fd\u52a0\u901f\u3002", "conclusion": "AIM\u901a\u8fc7\u8f6f\u786c\u4ef6\u534f\u540c\u7684\u67b6\u6784\u7ea7\u8bbe\u8ba1\uff0c\u5728\u4e0d\u727a\u7272\u8ba1\u7b97\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\u6709\u6548\u7f13\u89e3\u4e86\u9ad8\u6027\u80fdPIM\u4e2d\u7684IR-drop\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u80fd\u6548\u4e0e\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u9ad8\u5bc6\u5ea6\u5b58\u5185\u8ba1\u7b97\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u4f18\u5316\u8def\u5f84\u3002"}}
{"id": "2511.04477", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.04477", "abs": "https://arxiv.org/abs/2511.04477", "authors": ["Rongxiang Wang", "Kangyuan Shu", "Felix Xiaozhu Lin"], "title": "Enabling Dynamic Sparsity in Quantized LLM Inference", "comment": null, "summary": "Deploying large language models (LLMs) on end-user devices is gaining\nimportance due to benefits in responsiveness, privacy, and operational cost.\nYet the limited memory and compute capability of mobile and desktop GPUs make\nefficient execution difficult. Recent observations suggest that the internal\nactivations of LLMs are often dynamically sparse, meaning that for each input,\nonly part of the network contributes significantly to the output. Such sparsity\ncould reduce computation, but it interacts poorly with group-wise quantization,\nwhich remains the dominant approach for fitting LLMs onto resource-constrained\nhardware. To reconcile these two properties, this study proposes a set of\ntechniques that realize dynamic sparse inference under low-bit quantization.\nThe method features: (1) a zigzag-patterned quantization layout that organizes\nweights in a way consistent with activation sparsity and improves GPU memory\nlocality; (2) a specialized GEMV kernel designed for this layout to fully\nutilize parallel compute units; and (3) a compact runtime mechanism that\ngathers sparse indices with minimal overhead. Across several model scales and\nhardware configurations, the approach achieves up to 1.55x faster decoding\nthroughput while maintaining accuracy comparable to dense quantized inference,\nshowing that structured sparsity and quantization can effectively coexist on\ncommodity GPUs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u4f4e\u6bd4\u7279\u91cf\u5316\u4e0b\u5b9e\u73b0\u52a8\u6001\u7a00\u758f\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7zigzag\u91cf\u5316\u5e03\u5c40\u3001\u4e13\u7528GEMV\u6838\u548c\u7d27\u51d1\u8fd0\u884c\u65f6\u673a\u5236\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u5728\u591a\u79cd\u786c\u4ef6\u4e0a\u5b9e\u73b0\u6700\u9ad81.55\u500d\u7684\u89e3\u7801\u52a0\u901f\u3002", "motivation": "\u5728\u7ec8\u7aef\u8bbe\u5907\u4e0a\u90e8\u7f72\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9762\u4e34\u5185\u5b58\u548c\u8ba1\u7b97\u8d44\u6e90\u53d7\u9650\u7684\u95ee\u9898\uff1b\u5c3d\u7ba1LLMs\u5185\u90e8\u6fc0\u6d3b\u5177\u6709\u52a8\u6001\u7a00\u758f\u6027\u53ef\u51cf\u5c11\u8ba1\u7b97\uff0c\u4f46\u5176\u4e0e\u4e3b\u6d41\u7684\u5206\u7ec4\u91cf\u5316\u65b9\u6cd5\u4e0d\u517c\u5bb9\uff0c\u963b\u788d\u4e86\u9ad8\u6548\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u5173\u952e\u6280\u672f\uff1a(1) \u4e0e\u6fc0\u6d3b\u7a00\u758f\u6027\u4e00\u81f4\u4e14\u63d0\u5347GPU\u5185\u5b58\u5c40\u90e8\u6027\u7684zigzag\u91cf\u5316\u5e03\u5c40\uff1b(2) \u9488\u5bf9\u8be5\u5e03\u5c40\u8bbe\u8ba1\u7684\u4e13\u7528GEMV\u6838\u4ee5\u5145\u5206\u5229\u7528\u5e76\u884c\u8ba1\u7b97\u5355\u5143\uff1b(3) \u5f00\u9500\u6781\u5c0f\u7684\u7a00\u758f\u7d22\u5f15\u6536\u96c6\u8fd0\u884c\u65f6\u673a\u5236\u3002", "result": "\u5728\u591a\u79cd\u6a21\u578b\u89c4\u6a21\u548c\u786c\u4ef6\u914d\u7f6e\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u4e0e\u7a20\u5bc6\u91cf\u5316\u63a8\u7406\u76f8\u5f53\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u6700\u9ad81.55\u500d\u7684\u89e3\u7801\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "\u7ed3\u6784\u5316\u7a00\u758f\u6027\u4e0e\u91cf\u5316\u53ef\u5728\u5546\u7528GPU\u4e0a\u6709\u6548\u5171\u5b58\uff0c\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u7ec8\u7aef\u8bbe\u5907\u4e0aLLM\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2511.04115", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.04115", "abs": "https://arxiv.org/abs/2511.04115", "authors": ["Ruksit Rojpaisarnkit", "Youmei Fan", "Kenichi Matsumoto", "Raula Gaikovina Kula"], "title": "How Natural Language Proficiency Shapes GenAI Code for Software Engineering Tasks", "comment": "7 pages, 4 tables, 1 figure", "summary": "With the widespread adoption of Foundation Model (FM)-powered tools in\nsoftware engineering, the natural language prompt has become a critical\ninterface between developers and Large Language Models (LLMs). While much\nresearch has focused on prompt structure, the natural language proficiency is\nan underexplored factor that can influence the quality of generated code. This\npaper investigates whether the English language proficiency itself independent\nof the prompting technique affects the proficiency and correctness of code\ngenerated by LLMs. Using the HumanEval dataset, we systematically varied the\nEnglish proficiency of prompts from basic to advanced for 164 programming tasks\nand measured the resulting code proficiency and correctness. Our findings show\nthat LLMs default to an intermediate (B2) natural language level. While the\neffect on the resulting code proficiency was model-dependent, we found that\nhigher-proficiency prompts consistently yielded more correct code across all\nmodels. These results demonstrate that natural language proficiency is a key\nlever for controlling code generation, helping developers tailor AI output and\nimprove the reliability of solutions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u7684\u82f1\u8bed\u719f\u7ec3\u5ea6\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u548c\u6b63\u786e\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u66f4\u9ad8\u82f1\u8bed\u6c34\u5e73\u7684\u63d0\u793a\u80fd\u6301\u7eed\u63d0\u5347\u4ee3\u7801\u6b63\u786e\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u5927\u91cf\u7814\u7a76\u5173\u6ce8\u63d0\u793a\u7ed3\u6784\uff0c\u4f46\u81ea\u7136\u8bed\u8a00\u719f\u7ec3\u5ea6\u5bf9LLM\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u9a8c\u8bc1\u82f1\u8bed\u719f\u7ec3\u5ea6\u672c\u8eab\u662f\u5426\u72ec\u7acb\u4e8e\u63d0\u793a\u6280\u672f\u5f71\u54cd\u4ee3\u7801\u751f\u6210\u6548\u679c\u3002", "method": "\u57fa\u4e8eHumanEval\u6570\u636e\u96c6\uff0c\u5bf9164\u4e2a\u7f16\u7a0b\u4efb\u52a1\u7684\u63d0\u793a\u8bed\u4ece\u57fa\u7840\u5230\u9ad8\u7ea7\u7cfb\u7edf\u6027\u5730\u8c03\u6574\u82f1\u8bed\u719f\u7ec3\u5ea6\uff0c\u5e76\u8bc4\u4f30\u6240\u751f\u6210\u4ee3\u7801\u7684\u719f\u7ec3\u5ea6\u4e0e\u6b63\u786e\u6027\u3002", "result": "LLM\u9ed8\u8ba4\u4f7f\u7528\u4e2d\u7b49\uff08B2\uff09\u81ea\u7136\u8bed\u8a00\u6c34\u5e73\uff1b\u867d\u7136\u5bf9\u4ee3\u7801\u719f\u7ec3\u5ea6\u7684\u5f71\u54cd\u56e0\u6a21\u578b\u800c\u5f02\uff0c\u4f46\u9ad8\u719f\u7ec3\u5ea6\u63d0\u793a\u5728\u6240\u6709\u6a21\u578b\u4e2d\u5747\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u6b63\u786e\u6027\u3002", "conclusion": "\u81ea\u7136\u8bed\u8a00\u719f\u7ec3\u5ea6\u662f\u63a7\u5236\u4ee3\u7801\u751f\u6210\u7684\u5173\u952e\u56e0\u7d20\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u4f18\u5316AI\u8f93\u51fa\u5e76\u63d0\u5347\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.04523", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.04523", "abs": "https://arxiv.org/abs/2511.04523", "authors": ["Silvia Bonomi", "Giovanni Farina", "Roy Friedman", "Eviatar B. Procaccia", "Sebastien Tixeuil"], "title": "A New Probabilistic Mobile Byzantine Failure Model for Self-Protecting Systems", "comment": null, "summary": "Modern distributed systems face growing security threats, as attackers\ncontinuously enhance their skills and vulnerabilities span across the entire\nsystem stack, from hardware to the application layer. In the system design\nphase, fault tolerance techniques can be employed to safeguard systems. From a\ntheoretical perspective, an attacker attempting to compromise a system can be\nabstracted by considering the presence of Byzantine processes in the system.\nAlthough this approach enhances the resilience of the distributed system, it\nintroduces certain limitations regarding the accuracy of the model in\nreflecting real-world scenarios. In this paper, we consider a self-protecting\ndistributed system based on the \\emph{Monitoring-Analyse-Plan-Execute over a\nshared Knowledge} (MAPE-K) architecture, and we propose a new probabilistic\nMobile Byzantine Failure (MBF) that can be plugged into the Analysis component.\nOur new model captures the dynamics of evolving attacks and can be used to\ndrive the self-protection and reconfiguration strategy. We analyze\nmathematically the time that it takes until the number of Byzantine nodes\ncrosses given thresholds, or for the system to self-recover back into a safe\nstate, depending on the rates of Byzantine infection spreading \\emph{vs.} the\nrate of self-recovery. We also provide simulation results that illustrate the\nbehavior of the system under such assumptions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eMAPE-K\u67b6\u6784\u7684\u81ea\u4fdd\u62a4\u5206\u5e03\u5f0f\u7cfb\u7edf\u6a21\u578b\uff0c\u5f15\u5165\u65b0\u7684\u6982\u7387\u6027\u79fb\u52a8\u62dc\u5360\u5ead\u6545\u969c\uff08MBF\uff09\u673a\u5236\uff0c\u7528\u4e8e\u523b\u753b\u52a8\u6001\u653b\u51fb\u884c\u4e3a\uff0c\u5e76\u901a\u8fc7\u6570\u5b66\u5206\u6790\u4e0e\u4eff\u771f\u7814\u7a76\u7cfb\u7edf\u5728\u653b\u51fb\u4f20\u64ad\u4e0e\u81ea\u6062\u590d\u4e4b\u95f4\u7684\u52a8\u6001\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u62dc\u5360\u5ead\u8fdb\u7a0b\u7684\u5bb9\u9519\u6a21\u578b\u96be\u4ee5\u51c6\u786e\u53cd\u6620\u73b0\u5b9e\u4e2d\u7684\u52a8\u6001\u653b\u51fb\u573a\u666f\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u8d34\u8fd1\u5b9e\u9645\u7684\u5efa\u6a21\u65b9\u6cd5\u6765\u63d0\u5347\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u81ea\u4fdd\u62a4\u80fd\u529b\u3002", "method": "\u5728MAPE-K\u81ea\u9002\u5e94\u67b6\u6784\u7684\u5206\u6790\u7ec4\u4ef6\u4e2d\u5d4c\u5165\u4e00\u79cd\u65b0\u7684\u6982\u7387\u6027\u79fb\u52a8\u62dc\u5360\u5ead\u6545\u969c\uff08MBF\uff09\u6a21\u578b\uff0c\u7ed3\u5408\u6570\u5b66\u5206\u6790\u4e0e\u4eff\u771f\u5b9e\u9a8c\uff0c\u7814\u7a76\u653b\u51fb\u4f20\u64ad\u901f\u7387\u4e0e\u7cfb\u7edf\u81ea\u6062\u590d\u901f\u7387\u5bf9\u7cfb\u7edf\u72b6\u6001\u6f14\u5316\u7684\u5f71\u54cd\u3002", "result": "\u8bba\u6587\u63a8\u5bfc\u4e86\u7cfb\u7edf\u4e2d\u62dc\u5360\u5ead\u8282\u70b9\u6570\u91cf\u8d8a\u8fc7\u5b89\u5168\u9608\u503c\u6216\u6062\u590d\u81f3\u5b89\u5168\u72b6\u6001\u6240\u9700\u7684\u65f6\u95f4\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u6240\u63d0\u6a21\u578b\u5728\u4e0d\u540c\u53c2\u6570\u8bbe\u7f6e\u4e0b\u7684\u7cfb\u7edf\u884c\u4e3a\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6982\u7387\u6027MBF\u6a21\u578b\u80fd\u6709\u6548\u523b\u753b\u52a8\u6001\u653b\u51fb\u8fc7\u7a0b\uff0c\u4e3a\u81ea\u4fdd\u62a4\u5206\u5e03\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u548c\u5b9e\u7528\u6307\u5bfc\uff0c\u589e\u5f3a\u5176\u5728\u9762\u5bf9\u590d\u6742\u5a01\u80c1\u65f6\u7684\u9002\u5e94\u6027\u548c\u97e7\u6027\u3002"}}
{"id": "2511.04157", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04157", "abs": "https://arxiv.org/abs/2511.04157", "authors": ["Asma Yamani", "Malak Baslyman", "Moataz Ahmed"], "title": "Are We Aligned? A Preliminary Investigation of the Alignment of Responsible AI Values between LLMs and Human Judgment", "comment": null, "summary": "Large Language Models (LLMs) are increasingly employed in software\nengineering tasks such as requirements elicitation, design, and evaluation,\nraising critical questions regarding their alignment with human judgments on\nresponsible AI values. This study investigates how closely LLMs' value\npreferences align with those of two human groups: a US-representative sample\nand AI practitioners. We evaluate 23 LLMs across four tasks: (T1) selecting key\nresponsible AI values, (T2) rating their importance in specific contexts, (T3)\nresolving trade-offs between competing values, and (T4) prioritizing software\nrequirements that embody those values. The results show that LLMs generally\nalign more closely with AI practitioners than with the US-representative\nsample, emphasizing fairness, privacy, transparency, safety, and\naccountability. However, inconsistencies appear between the values that LLMs\nclaim to uphold (Tasks 1-3) and the way they prioritize requirements (Task 4),\nrevealing gaps in faithfulness between stated and applied behavior. These\nfindings highlight the practical risk of relying on LLMs in requirements\nengineering without human oversight and motivate the need for systematic\napproaches to benchmark, interpret, and monitor value alignment in AI-assisted\nsoftware development.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e8623\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8d1f\u8d23\u4efbAI\u4ef7\u503c\u89c2\u65b9\u9762\u4e0e\u4e24\u7c7b\u4eba\u7fa4\uff08\u7f8e\u56fd\u4ee3\u8868\u6027\u6837\u672c\u548cAI\u4ece\u4e1a\u8005\uff09\u7684\u4e00\u81f4\u6027\uff0c\u53d1\u73b0LLMs\u66f4\u8d34\u8fd1AI\u4ece\u4e1a\u8005\u7684\u504f\u597d\uff0c\u4f46\u5728\u58f0\u660e\u7684\u4ef7\u503c\u89c2\u4e0e\u5b9e\u9645\u9700\u6c42\u4f18\u5148\u7ea7\u4e4b\u95f4\u5b58\u5728\u4e0d\u4e00\u81f4\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5728\u8d1f\u8d23\u4efbAI\u4ef7\u503c\u89c2\u4e0a\u662f\u5426\u4e0e\u4eba\u7c7b\u5224\u65ad\u4e00\u81f4\u6210\u4e3a\u5173\u952e\u95ee\u9898\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30LLMs\u5728\u4ef7\u503c\u89c2\u504f\u597d\u4e0a\u4e0e\u4e0d\u540c\u4eba\u7fa4\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u5e76\u63ed\u793a\u6f5c\u5728\u98ce\u9669\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u56db\u9879\u4efb\u52a1\u8bc4\u4f3023\u4e2aLLMs\uff1a(T1) \u9009\u62e9\u5173\u952e\u8d1f\u8d23\u4efbAI\u4ef7\u503c\u89c2\uff1b(T2) \u8bc4\u4f30\u8fd9\u4e9b\u4ef7\u503c\u89c2\u5728\u7279\u5b9a\u60c5\u5883\u4e2d\u7684\u91cd\u8981\u6027\uff1b(T3) \u89e3\u51b3\u4ef7\u503c\u89c2\u4e4b\u95f4\u7684\u6743\u8861\uff1b(T4) \u5bf9\u4f53\u73b0\u8fd9\u4e9b\u4ef7\u503c\u89c2\u7684\u8f6f\u4ef6\u9700\u6c42\u8fdb\u884c\u4f18\u5148\u7ea7\u6392\u5e8f\u3002\u6bd4\u8f83LLMs\u4e0e\u7f8e\u56fd\u4ee3\u8868\u6027\u6837\u672c\u53caAI\u4ece\u4e1a\u8005\u4e4b\u95f4\u7684\u5bf9\u9f50\u60c5\u51b5\u3002", "result": "LLMs\u6574\u4f53\u4e0a\u66f4\u8d34\u8fd1AI\u4ece\u4e1a\u8005\u800c\u975e\u7f8e\u56fd\u4ee3\u8868\u6027\u6837\u672c\u7684\u4ef7\u503c\u89c2\uff0c\u5f3a\u8c03\u516c\u5e73\u3001\u9690\u79c1\u3001\u900f\u660e\u3001\u5b89\u5168\u548c\u95ee\u8d23\u3002\u7136\u800c\uff0c\u5728\u524d\u4e09\u4e2a\u4efb\u52a1\u4e2d\u58f0\u660e\u7684\u4ef7\u503c\u89c2\u4e0e\u7b2c\u56db\u4e2a\u4efb\u52a1\u4e2d\u5b9e\u9645\u7684\u9700\u6c42\u4f18\u5148\u7ea7\u4e4b\u95f4\u5b58\u5728\u4e0d\u4e00\u81f4\uff0c\u663e\u793a\u51fa\u201c\u8a00\u884c\u4e0d\u4e00\u201d\u7684\u95ee\u9898\u3002", "conclusion": "\u4f9d\u8d56LLMs\u8fdb\u884c\u9700\u6c42\u5de5\u7a0b\u5b58\u5728\u5b9e\u9645\u98ce\u9669\uff0c\u9700\u8f85\u4ee5\u4eba\u5de5\u76d1\u7763\uff1b\u7814\u7a76\u547c\u5401\u5efa\u7acb\u7cfb\u7edf\u5316\u65b9\u6cd5\u6765\u5bf9\u9f50\u3001\u89e3\u91ca\u548c\u76d1\u63a7AI\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u4ef7\u503c\u89c2\u4e00\u81f4\u6027\u3002"}}
{"id": "2511.04631", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.04631", "abs": "https://arxiv.org/abs/2511.04631", "authors": ["Petr Kuznetsov", "Nathan Josia Schrodt"], "title": "Resolving Conflicts with Grace: Dynamically Concurrent Universality", "comment": null, "summary": "Synchronization is the major obstacle to scalability in distributed\ncomputing. Concurrent operations on the shared data engage in synchronization\nwhen they encounter a \\emph{conflict}, i.e., their effects depend on the order\nin which they are applied. Ideally, one would like to detect conflicts in a\n\\emph{dynamic} manner, i.e., adjusting to the current system state. Indeed, it\nis very common that two concurrent operations conflict only in some rarely\noccurring states. In this paper, we define the notion of \\emph{dynamic\nconcurrency}: an operation employs strong synchronization primitives only if it\n\\emph{has} to arbitrate with concurrent operations, given the current system\nstate. We then present a dynamically concurrent universal construction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u52a8\u6001\u5e76\u53d1\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u6839\u636e\u7cfb\u7edf\u5f53\u524d\u72b6\u6001\u52a8\u6001\u8c03\u6574\u540c\u6b65\u673a\u5236\uff0c\u4ec5\u5728\u5fc5\u8981\u65f6\u4f7f\u7528\u5f3a\u540c\u6b65\u539f\u8bed\uff0c\u5e76\u7ed9\u51fa\u4e00\u79cd\u52a8\u6001\u5e76\u53d1\u7684\u901a\u7528\u6784\u9020\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\uff0c\u540c\u6b65\u662f\u53ef\u6269\u5c55\u6027\u7684\u4e3b\u8981\u969c\u788d\u3002\u5f53\u5e76\u53d1\u64cd\u4f5c\u56e0\u987a\u5e8f\u4f9d\u8d56\u800c\u53d1\u751f\u51b2\u7a81\u65f6\uff0c\u901a\u5e38\u91c7\u7528\u9759\u6001\u540c\u6b65\u7b56\u7565\uff0c\u4f46\u5f88\u591a\u51b2\u7a81\u4ec5\u5728\u7f55\u89c1\u72b6\u6001\u4e0b\u624d\u51fa\u73b0\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u6839\u636e\u7cfb\u7edf\u72b6\u6001\u52a8\u6001\u68c0\u6d4b\u548c\u5904\u7406\u51b2\u7a81\u7684\u65b9\u6cd5\u3002", "method": "\u5b9a\u4e49\u201c\u52a8\u6001\u5e76\u53d1\u201d\u6982\u5ff5\uff1a\u64cd\u4f5c\u4ec5\u5728\u5f53\u524d\u7cfb\u7edf\u72b6\u6001\u4e0b\u786e\u5b9e\u9700\u8981\u4e0e\u5e76\u53d1\u64cd\u4f5c\u4ef2\u88c1\u65f6\uff0c\u624d\u4f7f\u7528\u5f3a\u540c\u6b65\u539f\u8bed\uff1b\u5e76\u57fa\u4e8e\u6b64\u6784\u5efa\u4e00\u4e2a\u52a8\u6001\u5e76\u53d1\u7684\u901a\u7528\u6784\u9020\u3002", "result": "\u63d0\u51fa\u4e86\u52a8\u6001\u5e76\u53d1\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u652f\u6301\u8be5\u7279\u6027\u7684\u901a\u7528\u6784\u9020\uff0c\u80fd\u591f\u5728\u51cf\u5c11\u4e0d\u5fc5\u8981\u540c\u6b65\u7684\u540c\u65f6\u4fdd\u8bc1\u6b63\u786e\u6027\u3002", "conclusion": "\u52a8\u6001\u5e76\u53d1\u80fd\u591f\u6709\u6548\u7f13\u89e3\u540c\u6b65\u5e26\u6765\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u72b6\u6001\u611f\u77e5\u7684\u51b2\u7a81\u68c0\u6d4b\u673a\u5236\uff0c\u5728\u4fdd\u8bc1\u6b63\u786e\u6027\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2511.04179", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04179", "abs": "https://arxiv.org/abs/2511.04179", "authors": ["Oshando Johnson", "Alexandra Fomina", "Ranjith Krishnamurthy", "Vaibhav Chaudhari", "Rohith Kumar Shanmuganathan", "Eric Bodden"], "title": "Explaining Software Vulnerabilities with Large Language Models", "comment": null, "summary": "The prevalence of security vulnerabilities has prompted companies to adopt\nstatic application security testing (SAST) tools for vulnerability detection.\nNevertheless, these tools frequently exhibit usability limitations, as their\ngeneric warning messages do not sufficiently communicate important information\nto developers, resulting in misunderstandings or oversight of critical\nfindings. In light of recent developments in Large Language Models (LLMs) and\ntheir text generation capabilities, our work investigates a hybrid approach\nthat uses LLMs to tackle the SAST explainability challenges. In this paper, we\npresent SAFE, an Integrated Development Environment (IDE) plugin that leverages\nGPT-4o to explain the causes, impacts, and mitigation strategies of\nvulnerabilities detected by SAST tools. Our expert user study findings indicate\nthat the explanations generated by SAFE can significantly assist beginner to\nintermediate developers in understanding and addressing security\nvulnerabilities, thereby improving the overall usability of SAST tools.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSAFE\uff0c\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\uff09\u7684IDE\u63d2\u4ef6\uff0c\u7528\u4e8e\u63d0\u5347\u9759\u6001\u5e94\u7528\u5b89\u5168\u6d4b\u8bd5\uff08SAST\uff09\u5de5\u5177\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e2e\u52a9\u521d\u7ea7\u81f3\u4e2d\u7ea7\u5f00\u53d1\u8005\u66f4\u597d\u5730\u7406\u89e3\u548c\u4fee\u590d\u5b89\u5168\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709SAST\u5de5\u5177\u751f\u6210\u7684\u8b66\u544a\u4fe1\u606f\u8fc7\u4e8e\u901a\u7528\uff0c\u7f3a\u4e4f\u5bf9\u6f0f\u6d1e\u6210\u56e0\u3001\u5f71\u54cd\u548c\u4fee\u590d\u7b56\u7565\u7684\u6e05\u6670\u8bf4\u660e\uff0c\u5bfc\u81f4\u5f00\u53d1\u8005\u96be\u4ee5\u7406\u89e3\u6216\u5ffd\u89c6\u5173\u952e\u6f0f\u6d1e\u3002", "method": "\u5f00\u53d1SAFE\u63d2\u4ef6\uff0c\u96c6\u6210GPT-4o\uff0c\u5728IDE\u4e2d\u81ea\u52a8\u751f\u6210\u9488\u5bf9SAST\u68c0\u6d4b\u51fa\u7684\u6f0f\u6d1e\u7684\u8be6\u7ec6\u89e3\u91ca\uff0c\u5305\u62ec\u539f\u56e0\u3001\u5f71\u54cd\u548c\u7f13\u89e3\u63aa\u65bd\u3002", "result": "\u4e13\u5bb6\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cSAFE\u751f\u6210\u7684\u89e3\u91ca\u663e\u8457\u63d0\u5347\u4e86\u521d\u7ea7\u81f3\u4e2d\u7ea7\u5f00\u53d1\u8005\u5bf9\u5b89\u5168\u6f0f\u6d1e\u7684\u7406\u89e3\u4e0e\u5904\u7406\u80fd\u529b\u3002", "conclusion": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3aSAST\u5de5\u5177\u7684\u53ef\u89e3\u91ca\u6027\u662f\u4e00\u79cd\u6709\u6548\u624b\u6bb5\uff0c\u80fd\u663e\u8457\u6539\u5584\u5176\u53ef\u7528\u6027\uff0c\u5c24\u5176\u5bf9\u7ecf\u9a8c\u8f83\u5c11\u7684\u5f00\u53d1\u8005\u5177\u6709\u91cd\u8981\u5e2e\u52a9\u3002"}}
{"id": "2511.04182", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04182", "abs": "https://arxiv.org/abs/2511.04182", "authors": ["Christos Tranoris"], "title": "GITER: A Git-Based Declarative Exchange Model Using Kubernetes-Style Custom Resources", "comment": null, "summary": "This paper introduces a lightweight and auditable method for asynchronous\ninformation exchange between distributed entities using Git as the coordination\nmedium. The proposed approach replaces traditional APIs and message brokers\nwith a Git-based communication model built on the principles of Kubernetes\nOperators and Custom Resources (CRs). Each participating entity, designated as\na Publisher or Consumer, interacts through a shared repository that serves as a\nsingle source of truth, where the spec field captures the desired state and the\nstatus field reflects the observed outcome. This pattern extends GitOps beyond\ninfrastructure management to support cross-domain, inter-organizational, and\nair-gapped collaboration scenarios. By leveraging Git native features\n(versioning, commit signing, and access control) the model ensures\ntransparency, traceability, and reproducibility while preserving loose coupling\nand autonomy between systems. The paper discusses architectural principles,\nimplementation considerations, and comparisons with RESTful and broker-based\nintegrations, highlighting both the advantages and trade-offs of adopting Git\nas a declarative communication substrate.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e Git \u7684\u8f7b\u91cf\u7ea7\u3001\u53ef\u5ba1\u8ba1\u7684\u5f02\u6b65\u4fe1\u606f\u4ea4\u6362\u65b9\u6cd5\uff0c\u5229\u7528 Kubernetes Operator \u548c\u81ea\u5b9a\u4e49\u8d44\u6e90\uff08CR\uff09\u6a21\u5f0f\uff0c\u5c06 Git \u4f5c\u4e3a\u5206\u5e03\u5f0f\u5b9e\u4f53\u95f4\u7684\u901a\u4fe1\u5a92\u4ecb\uff0c\u6269\u5c55\u4e86 GitOps \u7684\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u4f20\u7edf API \u548c\u6d88\u606f\u4e2d\u95f4\u4ef6\u5728\u8de8\u57df\u3001\u8de8\u7ec4\u7ec7\u6216\u9694\u79bb\u73af\u5883\u4e0b\u7684\u534f\u4f5c\u4e2d\u5b58\u5728\u8026\u5408\u5ea6\u9ad8\u3001\u5ba1\u8ba1\u56f0\u96be\u7b49\u95ee\u9898\uff0c\u4f5c\u8005\u65e8\u5728\u901a\u8fc7 Git \u63d0\u4f9b\u4e00\u79cd\u66f4\u900f\u660e\u3001\u53ef\u8ffd\u6eaf\u4e14\u677e\u8026\u5408\u7684\u901a\u4fe1\u673a\u5236\u3002", "method": "\u91c7\u7528 Git \u4f5c\u4e3a\u534f\u8c03\u5a92\u4ecb\uff0c\u7ed3\u5408 Kubernetes Operator \u548c\u81ea\u5b9a\u4e49\u8d44\u6e90\uff08CR\uff09\uff0c\u901a\u8fc7\u5171\u4eab\u4ed3\u5e93\u4e2d\u7684 spec \u5b57\u6bb5\u8868\u793a\u671f\u671b\u72b6\u6001\u3001status \u5b57\u6bb5\u53cd\u6620\u5b9e\u9645\u72b6\u6001\uff0c\u5b9e\u73b0\u58f0\u660e\u5f0f\u901a\u4fe1\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u5c06 GitOps \u6269\u5c55\u81f3\u8de8\u57df\u548c\u9694\u79bb\u73af\u5883\u7684\u4fe1\u606f\u4ea4\u6362\u573a\u666f\uff0c\u5177\u5907\u7248\u672c\u63a7\u5236\u3001\u63d0\u4ea4\u7b7e\u540d\u548c\u8bbf\u95ee\u63a7\u5236\u7b49\u539f\u751f\u7279\u6027\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u900f\u660e\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u53ef\u590d\u73b0\u6027\u3002", "conclusion": "Git \u53ef\u4f5c\u4e3a\u58f0\u660e\u5f0f\u901a\u4fe1\u7684\u57fa\u7840\u67b6\u6784\uff0c\u5728\u4fdd\u6301\u7cfb\u7edf\u81ea\u6cbb\u4e0e\u677e\u8026\u5408\u7684\u540c\u65f6\uff0c\u652f\u6301\u5b89\u5168\u3001\u53ef\u5ba1\u8ba1\u7684\u5f02\u6b65\u4fe1\u606f\u4ea4\u6362\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u590d\u6742\u534f\u4f5c\u573a\u666f\u3002"}}
{"id": "2511.04267", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04267", "abs": "https://arxiv.org/abs/2511.04267", "authors": ["Jiahui Wu", "Chengjie Lu", "Aitor Arrieta", "Shaukat Ali"], "title": "A Tool for Benchmarking Large Language Models' Robustness in Assessing the Realism of Driving Scenarios", "comment": null, "summary": "In recent years, autonomous driving systems have made significant progress,\nyet ensuring their safety remains a key challenge. To this end, scenario-based\ntesting offers a practical solution, and simulation-based methods have gained\ntraction due to the high cost and risk of real-world testing. However,\nevaluating the realism of simulated scenarios remains difficult, creating\ndemand for effective assessment methods. Recent advances show that Large\nLanguage Models (LLMs) possess strong reasoning and generalization\ncapabilities, suggesting their potential in assessing scenario realism through\nscenario-related textual prompts. Motivated by this, we propose DriveRLR, a\nbenchmark tool to assess the robustness of LLMs in evaluating the realism of\ndriving scenarios. DriveRLR generates mutated scenario variants, constructs\nprompts, which are then used to assess a given LLM's ability and robustness in\ndetermining the realism of driving scenarios. We validate DriveRLR on the\nDeepScenario dataset using three state-of-the-art LLMs: GPT-5, Llama 4\nMaverick, and Mistral Small 3.2. Results show that DriveRLR effectively reveals\ndifferences in the robustness of various LLMs, demonstrating its effectiveness\nand practical value in scenario realism assessment. Beyond LLM robustness\nevaluation, DriveRLR can serve as a practical component in applications such as\nan objective function to guide scenario generation, supporting simulation-based\nADS testing workflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DriveRLR\uff0c\u4e00\u79cd\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5224\u65ad\u9a7e\u9a76\u573a\u666f\u771f\u5b9e\u6027\u65b9\u9762\u9c81\u68d2\u6027\u7684\u57fa\u51c6\u5de5\u5177\u3002\u8be5\u5de5\u5177\u901a\u8fc7\u751f\u6210\u53d8\u5f02\u573a\u666f\u5e76\u6784\u5efa\u6587\u672c\u63d0\u793a\uff0c\u6d4b\u8bd5LLM\u5bf9\u771f\u5b9e\u611f\u7684\u5224\u65ad\u80fd\u529b\uff0c\u5e76\u5728DeepScenario\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u4eff\u771f\u6d4b\u8bd5\u4e2d\u7f3a\u4e4f\u6709\u6548\u8bc4\u4f30\u9a7e\u9a76\u573a\u666f\u771f\u5b9e\u6027\u7684\u65b9\u6cd5\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u4e0e\u6cdb\u5316\u80fd\u529b\uff0c\u6709\u671b\u7528\u4e8e\u8be5\u4efb\u52a1\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u7cfb\u7edf\u6027\u57fa\u51c6\u6765\u8bc4\u4f30LLM\u5728\u6b64\u7c7b\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "method": "DriveRLR\u901a\u8fc7\u751f\u6210\u53d8\u5f02\u7684\u9a7e\u9a76\u573a\u666f\u53d8\u4f53\u5e76\u6784\u9020\u76f8\u5e94\u7684\u6587\u672c\u63d0\u793a\uff0c\u8f93\u5165\u7ed9\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4ece\u800c\u8bc4\u4f30\u5176\u5224\u65ad\u573a\u666f\u771f\u5b9e\u6027\u7684\u80fd\u529b\u4e0e\u9c81\u68d2\u6027\u3002", "result": "\u5728DeepScenario\u6570\u636e\u96c6\u4e0a\u5bf9GPT-5\u3001Llama 4 Maverick\u548cMistral Small 3.2\u4e09\u79cd\u5148\u8fdbLLM\u7684\u6d4b\u8bd5\u8868\u660e\uff0cDriveRLR\u80fd\u6709\u6548\u63ed\u793a\u4e0d\u540c\u6a21\u578b\u5728\u9c81\u68d2\u6027\u4e0a\u7684\u5dee\u5f02\u3002", "conclusion": "DriveRLR\u4e0d\u4ec5\u53ef\u4f5c\u4e3a\u8bc4\u4f30LLM\u9c81\u68d2\u6027\u7684\u6709\u6548\u57fa\u51c6\uff0c\u8fd8\u53ef\u4f5c\u4e3a\u5b9e\u9645\u5e94\u7528\u7ec4\u4ef6\uff0c\u4f8b\u5982\u4f5c\u4e3a\u76ee\u6807\u51fd\u6570\u5f15\u5bfc\u573a\u666f\u751f\u6210\uff0c\u652f\u6301\u57fa\u4e8e\u4eff\u771f\u7684\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u6d4b\u8bd5\u6d41\u7a0b\u3002"}}
{"id": "2511.04355", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04355", "abs": "https://arxiv.org/abs/2511.04355", "authors": ["Amir Molzam Sharifloo", "Maedeh Heydari", "Parsa Kazerooni", "Daniel Maninger", "Mira Mezini"], "title": "Where Do LLMs Still Struggle? An In-Depth Analysis of Code Generation Benchmarks", "comment": "To be published in Proceedings of 2025 2nd IEEE/ACM International\n  Conference on AI-powered Software (AIware), Data & Benchmark Track", "summary": "Large Language Models (LLMs) have achieved remarkable success in code\ngeneration, and the race to improve their performance has become a central\nfocus of AI research. Benchmarks and leaderboards are increasingly popular,\noffering quantitative rankings of LLMs. However, they provide limited insight\ninto the tasks that LLMs consistently fail to solve - information that is\ncrucial for understanding current limitations and guiding the development of\nmore capable models. To address this gap, we examined code generation tasks\nacross four popular benchmarks, identifying those that major LLMs are most\nlikely to fail. To understand the causes of these failures, we investigated\nwhether the static complexity of solution code contributes to them, followed by\na systematic inspection of 114 tasks that LLMs consistently struggled with. Our\nanalysis revealed four recurring patterns of weaknesses in LLMs, as well as\ncommon complications within benchmark tasks that most often lead to failure.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u5931\u8d25\u6848\u4f8b\uff0c\u8bc6\u522b\u51fa\u5176\u5728\u56db\u4e2a\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u666e\u904d\u96be\u4ee5\u89e3\u51b3\u7684\u4efb\u52a1\uff0c\u5e76\u63ed\u793a\u4e86\u5bfc\u81f4\u5931\u8d25\u7684\u56db\u79cd\u5e38\u89c1\u5f31\u70b9\u6a21\u5f0f\u53ca\u4efb\u52a1\u672c\u8eab\u7684\u590d\u6742\u6027\u56e0\u7d20\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u6392\u884c\u699c\u867d\u80fd\u5bf9LLMs\u8fdb\u884c\u6027\u80fd\u6392\u5e8f\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u5931\u8d25\u4efb\u52a1\u7684\u6df1\u5165\u6d1e\u5bdf\uff0c\u800c\u8fd9\u4e9b\u4fe1\u606f\u5bf9\u4e8e\u7406\u89e3\u6a21\u578b\u5c40\u9650\u6027\u548c\u6307\u5bfc\u672a\u6765\u6539\u8fdb\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f5c\u8005\u8003\u5bdf\u4e86\u56db\u4e2a\u6d41\u884c\u57fa\u51c6\u4e2d\u7684\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u7b5b\u9009\u51fa\u4e3b\u6d41LLMs\u6700\u5e38\u5931\u8d25\u7684\u4efb\u52a1\uff1b\u901a\u8fc7\u5206\u6790\u89e3\u51b3\u65b9\u6848\u4ee3\u7801\u7684\u9759\u6001\u590d\u6742\u5ea6\uff0c\u5e76\u7cfb\u7edf\u68c0\u67e5114\u4e2aLLMs\u6301\u7eed\u8868\u73b0\u4e0d\u4f73\u7684\u4efb\u52a1\uff0c\u5f52\u7eb3\u5931\u8d25\u539f\u56e0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e86LLMs\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u56db\u79cd\u53cd\u590d\u51fa\u73b0\u7684\u5f31\u70b9\u6a21\u5f0f\uff0c\u4ee5\u53ca\u57fa\u51c6\u4efb\u52a1\u4e2d\u5e38\u89c1\u7684\u5bfc\u81f4\u5931\u8d25\u7684\u590d\u6742\u6027\u56e0\u7d20\u3002", "conclusion": "\u4e3a\u63d0\u5347LLMs\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u9700\u5173\u6ce8\u5176\u5728\u7279\u5b9a\u7c7b\u578b\u4efb\u52a1\u4e2d\u7684\u7cfb\u7edf\u6027\u5f31\u70b9\uff0c\u5e76\u91cd\u65b0\u5ba1\u89c6\u73b0\u6709\u57fa\u51c6\u4efb\u52a1\u7684\u8bbe\u8ba1\u662f\u5426\u5408\u7406\u3002"}}
{"id": "2511.04486", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04486", "abs": "https://arxiv.org/abs/2511.04486", "authors": ["Wayne Chi", "Valerie Chen", "Ryan Shar", "Aditya Mittal", "Jenny Liang", "Wei-Lin Chiang", "Anastasios Nikolas Angelopoulos", "Ion Stoica", "Graham Neubig", "Ameet Talwalkar", "Chris Donahue"], "title": "EDIT-Bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits", "comment": null, "summary": "Instructed code editing, where LLMs directly modify a developer's existing\ncode based on a user instruction, is becoming a widely used interaction mode in\nAI coding assistants. However, few benchmarks directly evaluate this capability\nand current datasets often rely on artificial sources. We introduce EDIT-Bench,\na benchmark for evaluating LLM code editing capabilities grounded in real-world\nusage, i.e., user instructions and code contexts collected in the wild.\nEDIT-Bench comprises of 545 problems, multiple natural and programming\nlanguages, and a diverse set of real-world use cases, ranging from resolving\nerrors to adding features. EDIT-Bench introduces context-dependent problems\nthat require the model to understand code context, highlighted code, and cursor\nposition in addition to the user instruction. We evaluate 40 diverse LLMs and\nobserve that EDIT-Bench is a challenging set of problems where only 5 models\nscore over 60%. We find that model performance varies across different\ncategories of user instructions. Further, we find that varying levels of\ncontextual information greatly affect task success rate, with performance\nvarying up to 11%, indicating the importance of evaluating with realistic\ncontext.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86 EDIT-Bench\uff0c\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u7528\u6237\u6307\u4ee4\u548c\u4ee3\u7801\u4e0a\u4e0b\u6587\u7684\u4ee3\u7801\u7f16\u8f91\u80fd\u529b\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5305\u542b545\u4e2a\u591a\u6837\u5316\u7684\u771f\u5b9e\u573a\u666f\u95ee\u9898\uff0c\u8bc4\u4f30\u4e8640\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u4ec5\u67095\u4e2a\u6a21\u578b\u5f97\u5206\u8d85\u8fc760%\uff0c\u5e76\u63ed\u793a\u4e86\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bf9\u6a21\u578b\u8868\u73b0\u7684\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u7f16\u8f91\u80fd\u529b\u8bc4\u6d4b\u57fa\u51c6\u591a\u4f9d\u8d56\u4eba\u5de5\u6784\u9020\u6570\u636e\uff0c\u7f3a\u4e4f\u5bf9\u771f\u5b9e\u4f7f\u7528\u573a\u666f\u7684\u8986\u76d6\uff0c\u96be\u4ee5\u6709\u6548\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u5f00\u53d1\u4e2d\u6839\u636e\u7528\u6237\u6307\u4ee4\u4fee\u6539\u4ee3\u7801\u7684\u80fd\u529b\u3002", "method": "\u6784\u5efa EDIT-Bench \u57fa\u51c6\uff0c\u6536\u96c6\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u7528\u6237\u6307\u4ee4\u4e0e\u4ee3\u7801\u4e0a\u4e0b\u6587\uff0c\u6db5\u76d6\u591a\u79cd\u81ea\u7136\u8bed\u8a00\u3001\u7f16\u7a0b\u8bed\u8a00\u53ca\u591a\u6837\u5316\u7528\u4f8b\uff0c\u5e76\u5f15\u5165\u4f9d\u8d56\u4ee3\u7801\u4e0a\u4e0b\u6587\u3001\u9ad8\u4eae\u4ee3\u7801\u548c\u5149\u6807\u4f4d\u7f6e\u7684\u95ee\u9898\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u5bf940\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "EDIT-Bench \u5bf9\u5f53\u524d\u6a21\u578b\u5177\u6709\u6311\u6218\u6027\uff0c\u4ec55\u4e2a\u6a21\u578b\u5f97\u5206\u8d85\u8fc760%\uff1b\u6a21\u578b\u5728\u4e0d\u540c\u6307\u4ee4\u7c7b\u522b\u4e0a\u7684\u8868\u73b0\u5b58\u5728\u5dee\u5f02\uff1b\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u4e30\u5bcc\u7a0b\u5ea6\u663e\u8457\u5f71\u54cd\u4efb\u52a1\u6210\u529f\u7387\uff0c\u6027\u80fd\u5dee\u5f02\u6700\u9ad8\u8fbe11%\u3002", "conclusion": "\u771f\u5b9e\u4e0a\u4e0b\u6587\u5bf9\u4ee3\u7801\u7f16\u8f91\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0cEDIT-Bench \u4e3a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u7f16\u8f91\u80fd\u529b\u63d0\u4f9b\u4e86\u66f4\u8d34\u8fd1\u5b9e\u9645\u5e94\u7528\u7684\u57fa\u51c6\u3002"}}
{"id": "2511.04548", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04548", "abs": "https://arxiv.org/abs/2511.04548", "authors": ["Qing Wang", "Yong Zhang"], "title": "Microservices Is Dying, A New Method for Module Division Based on Universal Interfaces", "comment": "12 pages", "summary": "Although microservices have physically isolated modules, they have failed to\nprevent the propagation and diffusion of dependencies. To trace the root cause\nof the inter-module coupling, this paper, starting from the impact assessment\napproach for module changes, proposes a conceptual method for calculating\nmodule independence and utilizes this method to derive the necessary conditions\nfor module independence. Then, a new system design philosophy and software\nengineering methodology is proposed, aimed at eliminating dependencies between\nmodules. A specific pattern is employed to design a set of universal\ninterfaces, serving as a universal boundary between modules. Subsequently, this\nmethod is used to implement a platform architecture named EIGHT, demonstrating\nthat, as long as module independence is guaranteed, even a monolithic\napplication within a single process can dynamically load, unload, or modify any\npart at runtime. Finally, the paper concludes that this architecture aims to\nexplore a novel path for increasingly complex systems, beyond microservice and\nmonolithic architectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u8861\u91cf\u6a21\u5757\u72ec\u7acb\u6027\u7684\u65b9\u6cd5\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u7cfb\u7edf\u67b6\u6784EIGHT\uff0c\u65e8\u5728\u6d88\u9664\u6a21\u5757\u95f4\u4f9d\u8d56\uff0c\u5b9e\u73b0\u5373\u4f7f\u5728\u5355\u4f53\u5e94\u7528\u4e2d\u4e5f\u80fd\u52a8\u6001\u52a0\u8f7d\u3001\u5378\u8f7d\u6216\u4fee\u6539\u6a21\u5757\uff0c\u4ece\u800c\u63a2\u7d22\u8d85\u8d8a\u5fae\u670d\u52a1\u4e0e\u5355\u4f53\u67b6\u6784\u7684\u65b0\u8def\u5f84\u3002", "motivation": "\u5c3d\u7ba1\u5fae\u670d\u52a1\u5728\u7269\u7406\u4e0a\u9694\u79bb\u4e86\u6a21\u5757\uff0c\u4f46\u672a\u80fd\u963b\u6b62\u4f9d\u8d56\u7684\u4f20\u64ad\u548c\u6269\u6563\u3002\u4e3a\u4e86\u89e3\u51b3\u6a21\u5757\u95f4\u8026\u5408\u95ee\u9898\uff0c\u9700\u8981\u4ece\u6839\u6e90\u4e0a\u8bc4\u4f30\u6a21\u5757\u53d8\u66f4\u7684\u5f71\u54cd\u5e76\u786e\u4fdd\u6a21\u5757\u72ec\u7acb\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u8ba1\u7b97\u6a21\u5757\u72ec\u7acb\u6027\u7684\u6982\u5ff5\u65b9\u6cd5\uff0c\u63a8\u5bfc\u51fa\u6a21\u5757\u72ec\u7acb\u7684\u5fc5\u8981\u6761\u4ef6\uff0c\u5e76\u636e\u6b64\u8bbe\u8ba1\u901a\u7528\u63a5\u53e3\u6a21\u5f0f\u4f5c\u4e3a\u6a21\u5757\u95f4\u7684\u901a\u7528\u8fb9\u754c\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u6784\u5efa\u540d\u4e3aEIGHT\u7684\u5e73\u53f0\u67b6\u6784\u3002", "result": "\u5b9e\u73b0\u4e86EIGHT\u67b6\u6784\uff0c\u9a8c\u8bc1\u4e86\u53ea\u8981\u4fdd\u8bc1\u6a21\u5757\u72ec\u7acb\u6027\uff0c\u5373\u4f7f\u662f\u5355\u8fdb\u7a0b\u5185\u7684\u5355\u4f53\u5e94\u7528\u4e5f\u80fd\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u52a0\u8f7d\u3001\u5378\u8f7d\u6216\u4fee\u6539\u4efb\u610f\u90e8\u5206\u3002", "conclusion": "\u8be5\u67b6\u6784\u4e3a\u65e5\u76ca\u590d\u6742\u7684\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u6761\u8d85\u8d8a\u4f20\u7edf\u5fae\u670d\u52a1\u4e0e\u5355\u4f53\u67b6\u6784\u7684\u65b0\u8def\u5f84\u3002"}}
