<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 1]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.AR](#cs.AR) [Total: 3]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.PF](#cs.PF) [Total: 1]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [A Confidence-Constrained Cloud-Edge Collaborative Framework for Autism Spectrum Disorder Diagnosis](https://arxiv.org/abs/2510.21130)
*Qi Deng,Yinghao Zhang,Yalin Liu,Bishenghui Tao*

Main category: cs.NI

TL;DR: 提出了一种名为C3EKD的云边协同框架，通过在边缘设备进行大部分推理，并仅将低置信度样本上传至云端进行知识蒸馏，从而在保护隐私的同时提升自闭症谱系障碍（ASD）诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于IoT摄像头的ASD诊断系统在纯云端处理时存在隐私泄露和延迟问题，而纯边缘推理则受限于准确率不足，亟需一种兼顾隐私、延迟与准确性的解决方案。

Method: 提出C3EKD框架：边缘端执行初步推理，仅将低置信度样本上传至云端；云端生成温度缩放的软标签，并通过跨学校的全局损失函数将知识蒸馏回边缘模型，提升泛化能力且不集中原始数据。

Result: 在两个公开的ASD面部图像数据集上，该框架达到了87.4%的准确率，优于现有方法。

Conclusion: C3EKD在保障数据隐私和降低延迟的同时显著提升了边缘ASD诊断系统的准确性，具备在真实校园环境中大规模部署的潜力。

Abstract: Autism Spectrum Disorder (ASD) diagnosis systems in school environments
increasingly relies on IoT-enabled cameras, yet pure cloud processing raises
privacy and latency concerns while pure edge inference suffers from limited
accuracy. We propose Confidence-Constrained Cloud-Edge Knowledge Distillation
(C3EKD), a hierarchical framework that performs most inference at the edge and
selectively uploads only low-confidence samples to the cloud. The cloud
produces temperature-scaled soft labels and distils them back to edge models
via a global loss aggregated across participating schools, improving
generalization without centralizing raw data. On two public ASD facial-image
datasets, the proposed framework achieves a superior accuracy of 87.4\%,
demonstrating its potential for scalable deployment in real-world applications.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [2] [Lincoln AI Computing Survey (LAICS) and Trends](https://arxiv.org/abs/2510.20931)
*Albert Reuther,Peter Michaleas,Michael Jones,Vijay Gadepally,Jeremy Kepner*

Main category: cs.DC

TL;DR: 本文更新了过去七年对AI加速器和处理器的调查（LAICS），汇总了最新公开发布的商用加速器的峰值性能与功耗数据，通过散点图展示趋势，分析市场细分，并引入新的计算架构分类。


<details>
  <summary>Details</summary>
Motivation: 由于生成式AI模型在过去一年中备受关注，推动了对训练和推理计算系统的需求，因此有必要更新对AI加速器的调查。

Method: 收集并汇总过去一年新发布的商用AI加速器的峰值性能和功耗数据，沿用以往方法将其绘制在散点图上，分析趋势、市场细分，并对新增加速器进行简要描述和架构分类。

Result: 更新了LAICS调查，新增了加速器条目，提出了新的计算架构分类，并通过可视化手段揭示了性能与功耗之间的趋势及市场细分特征。

Conclusion: 该调查为理解当前AI加速器的发展趋势、性能功耗权衡及市场格局提供了系统性参考，并通过新架构分类增强了对加速器设计的理解。

Abstract: In the past year, generative AI (GenAI) models have received a tremendous
amount of attention, which in turn has increased attention to computing systems
for training and inference for GenAI. Hence, an update to this survey is due.
This paper is an update of the survey of AI accelerators and processors from
past seven years, which is called the Lincoln AI Computing Survey -- LAICS
(pronounced "lace"). This multi-year survey collects and summarizes the current
commercial accelerators that have been publicly announced with peak performance
and peak power consumption numbers. In the same tradition of past papers of
this survey, the performance and power values are plotted on a scatter graph,
and a number of dimensions and observations from the trends on this plot are
again discussed and analyzed. Market segments are highlighted on the scatter
plot, and zoomed plots of each segment are also included. A brief description
of each of the new accelerators that have been added in the survey this year is
included, and this update features a new categorization of computing
architectures that implement each of the accelerators.

</details>


### [3] [Towards Straggler-Resilient Split Federated Learning: An Unbalanced Update Approach](https://arxiv.org/abs/2510.21155)
*Dandan Liang,Jianing Zhang,Evan Chen,Zhe Li,Rui Li,Haibo Yang*

Main category: cs.DC

TL;DR: 本文提出MU-SplitFed，一种在零阶优化框架下具有抗拖慢节点能力的拆分联邦学习算法，通过不平衡更新机制解耦训练进度与拖慢节点延迟，实现通信轮次的线性加速。


<details>
  <summary>Details</summary>
Motivation: 拆分联邦学习（SFL）因客户端与拆分服务器之间的同步依赖而易受拖慢节点影响，导致显著的时间延迟，限制了系统的可扩展性和效率。

Method: 提出MU-SplitFed算法，允许服务器在每轮客户端通信后执行τ次本地更新，通过不平衡更新机制减少对拖慢节点的依赖，并在零阶优化下实现高效训练。

Result: 理论分析表明MU-SplitFed对非凸目标函数的收敛速率为O(√(d/(τT)))，实验验证其在存在拖慢节点时优于基线方法，并可通过自适应调整τ有效缓解拖慢影响。

Conclusion: MU-SplitFed有效解决了SFL中的拖慢节点问题，提升了系统在异构边缘环境下的训练效率与可扩展性。

Abstract: Split Federated Learning (SFL) enables scalable training on edge devices by
combining the parallelism of Federated Learning (FL) with the computational
offloading of Split Learning (SL). Despite its great success, SFL suffers
significantly from the well-known straggler issue in distributed learning
systems. This problem is exacerbated by the dependency between Split Server and
clients: the Split Server side model update relies on receiving activations
from clients. Such synchronization requirement introduces significant time
latency, making straggler a critical bottleneck to the scalability and
efficiency of the system. To mitigate this problem, we propose MU-SplitFed, a
straggler-resilient SFL algorithm in zeroth-order optimization that decouples
training progress from straggler delays via a simple yet effective unbalanced
update mechanism.
  By enabling the server to perform $\tau$ local updates per client round,
MU-SplitFed achieves a convergence rate of $O(\sqrt{d/(\tau T)})$ for
non-convex objectives, demonstrating a linear speedup of $\tau$ in
communication rounds. Experiments demonstrate that MU-SplitFed consistently
outperforms baseline methods with the presence of stragglers and effectively
mitigates their impact through adaptive tuning of $\tau$. The code for this
project is available at https://github.com/Johnny-Zip/MU-SplitFed.

</details>


### [4] [From SLA to vendor-neutral metrics: An intelligent knowledge-based approach for multi-cloud SLA-based broker](https://arxiv.org/abs/2510.21173)
*Víctor Rampérez,Javier Soriano,David Lizcano,Shadi Aljawarneh,Juan A. Lara*

Main category: cs.DC

TL;DR: 本文提出了一种智能知识系统，能将用户定义的高层服务等级协议（SLA）自动转换为跨云厂商通用的中立指标，并通过两个多云用例验证了该方法的有效性，从而帮助用户摆脱厂商锁定，实现透明的多云管理。


<details>
  <summary>Details</summary>
Motivation: 当前主流云服务商将保障服务等级协议（SLA）合规的责任推给用户，而用户缺乏专业知识；同时各厂商提供的底层指标不统一，导致SLA策略绑定特定厂商，阻碍多云环境的使用。

Method: 提出一个基于知识的智能系统，将高层SLA自动翻译为厂商中立的可度量指标，并定义一套通用指标体系，说明其在不同云平台上的测量方式。

Result: 在IaaS和PaaS两个用例的多云环境中验证了方案的有效性，证明用户可自动、透明地利用多云优势，该结论也得到了领域专家的认可。

Conclusion: 通过将SLA自动转换为厂商中立指标，所提方法有效解决了云厂商锁定问题，使用户能够在多云环境中无缝实施SLA策略，提升云资源管理的灵活性与自动化水平。

Abstract: Cloud computing has been consolidated as a support for the vast majority of
current and emerging technologies. However, there are some barriers that
prevent the exploitation of the full potential of this technology. First, the
major cloud providers currently put the onus of implementing the mechanisms
that ensure compliance with the desired service levels on cloud consumers.
However, consumers do not have the required expertise. Since each cloud
provider exports a different set of low-level metrics, the strategies defined
to ensure compliance with the established service-level agreement (SLA) are
bound to a particular cloud provider. This fosters provider lock-in and
prevents consumers from benefiting from the advantages of multi-cloud
environments. This paper presents a solution to the problem of automatically
translating SLAs into objectives expressed as metrics that can be measured
across multiple cloud providers. First, we propose an intelligent
knowledge-based system capable of automatically translating high-level SLAs
defined by cloud consumers into a set of conditions expressed as vendor-neutral
metrics, providing feedback to cloud consumers (intelligent tutoring system).
Secondly, we present the set of vendor-neutral metrics and explain how they can
be measured for the different cloud providers. Finally, we report a validation
based on two use cases (IaaS and PaaS) in a multi-cloud environment formed by
leading cloud providers. This evaluation has demonstrated that, thanks to the
complementarity of the two solutions, cloud consumers can automatically and
transparently exploit the multi-cloud in many application domains, as endorsed
by the cloud experts consulted in the course of this study.

</details>


### [5] [LIDC: A Location Independent Multi-Cluster Computing Framework for Data Intensive Science](https://arxiv.org/abs/2510.21373)
*Sankalpa Timilsina,Susmit Shannigrahi*

Main category: cs.DC

TL;DR: 本文提出了一种基于语义名称的去中心化计算任务调度控制平面，用于在地理分布的计算集群中动态、灵活地部署任务，摆脱对集中式控制器和静态配置的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前科学计算社区广泛依赖集中式控制器（如Kubernetes）进行任务调度，这种方式在多组织协作场景下不适用，且工作流通常依赖针对单一平台的手动配置，难以适应基础设施的动态变化。

Method: 引入一个去中心化的控制平面，通过为计算任务分配语义名称，并将其与命名的Kubernetes服务端点匹配，实现任务在地理分散集群中的动态调度。

Result: 该方法实现了计算任务与位置解耦，使任何具备足够资源的集群均可执行任务，且无需预先了解集群位置或进行静态配置即可实现动态调度。

Conclusion: 基于语义名称的去中心化调度机制有效解决了多组织协作和动态基础设施环境下计算任务部署的灵活性与可扩展性问题。

Abstract: Scientific communities are increasingly using geographically distributed
computing platforms. The current methods of compute placement predominantly use
logically centralized controllers such as Kubernetes (K8s) to match tasks to
available resources. However, this centralized approach is unsuitable in
multi-organizational collaborations. Furthermore, workflows often need to use
manual configurations tailored for a single platform and cannot adapt to
dynamic changes across infrastructure. Our work introduces a decentralized
control plane for placing computations on geographically dispersed compute
clusters using semantic names. We assign semantic names to computations to
match requests with named Kubernetes (K8s) service endpoints. We show that this
approach provides multiple benefits. First, it allows placement of
computational jobs to be independent of location, enabling any cluster with
sufficient resources to execute the computation. Second, it facilitates dynamic
compute placement without requiring prior knowledge of cluster locations or
predefined configurations.

</details>


### [6] [Arbitration-Free Consistency is Available (and Vice Versa)](https://arxiv.org/abs/2510.21304)
*Hagit Attiya,Constantin Enea,Enrique Román-Calvo*

Main category: cs.DC

TL;DR: 本文提出一个通用语义框架，用于分析分布式存储系统中对象语义与一致性模型的组合，并证明了“无仲裁一致性”（AFC）定理：一个对象在给定一致性模型下可实现高可用，当且仅当其是“无仲裁”的，即无需全局仲裁顺序来解决可见性或读依赖。


<details>
  <summary>Details</summary>
Motivation: 经典理论（如CAP定理）仅适用于简单读写接口，无法精确解释复杂对象语义与一致性模型组合下是否支持高可用实现。本文旨在填补这一空白。

Method: 构建一个统一的语义框架，将操作语义与一致性模型结合，涵盖多种对象（如键值存储、计数器、集合、CRDT、事务数据库）和一致性模型（如因果一致性、顺序一致性、快照隔离等），并在该框架下形式化并证明AFC定理。

Result: 证明了AFC定理，表明“无仲裁性”是判断一个对象在特定一致性模型下是否可高可用实现的充要条件，并统一推广了已有结果。

Conclusion: 仲裁自由性是区分无需协调的一致性与必须同步行为的根本属性，为设计高可用分布式系统提供了理论基础。

Abstract: The fundamental tension between \emph{availability} and \emph{consistency}
shapes the design of distributed storage systems. Classical results capture
extreme points of this trade-off: the CAP theorem shows that strong models like
linearizability preclude availability under partitions, while weak models like
causal consistency remain implementable without coordination. These theorems
apply to simple read-write interfaces, leaving open a precise explanation of
the combinations of object semantics and consistency models that admit
available implementations.
  This paper develops a general semantic framework in which storage
specifications combine operation semantics and consistency models. The
framework encompasses a broad range of objects (key-value stores, counters,
sets, CRDTs, and transactional databases) and consistency models (from causal
consistency and sequential consistency to snapshot isolation and transactional
and non-transactional SQL).
  Within this framework, we prove the \emph{Arbitration-Free Consistency} (AFC)
theorem, showing that an object specification within a consistency model admits
an available implementation if and only if it is \emph{arbitration-free}, that
is, it does not require a total arbitration order to resolve visibility or read
dependencies.
  The AFC theorem unifies and generalizes previous results, revealing
arbitration-freedom as the fundamental property that delineates
coordination-free consistency from inherently synchronized behavior.

</details>


### [7] [On Reduction and Synthesis of Petri's Cycloids](https://arxiv.org/abs/2510.21493)
*Rüdiger Valk,Daniel Moldt*

Main category: cs.DC

TL;DR: 本文研究了用于建模动作与事件过程的环轨（cycloid）Petri网，通过定义其约简系统，分析不可约环轨的性质，并提出了从Petri网结构合成环轨参数的方法，从而实现高效的环轨同构判定算法。


<details>
  <summary>Details</summary>
Motivation: 环轨是Petri一般系统理论中的基础模型，用于描述强同步的顺序过程，但其结构特性尚需深入研究，尤其是如何从结构中恢复参数以及判断同构的问题。

Method: 作者采用重写系统风格定义环轨的约简系统，分析不可约环轨的性质，并从Petri网结构中推导出环轨参数的合成方法。

Result: 成功推导出从Petri网结构合成环轨参数的方法，并基于此提出了一种高效的环轨同构判定算法。

Conclusion: 该研究深化了对环轨结构的理解，为环轨的参数识别与同构判定提供了有效工具，有助于其在系统建模中的应用。

Abstract: Cycloids are particular Petri nets for modelling processes of actions and
events, belonging to the fundaments of Petri's general systems theory. Defined
by four parameters they provide an algebraic formalism to describe strongly
synchronized sequential processes. To further investigate their structure,
reduction systems of cycloids are defined in the style of rewriting systems and
properties of irreducible cycloids are proved. In particular the synthesis of
cycloid parameters from their Petri net structure is derived, leading to an
efficient method for a decision procedure for cycloid isomorphism.

</details>


### [8] [Distributed $(Δ+1)$-Coloring in Graphs of Bounded Neighborhood Independence](https://arxiv.org/abs/2510.21549)
*Marc Fuchs,Fabian Kuhn*

Main category: cs.DC

TL;DR: 本文研究了在邻域独立数为θ的图中，确定性(Δ+1)-着色问题的分布式复杂度，提出了一个准对数多项式时间算法，并指出已有方法在超图边着色中的局限性。


<details>
  <summary>Details</summary>
Motivation: 确定标准消息传递模型中(Δ+1)-着色问题的确定性复杂度是一个重要开放问题。已有工作在邻域独立数θ=O(1)的图上取得较快算法，但仍有改进空间。

Method: 分析邻域独立数θ对(Δ+1)-着色复杂度的影响，设计新的分布式算法以降低运行轮数。

Result: 在邻域独立数为θ的图中，(Δ+1)-着色可在(θ·logΔ)^{O(loglogΔ / logloglogΔ)} + O(log* n)轮内完成；若θ至多为Δ的多项式对数，则算法在Δ上为准对数多项式时间。同时证明已有(2Δ−1)-边着色方法无法推广至秩≥3的超图。

Conclusion: 本文显著改进了邻域独立图上(Δ+1)-着色的确定性分布式算法复杂度，并揭示了现有边着色方法在超图中的局限性。

Abstract: The distributed coloring problem is arguably one of the key problems studied
in the area of distributed graph algorithms. The most standard variant of the
problem asks for a proper vertex coloring of a graph with $\Delta+1$ colors,
where $\Delta$ is the maximum degree of the graph. Despite an immense amount of
work on distributed coloring problems in the distributed setting, determining
the deterministic complexity of $(\Delta+1)$-coloring in the standard message
passing model remains one of the most important open questions of the area. In
this paper, we aim to improve our understanding of the deterministic complexity
of $(\Delta+1)$-coloring as a function of $\Delta$ in a special family of
graphs for which significantly faster algorithms are already known. The
neighborhood independence $\theta$ of a graph is the maximum number of pairwise
non-adjacent neighbors of some node of the graph. In general, in graphs of
neighborhood independence $\theta=O(1)$ (e.g., line graphs), it is known that
$(\Delta+1)$-coloring can be solved in $2^{O(\sqrt{\log\Delta})}+O(\log^* n)$
rounds. In the present paper, we significantly improve this result, and we show
that in graphs of neighborhood independence $\theta$, a $(\Delta+1)$-coloring
can be computed in $(\theta\cdot\log\Delta)^{O(\log\log\Delta /
\log\log\log\Delta)}+O(\log^* n)$ rounds and thus in quasipolylogarithmic time
in $\Delta$ as long as $\theta$ is at most polylogarithmic in $\Delta$. We also
show that the known approach that leads to a polylogarithmic in $\Delta$
algorithm for $(2\Delta-1)$-edge coloring already fails for edge colorings of
hypergraphs of rank at least $3$.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [9] [FIFOAdvisor: A DSE Framework for Automated FIFO Sizing of High-Level Synthesis Designs](https://arxiv.org/abs/2510.20981)
*Stefan Abi-Karam,Rishov Sarkar,Suhail Basalama,Jason Cong,Callie Hao*

Main category: cs.AR

TL;DR: FIFOAdvisor 是一个自动优化 HLS 数据流设计中 FIFO 缓冲区大小的框架，通过高精度快速仿真与多目标优化，在保证无死锁的前提下显著降低内存开销并支持高效设计空间探索。


<details>
  <summary>Details</summary>
Motivation: 在基于 HLS 的 FPGA 数据流设计中，FIFO 缓冲区大小需手动设定，过小会导致停顿甚至死锁，过大会浪费存储资源；现有方法依赖强假设、保守分配或耗时的 RTL 仿真，难以高效准确地确定最优 FIFO 尺寸。

Method: 提出 FIFOAdvisor 框架，结合高精度（99.9% 周期精确）且支持毫秒级增量仿真的 LightningSim，将 FIFO 尺寸优化建模为黑盒双目标优化问题，采用启发式与搜索策略探索延迟-资源权衡，并集成于 Stream-HLS 以支持 C++/MLIR/PyTorch 下降的仿射数据流设计。

Result: 在多个线性代数与深度学习基准上，FIFOAdvisor 找到了帕累托最优的延迟-内存前沿，在几乎不增加延迟的情况下大幅减少内存使用，并相比传统 HLS/RTL 联合仿真显著加速设计空间探索；还在含数据依赖控制流的复杂加速器上验证了有效性。

Conclusion: FIFOAdvisor 通过高效仿真驱动的优化方法，实现了对 HLS 数据流设计中 FIFO 尺寸的自动、可靠且实用的优化，兼顾性能与资源效率，适用于复杂和数据依赖型加速器设计。

Abstract: Dataflow hardware designs enable efficient FPGA implementations via
high-level synthesis (HLS), but correctly sizing first-in-first-out (FIFO)
channel buffers remains challenging. FIFO sizes are user-defined and balance
latency and area-undersized FIFOs cause stalls and potential deadlocks, while
oversized ones waste memory. Determining optimal sizes is non-trivial: existing
methods rely on restrictive assumptions, conservative over-allocation, or slow
RTL simulations. We emphasize that runtime-based analyses (i.e., simulation)
are the only reliable way to ensure deadlock-free FIFO optimization for
data-dependent designs.
  We present FIFOAdvisor, a framework that automatically determines FIFO sizes
in HLS designs. It leverages LightningSim, a 99.9\% cycle-accurate simulator
supporting millisecond-scale incremental runs with new FIFO configurations.
FIFO sizing is formulated as a dual-objective black-box optimization problem,
and we explore heuristic and search-based methods to characterize the
latency-resource trade-off. FIFOAdvisor also integrates with Stream-HLS, a
framework for optimizing affine dataflow designs lowered from C++, MLIR, or
PyTorch, enabling deeper optimization of FIFOs in these workloads.
  We evaluate FIFOAdvisor on Stream-HLS design benchmarks spanning linear
algebra and deep learning workloads. Our results reveal Pareto-optimal
latency-memory frontiers across optimization strategies. Compared to baseline
designs, FIFOAdvisor achieves much lower memory usage with minimal delay
overhead. Additionally, it delivers significant runtime speedups over
traditional HLS/RTL co-simulation, making it practical for rapid design space
exploration. We further demonstrate its capability on a complex accelerator
with data-dependent control flow.
  Code and results: https://github.com/sharc-lab/fifo-advisor

</details>


### [10] [Hardware-Efficient Accurate 4-bit Multiplier for Xilinx 7 Series FPGAs](https://arxiv.org/abs/2510.21533)
*Misaki Kida,Shimpei Sato*

Main category: cs.AR

TL;DR: 本文提出了一种面向AMD Xilinx 7系列FPGA的高效4位乘法器设计，仅使用11个LUT和两个CARRY4模块，在减少资源占用的同时缩短了关键路径延迟。


<details>
  <summary>Details</summary>
Motivation: 随着物联网和边缘推理的发展，需要在基于查找表（LUT）的乘法器中同时优化面积和延迟，以支持大量低比特宽度运算的并行执行。

Method: 通过重新组织映射到LUT的逻辑函数，设计了一种仅使用11个LUT和两个CARRY4模块的4位乘法器。

Result: 该设计相比先前的12-LUT方案减少了一个LUT，并实现了2.750纳秒的关键路径延迟，达到最小资源占用。

Conclusion: 所提出的乘法器在Xilinx 7系列FPGA上实现了资源使用和延迟的双重优化，适用于大规模低比特并行计算场景。

Abstract: As IoT and edge inference proliferate,there is a growing need to
simultaneously optimize area and delay in lookup-table (LUT)-based multipliers
that implement large numbers of low-bitwidth operations in parallel. This paper
proposes a hardwareefficientaccurate 4-bit multiplier design for AMD Xilinx
7-series FPGAs using only 11 LUTs and two CARRY4 blocks. By reorganizing the
logic functions mapped to the LUTs, the proposed method reduces the LUT count
by one compared with the prior 12-LUT design while also shortening the critical
path. Evaluation confirms that the circuit attains minimal resource usage and a
critical-path delay of 2.750 ns.

</details>


### [11] [Accelerating Electrostatics-based Global Placement with Enhanced FFT Computation](https://arxiv.org/abs/2510.21547)
*Hangyu Zhang,Sachin S. Sapatnekar*

Main category: cs.AR

TL;DR: 本文通过引入加速FFT技术（AccFFT）优化电场计算，显著提升了ePlace-MS和Pplace-MS等电路布局算法的运行效率，在标准测试集上实现了FFT计算5.78倍加速和整体运行时间32%的提升，同时线长指标略有改善。


<details>
  <summary>Details</summary>
Motivation: 现代VLSI设计中，高质量且高效的全局布局至关重要；尽管已有基于静电学的解析布局方法提升了可扩展性和解质量，但计算效率仍有优化空间。

Method: 在ePlace-MS和Pplace-MS算法中引入AccFFT加速技术，用于快速计算电场，从而加快全局布局过程。

Result: 在标准基准测试中，FFT计算速度提升5.78倍，整体运行时间减少32%，且在详细布局后归一化半周长线长（HPWL）减少1.0%。

Conclusion: 使用AccFFT加速电场计算能有效提升现有解析布局算法的运行效率，同时保持甚至略微改善布局质量。

Abstract: Global placement is essential for high-quality and efficient circuit
placement for complex modern VLSI designs. Recent advancements, such as
electrostatics-based analytic placement, have improved scalability and solution
quality. This work demonstrates that using an accelerated FFT technique,
AccFFT, for electric field computation significantly reduces runtime.
Experimental results on standard benchmarks show significant improvements when
incorporated into the ePlace-MS and Pplace-MS algorithms, e.g., a 5.78x speedup
in FFT computation and a 32% total runtime improvement against ePlace-MS, with
1.0% reduction of scaled half-perimeter wirelength after detailed placement.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [12] [\textsc{autoresearcher}: Automating Knowledge-Grounded and Transparent Research Ideation with Multi-Agent Collaboration](https://arxiv.org/abs/2510.20844)
*Jiawei Zhou,Ruicheng Zhu,Mengshi Chen,Jianwei Wang,Kai Wang*

Main category: cs.MA

TL;DR: 本文提出了一个名为\textsc{autoresearcher}的多智能体系统，用于实现基于文献的透明化、知识驱动的研究构思，包含四个阶段：结构化知识整理、多样化创意生成、多阶段创意筛选和专家小组评审与综合，并在图挖掘问题上进行了案例演示。


<details>
  <summary>Details</summary>
Motivation: 当前基于智能体的自动化研究构思系统多为黑箱，输出缺乏透明度、可解释性和可控性，难以确保其假设与现有知识充分对齐。

Method: 设计了一个包含四个阶段的统一多智能体框架：(A) 结构化知识整理，(B) 多样化创意生成，(C) 多阶段创意筛选，(D) 专家小组评审与综合；系统公开中间推理状态、执行日志并支持智能体调参。

Result: 在图挖掘（k-truss破坏问题）案例中，系统生成了多个具有证据支持且附带批评意见的合理假设，验证了其有效性与透明性。

Conclusion: \textsc{autoresearcher}提供了一个领域无关、透明可控、知识驱动的研究构思框架，有助于提升科研自动化系统的可信度与实用性。

Abstract: Effective research relies on organizing extensive information and stimulating
novel solutions. Agentic systems have recently emerged as a promising tool to
automate literature-based ideation. However, current systems often remain
black-box. Their outputs may appear plausible but weakly grounded, with limited
transparency or control for researchers. Our work introduces
\textsc{autoresearcher}, a multi-agent demo system for knowledge-grounded and
transparent ideation. Specifically, \textsc{autoresearcher} integrates
meticulously designed four stages into a unified framework: (A) Structured
Knowledge Curation, (B) Diversified Idea Generation, (C) Multi-stage Idea
Selection, and (D) Expert Panel Review \& Synthesis. Different from prior
pipelines, our system not only exposes intermediate reasoning states, execution
logs, and tunable agents for inspections, but also enables the generation of
hypotheses that are both diverse and evidence-aligned. Our design is also
domain-agnostic: as long as literature sources exist, the same pipeline can be
instantiated in any scientific field. As an illustrative case, we demonstrate
\textsc{autoresearcher} on a graph-mining case study ($k$-truss breaking
problem), where it generates distinct, plausible hypotheses with evidence and
critiques. A live demo and source code are available at
https://github.com/valleysprings/AutoResearcher.

</details>


### [13] [HIKMA: Human-Inspired Knowledge by Machine Agents through a Multi-Agent Framework for Semi-Autonomous Scientific Conferences](https://arxiv.org/abs/2510.21370)
*Zain Ul Abideen Tariq,Mahmood Al-Zubaidi,Uzair Shah,Marco Agus,Mowafa Househ*

Main category: cs.MA

TL;DR: HIKMA 是首个端到端整合人工智能于学术出版与展示流程的半自主会议实验，展示了AI如何在保障知识产权、透明度与学术诚信的前提下辅助而非取代传统学术实践。


<details>
  <summary>Details</summary>
Motivation: 重新构想学术交流方式，探索人工智能在学术出版与展示全流程中的整合潜力，同时应对AI作者身份、问责机制及人机协作等关键问题。

Method: 设计并实施HIKMA框架，涵盖AI数据集整理、AI手稿生成、AI辅助同行评审、AI驱动修订、AI会议展示及AI存档传播，并结合语言模型、结构化研究流程与领域保障机制。

Result: HIKMA会议作为试验平台验证了AI支持学术工作的可行性，揭示了AI赋能学术研究的机遇与挑战。

Conclusion: AI可在保护知识产权、透明度和学术诚信的前提下有效辅助传统学术实践，但需深入探讨AI作者身份、责任归属及人机协作模式。

Abstract: HIKMA Semi-Autonomous Conference is the first experiment in reimagining
scholarly communication through an end-to-end integration of artificial
intelligence into the academic publishing and presentation pipeline. This paper
presents the design, implementation, and evaluation of the HIKMA framework,
which includes AI dataset curation, AI-based manuscript generation, AI-assisted
peer review, AI-driven revision, AI conference presentation, and AI archival
dissemination. By combining language models, structured research workflows, and
domain safeguards, HIKMA shows how AI can support - not replace traditional
scholarly practices while maintaining intellectual property protection,
transparency, and integrity. The conference functions as a testbed and proof of
concept, providing insights into the opportunities and challenges of AI-enabled
scholarship. It also examines questions about AI authorship, accountability,
and the role of human-AI collaboration in research.

</details>


### [14] [ColorEcosystem: Powering Personalized, Standardized, and Trustworthy Agentic Service in massive-agent Ecosystem](https://arxiv.org/abs/2510.21566)
*Fangwen Wu,Zheng Wu,Jihong Wang,Yunku Chen,Ruiguang Pei,Heyuan Huang,Xin Liao,Xingyu Lou,Huarong Deng,Zhihui Fu,Weiwen Liu,Zhuosheng Zhang,Weinan Zhang,Jun Wang*

Main category: cs.MA

TL;DR: 本文提出了ColorEcosystem，一种面向大规模智能体生态系统的新型架构，旨在实现个性化、标准化和可信赖的智能体服务。


<details>
  <summary>Details</summary>
Motivation: 当前大规模智能体生态系统面临服务体验缺乏个性化、缺乏标准化以及行为不可信等挑战。

Method: ColorEcosystem包含三个核心组件：智能体载体（agent carrier）利用用户特定数据构建数字孪生以提供个性化服务；智能体商店（agent store）作为集中化平台实现服务标准化管理；智能体审计（agent audit）通过监督开发者与用户活动保障服务提供者与用户的可信度。

Result: 作者分析了大规模智能体生态系统的挑战、演进形态与实践考量，并部分实现了ColorEcosystem，相关代码已开源。

Conclusion: ColorEcosystem为实现大规模智能体生态系统中个性化、标准化和可信赖的服务提供了可行蓝图。

Abstract: With the rapid development of (multimodal) large language model-based agents,
the landscape of agentic service management has evolved from single-agent
systems to multi-agent systems, and now to massive-agent ecosystems. Current
massive-agent ecosystems face growing challenges, including impersonal service
experiences, a lack of standardization, and untrustworthy behavior. To address
these issues, we propose ColorEcosystem, a novel blueprint designed to enable
personalized, standardized, and trustworthy agentic service at scale.
Concretely, ColorEcosystem consists of three key components: agent carrier,
agent store, and agent audit. The agent carrier provides personalized service
experiences by utilizing user-specific data and creating a digital twin, while
the agent store serves as a centralized, standardized platform for managing
diverse agentic services. The agent audit, based on the supervision of
developer and user activities, ensures the integrity and credibility of both
service providers and users. Through the analysis of challenges, transitional
forms, and practical considerations, the ColorEcosystem is poised to power
personalized, standardized, and trustworthy agentic service across
massive-agent ecosystems. Meanwhile, we have also implemented part of
ColorEcosystem's functionality, and the relevant code is open-sourced at
https://github.com/opas-lab/color-ecosystem.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [15] [AgentArcEval: An Architecture Evaluation Method for Foundation Model based Agents](https://arxiv.org/abs/2510.21031)
*Qinghua Lu,Dehai Zhao,Yue Liu,Hao Zhang,Liming Zhu,Xiwei Xu,Angela Shi,Tristan Tan,Rick Kazman*

Main category: cs.SE

TL;DR: 本文提出了AgentArcEval，一种专为基于基础模型的智能体架构评估设计的新方法，并配套提供了一个智能体特定的通用场景目录，通过真实税务助手Luna的案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统架构评估方法难以应对基于基础模型的智能体所具有的复合架构、自主性、非确定性行为和持续演化等独特特性，因此亟需专门的评估方法。

Method: 提出AgentArcEval评估方法及配套的智能体专用通用场景目录，用于指导具体评估场景的生成，并通过真实税务助手Luna的案例进行验证。

Result: 通过Luna税务助手的案例研究，展示了AgentArcEval方法和场景目录在实际智能体架构评估中的实用性和有效性。

Conclusion: AgentArcEval能够有效应对基础模型驱动智能体架构评估的复杂性，为智能体系统的设计与评估提供了实用工具和指导。

Abstract: The emergence of foundation models (FMs) has enabled the development of
highly capable and autonomous agents, unlocking new application opportunities
across a wide range of domains. Evaluating the architecture of agents is
particularly important as the architectural decisions significantly impact the
quality attributes of agents given their unique characteristics, including
compound architecture, autonomous and non-deterministic behaviour, and
continuous evolution. However, these traditional methods fall short in
addressing the evaluation needs of agent architecture due to the unique
characteristics of these agents. Therefore, in this paper, we present
AgentArcEval, a novel agent architecture evaluation method designed specially
to address the complexities of FM-based agent architecture and its evaluation.
Moreover, we present a catalogue of agent-specific general scenarios, which
serves as a guide for generating concrete scenarios to design and evaluate the
agent architecture. We demonstrate the usefulness of AgentArcEval and the
catalogue through a case study on the architecture evaluation of a real-world
tax copilot, named Luna.

</details>


### [16] [BDiff: Block-aware and Accurate Text-based Code Differencing](https://arxiv.org/abs/2510.21094)
*Yao Lu,Wanwei Liu,Tanghaoran Zhang,Kang Yang,Yang Zhang,Wenyu Xu,Longfei Sun,Xinjun Mao,Shuzheng Gao,Michael R. Lyu*

Main category: cs.SE

TL;DR: BDiff is a novel text-based code differencing algorithm that identifies both block-level and line-level edit actions, outperforming existing tools—including LLMs—in result quality while maintaining efficient runtime.


<details>
  <summary>Details</summary>
Motivation: Existing text-based differencing tools fail to capture multi-line block-level edit actions (e.g., moving or duplicating code blocks), instead representing them as fragmented line-level edits, which hinders developers’ ability to understand code changes efficiently.

Method: BDiff constructs a candidate set of all possible line and block mappings and applies the Kuhn-Munkres algorithm to find the optimal mapping that minimizes edit script size while preserving developer intent. It supports two block-level and five line-level edit action types.

Result: Experiments show BDiff generates higher-quality differencing results than five state-of-the-art baselines (including LLMs), with competitive runtime. LLMs are found to be unreliable in result quality and inefficient in runtime for this task.

Conclusion: BDiff effectively addresses the limitation of existing differencing tools in handling block-level edits, improving change comprehension without sacrificing performance, and demonstrates the current inadequacy of LLMs for precise code differencing tasks.

Abstract: Code differencing is a fundamental technique in software engineering practice
and research. While researchers have proposed text-based differencing
techniques capable of identifying line changes over the past decade, existing
methods exhibit a notable limitation in identifying edit actions (EAs) that
operate on text blocks spanning multiple lines. Such EAs are common in
developers' practice, such as moving a code block for conditional branching or
duplicating a method definition block for overloading. Existing tools represent
such block-level operations as discrete sequences of line-level EAs, compelling
developers to manually correlate them and thereby substantially impeding the
efficiency of change comprehension. To address this issue, we propose BDiff, a
text-based differencing algorithm capable of identifying two types of
block-level EAs and five types of line-level EAs. Building on traditional
differencing algorithms, we first construct a candidate set containing all
possible line mappings and block mappings. Leveraging the Kuhn-Munkres
algorithm, we then compute the optimal mapping set that can minimize the size
of the edit script (ES) while closely aligning with the original developer's
intent. To validate the effectiveness of BDiff, we selected five
state-of-the-art tools, including large language models (LLMs), as baselines
and adopted a combined qualitative and quantitative approach to evaluate their
performance in terms of ES size, result quality, and running time. Experimental
results show that BDiff produces higher-quality differencing results than
baseline tools while maintaining competitive runtime performance. Our
experiments also show the unreliability of LLMs in code differencing tasks
regarding result quality and their infeasibility in terms of runtime
efficiency. We have implemented a web-based visual differencing tool.

</details>


### [17] [R2ComSync: Improving Code-Comment Synchronization with In-Context Learning and Reranking](https://arxiv.org/abs/2510.21106)
*Zhen Yang,Hongyi Lin,Xiao Yu,Jacky Wai Keung,Shuo Liu,Pak Yuen Patrick Chan,Yicheng Sun,Fengji Zhang*

Main category: cs.SE

TL;DR: 本文提出R2ComSync，一种基于检索与重排序的上下文学习（ICL）方法，用于提升大语言模型在代码注释同步（CCS）任务中的性能，显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有代码注释同步方法泛化能力不足或依赖大量任务特定资源，而大语言模型（LLMs）在该任务中因缺乏有效示例和候选排序机制表现不佳。

Method: R2ComSync包含两项创新：(1) 集成混合检索，同时考虑代码-注释语义和变更模式的相似性以构建有效的ICL提示；(2) 多轮重排序策略，基于大规模分析得出的三条规则对LLM生成结果进行逐步优化排序。

Result: 在Java和Python的三个CCS数据集上，使用五个最新LLM进行评估，R2ComSync在性能和注释质量上均显著优于五种SOTA方法。

Conclusion: R2ComSync通过结合检索与重排序机制有效提升了LLM在代码注释同步任务中的准确性和实用性，为自动化软件维护提供了高效解决方案。

Abstract: Code-Comment Synchronization (CCS) aims to synchronize the comments with code
changes in an automated fashion, thereby significantly reducing the workload of
developers during software maintenance and evolution. While previous studies
have proposed various solutions that have shown success, they often exhibit
limitations, such as a lack of generalization ability or the need for extensive
task-specific learning resources. This motivates us to investigate the
potential of Large Language Models (LLMs) in this area. However, a pilot
analysis proves that LLMs fall short of State-Of-The-Art (SOTA) CCS approaches
because (1) they lack instructive demonstrations for In-Context Learning (ICL)
and (2) many correct-prone candidates are not prioritized.To tackle the above
challenges, we propose R2ComSync, an ICL-based code-Comment Synchronization
approach enhanced with Retrieval and Re-ranking. Specifically, R2ComSync
carries corresponding two novelties: (1) Ensemble hybrid retrieval. It equally
considers the similarity in both code-comment semantics and change patterns
when retrieval, thereby creating ICL prompts with effective examples. (2)
Multi-turn re-ranking strategy. We derived three significant rules through
large-scale CCS sample analysis. Given the inference results of LLMs, it
progressively exploits three re-ranking rules to prioritize relatively
correct-prone candidates. We evaluate R2ComSync using five recent LLMs on three
CCS datasets covering both Java and Python programming languages, and make
comparisons with five SOTA approaches. Extensive experiments demonstrate the
superior performance of R2ComSync against other approaches. Moreover, both
quantitative and qualitative analyses provide compelling evidence that the
comments synchronized by our proposal exhibit significantly higher quality.}

</details>


### [18] [Does Model Size Matter? A Comparison of Small and Large Language Models for Requirements Classification](https://arxiv.org/abs/2510.21443)
*Mohammad Amin Zadenoori,Vincenzo De Martino,Jacek Dabrowski,Xavier Franch,Alessio Ferrari*

Main category: cs.SE

TL;DR: 该研究发现，在需求分类任务中，小型语言模型（SLMs）的性能几乎与大型语言模型（LLMs）相当，尽管其规模小得多，且在某些指标上甚至更优，表明SLMs是LLMs在隐私、成本和本地部署方面的一个有效替代方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在需求工程任务中表现良好，但存在计算成本高、数据共享风险和依赖外部服务等问题，因此探索轻量级且可本地部署的小型语言模型是否能作为有效替代方案。

Method: 对包括3个LLMs和5个SLMs在内的8个模型在PROMISE、PROMISE Reclass和SecReq三个数据集上进行需求分类任务的性能比较，主要评估指标为F1分数和召回率。

Result: LLMs平均F1分数仅比SLMs高2%，差异无统计显著性；SLMs在PROMISE Reclass数据集上的召回率优于LLMs，且模型规模最多小300倍；数据集特性对性能的影响大于模型大小。

Conclusion: 小型语言模型在需求分类任务中可作为大型语言模型的有效替代，具备隐私保护、低成本和本地部署等优势。

Abstract: [Context and motivation] Large language models (LLMs) show notable results in
natural language processing (NLP) tasks for requirements engineering (RE).
However, their use is compromised by high computational cost, data sharing
risks, and dependence on external services. In contrast, small language models
(SLMs) offer a lightweight, locally deployable alternative. [Question/problem]
It remains unclear how well SLMs perform compared to LLMs in RE tasks in terms
of accuracy. [Results] Our preliminary study compares eight models, including
three LLMs and five SLMs, on requirements classification tasks using the
PROMISE, PROMISE Reclass, and SecReq datasets. Our results show that although
LLMs achieve an average F1 score of 2% higher than SLMs, this difference is not
statistically significant. SLMs almost reach LLMs performance across all
datasets and even outperform them in recall on the PROMISE Reclass dataset,
despite being up to 300 times smaller. We also found that dataset
characteristics play a more significant role in performance than model size.
[Contribution] Our study contributes with evidence that SLMs are a valid
alternative to LLMs for requirements classification, offering advantages in
privacy, cost, and local deployability.

</details>


### [19] [Scalpel: Automotive Deep Learning Framework Testing via Assembling Model Components](https://arxiv.org/abs/2510.21451)
*Yinglong Zou,Juan Zhai,Chunrong Fang,An Guo,Jiawei Liu,Zhenyu Chen*

Main category: cs.SE

TL;DR: 本文提出Scalpel，一种面向汽车深度学习框架的测试方法，通过在模型组件级别生成具备多输入/输出、多模态处理和多层次特征提取能力的测试模型，以检测现有方法难以发现的部署质量问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习框架测试方法无法有效检测汽车部署环境中特有的质量问题（如内存调度不足导致的崩溃），因其生成的测试模型缺乏自动驾驶系统所需的三种关键能力：多输入/输出张量处理、多模态数据处理和多层次数据特征提取。

Method: Scalpel通过维护和更新一个模型组件库（包括head、neck、backbone等），选择、变异并组装这些组件来生成具备自动驾驶所需能力的测试模型；成功生成的模型被用于差分测试，并反馈回组件库以持续丰富测试用例。

Result: Scalpel能够生成符合自动驾驶系统需求的测试模型，并成功部署于真实系统中，有效检测出汽车深度学习框架中的质量问题，如崩溃和内存分配错误。

Conclusion: 通过在模型组件层面生成测试输入，Scalpel弥补了现有测试方法在汽车深度学习框架质量保障方面的不足，为复杂部署环境下的DL框架测试提供了新思路。

Abstract: Deep learning (DL) plays a key role in autonomous driving systems. DL models
support perception modules, equipped with tasks such as object detection and
sensor fusion. These DL models enable vehicles to process multi-sensor inputs
to understand complex surroundings. Deploying DL models in autonomous driving
systems faces stringent challenges, including real-time processing, limited
computational resources, and strict power constraints. To address these
challenges, automotive DL frameworks (e.g., PaddleInference) have emerged to
optimize inference efficiency. However, these frameworks encounter unique
quality issues due to their more complex deployment environments, such as
crashes stemming from limited scheduled memory and incorrect memory allocation.
Unfortunately, existing DL framework testing methods fail to detect these
quality issues due to the failure in deploying generated test input models, as
these models lack three essential capabilities: (1) multi-input/output tensor
processing, (2) multi-modal data processing, and (3) multi-level data feature
extraction. These capabilities necessitate specialized model components, which
existing testing methods neglect during model generation. To bridge this gap,
we propose Scalpel, an automotive DL frameworks testing method that generates
test input models at the model component level. Scalpel generates models by
assembling model components (heads, necks, backbones) to support capabilities
required by autonomous driving systems. Specifically, Scalpel maintains and
updates a repository of model components, generating test inputs by selecting,
mutating, and assembling them. Successfully generated models are added back to
enrich the repository. Newly generated models are then deployed within the
autonomous driving system to test automotive DL frameworks via differential
testing.

</details>


### [20] [Towards Socio-Technical Topology-Aware Adaptive Threat Detection in Software Supply Chains](https://arxiv.org/abs/2510.21452)
*Thomas Welsh,Kristófer Finnsson,Brynjólfur Stefánsson,Helmut Neukirchen*

Main category: cs.SE

TL;DR: 本文提出利用社会技术模型来支持软件供应链（SSC）的自适应威胁检测，强调结合技术与社会数据以识别可疑行为，并通过XZ Utils攻击案例说明其必要性。


<details>
  <summary>Details</summary>
Motivation: 当前软件供应链攻击日益增多，但因其结构复杂、动态且异构，全面漏洞分析困难。现有研究多聚焦于技术层面的依赖监控和组件控制，缺乏通过理解社会技术动态来支持威胁检测的方法。

Method: 提出构建和研究社会技术模型，用于自适应威胁检测；结合对开发者行为与软件的技术分析、去中心化适应机制，并呼吁建立软件供应链安全研究的测试平台。

Result: 通过分析XZ Utils攻击事件，展示了恶意行为者如何通过GitHub和邮件列表破坏维护者信任，说明监控技术与社会数据可识别可疑趋势，从而指导有针对性的漏洞评估。

Conclusion: 将社会技术视角融入软件供应链安全，有助于实现更精准、自适应的威胁检测，未来需在开发者分析、软件分析、去中心化适应机制和测试平台等方面开展研究。

Abstract: Software supply chains (SSCs) are complex systems composed of dynamic,
heterogeneous technical and social components which collectively achieve the
production and maintenance of software artefacts. Attacks on SSCs are
increasing, yet pervasive vulnerability analysis is challenging due to their
complexity. Therefore, threat detection must be targeted, to account for the
large and dynamic structure, and adaptive, to account for its change and
diversity. While current work focuses on technical approaches for monitoring
supply chain dependencies and establishing component controls, approaches which
inform threat detection through understanding the socio-technical dynamics are
lacking. We outline a position and research vision to develop and investigate
the use of socio-technical models to support adaptive threat detection of SSCs.
We motivate this approach through an analysis of the XZ Utils attack whereby
malicious actors undermined the maintainers' trust via the project's GitHub and
mailing lists. We highlight that monitoring technical and social data can
identify trends which indicate suspicious behaviour to then inform targeted and
intensive vulnerability assessment. We identify challenges and research
directions to achieve this vision considering techniques for developer and
software analysis, decentralised adaptation and the need for a test bed for
software supply chain security research.

</details>


### [21] [Risk Management for Mitigating Benchmark Failure Modes: BenchRisk](https://arxiv.org/abs/2510.21460)
*Sean McGregor,Victor Lu,Vassil Tashev,Armstrong Foundjem,Aishwarya Ramasethu,Sadegh AlMahdi Kazemi Zarkouei,Chris Knotz,Kongtao Chen,Alicia Parrish,Anka Reuel,Heather Frase*

Main category: cs.SE

TL;DR: 该研究基于NIST风险管理流程，分析了26个主流大语言模型（LLM）基准测试，识别出57种潜在失效模式及196项缓解策略，并提出了名为BenchRisk的元评估基准，用于衡量基准测试在全面性、可理解性、一致性、正确性和持久性五个维度上的风险。


<details>
  <summary>Details</summary>
Motivation: 当前LLM基准测试可能因各种失效模式（如偏差、方差、覆盖不足或难以理解）而不可靠，影响用户对模型适用性的判断，因此亟需系统性评估和改进基准测试的可靠性。

Method: 采用NIST风险管理办法，对26个流行LLM基准进行迭代分析，识别失效模式并制定缓解策略，进而构建BenchRisk评分体系，从五个维度对基准测试进行风险评估。

Result: 所有26个被评估的基准在至少一个维度上存在显著风险；研究提出了BenchRisk这一开源工具，支持基准间比较及风险与缓解策略的共享。

Conclusion: LLM基准测试领域仍存在重大研究空白，BenchRisk为提升基准可靠性提供了系统性框架，并推动社区协作改进基准设计。

Abstract: Large language model (LLM) benchmarks inform LLM use decisions (e.g., "is
this LLM safe to deploy for my use case and context?"). However, benchmarks may
be rendered unreliable by various failure modes that impact benchmark bias,
variance, coverage, or people's capacity to understand benchmark evidence.
Using the National Institute of Standards and Technology's risk management
process as a foundation, this research iteratively analyzed 26 popular
benchmarks, identifying 57 potential failure modes and 196 corresponding
mitigation strategies. The mitigations reduce failure likelihood and/or
severity, providing a frame for evaluating "benchmark risk," which is scored to
provide a metaevaluation benchmark: BenchRisk. Higher scores indicate that
benchmark users are less likely to reach an incorrect or unsupported conclusion
about an LLM. All 26 scored benchmarks present significant risk within one or
more of the five scored dimensions (comprehensiveness, intelligibility,
consistency, correctness, and longevity), which points to important open
research directions for the field of LLM benchmarking. The BenchRisk workflow
allows for comparison between benchmarks; as an open-source tool, it also
facilitates the identification and sharing of risks and their mitigations.

</details>


### [22] [Wisdom and Delusion of LLM Ensembles for Code Generation and Repair](https://arxiv.org/abs/2510.21513)
*Fernando Vallecillos Ruiz,Max Hort,Leon Moonen*

Main category: cs.SE

TL;DR: 本文研究多个代码大语言模型（LLM）组合使用的潜力，发现基于多样性的集成策略能显著提升性能，远超单一模型，且避免了基于共识策略的“流行陷阱”。


<details>
  <summary>Details</summary>
Motivation: 当前软件工程任务普遍依赖单一LLM，资源消耗大且忽视了不同模型间互补性的潜力；但模型间互补程度及最优集成策略尚不明确，阻碍了实践者采用多模型系统。

Method: 对来自五个系列的十个LLM及其三种集成方案在三个软件工程基准（代码生成与程序修复）上进行实证比较，评估模型互补性、集成性能上限，并测试多种候选解选择启发式策略。

Result: 集成模型的理论性能上限比最佳单模型高83%；基于共识的策略易陷入“流行陷阱”，而基于多样性的策略可实现理论潜力的95%，即使在双模型小规模集成中也高效。

Conclusion: 利用多样性的集成策略能以较低成本显著提升软件工程任务性能，为超越单一LLM系统提供了有效路径。

Abstract: Today's pursuit of a single Large Language Model (LMM) for all software
engineering tasks is resource-intensive and overlooks the potential benefits of
complementarity, where different models contribute unique strengths. However,
the degree to which coding LLMs complement each other and the best strategy for
maximizing an ensemble's potential are unclear, leaving practitioners without a
clear path to move beyond single-model systems.
  To address this gap, we empirically compare ten individual LLMs from five
families, and three ensembles of these LLMs across three software engineering
benchmarks covering code generation and program repair. We assess the
complementarity between models and the performance gap between the best
individual model and the ensembles. Next, we evaluate various selection
heuristics to identify correct solutions from an ensemble's candidate pool.
  We find that the theoretical upperbound for an ensemble's performance can be
83% above the best single model. Our results show that consensus-based
strategies for selecting solutions fall into a "popularity trap," amplifying
common but incorrect outputs. In contrast, a diversity-based strategy realizes
up to 95% of this theoretical potential, and proves effective even in small
two-model ensembles, enabling a cost-efficient way to enhance performance by
leveraging multiple LLMs.

</details>


### [23] [Lights-Out: An Automated Ground Segment for unstaffed Satellite Operations](https://arxiv.org/abs/2510.21516)
*Marvin Böcker,Ralph Biggins,Michael Schmeing*

Main category: cs.SE

TL;DR: 本文介绍了德国Heinrich Hertz卫星任务中首次应用的全自动、周期性无人值守地面段系统，支持24/7自主运行与用户自助实验。


<details>
  <summary>Details</summary>
Motivation: 为实现卫星任务在非工作时间的全自动运行，减少对人工值守的依赖，并为外部用户提供灵活、实时的实验访问能力。

Method: 采用预规划并自动执行的任务调度机制，实现卫星平台的全自动跟踪、遥测与指令（TTC）操作；通过自动监控系统对卫星及地面资产进行实时监测，并根据配置触发应急响应或自动执行飞行操作流程；同时开发了支持24/7访问的自助用户门户，允许用户远程安排实验、实时监控并操控相关设备。

Result: 该系统已成功应用于2023年7月发射的Heinrich Hertz卫星任务，实现了无人值守条件下的全自动运行，并支持用户快速（小于1分钟）调度和调整实验。

Conclusion: 所提出的全自动地面段架构有效提升了卫星任务的运行效率与用户灵活性，为未来类似任务提供了可复用的自动化范式。

Abstract: We present our approach for a periodically unstaffed, fully automated ground
segment. The concept is in use for the first time on the German satellite
communications mission Heinrich Hertz on behalf of the German Space Agency at
DLR. Heinrich Hertz was launched in July 2023 and offers access to scientific
and technical experiments to its users. The mission utilizes major automation
concepts for the satellite platform operations, allowing fully automated
operations outside of office hours. The concept includes tracking, telemetry
and commanding (TTC) of the satellite. Pre-planned and automatically executed
schedules enable commanding without human interaction. The user mission
schedule is planned separately from the main mission schedule and is
automatically de-conflicted. The automatic monitoring concept monitors the
systems of the satellite and all assets in the ground segment and triggers
reactions in operator-configurable ways depending on the mission needs, for
example emergency notifications or automated execution of flight operation
procedures. Additionally, the concept also puts special emphasis on a
self-service user portal that provides flexible access 24/7, even when the
control center is not staffed. The portal allows external users of the payload
to schedule pre-defined experiments, monitor the live execution of the
experiment with browser-based displays and access ground station telemetry and
dedicated RF test equipment during the time of their scheduled experiment.
Tasks can be planned long in advance as well as with a short reaction time
(less than 1 minute), which allows, for example, the reconfiguration of the
payload during a running experiment.

</details>


### [24] [Privacy by Design: Aligning GDPR and Software Engineering Specifications with a Requirements Engineering Approach](https://arxiv.org/abs/2510.21591)
*Oleksandr Kosenkov,Ehsan Zabardast,Davide Fucci,Daniel Mendez,Michael Unterkalmsteiner*

Main category: cs.SE

TL;DR: 本文探讨了如何通过结合需求与系统规格说明来实现隐私设计（PbD），提出一种基于GDPR原始法律概念建模的方法，以提升法律知识捕获、透明性和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分处理GDPR中问题空间与解决方案空间之间的复杂交集，且缺乏对从业者在PbD规格目标方面视角的理解。

Method: 通过文献综述和对从业者的访谈，调查当前实践状态并理解底层规格目标；随后开发并评估了一种面向PbD的需求与系统规格说明方法。

Result: 所提出的方法通过建模GDPR中的原始法律概念，有效支持了法律知识捕获、规格透明性和可追溯性等目标。

Conclusion: 为实现PbD，GDPR需求需在工程生命周期的不同抽象层次上加以处理，并将GDPR中的法律知识纳入规格说明中，以满足多方利益相关者的需求并确保合规。

Abstract: Context: Consistent requirements and system specifications are essential for
the compliance of software systems towards the General Data Protection
Regulation (GDPR). Both artefacts need to be grounded in the original text and
conjointly assure the achievement of privacy by design (PbD). Objectives: There
is little understanding of the perspectives of practitioners on specification
objectives and goals to address PbD. Existing approaches do not account for the
complex intersection between problem and solution space expressed in GDPR. In
this study we explore the demand for conjoint requirements and system
specification for PbD and suggest an approach to address this demand. Methods:
We reviewed secondary and related primary studies and conducted interviews with
practitioners to (1) investigate the state-of-practice and (2) understand the
underlying specification objectives and goals (e.g., traceability). We
developed and evaluated an approach for requirements and systems specification
for PbD, and evaluated it against the specification objectives. Results: The
relationship between problem and solution space, as expressed in GDPR, is
instrumental in supporting PbD. We demonstrate how our approach, based on the
modeling GDPR content with original legal concepts, contributes to
specification objectives of capturing legal knowledge, supporting specification
transparency, and traceability. Conclusion: GDPR demands need to be addressed
throughout different levels of abstraction in the engineering lifecycle to
achieve PbD. Legal knowledge specified in the GDPR text should be captured in
specifications to address the demands of different stakeholders and ensure
compliance. While our results confirm the suitability of our approach to
address practical needs, we also revealed specific needs for the future
effective operationalization of the approach.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [25] [xMem: A CPU-Based Approach for Accurate Estimation of GPU Memory in Deep Learning Training Workloads](https://arxiv.org/abs/2510.21048)
*Jiabo Shi,Dimitrios Pezaros,Yehia Elkhatib*

Main category: cs.PF

TL;DR: xMem 是一种无需 GPU 资源、无需侵入式代码修改的 CPU 动态分析框架，能准确预估深度学习任务的峰值 GPU 内存需求，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在 GPU 资源稀缺的共享集群环境中，准确预估深度学习任务的 GPU 内存需求对高级调度和避免 OOM 错误至关重要，但现有方法在动态内存估计方面存在不足。

Method: 提出 xMem 框架，利用纯 CPU 动态分析，在不使用 GPU 资源且无需修改代码的前提下，提前准确估计任务的峰值 GPU 内存需求。

Result: 在 25 种模型、5209 次运行的评估中，xMem 将中位相对误差降低 91%，安全 OOM 阈值下的估计失败概率降低 75%，内存节约潜力提升 368%。

Conclusion: xMem 能高效、准确地预估 GPU 内存需求，显著提升集群资源利用率并减少 OOM 风险，优于当前最先进的方法。

Abstract: The global scarcity of GPUs necessitates more sophisticated strategies for
Deep Learning jobs in shared cluster environments. Accurate estimation of how
much GPU memory a job will require is fundamental to enabling advanced
scheduling and GPU sharing, which helps prevent out-of-memory (OOM) errors and
resource underutilization. However, existing estimation methods have
limitations. Approaches relying on static analysis or historical data with
machine learning often fail to accurately capture runtime dynamics.
Furthermore, direct GPU analysis consumes scarce resources, and some techniques
require intrusive code modifications. Thus, the key challenge lies in precisely
estimating dynamic memory requirements, including memory allocator nuances,
without consuming GPU resources and non-intrusive code changes. To address this
challenge, we propose xMem, a novel framework that leverages CPU-only dynamic
analysis to accurately estimate peak GPU memory requirements a priori. We
conducted a thorough evaluation of xMem against state-of-the-art solutions
using workloads from 25 different models, including architectures like
Convolutional Neural Networks and Transformers. The analysis of 5209 runs,
which includes ANOVA and Monte Carlo results, highlights xMem's benefits: it
decreases the median relative error by 91% and significantly reduces the
probability of estimation failure as safe OOM thresholds by 75%, meaning that
the estimated value can often be used directly without causing OOM. Ultimately,
these improvements lead to a 368% increase in memory conservation potential
over current solutions.

</details>
