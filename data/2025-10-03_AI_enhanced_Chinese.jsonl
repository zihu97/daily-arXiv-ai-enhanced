{"id": "2510.01730", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.01730", "abs": "https://arxiv.org/abs/2510.01730", "authors": ["Ashiyana Abdul Majeed", "Mahmoud Meribout", "Safa Mohammed Sali"], "title": "Edge GPU Aware Multiple AI Model Pipeline for Accelerated MRI Reconstruction and Analysis", "comment": "11 pages. 14 figures. This work has been submitted to IEEE for\n  possible publication", "summary": "Advancements in AI have greatly enhanced the medical imaging process, making\nit quicker to diagnose patients. However, very few have investigated the\noptimization of a multi-model system with hardware acceleration. As specialized\nedge devices emerge, the efficient use of their accelerators is becoming\nincreasingly crucial. This paper proposes a hardware-accelerated method for\nsimultaneous reconstruction and diagnosis of \\ac{MRI} from \\ac{CT} images.\nReal-time performance of achieving a throughput of nearly 150 frames per second\nwas achieved by leveraging hardware engines available in modern NVIDIA edge\nGPU, along with scheduling techniques. This includes the GPU and the \\ac{DLA}\navailable in both Jetson AGX Xavier and Jetson AGX Orin, which were considered\nin this paper. The hardware allocation of different layers of the multiple AI\nmodels was done in such a way that the ideal time between the hardware engines\nis reduced. In addition, the AI models corresponding to the \\ac{GAN} model were\nfine-tuned in such a way that no fallback execution into the GPU engine is\nrequired without compromising accuracy. Indeed, the accuracy corresponding to\nthe fine-tuned edge GPU-aware AI models exhibited an accuracy enhancement of\n5\\%. A further hardware allocation of two fine-tuned GPU-aware GAN models\nproves they can double the performance over the original model, leveraging\nadequate partitioning on the NVIDIA Jetson AGX Xavier and Orin devices. The\nresults prove the effectiveness of employing hardware-aware models in parallel\nfor medical image analysis and diagnosis.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u786c\u4ef6\u52a0\u901f\u7684\u591a\u6a21\u578b\u7cfb\u7edf\uff0c\u7528\u4e8e\u4eceCT\u56fe\u50cf\u540c\u65f6\u8fdb\u884cMRI\u91cd\u5efa\u548c\u8bca\u65ad\uff0c\u901a\u8fc7\u786c\u4ef6\u5f15\u64ce\u8c03\u5ea6\u548c\u6a21\u578b\u5fae\u8c03\u5b9e\u73b0\u4e86\u5b9e\u65f6\u6027\u80fd\uff08150\u5e27/\u79d2\uff09\u548c5%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "motivation": "AI\u5728\u533b\u5b66\u5f71\u50cf\u5904\u7406\u4e2d\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5f88\u5c11\u6709\u7814\u7a76\u5173\u6ce8\u786c\u4ef6\u52a0\u901f\u7684\u591a\u6a21\u578b\u7cfb\u7edf\u4f18\u5316\u3002\u968f\u7740\u4e13\u7528\u8fb9\u7f18\u8bbe\u5907\u7684\u51fa\u73b0\uff0c\u9ad8\u6548\u5229\u7528\u5176\u52a0\u901f\u5668\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5229\u7528\u73b0\u4ee3NVIDIA\u8fb9\u7f18GPU\u7684\u786c\u4ef6\u5f15\u64ce\uff08GPU\u548cDLA\uff09\u548c\u8c03\u5ea6\u6280\u672f\uff0c\u5bf9\u591a\u4e2aAI\u6a21\u578b\u7684\u4e0d\u540c\u5c42\u8fdb\u884c\u786c\u4ef6\u5206\u914d\u4ee5\u51cf\u5c11\u786c\u4ef6\u5f15\u64ce\u95f4\u7684\u7406\u60f3\u65f6\u95f4\u3002\u5bf9GAN\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u4ee5\u907f\u514d\u56de\u9000\u5230GPU\u5f15\u64ce\u6267\u884c\u3002", "result": "\u5b9e\u73b0\u4e86\u8fd1150\u5e27/\u79d2\u7684\u541e\u5410\u91cf\uff0c\u5fae\u8c03\u540e\u7684\u8fb9\u7f18GPU\u611f\u77e5AI\u6a21\u578b\u51c6\u786e\u7387\u63d0\u5347\u4e865%\u3002\u4e24\u4e2a\u5fae\u8c03\u540e\u7684GPU\u611f\u77e5GAN\u6a21\u578b\u7684\u786c\u4ef6\u5206\u914d\u8bc1\u660e\u6027\u80fd\u53ef\u4ee5\u7ffb\u500d\u3002", "conclusion": "\u7ed3\u679c\u8bc1\u660e\u4e86\u5728\u533b\u5b66\u56fe\u50cf\u5206\u6790\u548c\u8bca\u65ad\u4e2d\u91c7\u7528\u786c\u4ef6\u611f\u77e5\u5e76\u884c\u6a21\u578b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.02099", "categories": ["cs.AR", "cs.NE", "B.3; B.7; I.4"], "pdf": "https://arxiv.org/pdf/2510.02099", "abs": "https://arxiv.org/abs/2510.02099", "authors": ["Felix Zeller", "John Reuben", "Dietmar Fey"], "title": "Multiplier-free In-Memory Vector-Matrix Multiplication Using Distributed Arithmetic", "comment": "9 pages, 10 figures", "summary": "Vector-Matrix Multiplication (VMM) is the fundamental and frequently required\ncomputation in inference of Neural Networks (NN). Due to the large data\nmovement required during inference, VMM can benefit greatly from in-memory\ncomputing. However, ADC/DACs required for in-memory VMM consume significant\npower and area. `Distributed Arithmetic (DA)', a technique in computer\narchitecture prevalent in 1980s was used to achieve inner product or dot\nproduct of two vectors without using a hard-wired multiplier when one of the\nvectors is a constant. In this work, we extend the DA technique to multiply an\ninput vector with a constant matrix. By storing the sum of the weights in\nmemory, DA achieves VMM using shift-and-add circuits in the periphery of ReRAM\nmemory. We verify functional and also estimate non-functional properties\n(latency, energy, area) by performing transistor-level simulations. Using\nenergy-efficient sensing and fine grained pipelining, our approach achieves 4.5\nx less latency and 12 x less energy than VMM performed in memory conventionally\nby bit slicing. Furthermore, DA completely eliminated the need for power-hungry\nADCs which are the main source of area and energy consumption in the current\nVMM implementations in memory.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u5e03\u5f0f\u7b97\u6cd5(DA)\u7684ReRAM\u5185\u5b58\u8ba1\u7b97\u65b9\u6848\uff0c\u901a\u8fc7\u5b58\u50a8\u6743\u91cd\u548c\u5e76\u4f7f\u7528\u79fb\u4f4d\u52a0\u6cd5\u7535\u8def\u5b9e\u73b0\u5411\u91cf\u77e9\u9635\u4e58\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u4f4d\u5207\u7247\u65b9\u6cd5\u5ef6\u8fdf\u964d\u4f4e4.5\u500d\uff0c\u80fd\u8017\u964d\u4f4e12\u500d\uff0c\u4e14\u5b8c\u5168\u6d88\u9664\u4e86\u529f\u8017\u5927\u7684ADC\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u5185\u5b58\u8ba1\u7b97\u4e2d\u7684\u5411\u91cf\u77e9\u9635\u4e58\u6cd5\u9700\u8981\u5927\u91cfADC/DAC\uff0c\u6d88\u8017\u5927\u91cf\u529f\u8017\u548c\u9762\u79ef\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5b9e\u73b0\u65b9\u6cd5\u3002", "method": "\u6269\u5c55\u5206\u5e03\u5f0f\u7b97\u6cd5\u6280\u672f\uff0c\u5728ReRAM\u5185\u5b58\u5916\u56f4\u4f7f\u7528\u79fb\u4f4d\u52a0\u6cd5\u7535\u8def\u5b9e\u73b0\u5411\u91cf\u77e9\u9635\u4e58\u6cd5\uff0c\u5b58\u50a8\u6743\u91cd\u548c\u6765\u907f\u514d\u786c\u4ef6\u4e58\u6cd5\u5668\u3002", "result": "\u901a\u8fc7\u6676\u4f53\u7ba1\u7ea7\u4eff\u771f\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u4f20\u7edf\u4f4d\u5207\u7247\u65b9\u6cd5\u5ef6\u8fdf\u964d\u4f4e4.5\u500d\uff0c\u80fd\u8017\u964d\u4f4e12\u500d\uff0c\u5b8c\u5168\u6d88\u9664\u4e86ADC\u9700\u6c42\u3002", "conclusion": "\u5206\u5e03\u5f0f\u7b97\u6cd5\u4e3a\u5185\u5b58\u8ba1\u7b97\u4e2d\u7684\u5411\u91cf\u77e9\u9635\u4e58\u6cd5\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u80fd\u8017\uff0c\u540c\u65f6\u6d88\u9664\u4e86ADC\u5e26\u6765\u7684\u9762\u79ef\u548c\u529f\u8017\u5f00\u9500\u3002"}}
{"id": "2510.01216", "categories": ["cs.DC", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.01216", "abs": "https://arxiv.org/abs/2510.01216", "authors": ["Preston Vander Vos"], "title": "Odontoceti: Ultra-Fast DAG Consensus with Two Round Commitment", "comment": "MSc thesis. Supervisors: Philipp Jovanovic and Alberto Sonnino", "summary": "Users of blockchains value scalability, expecting fast confirmations and\nimmediate transaction processing. Odontoceti, the latest in DAG-based\nconsensus, addresses these concerns by prioritizing low latency and high\nthroughput, making a strategic trade-off in security by operating with a 20%\nfault tolerance instead of the established 33% level. It is the first DAG-based\nprotocol to achieve commitment in just two communication rounds, delivering\nmedian latency of 300 milliseconds while processing 10,000 transactions per\nsecond under realistic network conditions. Odontoceti operates with n = 5f + 1\nvalidators and creates an uncertified DAG with a novel decision rule for\ncommitting blocks. The protocol includes an optimization that advances progress\nwhen participants are slow, benefiting crash fault scenarios which are more\ncommon in practice than Byzantine faults. Evaluation results demonstrate 20-25%\nlatency improvements compared to an existing production protocol, validating\nthat reducing wave length from three rounds to two rounds yields meaningful\nperformance benefits. This paper establishes the practical viability of lower\nfault tolerance consensus protocols for blockchains.", "AI": {"tldr": "Odontoceti\u662f\u4e00\u79cd\u57fa\u4e8eDAG\u7684\u65b0\u578b\u5171\u8bc6\u534f\u8bae\uff0c\u901a\u8fc7\u5c06\u5bb9\u9519\u7387\u4ece33%\u964d\u4f4e\u523020%\uff0c\u5b9e\u73b0\u4e86\u4ec5\u9700\u4e24\u8f6e\u901a\u4fe1\u7684\u5feb\u901f\u786e\u8ba4\uff0c\u5728\u73b0\u5b9e\u7f51\u7edc\u6761\u4ef6\u4e0b\u8fbe\u5230300\u6beb\u79d2\u4e2d\u4f4d\u5ef6\u8fdf\u548c10,000 TPS\u7684\u9ad8\u541e\u5410\u91cf\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u533a\u5757\u94fe\u7528\u6237\u5bf9\u53ef\u6269\u5c55\u6027\u7684\u9700\u6c42\uff0c\u8ffd\u6c42\u4f4e\u5ef6\u8fdf\u548c\u5373\u65f6\u4ea4\u6613\u5904\u7406\uff0c\u540c\u65f6\u63a2\u7d22\u8f83\u4f4e\u5bb9\u9519\u7387\u5171\u8bc6\u534f\u8bae\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528n=5f+1\u9a8c\u8bc1\u8005\u67b6\u6784\uff0c\u6784\u5efa\u65e0\u8ba4\u8bc1DAG\u7ed3\u6784\uff0c\u5f15\u5165\u65b0\u9896\u7684\u533a\u5757\u63d0\u4ea4\u51b3\u7b56\u89c4\u5219\uff0c\u5e76\u5305\u542b\u9488\u5bf9\u5d29\u6e83\u6545\u969c\u7684\u8fdb\u5ea6\u4f18\u5316\u673a\u5236\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u751f\u4ea7\u534f\u8bae\u5b9e\u73b020-25%\u7684\u5ef6\u8fdf\u6539\u8fdb\uff0c\u5728\u4e24\u8f6e\u901a\u4fe1\u5185\u5b8c\u6210\u533a\u5757\u786e\u8ba4\uff0c\u5728\u73b0\u5b9e\u7f51\u7edc\u6761\u4ef6\u4e0b\u8fbe\u5230300ms\u4e2d\u4f4d\u5ef6\u8fdf\u548c10,000 TPS\u541e\u5410\u91cf\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u8f83\u4f4e\u5bb9\u9519\u7387\u5171\u8bc6\u534f\u8bae\u5728\u533a\u5757\u94fe\u4e2d\u7684\u5b9e\u9645\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u6218\u7565\u6027\u5b89\u5168\u6743\u8861\u83b7\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2510.01379", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.01379", "abs": "https://arxiv.org/abs/2510.01379", "authors": ["Huashan Chen", "Zhenyu Qi", "Haotang Li", "Hong Chen", "Jinfu Chen", "Kebin Peng", "In Kee Kim", "Kyu Hyung Lee", "Sen He"], "title": "Beyond Single LLMs: Enhanced Code Generation via Multi-Stage Performance-Guided LLM Orchestration", "comment": null, "summary": "While Large Language Models (LLMs) have become the predominant paradigm for\nautomated code generation, current single-model approaches fundamentally ignore\nthe heterogeneous computational strengths that different models exhibit across\nprogramming languages, algorithmic domains, and development stages. This paper\nchallenges the single-model convention by introducing a multi-stage,\nperformance-guided orchestration framework that dynamically routes coding tasks\nto the most suitable LLMs within a structured generate-fix-refine workflow. Our\napproach is grounded in a comprehensive empirical study of 17 state-of-the-art\nLLMs across five programming languages (Python, Java, C++, Go, and Rust) using\nHumanEval-X benchmark. The study, which evaluates both functional correctness\nand runtime performance metrics (execution time, mean/max memory utilization,\nand CPU efficiency), reveals pronounced performance heterogeneity by language,\ndevelopment stage, and problem category. Guided by these empirical insights, we\npresent PerfOrch, an LLM agent that orchestrates top-performing LLMs for each\ntask context through stage-wise validation and rollback mechanisms. Without\nrequiring model fine-tuning, PerfOrch achieves substantial improvements over\nstrong single-model baselines: average correctness rates of 96.22% and 91.37%\non HumanEval-X and EffiBench-X respectively, surpassing GPT-4o's 78.66% and\n49.11%. Beyond correctness gains, the framework delivers consistent performance\noptimizations, improving execution time for 58.76% of problems with median\nspeedups ranging from 17.67% to 27.66% across languages on two benchmarks. The\nframework's plug-and-play architecture ensures practical scalability, allowing\nnew LLMs to be profiled and integrated seamlessly, thereby offering a paradigm\nfor production-grade automated software engineering that adapts to the rapidly\nevolving generative AI landscape.", "AI": {"tldr": "\u63d0\u51faPerfOrch\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u6027\u80fd\u5f15\u5bfc\u7684\u7f16\u6392\u673a\u5236\u52a8\u6001\u9009\u62e9\u6700\u9002\u5408\u7684LLM\u6765\u5904\u7406\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u7684\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u6b63\u786e\u6027\u548c\u8fd0\u884c\u65f6\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5355\u4e00\u6a21\u578b\u65b9\u6cd5\u5ffd\u89c6\u4e86\u4e0d\u540cLLM\u5728\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u3001\u7b97\u6cd5\u9886\u57df\u548c\u5f00\u53d1\u9636\u6bb5\u7684\u5f02\u6784\u8ba1\u7b97\u4f18\u52bf\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u5229\u7528\u5404\u6a21\u578b\u4f18\u52bf\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u5bf917\u4e2a\u5148\u8fdbLLM\u57285\u79cd\u7f16\u7a0b\u8bed\u8a00\u4e0a\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5f00\u53d1\u4e86PerfOrch\u6846\u67b6\uff0c\u91c7\u7528\u751f\u6210-\u4fee\u590d-\u4f18\u5316\u7684\u591a\u9636\u6bb5\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u9636\u6bb5\u9a8c\u8bc1\u548c\u56de\u6eda\u673a\u5236\u52a8\u6001\u8def\u7531\u4efb\u52a1\u5230\u6700\u9002\u5408\u7684LLM\u3002", "result": "\u5728HumanEval-X\u548cEffiBench-X\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u8fbe\u523096.22%\u548c91.37%\u7684\u5e73\u5747\u6b63\u786e\u7387\uff0c\u663e\u8457\u8d85\u8d8aGPT-4o\u768478.66%\u548c49.11%\uff0c\u540c\u65f6\u572858.76%\u7684\u95ee\u9898\u4e0a\u6539\u5584\u4e86\u6267\u884c\u65f6\u95f4\uff0c\u4e2d\u4f4d\u6570\u52a0\u901f\u8fbe\u523017.67%-27.66%\u3002", "conclusion": "PerfOrch\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u5b9e\u73b0\u751f\u4ea7\u7ea7\u81ea\u52a8\u5316\u8f6f\u4ef6\u5de5\u7a0b\u7684\u8303\u5f0f\uff0c\u5176\u5373\u63d2\u5373\u7528\u67b6\u6784\u80fd\u591f\u9002\u5e94\u5feb\u901f\u53d1\u5c55\u7684\u751f\u6210\u5f0fAI\u683c\u5c40\u3002"}}
{"id": "2510.01579", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.01579", "abs": "https://arxiv.org/abs/2510.01579", "authors": ["Abhishek Kumar Singh", "Kyle Jamieson"], "title": "MMGaP: Multi-User MIMO Detection and Precoding using GPU-assisted Physics-inspired Computation", "comment": null, "summary": "Physics-inspired and quantum compute based methods for processing in the\nphysical layer of next-generation cellular radio access networks have\ndemonstrated theoretical advances in spectral efficiency in recent years, but\nhave stopped short of practical realization on commodity processors, leaving a\ngap between the throughput practical systems can achieve and the projected\nthroughput the state-of-the-art should achieve. To fill this gap, this paper\nproposes MMGaP, an uplink multi-user MIMO detector and downlink Vector\nperturbation precoder for next-generation cellular networks. MMGaP realizes\nthese large MIMO processing algorithms for the first time on bare-metal CUDA\nkernels that scale to run on large GPU processing platforms, and can be\npackaged as TensorFlow modules, allowing easy integration with a variety of\nsystems. We integrate MMGaP with NVIDIA's software-defined, GPU-accelerated 5G\nplatform and evaluate its performance against the state-of-the-art. In a 5G\ncellular network using 100 MHz of radio bandwidth, eight antennas at the base\nstation and eight concurrent users, we show that MMGaP improves uplink\nthroughput by approximately 50 Mbps per user and downlink throughput by 100\nMbps per user over a wide range of SNR. We further show that MMGaP can also\nsupport larger MIMO sizes: for 16 antennas at the base station and 16\nconcurrent users, MMGaP provides more than 50 Mbps higher uplink throughput per\nuser. We measure the execution time of MMGaP on different NVIDIA GPUs and show\nthat it can operate at line-rate and meet the timing requirements of\nstate-of-the-art 5G systems.", "AI": {"tldr": "MMGaP\u662f\u4e00\u4e2a\u57fa\u4e8eCUDA\u5185\u6838\u7684\u5927\u89c4\u6a21MIMO\u68c0\u6d4b\u5668\u548c\u9884\u7f16\u7801\u5668\uff0c\u9996\u6b21\u5728GPU\u5e73\u53f0\u4e0a\u5b9e\u73b0\u4e86\u7269\u7406\u5c42\u5904\u7406\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e865G\u7f51\u7edc\u7684\u4e0a\u4e0b\u884c\u541e\u5410\u91cf\u3002", "motivation": "\u586b\u8865\u7269\u7406\u5c42\u91cf\u5b50\u8ba1\u7b97\u548c\u7269\u7406\u542f\u53d1\u65b9\u6cd5\u5728\u5546\u7528\u5904\u7406\u5668\u4e0a\u5b9e\u9645\u5b9e\u73b0\u7684\u7a7a\u767d\uff0c\u89e3\u51b3\u7406\u8bba\u5148\u8fdb\u6027\u4e0e\u5b9e\u9645\u7cfb\u7edf\u541e\u5410\u91cf\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u88f8\u91d1\u5c5eCUDA\u5185\u6838\u7684\u5927\u89c4\u6a21MIMO\u5904\u7406\u7b97\u6cd5\uff0c\u53ef\u6253\u5305\u4e3aTensorFlow\u6a21\u5757\uff0c\u5e76\u4e0eNVIDIA\u8f6f\u4ef6\u5b9a\u4e49\u7684GPU\u52a0\u901f5G\u5e73\u53f0\u96c6\u6210\u3002", "result": "\u5728100MHz\u5e26\u5bbd\u30018\u5929\u7ebf8\u7528\u6237\u76845G\u7f51\u7edc\u4e2d\uff0cMMGaP\u4f7f\u4e0a\u884c\u541e\u5410\u91cf\u6bcf\u7528\u6237\u63d0\u5347\u7ea650Mbps\uff0c\u4e0b\u884c\u541e\u5410\u91cf\u6bcf\u7528\u6237\u63d0\u5347100Mbps\uff1b\u572816\u5929\u7ebf16\u7528\u6237\u573a\u666f\u4e0b\uff0c\u4e0a\u884c\u541e\u5410\u91cf\u6bcf\u7528\u6237\u63d0\u5347\u8d85\u8fc750Mbps\u3002", "conclusion": "MMGaP\u80fd\u591f\u6ee1\u8db3\u6700\u5148\u8fdb5G\u7cfb\u7edf\u7684\u65f6\u5e8f\u8981\u6c42\uff0c\u5728\u7ebf\u901f\u7387\u4e0b\u8fd0\u884c\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u8702\u7a9d\u7f51\u7edc\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5927\u89c4\u6a21MIMO\u5904\u7406\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.01256", "categories": ["cs.DC", "cs.AI", "cs.IT", "cs.LG", "math.IT", "I.2.6; I.2.7; C.2.4; C.1.4"], "pdf": "https://arxiv.org/pdf/2510.01256", "abs": "https://arxiv.org/abs/2510.01256", "authors": ["Lingling Zeng", "Gen Zhang", "Jialin Peng", "Xiang Xu", "Yuan Xu", "Lijun Ma"], "title": "Kant: An Efficient Unified Scheduling System for Large-Scale AI Clusters", "comment": "25 pages,15 figures", "summary": "As AI cluster sizes continue to expand and the demand for\nlarge-language-model (LLM) training and inference workloads grows rapidly,\ntraditional scheduling systems face significant challenges in balancing\nresource utilization, scheduling efficiency, and service quality. This paper\npresents and evaluates Kant: an efficient unified scheduling platform designed\nfor large-scale AI container clusters, supporting the co-scheduling of both\ntraining and inference jobs. Based on the practical implementation of the Kant\nsystem, we systematically define a set of key evaluation metrics for AI\nclusters, including GPU Allocation Ratio (GAR), Scheduling Occupancy Rate\n(SOR), GPU Node Fragmentation Ratio (GFR), Job Waiting Time Distribution\n(JWTD), and Job Training Time Estimation Distribution (JTTED), providing a\nfoundation for quantitative performance analysis. Experimental results\ndemonstrate that Kant achieves exceptional performance in clusters ranging from\nhundreds to tens of thousands of GPUs. By leveraging scheduling strategies such\nas Backfill and Enhanced Binpack (E-Binpack), the system significantly improves\nresource utilization and scheduling efficiency, while effectively reducing\nresource fragmentation and communication overhead in distributed training. The\nsystem has been deployed in multiple AI data center clusters, where it stably\nsupports large-scale intelligent computing workloads. This work provides a\npractical engineering approach for building high-performance, highly available,\nAI-native scheduling infrastructure.", "AI": {"tldr": "Kant\u662f\u4e00\u4e2a\u9ad8\u6548\u7edf\u4e00\u7684\u5927\u89c4\u6a21AI\u5bb9\u5668\u96c6\u7fa4\u8c03\u5ea6\u5e73\u53f0\uff0c\u652f\u6301\u8bad\u7ec3\u548c\u63a8\u7406\u4efb\u52a1\u7684\u534f\u540c\u8c03\u5ea6\uff0c\u901a\u8fc7Backfill\u548c\u589e\u5f3aBinpack\u7b49\u7b56\u7565\u663e\u8457\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\u548c\u8c03\u5ea6\u6548\u7387\u3002", "motivation": "\u968f\u7740AI\u96c6\u7fa4\u89c4\u6a21\u6269\u5927\u548c\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u63a8\u7406\u9700\u6c42\u5feb\u901f\u589e\u957f\uff0c\u4f20\u7edf\u8c03\u5ea6\u7cfb\u7edf\u5728\u8d44\u6e90\u5229\u7528\u7387\u3001\u8c03\u5ea6\u6548\u7387\u548c\u670d\u52a1\u8d28\u91cf\u5e73\u8861\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002", "method": "\u57fa\u4e8eKant\u7cfb\u7edf\u5b9e\u8df5\u5b9e\u73b0\uff0c\u91c7\u7528Backfill\u548c\u589e\u5f3aBinpack\uff08E-Binpack\uff09\u7b49\u8c03\u5ea6\u7b56\u7565\uff0c\u5b9a\u4e49\u4e86\u4e00\u5957AI\u96c6\u7fa4\u5173\u952e\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aKant\u5728\u6570\u767e\u5230\u6570\u4e07GPU\u89c4\u6a21\u7684\u96c6\u7fa4\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u63d0\u5347\u8d44\u6e90\u5229\u7528\u7387\u3001\u964d\u4f4e\u8d44\u6e90\u788e\u7247\u5316\u548c\u5206\u5e03\u5f0f\u8bad\u7ec3\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "Kant\u4e3a\u6784\u5efa\u9ad8\u6027\u80fd\u3001\u9ad8\u53ef\u7528\u7684AI\u539f\u751f\u8c03\u5ea6\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5de5\u7a0b\u89e3\u51b3\u65b9\u6848\uff0c\u5df2\u5728\u591a\u4e2aAI\u6570\u636e\u4e2d\u5fc3\u96c6\u7fa4\u4e2d\u7a33\u5b9a\u90e8\u7f72\u3002"}}
{"id": "2510.01514", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.01514", "abs": "https://arxiv.org/abs/2510.01514", "authors": ["J. Alexander Curtis", "Sharadha Kasiviswanathan", "Nasir Eisty"], "title": "Deciphering WONTFIX: A Mixed-Method Study on Why GitHub Issues Get Rejected", "comment": null, "summary": "Context: The ``wontfix'' label is a widely used yet narrowly understood tool\nin GitHub repositories, indicating that an issue will not be pursued further.\nDespite its prevalence, the impact of this label on project management and\ncommunity dynamics within open-source software development is not clearly\ndefined. Objective: This study examines the prevalence and reasons behind\nissues being labeled as wontfix across various open-source repositories on\nGitHub. Method: Employing a mixed-method approach, we analyze both quantitative\ndata to assess the prevalence of the wontfix label and qualitative data to\nexplore the reasoning that it was used. Data were collected from 3,132 of\nGitHub's most-popular repositories. Later, we employ open coding and thematic\nanalysis to categorize the reasons behind wontfix labels, providing a\nstructured understanding of the issue management landscape. Results: Our\nfindings show that about 30% of projects on GitHub apply the wontfix label to\nsome issues. These issues most often occur on user-submitted issues for bug\nreports and feature requests. The study identified eight common themes behind\nlabeling issues as wontfix, ranging from user-specific control factors to\nmaintainer-specific decisions. Conclusions: The wontfix label is a critical\ntool for managing resources and guiding contributor efforts in GitHub projects.\nHowever, it can also discourage community involvement and obscure the\ntransparency of project management. Understanding these reasons aids project\nmanagers in making informed decisions and fostering efficient collaboration\nwithin open-source communities.", "AI": {"tldr": "GitHub\u4e2dwontfix\u6807\u7b7e\u7684\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\uff1a30%\u9879\u76ee\u4f7f\u7528\u8be5\u6807\u7b7e\uff0c\u4e3b\u8981\u7528\u4e8ebug\u62a5\u544a\u548c\u529f\u80fd\u8bf7\u6c42\uff0c\u8bc6\u522b\u51fa8\u4e2a\u5e38\u89c1\u539f\u56e0\uff0c\u65e2\u6709\u8d44\u6e90\u7ba1\u7406\u4ef7\u503c\u4e5f\u53ef\u80fd\u5f71\u54cd\u793e\u533a\u53c2\u4e0e", "motivation": "\u7814\u7a76GitHub\u4e2d\u5e7f\u6cdb\u4f7f\u7528\u4f46\u7406\u89e3\u6709\u9650\u7684wontfix\u6807\u7b7e\uff0c\u63a2\u7d22\u5176\u5bf9\u5f00\u6e90\u9879\u76ee\u7ba1\u7406\u7684\u5f71\u54cd\u548c\u793e\u533a\u52a8\u6001", "method": "\u6df7\u5408\u65b9\u6cd5\uff1a\u4ece3132\u4e2a\u6700\u53d7\u6b22\u8fceGitHub\u4ed3\u5e93\u6536\u96c6\u6570\u636e\uff0c\u5b9a\u91cf\u5206\u6790wontfix\u6807\u7b7e\u666e\u53ca\u7387\uff0c\u5b9a\u6027\u5206\u6790\u4f7f\u7528\u539f\u56e0\uff0c\u91c7\u7528\u5f00\u653e\u7f16\u7801\u548c\u4e3b\u9898\u5206\u6790", "result": "\u7ea630%\u9879\u76ee\u4f7f\u7528wontfix\u6807\u7b7e\uff0c\u4e3b\u8981\u7528\u4e8e\u7528\u6237\u63d0\u4ea4\u7684bug\u62a5\u544a\u548c\u529f\u80fd\u8bf7\u6c42\uff0c\u8bc6\u522b\u51fa8\u4e2a\u4e3b\u9898\u539f\u56e0\uff0c\u5305\u62ec\u7528\u6237\u7279\u5b9a\u56e0\u7d20\u548c\u7ef4\u62a4\u8005\u51b3\u7b56", "conclusion": "wontfix\u6807\u7b7e\u662f\u7ba1\u7406\u8d44\u6e90\u548c\u6307\u5bfc\u8d21\u732e\u8005\u7684\u91cd\u8981\u5de5\u5177\uff0c\u4f46\u53ef\u80fd\u6291\u5236\u793e\u533a\u53c2\u4e0e\u548c\u964d\u4f4e\u7ba1\u7406\u900f\u660e\u5ea6\uff0c\u7406\u89e3\u8fd9\u4e9b\u539f\u56e0\u6709\u52a9\u4e8e\u9879\u76ee\u7ba1\u7406\u8005\u505a\u51fa\u660e\u667a\u51b3\u7b56"}}
{"id": "2510.01885", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.01885", "abs": "https://arxiv.org/abs/2510.01885", "authors": ["Jamie Cotter", "Ignacio Castineiras", "Victor Cionca"], "title": "Accuracy vs Performance: An abstraction model for deadline constrained offloading at the mobile-edge", "comment": "Presented at in Irish Signals and Systems Conference 2025", "summary": "In this paper, we present a solution for low-latency deadline-constrained DNN\noffloading on mobile edge devices. We design a scheduling algorithm with\nlightweight network state representation, considering device availability,\ncommunication on the network link, priority-aware pre-emption, and task\ndeadlines. The scheduling algorithm aims to reduce latency by designing a\nresource availability representation, as well as a network discretisation and a\ndynamic bandwidth estimation mechanism. We implement the scheduling algorithm\ninto a system composed of four Raspberry Pi 2 (model Bs) mobile edge devices,\nsampling a waste classification conveyor belt at a set frame rate. The system\nis evaluated and compared to a previous approach of ours, which was proven to\noutcompete work-stealers and a non-pre-emption based scheduling heuristic under\nthe aforementioned waste classification scenario. Our findings show the novel\nlower latency abstraction models yield better performance under high-volume\nworkloads, with the dynamic bandwidth estimation assisting the task placement\nwhile, ultimately, increasing task throughput in times of resource scarcity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u79fb\u52a8\u8fb9\u7f18\u8bbe\u5907\u7684\u4f4e\u5ef6\u8fdfDNN\u5378\u8f7d\u8c03\u5ea6\u7b97\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7f51\u7edc\u72b6\u6001\u8868\u793a\u3001\u52a8\u6001\u5e26\u5bbd\u4f30\u8ba1\u548c\u4f18\u5148\u7ea7\u611f\u77e5\u62a2\u5360\u673a\u5236\uff0c\u5728\u8d44\u6e90\u7a00\u7f3a\u65f6\u63d0\u9ad8\u4efb\u52a1\u541e\u5410\u91cf\u3002", "motivation": "\u89e3\u51b3\u79fb\u52a8\u8fb9\u7f18\u8bbe\u5907\u4e0aDNN\u4efb\u52a1\u5378\u8f7d\u7684\u4f4e\u5ef6\u8fdf\u548c\u622a\u6b62\u65f6\u95f4\u7ea6\u675f\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9ad8\u5de5\u4f5c\u8d1f\u8f7d\u548c\u8d44\u6e90\u7a00\u7f3a\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u4f18\u5316\u3002", "method": "\u8bbe\u8ba1\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5305\u542b\u8d44\u6e90\u53ef\u7528\u6027\u8868\u793a\u3001\u7f51\u7edc\u79bb\u6563\u5316\u548c\u52a8\u6001\u5e26\u5bbd\u4f30\u8ba1\u673a\u5236\uff0c\u5e76\u5728\u56db\u4e2a\u6811\u8393\u6d3e2\u8bbe\u5907\u4e0a\u5b9e\u73b0\u7cfb\u7edf\uff0c\u6a21\u62df\u5e9f\u7269\u5206\u7c7b\u4f20\u9001\u5e26\u573a\u666f\u3002", "result": "\u65b0\u578b\u4f4e\u5ef6\u8fdf\u62bd\u8c61\u6a21\u578b\u5728\u9ad8\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u8868\u73b0\u66f4\u597d\uff0c\u52a8\u6001\u5e26\u5bbd\u4f30\u8ba1\u6709\u52a9\u4e8e\u4efb\u52a1\u653e\u7f6e\u5e76\u5728\u8d44\u6e90\u7a00\u7f3a\u65f6\u63d0\u9ad8\u4efb\u52a1\u541e\u5410\u91cf\u3002", "conclusion": "\u8be5\u8c03\u5ea6\u7b97\u6cd5\u901a\u8fc7\u521b\u65b0\u7684\u7f51\u7edc\u72b6\u6001\u8868\u793a\u548c\u52a8\u6001\u5e26\u5bbd\u4f30\u8ba1\u673a\u5236\uff0c\u6709\u6548\u964d\u4f4e\u4e86DNN\u4efb\u52a1\u5378\u8f7d\u7684\u5ef6\u8fdf\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.01285", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01285", "abs": "https://arxiv.org/abs/2510.01285", "authors": ["Alireza Salemi", "Mihir Parmar", "Palash Goyal", "Yiwen Song", "Jinsung Yoon", "Hamed Zamani", "Hamid Palangi", "Tomas Pfister"], "title": "LLM-based Multi-Agent Blackboard System for Information Discovery in Data Science", "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has opened new\nopportunities in data science, yet their practical deployment is often\nconstrained by the challenge of discovering relevant data within large\nheterogeneous data lakes. Existing methods struggle with this: single-agent\nsystems are quickly overwhelmed by large, heterogeneous files in the large data\nlakes, while multi-agent systems designed based on a master-slave paradigm\ndepend on a rigid central controller for task allocation that requires precise\nknowledge of each sub-agent's capabilities. To address these limitations, we\npropose a novel multi-agent communication paradigm inspired by the blackboard\narchitecture for traditional AI models. In this framework, a central agent\nposts requests to a shared blackboard, and autonomous subordinate agents --\neither responsible for a partition of the data lake or general information\nretrieval -- volunteer to respond based on their capabilities. This design\nimproves scalability and flexibility by eliminating the need for a central\ncoordinator to have prior knowledge of all sub-agents' expertise. We evaluate\nour method on three benchmarks that require explicit data discovery: KramaBench\nand modified versions of DS-Bench and DA-Code to incorporate data discovery.\nExperimental results demonstrate that the blackboard architecture substantially\noutperforms baselines, including RAG and the master-slave multi-agent paradigm,\nachieving between 13% to 57% relative improvement in end-to-end task success\nand up to a 9% relative gain in F1 score for data discovery over the\nbest-performing baselines across both proprietary and open-source LLMs. Our\nfindings establish the blackboard paradigm as a scalable and generalizable\ncommunication framework for multi-agent systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9ed1\u677f\u67b6\u6784\u7684\u591a\u667a\u80fd\u4f53\u901a\u4fe1\u8303\u5f0f\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u578b\u5f02\u6784\u6570\u636e\u6e56\u4e2d\u7684\u6570\u636e\u53d1\u73b0\u95ee\u9898\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\u548cF1\u5206\u6570", "motivation": "\u73b0\u6709\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u96be\u4ee5\u5904\u7406\u5927\u578b\u5f02\u6784\u6570\u636e\u6e56\uff0c\u800c\u4e3b\u4ece\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u9700\u8981\u4e2d\u592e\u63a7\u5236\u5668\u7cbe\u786e\u4e86\u89e3\u6bcf\u4e2a\u5b50\u667a\u80fd\u4f53\u7684\u80fd\u529b\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027", "method": "\u91c7\u7528\u9ed1\u677f\u67b6\u6784\uff0c\u4e2d\u592e\u667a\u80fd\u4f53\u5c06\u8bf7\u6c42\u53d1\u5e03\u5230\u5171\u4eab\u9ed1\u677f\uff0c\u81ea\u4e3b\u5b50\u667a\u80fd\u4f53\u6839\u636e\u81ea\u8eab\u80fd\u529b\u81ea\u613f\u54cd\u5e94\uff0c\u65e0\u9700\u4e2d\u592e\u534f\u8c03\u5668\u9884\u5148\u4e86\u89e3\u6240\u6709\u5b50\u667a\u80fd\u4f53\u7684\u4e13\u4e1a\u77e5\u8bc6", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff08\u5305\u62ecRAG\u548c\u4e3b\u4ece\u5f0f\u591a\u667a\u80fd\u4f53\u8303\u5f0f\uff09\uff0c\u7aef\u5230\u7aef\u4efb\u52a1\u6210\u529f\u7387\u76f8\u5bf9\u63d0\u534713%-57%\uff0c\u6570\u636e\u53d1\u73b0F1\u5206\u6570\u76f8\u5bf9\u63d0\u5347\u6700\u9ad89%", "conclusion": "\u9ed1\u677f\u8303\u5f0f\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u548c\u53ef\u6cdb\u5316\u7684\u901a\u4fe1\u6846\u67b6"}}
{"id": "2510.01260", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01260", "abs": "https://arxiv.org/abs/2510.01260", "authors": ["Ningyuan Yang", "Guanliang Lyu", "Mingchen Ma", "Yiyi Lu", "Yiming Li", "Zhihui Gao", "Hancheng Ye", "Jianyi Zhang", "Tingjun Chen", "Yiran Chen"], "title": "IoT-MCP: Bridging LLMs and IoT Systems Through Model Context Protocol", "comment": null, "summary": "The integration of Large Language Models (LLMs) with Internet-of-Things (IoT)\nsystems faces significant challenges in hardware heterogeneity and control\ncomplexity. The Model Context Protocol (MCP) emerges as a critical enabler,\nproviding standardized communication between LLMs and physical devices. We\npropose IoT-MCP, a novel framework that implements MCP through edge-deployed\nservers to bridge LLMs and IoT ecosystems. To support rigorous evaluation, we\nintroduce IoT-MCP Bench, the first benchmark containing 114 Basic Tasks (e.g.,\n``What is the current temperature?'') and 1,140 Complex Tasks (e.g., ``I feel\nso hot, do you have any ideas?'') for IoT-enabled LLMs. Experimental validation\nacross 22 sensor types and 6 microcontroller units demonstrates IoT-MCP's 100%\ntask success rate to generate tool calls that fully meet expectations and\nobtain completely accurate results, 205ms average response time, and 74KB peak\nmemory footprint. This work delivers both an open-source integration framework\n(https://github.com/Duke-CEI-Center/IoT-MCP-Servers) and a standardized\nevaluation methodology for LLM-IoT systems.", "AI": {"tldr": "IoT-MCP\u6846\u67b6\u901a\u8fc7\u8fb9\u7f18\u670d\u52a1\u5668\u5b9e\u73b0MCP\u534f\u8bae\uff0c\u6210\u529f\u8fde\u63a5LLM\u4e0eIoT\u8bbe\u5907\uff0c\u57281140\u4e2a\u590d\u6742\u4efb\u52a1\u4e2d\u5b9e\u73b0100%\u6210\u529f\u7387\u3001205ms\u54cd\u5e94\u65f6\u95f4\u548c74KB\u5185\u5b58\u5360\u7528", "motivation": "\u89e3\u51b3LLM\u4e0eIoT\u7cfb\u7edf\u96c6\u6210\u4e2d\u7684\u786c\u4ef6\u5f02\u6784\u6027\u548c\u63a7\u5236\u590d\u6742\u6027\u6311\u6218\uff0c\u9700\u8981\u6807\u51c6\u5316\u901a\u4fe1\u534f\u8bae\u6765\u8fde\u63a5\u8bed\u8a00\u6a21\u578b\u4e0e\u7269\u7406\u8bbe\u5907", "method": "\u63d0\u51faIoT-MCP\u6846\u67b6\uff0c\u901a\u8fc7\u8fb9\u7f18\u90e8\u7f72\u7684\u670d\u52a1\u5668\u5b9e\u73b0Model Context Protocol(MCP)\uff0c\u5e76\u5efa\u7acbIoT-MCP Bench\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u5305\u542b114\u4e2a\u57fa\u7840\u4efb\u52a1\u548c1140\u4e2a\u590d\u6742\u4efb\u52a1", "result": "\u572822\u79cd\u4f20\u611f\u5668\u7c7b\u578b\u548c6\u79cd\u5fae\u63a7\u5236\u5668\u5355\u5143\u4e0a\u9a8c\u8bc1\uff0c\u5b9e\u73b0100%\u4efb\u52a1\u6210\u529f\u7387\u3001205ms\u5e73\u5747\u54cd\u5e94\u65f6\u95f4\u548c74KB\u5cf0\u503c\u5185\u5b58\u5360\u7528", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u5f00\u6e90\u96c6\u6210\u6846\u67b6\u548c\u6807\u51c6\u5316\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e3aLLM-IoT\u7cfb\u7edf\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840"}}
{"id": "2510.01635", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.01635", "abs": "https://arxiv.org/abs/2510.01635", "authors": ["Yifei Chen", "Sarra Habchi", "Lili Wei"], "title": "MIMIC: Integrating Diverse Personality Traits for Better Game Testing Using Large Language Model", "comment": "13 pages, 7 figures, 6 tables. This paper is accepted by the 40th\n  IEEE/ACM International Conference on Automated Software Engineering, ASE 2025", "summary": "Modern video games pose significant challenges for traditional automated\ntesting algorithms, yet intensive testing is crucial to ensure game quality. To\naddress these challenges, researchers designed gaming agents using\nReinforcement Learning, Imitation Learning, or Large Language Models. However,\nthese agents often neglect the diverse strategies employed by human players due\nto their different personalities, resulting in repetitive solutions in similar\nsituations. Without mimicking varied gaming strategies, these agents struggle\nto trigger diverse in-game interactions or uncover edge cases.\n  In this paper, we present MIMIC, a novel framework that integrates diverse\npersonality traits into gaming agents, enabling them to adopt different gaming\nstrategies for similar situations. By mimicking different playstyles, MIMIC can\nachieve higher test coverage and richer in-game interactions across different\ngames. It also outperforms state-of-the-art agents in Minecraft by achieving a\nhigher task completion rate and providing more diverse solutions. These results\nhighlight MIMIC's significant potential for effective game testing.", "AI": {"tldr": "MIMIC\u662f\u4e00\u4e2a\u5c06\u591a\u6837\u5316\u4eba\u683c\u7279\u8d28\u6574\u5408\u5230\u6e38\u620f\u4ee3\u7406\u4e2d\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u4eff\u4e0d\u540c\u73a9\u5bb6\u7684\u6e38\u620f\u7b56\u7565\u6765\u63d0\u9ad8\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u6e38\u620f\u4ea4\u4e92\u591a\u6837\u6027\u3002", "motivation": "\u4f20\u7edf\u6e38\u620f\u6d4b\u8bd5\u7b97\u6cd5\u96be\u4ee5\u5e94\u5bf9\u73b0\u4ee3\u6e38\u620f\u7684\u590d\u6742\u6027\uff0c\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u3001\u6a21\u4eff\u5b66\u4e60\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6e38\u620f\u4ee3\u7406\u5f80\u5f80\u5ffd\u89c6\u4eba\u7c7b\u73a9\u5bb6\u7684\u591a\u6837\u5316\u7b56\u7565\uff0c\u5bfc\u81f4\u91cd\u590d\u89e3\u51b3\u65b9\u6848\u548c\u65e0\u6cd5\u53d1\u73b0\u8fb9\u7f18\u60c5\u51b5\u3002", "method": "\u63d0\u51faMIMIC\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u591a\u6837\u5316\u4eba\u683c\u7279\u8d28\uff0c\u4f7f\u6e38\u620f\u4ee3\u7406\u80fd\u591f\u5728\u76f8\u4f3c\u60c5\u5883\u4e0b\u91c7\u7528\u4e0d\u540c\u7684\u6e38\u620f\u7b56\u7565\uff0c\u6a21\u4eff\u4e0d\u540c\u7684\u6e38\u620f\u98ce\u683c\u3002", "result": "\u5728Minecraft\u4e2d\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u4ee3\u7406\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u66f4\u591a\u6837\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u66f4\u4e30\u5bcc\u7684\u6e38\u620f\u5185\u4ea4\u4e92\u3002", "conclusion": "MIMIC\u5728\u6e38\u620f\u6d4b\u8bd5\u65b9\u9762\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u6e38\u620f\u8d28\u91cf\u548c\u53d1\u73b0\u8fb9\u7f18\u60c5\u51b5\u3002"}}
{"id": "2510.01297", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2510.01297", "abs": "https://arxiv.org/abs/2510.01297", "authors": ["Yeqi Feng", "Yucheng Lu", "Hongyu Su", "Tianxing He"], "title": "SimCity: Multi-Agent Urban Development Simulation with Rich Interactions", "comment": "32 pages, 8 figures", "summary": "Large Language Models (LLMs) open new possibilities for constructing\nrealistic and interpretable macroeconomic simulations. We present SimCity, a\nmulti-agent framework that leverages LLMs to model an interpretable\nmacroeconomic system with heterogeneous agents and rich interactions. Unlike\nclassical equilibrium models that limit heterogeneity for tractability, or\ntraditional agent-based models (ABMs) that rely on hand-crafted decision rules,\nSimCity enables flexible, adaptive behavior with transparent natural-language\nreasoning. Within SimCity, four core agent types (households, firms, a central\nbank, and a government) deliberate and participate in a frictional labor\nmarket, a heterogeneous goods market, and a financial market. Furthermore, a\nVision-Language Model (VLM) determines the geographic placement of new firms\nand renders a mapped virtual city, allowing us to study both macroeconomic\nregularities and urban expansion dynamics within a unified environment. To\nevaluate the framework, we compile a checklist of canonical macroeconomic\nphenomena, including price elasticity of demand, Engel's Law, Okun's Law, the\nPhillips Curve, and the Beveridge Curve, and show that SimCity naturally\nreproduces these empirical patterns while remaining robust across simulation\nruns.", "AI": {"tldr": "SimCity\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u5b8f\u89c2\u7ecf\u6d4e\u6a21\u62df\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u5b9e\u73b0\u5f02\u6784\u4ee3\u7406\u548c\u4e30\u5bcc\u4ea4\u4e92\uff0c\u80fd\u591f\u91cd\u73b0\u7ecf\u5178\u5b8f\u89c2\u7ecf\u6d4e\u73b0\u8c61\u3002", "motivation": "\u4f20\u7edf\u5747\u8861\u6a21\u578b\u56e0\u53ef\u5904\u7406\u6027\u9650\u5236\u800c\u9650\u5236\u5f02\u8d28\u6027\uff0c\u4f20\u7edf\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u578b\u4f9d\u8d56\u624b\u5de5\u5236\u5b9a\u7684\u51b3\u7b56\u89c4\u5219\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u3001\u81ea\u9002\u5e94\u4e14\u5177\u6709\u900f\u660e\u63a8\u7406\u7684\u5b8f\u89c2\u7ecf\u6d4e\u6a21\u62df\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528LLMs\u6784\u5efa\u56db\u79cd\u6838\u5fc3\u4ee3\u7406\u7c7b\u578b\uff08\u5bb6\u5ead\u3001\u4f01\u4e1a\u3001\u4e2d\u592e\u94f6\u884c\u548c\u653f\u5e9c\uff09\uff0c\u5728\u6469\u64e6\u52b3\u52a8\u529b\u5e02\u573a\u3001\u5f02\u8d28\u5546\u54c1\u5e02\u573a\u548c\u91d1\u878d\u5e02\u573a\u4e2d\u8fdb\u884c\u4ea4\u4e92\uff0c\u5e76\u5229\u7528\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u786e\u5b9a\u4f01\u4e1a\u5730\u7406\u4f4d\u7f6e\u548c\u6e32\u67d3\u865a\u62df\u57ce\u5e02\u3002", "result": "\u6846\u67b6\u80fd\u591f\u81ea\u7136\u91cd\u73b0\u4ef7\u683c\u9700\u6c42\u5f39\u6027\u3001\u6069\u683c\u5c14\u5b9a\u5f8b\u3001\u5965\u80af\u5b9a\u5f8b\u3001\u83f2\u5229\u666e\u65af\u66f2\u7ebf\u548c\u8d1d\u5f17\u91cc\u5947\u66f2\u7ebf\u7b49\u7ecf\u5178\u5b8f\u89c2\u7ecf\u6d4e\u73b0\u8c61\uff0c\u5e76\u5728\u591a\u6b21\u6a21\u62df\u8fd0\u884c\u4e2d\u4fdd\u6301\u7a33\u5065\u6027\u3002", "conclusion": "SimCity\u5c55\u793a\u4e86LLMs\u5728\u6784\u5efa\u73b0\u5b9e\u4e14\u53ef\u89e3\u91ca\u7684\u5b8f\u89c2\u7ecf\u6d4e\u6a21\u62df\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u7814\u7a76\u5b8f\u89c2\u7ecf\u6d4e\u89c4\u5f8b\u548c\u57ce\u5e02\u6269\u5f20\u52a8\u6001\u63d0\u4f9b\u4e86\u7edf\u4e00\u73af\u5883\u3002"}}
{"id": "2510.01536", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.01536", "abs": "https://arxiv.org/abs/2510.01536", "authors": ["Hasan Heydari", "Alysson Bessani", "Kartik Nayak"], "title": "QScale: Probabilistic Chained Consensus for Moderate-Scale Systems", "comment": null, "summary": "Existing distributed ledger protocols either incur a high communication\ncomplexity and are thus suited to systems with a small number of processes\n(e.g., PBFT), or rely on committee-sampling-based approaches that only work for\na very large number of processes (e.g., Algorand). Neither of these lines of\nwork is well-suited for moderate-scale distributed ledgers ranging from a few\nhundred to a thousand processes, which are common in production (e.g, Redbelly,\nSui). The goal of this work is to design a distributed ledger with sub-linear\ncommunication complexity per process, sub-quadratic total communication\ncomplexity, and low latency for finalizing a block into the ledger, such that\nit can be used for moderate-scale systems. We propose QScale, a protocol in\nwhich every process incurs only $\\widetilde{O}(\\kappa \\sqrt{n})$ communication\ncomplexity per-block in expectation, $\\widetilde{O}(n\\kappa)$ total\ncommunication complexity per-block in expectation, and a best-case latency of\n$O(\\kappa)$ rounds while ensuring safety and liveness with overwhelming\nprobability, with $\\kappa$ being a small security parameter.", "AI": {"tldr": "QScale\u534f\u8bae\u4e3a\u4e2d\u7b49\u89c4\u6a21\u5206\u5e03\u5f0f\u8d26\u672c\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u4e9a\u7ebf\u6027\u901a\u4fe1\u590d\u6742\u5ea6\u548c\u4f4e\u5ef6\u8fdf\uff0c\u586b\u8865\u4e86PBFT\u548cAlgorand\u4e4b\u95f4\u7684\u7a7a\u767d", "motivation": "\u73b0\u6709\u5206\u5e03\u5f0f\u8d26\u672c\u534f\u8bae\u8981\u4e48\u901a\u4fe1\u590d\u6742\u5ea6\u9ad8\uff08\u5982PBFT\uff09\uff0c\u8981\u4e48\u9700\u8981\u5927\u91cf\u8fdb\u7a0b\uff08\u5982Algorand\uff09\uff0c\u90fd\u4e0d\u9002\u5408\u51e0\u767e\u5230\u4e00\u5343\u4e2a\u8fdb\u7a0b\u7684\u4e2d\u7b49\u89c4\u6a21\u7cfb\u7edf", "method": "\u63d0\u51faQScale\u534f\u8bae\uff0c\u91c7\u7528\u4e9a\u7ebf\u6027\u901a\u4fe1\u590d\u6742\u5ea6\u8bbe\u8ba1\uff0c\u6bcf\u4e2a\u8fdb\u7a0b\u6bcf\u5757\u9884\u671f\u901a\u4fe1\u590d\u6742\u5ea6\u4e3a\u00d5(\u03ba\u221an)\uff0c\u603b\u901a\u4fe1\u590d\u6742\u5ea6\u4e3a\u00d5(n\u03ba)", "result": "\u534f\u8bae\u5728\u4fdd\u6301\u5b89\u5168\u6027\u548c\u6d3b\u8dc3\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u6700\u4f73\u60c5\u51b5O(\u03ba)\u8f6e\u5ef6\u8fdf\uff0c\u5176\u4e2d\u03ba\u662f\u5c0f\u7684\u5b89\u5168\u53c2\u6570", "conclusion": "QScale\u4e3a\u4e2d\u7b49\u89c4\u6a21\u5206\u5e03\u5f0f\u8d26\u672c\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e73\u8861\u4e86\u901a\u4fe1\u590d\u6742\u5ea6\u548c\u5ef6\u8fdf\u8981\u6c42"}}
{"id": "2510.01740", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.01740", "abs": "https://arxiv.org/abs/2510.01740", "authors": ["Kypros Iacovou", "Georgia M. Kapitsaki", "Evangelia Vanezi"], "title": "FOSS-chain: using blockchain for Open Source Software license compliance", "comment": null, "summary": "Open Source Software (OSS) is widely used and carries licenses that indicate\nthe terms under which the software is provided for use, also specifying\nmodification and distribution rules. Ensuring that users are respecting OSS\nlicense terms when creating derivative works is a complex process. Compliance\nissues arising from incompatibilities among licenses may lead to legal\ndisputes. At the same time, the blockchain technology with immutable entries\noffers a mechanism to provide transparency when it comes to licensing and\nensure software changes are recorded. In this work, we are introducing an\nintegration of blockchain and license management when creating derivative\nworks, in order to tackle the issue of OSS license compatibility. We have\ndesigned, implemented and performed a preliminary evaluation of FOSS-chain, a\nweb platform that uses blockchain and automates the license compliance process,\ncovering 14 OSS licenses. We have evaluated the initial prototype version of\nthe FOSS-chain platform via a small scale user study. Our preliminary results\nare promising, demonstrating the potential of the platform for adaptation on\nrealistic software systems.", "AI": {"tldr": "FOSS-chain\u662f\u4e00\u4e2a\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u5f00\u6e90\u8f6f\u4ef6\u8bb8\u53ef\u8bc1\u7ba1\u7406\u5e73\u53f0\uff0c\u65e8\u5728\u89e3\u51b3\u884d\u751f\u4f5c\u54c1\u521b\u5efa\u65f6\u7684\u8bb8\u53ef\u8bc1\u517c\u5bb9\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u5408\u89c4\u6d41\u7a0b\u8986\u76d614\u79cdOSS\u8bb8\u53ef\u8bc1", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u8bb8\u53ef\u8bc1\u5408\u89c4\u6027\u590d\u6742\uff0c\u8bb8\u53ef\u8bc1\u4e0d\u517c\u5bb9\u53ef\u80fd\u5bfc\u81f4\u6cd5\u5f8b\u7ea0\u7eb7\uff0c\u800c\u533a\u5757\u94fe\u6280\u672f\u80fd\u63d0\u4f9b\u900f\u660e\u6027\u548c\u4e0d\u53ef\u7be1\u6539\u7684\u8bb0\u5f55\u673a\u5236", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86FOSS-chain\u7f51\u7edc\u5e73\u53f0\uff0c\u96c6\u6210\u533a\u5757\u94fe\u6280\u672f\u81ea\u52a8\u5316\u8bb8\u53ef\u8bc1\u5408\u89c4\u6d41\u7a0b\uff0c\u5e76\u901a\u8fc7\u5c0f\u89c4\u6a21\u7528\u6237\u7814\u7a76\u8fdb\u884c\u521d\u6b65\u8bc4\u4f30", "result": "\u521d\u6b65\u7ed3\u679c\u4ee4\u4eba\u9f13\u821e\uff0c\u5c55\u793a\u4e86\u8be5\u5e73\u53f0\u5728\u5b9e\u9645\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u5e94\u7528\u7684\u6f5c\u529b", "conclusion": "\u533a\u5757\u94fe\u4e0e\u8bb8\u53ef\u8bc1\u7ba1\u7406\u7684\u6574\u5408\u4e3a\u89e3\u51b3OSS\u8bb8\u53ef\u8bc1\u517c\u5bb9\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.02185", "categories": ["cs.SE", "cs.CR", "cs.MA", "D.2.4; F.3.1"], "pdf": "https://arxiv.org/pdf/2510.02185", "abs": "https://arxiv.org/abs/2510.02185", "authors": ["Paschal C. Amusuo", "Dongge Liu", "Ricardo Andres Calvo Mendez", "Jonathan Metzman", "Oliver Chang", "James C. Davis"], "title": "FalseCrashReducer: Mitigating False Positive Crashes in OSS-Fuzz-Gen Using Agentic AI", "comment": "12 pages, 2 figures", "summary": "Fuzz testing has become a cornerstone technique for identifying software bugs\nand security vulnerabilities, with broad adoption in both industry and\nopen-source communities. Directly fuzzing a function requires fuzz drivers,\nwhich translate random fuzzer inputs into valid arguments for the target\nfunction. Given the cost and expertise required to manually develop fuzz\ndrivers, methods exist that leverage program analysis and Large Language Models\nto automatically generate these drivers. However, the generated fuzz drivers\nfrequently lead to false positive crashes, especially in functions highly\nstructured input and complex state requirements. This problem is especially\ncrucial in industry-scale fuzz driver generation efforts like OSS-Fuzz-en, as\nreporting false positive crashes to maintainers impede trust in both the system\nand the team.\n  This paper presents two AI-driven strategies to reduce false positives in\nOSS-Fuzz-Gen, a multi-agent system for automated fuzz driver generation. First,\nconstraint-based fuzz driver generation proactively enforces constraints on a\nfunction's inputs and state to guide driver creation. Second, context-based\ncrash validation reactively analyzes function callers to determine whether\nreported crashes are feasible from program entry points. Using 1,500 benchmark\nfunctions from OSS-Fuzz, we show that these strategies reduce spurious crashes\nby up to 8%, cut reported crashes by more than half, and demonstrate that\nfrontier LLMs can serve as reliable program analysis agents. Our results\nhighlight the promise and challenges of integrating AI into large-scale fuzzing\npipelines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u79cdAI\u9a71\u52a8\u7684\u7b56\u7565\u6765\u51cf\u5c11\u6a21\u7cca\u6d4b\u8bd5\u9a71\u52a8\u751f\u6210\u4e2d\u7684\u8bef\u62a5\u5d29\u6e83\uff1a\u57fa\u4e8e\u7ea6\u675f\u7684\u9a71\u52a8\u751f\u6210\u548c\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u5d29\u6e83\u9a8c\u8bc1\uff0c\u5728OSS-Fuzz\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u8bef\u62a5\u7387\u3002", "motivation": "\u6a21\u7cca\u6d4b\u8bd5\u9a71\u52a8\u81ea\u52a8\u751f\u6210\u7ecf\u5e38\u4ea7\u751f\u8bef\u62a5\u5d29\u6e83\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u7ed3\u6784\u5316\u8f93\u5165\u548c\u590d\u6742\u72b6\u6001\u9700\u6c42\u7684\u51fd\u6570\u65f6\uff0c\u8fd9\u5f71\u54cd\u4e86\u5de5\u4e1a\u7ea7\u6a21\u7cca\u6d4b\u8bd5\u7cfb\u7edf\uff08\u5982OSS-Fuzz-Gen\uff09\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u91c7\u7528\u4e24\u79cdAI\u7b56\u7565\uff1a1\uff09\u57fa\u4e8e\u7ea6\u675f\u7684\u6a21\u7cca\u9a71\u52a8\u751f\u6210\uff0c\u4e3b\u52a8\u5bf9\u51fd\u6570\u8f93\u5165\u548c\u72b6\u6001\u65bd\u52a0\u7ea6\u675f\uff1b2\uff09\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u5d29\u6e83\u9a8c\u8bc1\uff0c\u901a\u8fc7\u5206\u6790\u51fd\u6570\u8c03\u7528\u8005\u6765\u9a8c\u8bc1\u5d29\u6e83\u662f\u5426\u53ef\u884c\u3002", "result": "\u57281,500\u4e2aOSS-Fuzz\u57fa\u51c6\u51fd\u6570\u4e0a\uff0c\u8fd9\u4e9b\u7b56\u7565\u5c06\u865a\u5047\u5d29\u6e83\u51cf\u5c11\u9ad8\u8fbe8%\uff0c\u62a5\u544a\u7684\u5d29\u6e83\u6570\u91cf\u51cf\u5c11\u4e00\u534a\u4ee5\u4e0a\uff0c\u8bc1\u660e\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u53ef\u9760\u7684\u7a0b\u5e8f\u5206\u6790\u4ee3\u7406\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5c55\u793a\u4e86\u5c06AI\u96c6\u6210\u5230\u5927\u89c4\u6a21\u6a21\u7cca\u6d4b\u8bd5\u7ba1\u9053\u4e2d\u7684\u524d\u666f\u548c\u6311\u6218\uff0c\u4e3a\u5de5\u4e1a\u7ea7\u6a21\u7cca\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bef\u62a5\u51cf\u5c11\u65b9\u6848\u3002"}}
{"id": "2510.01754", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.01754", "abs": "https://arxiv.org/abs/2510.01754", "authors": ["Hina Anwar"], "title": "ARENA: A tool for measuring and analysing the energy efficiency of Android apps", "comment": null, "summary": "To build energy-efficient apps, there is a need to estimate and analyze their\nenergy consumption in typical usage scenarios. The energy consumption of\nAndroid apps could be estimated via software-based and hardware-based\napproaches. Software-based approaches, while easier to implement, are not as\naccurate as hardware-based approaches. The process of measuring the energy\nconsumption of an Android app via a hardware-based approach typically involves\n1) setting up a measurement environment, 2) executing the app under test on a\nmobile device, 3) recording current/voltage data via a hardware device to\nmeasure energy consumption, and 4) cleaning and aggregating data for analyses,\nreports, and visualizations. Specialized scripts are written for selected\nhardware and software components to ensure reliable energy measurements. The\nenergy measurement process is repeated many times and aggregated to remove\nnoise. These steps make the hardware-based energy measurement process\ntime-consuming and not easy to adapt or reproduce. There is a lack of\nopen-source tools available for developers and researchers to take reliable\nenergy measurements via hardware devices. In this paper, we present and\ndemonstrate ARENA, a support tool that enables developers and researchers to\nconnect to a physical measurement device without leaving the comfort of their\nIDE. Developers could use ARENA during development to compare energy\nconsumption between different apps or versions of the same app. ARENA\ncalculates energy consumption on an Android smartphone by executing a test\nscenario on the app under development. Further, ARENA helps aggregate,\nstatistically analyze, report, and visualize the data, allowing developers and\nresearchers to dig into the data directly or visually. We implemented ARENA as\nan IntelliJ and Android Studio plugin.", "AI": {"tldr": "ARENA\u662f\u4e00\u4e2aIDE\u63d2\u4ef6\u5de5\u5177\uff0c\u901a\u8fc7\u786c\u4ef6\u65b9\u5f0f\u51c6\u786e\u6d4b\u91cfAndroid\u5e94\u7528\u80fd\u8017\uff0c\u7b80\u5316\u4e86\u4f20\u7edf\u786c\u4ef6\u80fd\u8017\u6d4b\u91cf\u7684\u590d\u6742\u6d41\u7a0b", "motivation": "\u73b0\u6709\u7684\u786c\u4ef6\u80fd\u8017\u6d4b\u91cf\u65b9\u6cd5\u8bbe\u7f6e\u590d\u6742\u3001\u8017\u65f6\u4e14\u4e0d\u6613\u590d\u73b0\uff0c\u7f3a\u4e4f\u5f00\u6e90\u5de5\u5177\u652f\u6301\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u8fdb\u884c\u53ef\u9760\u7684\u786c\u4ef6\u80fd\u8017\u6d4b\u91cf", "method": "\u5f00\u53d1ARENA\u4f5c\u4e3aIntelliJ\u548cAndroid Studio\u63d2\u4ef6\uff0c\u8fde\u63a5\u7269\u7406\u6d4b\u91cf\u8bbe\u5907\uff0c\u6267\u884c\u6d4b\u8bd5\u573a\u666f\uff0c\u81ea\u52a8\u8fdb\u884c\u6570\u636e\u805a\u5408\u3001\u7edf\u8ba1\u5206\u6790\u3001\u62a5\u544a\u548c\u53ef\u89c6\u5316", "result": "\u5b9e\u73b0\u4e86\u5728IDE\u5185\u76f4\u63a5\u8fdb\u884c\u786c\u4ef6\u80fd\u8017\u6d4b\u91cf\u7684\u5de5\u5177\uff0c\u652f\u6301\u5f00\u53d1\u8005\u6bd4\u8f83\u4e0d\u540c\u5e94\u7528\u6216\u7248\u672c\u7684\u80fd\u8017\u5dee\u5f02", "conclusion": "ARENA\u4e3a\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4fbf\u6377\u53ef\u9760\u7684\u786c\u4ef6\u80fd\u8017\u6d4b\u91cf\u89e3\u51b3\u65b9\u6848\uff0c\u7b80\u5316\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u590d\u6742\u6027"}}
{"id": "2510.02170", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.02170", "abs": "https://arxiv.org/abs/2510.02170", "authors": ["Nick Brown", "Jake Davies", "Felix LeClair"], "title": "Programming RISC-V accelerators via Fortran", "comment": "Accepted extended abstract to the RISC-V Summit Europe 2025", "summary": "A range of RISC-V based accelerators are available and coming to market, and\nthere is strong potential for these to be used for High Performance Computing\n(HPC) workloads. However, such accelerators tend to provide bespoke programming\nmodels and APIs that require codes to be rewritten. In scientific computing,\nwhere many of the simulation code are highly complex, extensive, and written in\nFortran, this is not realistic. In this extended abstract we present an\napproach that enables driving such architectures via Fortran, avoiding code\nredevelopment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7Fortran\u9a71\u52a8RISC-V\u52a0\u901f\u5668\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u79d1\u5b66\u8ba1\u7b97\u4ee3\u7801\u91cd\u5199", "motivation": "RISC-V\u52a0\u901f\u5668\u5177\u6709\u9ad8\u6027\u80fd\u8ba1\u7b97\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u4e13\u95e8\u7684\u7f16\u7a0b\u6a21\u578b\u548cAPI\uff0c\u800c\u79d1\u5b66\u8ba1\u7b97\u4e2d\u5927\u91cf\u590d\u6742\u7684Fortran\u4ee3\u7801\u96be\u4ee5\u91cd\u5199", "method": "\u5f00\u53d1\u4e00\u79cd\u65b9\u6cd5\u4f7fFortran\u4ee3\u7801\u80fd\u591f\u76f4\u63a5\u9a71\u52a8RISC-V\u52a0\u901f\u5668\u67b6\u6784", "result": "\u5b9e\u73b0\u4e86\u65e0\u9700\u4ee3\u7801\u91cd\u5f00\u53d1\u5373\u53ef\u5229\u7528RISC-V\u52a0\u901f\u5668\u7684\u80fd\u529b", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u79d1\u5b66\u8ba1\u7b97\u9886\u57df\u4f7f\u7528RISC-V\u52a0\u901f\u5668\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4fdd\u62a4\u4e86\u73b0\u6709\u7684Fortran\u4ee3\u7801\u6295\u8d44"}}
{"id": "2510.01825", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.01825", "abs": "https://arxiv.org/abs/2510.01825", "authors": ["Zhenyu Yang", "Yue Pan", "Zhen Yang", "Zhongxing Yu"], "title": "Towards Speeding up Program Repair with Non-Autoregressive Model", "comment": "30 pages, 8 figures, 7 tables. arXiv admin note: substantial text\n  overlap with arXiv:2406.16526", "summary": "Enlightened by the success of machine learning techniques in various\napplication areas, recent years have witnessed a surge of research efforts on\nautomatic program repair (APR) using machine learning techniques. Previous\nmachine learning-based APR techniques essentially modified bugs in the\nautoregressive (AR) manner, which predicts future values based on past values.\nDue to the manner of token-by-token generation, the AR-based APR technique has\na huge time delay. In particular, the delay of the APR model with a large\nnumber of parameters is more serious. To address the issue, we aim to apply the\nnon-autoregressive (NAR) method to the APR task, which can output target code\nin a parallel manner to avoid huge repair delays. However, the naive use of the\nNAR manner for the APR task suffers from the issue of compromised patch\nquality. To effectively adapt the NAR manner for the APR task, we in this paper\npropose NARRepair, the first customized NAR code generation model for the APR\ntask. The NARRepair model features three major novelties, including 1) the\nrepair action predictor for alleviating the over-correction issue, 2) the\ninter-token dependency extractor for alleviating the issue of lacking\ninter-token dependency information, and 3) the two-stage decoder for\nalleviating the issue of lacking contextual information. We evaluated NARRepair\non three widely used datasets in the APR community, and the results show that\n1) compared to other APR techniques, the NARRepair model has the best\nperformance within the limited repair time, and 2) compared to AR-based APR\ntechniques, the repair speed of NARRepair has been increased by 1.4-6.4 times\nin the GPU environment. Overall, the results show that NARRepair has achieved\nstate-of-the-art comprehensive performance in terms of repair speed and\naccuracy.", "AI": {"tldr": "NARRepair\u662f\u9996\u4e2a\u9488\u5bf9\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u4efb\u52a1\u5b9a\u5236\u7684\u975e\u81ea\u56de\u5f52\u4ee3\u7801\u751f\u6210\u6a21\u578b\uff0c\u901a\u8fc7\u4fee\u590d\u52a8\u4f5c\u9884\u6d4b\u5668\u3001\u4ee4\u724c\u95f4\u4f9d\u8d56\u63d0\u53d6\u5668\u548c\u4e24\u9636\u6bb5\u89e3\u7801\u5668\u4e09\u5927\u521b\u65b0\uff0c\u5728\u4fdd\u8bc1\u4fee\u590d\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4fee\u590d\u901f\u5ea61.4-6.4\u500d\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u6280\u672f\u91c7\u7528\u81ea\u56de\u5f52\u65b9\u5f0f\uff0c\u5b58\u5728\u5de8\u5927\u7684\u65f6\u95f4\u5ef6\u8fdf\u95ee\u9898\uff0c\u7279\u522b\u662f\u53c2\u6570\u91cf\u5927\u7684\u6a21\u578b\u5ef6\u8fdf\u66f4\u4e25\u91cd\u3002\u975e\u81ea\u56de\u5f52\u65b9\u6cd5\u867d\u7136\u53ef\u4ee5\u5e76\u884c\u8f93\u51fa\u4ee3\u7801\u907f\u514d\u5ef6\u8fdf\uff0c\u4f46\u76f4\u63a5\u5e94\u7528\u4e8eAPR\u4efb\u52a1\u4f1a\u5bfc\u81f4\u8865\u4e01\u8d28\u91cf\u4e0b\u964d\u3002", "method": "\u63d0\u51faNARRepair\u6a21\u578b\uff0c\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1)\u4fee\u590d\u52a8\u4f5c\u9884\u6d4b\u5668\u7f13\u89e3\u8fc7\u5ea6\u4fee\u6b63\u95ee\u9898\uff1b2)\u4ee4\u724c\u95f4\u4f9d\u8d56\u63d0\u53d6\u5668\u89e3\u51b3\u7f3a\u4e4f\u4ee4\u724c\u95f4\u4f9d\u8d56\u4fe1\u606f\u7684\u95ee\u9898\uff1b3)\u4e24\u9636\u6bb5\u89e3\u7801\u5668\u89e3\u51b3\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u95ee\u9898\u3002", "result": "\u5728\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684APR\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u663e\u793a\uff0cNARRepair\u5728\u6709\u9650\u4fee\u590d\u65f6\u95f4\u5185\u6027\u80fd\u6700\u4f73\uff0c\u76f8\u6bd4AR-based APR\u6280\u672f\u5728GPU\u73af\u5883\u4e2d\u4fee\u590d\u901f\u5ea6\u63d0\u53471.4-6.4\u500d\u3002", "conclusion": "NARRepair\u5728\u4fee\u590d\u901f\u5ea6\u548c\u51c6\u786e\u6027\u65b9\u9762\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7efc\u5408\u6027\u80fd\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4f20\u7edfAR\u65b9\u6cd5\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u8d28\u91cf\u7684\u4fee\u590d\u6548\u679c\u3002"}}
{"id": "2510.01960", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.01960", "abs": "https://arxiv.org/abs/2510.01960", "authors": ["Victor Lira", "Paulo Borba", "Rodrigo Bonif\u00e1cio", "Galileu Santos e Matheus barbosa"], "title": "RefFilter: Improving Semantic Conflict Detection via Refactoring-Aware Static Analysis", "comment": null, "summary": "Detecting semantic interference remains a challenge in collaborative software\ndevelopment. Recent lightweight static analysis techniques improve efficiency\nover SDG-based methods, but they still suffer from a high rate of false\npositives. A key cause of these false positives is the presence of\nbehavior-preserving code refactorings, which current techniques cannot\neffectively distinguish from changes that impact behavior and can interfere\nwith others. To handle this problem we present RefFilter, a refactoring-aware\ntool for semantic interference detection. It builds on existing static\ntechniques by incorporating automated refactoring detection to improve\nprecision. RefFilter discards behavior-preserving refactorings from reports,\nreducing false positives while preserving detection coverage. To evaluate\neffectiveness and scalability, use two datasets: a labeled dataset with 99\nscenarios and ground truth, and a novel dataset of 1,087 diverse merge\nscenarios that we have built. Experimental results show that RefFilter reduces\nfalse positives by nearly 32% on the labeled dataset. While this reduction\ncomes with a non significant increase in false negatives, the overall gain in\nprecision significantly outweighs the minor trade-off in recall. These findings\ndemonstrate that refactoring-aware interference detection is a practical and\neffective strategy for improving merge support in modern development workflows.", "AI": {"tldr": "RefFilter\u662f\u4e00\u4e2a\u91cd\u6784\u611f\u77e5\u7684\u8bed\u4e49\u5e72\u6270\u68c0\u6d4b\u5de5\u5177\uff0c\u901a\u8fc7\u81ea\u52a8\u68c0\u6d4b\u884c\u4e3a\u4fdd\u6301\u7684\u91cd\u6784\u6765\u51cf\u5c11\u73b0\u6709\u9759\u6001\u5206\u6790\u6280\u672f\u4e2d\u7684\u5047\u9633\u6027\uff0c\u5728\u4fdd\u6301\u68c0\u6d4b\u8986\u76d6\u7387\u7684\u540c\u65f6\u5c06\u5047\u9633\u6027\u964d\u4f4e\u4e86\u8fd132%\u3002", "motivation": "\u534f\u4f5c\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u8bed\u4e49\u5e72\u6270\u68c0\u6d4b\u9762\u4e34\u5047\u9633\u6027\u7387\u9ad8\u7684\u95ee\u9898\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u73b0\u6709\u6280\u672f\u65e0\u6cd5\u6709\u6548\u533a\u5206\u884c\u4e3a\u4fdd\u6301\u7684\u4ee3\u7801\u91cd\u6784\u548c\u5f71\u54cd\u884c\u4e3a\u7684\u66f4\u6539\u3002", "method": "\u5728\u73b0\u6709\u9759\u6001\u5206\u6790\u6280\u672f\u57fa\u7840\u4e0a\u96c6\u6210\u81ea\u52a8\u5316\u91cd\u6784\u68c0\u6d4b\uff0c\u4ece\u62a5\u544a\u4e2d\u8fc7\u6ee4\u6389\u884c\u4e3a\u4fdd\u6301\u7684\u91cd\u6784\u64cd\u4f5c\u3002", "result": "\u5728\u6807\u8bb0\u6570\u636e\u96c6\u4e0a\u5047\u9633\u6027\u51cf\u5c11\u8fd132%\uff0c\u867d\u7136\u5047\u9634\u6027\u7565\u6709\u589e\u52a0\u4f46\u7cbe\u5ea6\u63d0\u5347\u663e\u8457\u8d85\u8fc7\u53ec\u56de\u7387\u7684\u5fae\u5c0f\u635f\u5931\u3002", "conclusion": "\u91cd\u6784\u611f\u77e5\u7684\u5e72\u6270\u68c0\u6d4b\u662f\u6539\u8fdb\u73b0\u4ee3\u5f00\u53d1\u5de5\u4f5c\u6d41\u4e2d\u5408\u5e76\u652f\u6301\u7684\u5b9e\u7528\u6709\u6548\u7b56\u7565\u3002"}}
{"id": "2510.01994", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01994", "abs": "https://arxiv.org/abs/2510.01994", "authors": ["Chen Yang", "Lin Yang", "Ziqi Wang", "Dong Wang", "Jianyi Zhou", "Junjie Chen"], "title": "Clarifying Semantics of In-Context Examples for Unit Test Generation", "comment": "accepted in the research track of ASE 2025", "summary": "Recent advances in large language models (LLMs) have enabled promising\nperformance in unit test generation through in-context learning (ICL). However,\nthe quality of in-context examples significantly influences the effectiveness\nof generated tests-poorly structured or semantically unclear test examples\noften lead to suboptimal outputs. In this paper, we propose CLAST, a novel\ntechnique that systematically refines unit tests to improve their semantic\nclarity, thereby enhancing their utility as in-context examples. The approach\ndecomposes complex tests into logically clearer ones and improves semantic\nclarity through a combination of program analysis and LLM-based rewriting. We\nevaluated CLAST on four open-source and three industrial projects. The results\ndemonstrate that CLAST largely outperforms UTgen, the state-of-the-art\nrefinement technique, in both preserving test effectiveness and enhancing\nsemantic clarity. Specifically, CLAST fully retains the original effectiveness\nof unit tests, while UTgen reduces compilation success rate (CSR), pass rate\n(PR), test coverage (Cov), and mutation score (MS) by an average of 12.90%,\n35.82%, 4.65%, and 5.07%, respectively. Over 85.33% of participants in our user\nstudy preferred the semantic clarity of CLAST-refined tests. Notably,\nincorporating CLAST-refined tests as examples effectively improves ICL-based\nunit test generation approaches such as RAGGen and TELPA, resulting in an\naverage increase of 25.97% in CSR, 28.22% in PR, and 45.99% in Cov for\ngenerated tests, compared to incorporating UTgen-refined tests. The insights\nfrom the follow-up user study not only reinforce CLAST's potential impact in\nsoftware testing practice but also illuminate avenues for future research.", "AI": {"tldr": "CLAST\u662f\u4e00\u79cd\u901a\u8fc7\u7a0b\u5e8f\u5206\u6790\u548cLLM\u91cd\u5199\u6765\u7cfb\u7edf\u5316\u6539\u8fdb\u5355\u5143\u6d4b\u8bd5\u8bed\u4e49\u6e05\u6670\u5ea6\u7684\u6280\u672f\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u57fa\u4e8eICL\u7684\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u8d28\u91cf\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u6280\u672fUTgen\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eICL\u7684\u5355\u5143\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u4e0a\u4e0b\u6587\u793a\u4f8b\u7684\u8d28\u91cf\uff0c\u4f46\u73b0\u6709\u6d4b\u8bd5\u5f80\u5f80\u7ed3\u6784\u6df7\u4e71\u3001\u8bed\u4e49\u4e0d\u6e05\u6670\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u6d4b\u8bd5\u8d28\u91cf\u4e0d\u4f73\u3002", "method": "CLAST\u901a\u8fc7\u5c06\u590d\u6742\u6d4b\u8bd5\u5206\u89e3\u4e3a\u903b\u8f91\u66f4\u6e05\u6670\u7684\u6d4b\u8bd5\uff0c\u5e76\u7ed3\u5408\u7a0b\u5e8f\u5206\u6790\u548c\u57fa\u4e8eLLM\u7684\u91cd\u5199\u6280\u672f\u6765\u63d0\u9ad8\u6d4b\u8bd5\u7684\u8bed\u4e49\u6e05\u6670\u5ea6\u3002", "result": "CLAST\u5b8c\u5168\u4fdd\u7559\u4e86\u539f\u59cb\u6d4b\u8bd5\u7684\u6709\u6548\u6027\uff0c\u5728\u7f16\u8bd1\u6210\u529f\u7387\u3001\u901a\u8fc7\u7387\u3001\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u53d8\u5f02\u5206\u6570\u7b49\u6307\u6807\u4e0a\u5747\u4f18\u4e8eUTgen\u3002\u7528\u6237\u7814\u7a76\u4e2d85.33%\u7684\u53c2\u4e0e\u8005\u66f4\u504f\u597dCLAST\u6539\u8fdb\u7684\u6d4b\u8bd5\u6e05\u6670\u5ea6\u3002", "conclusion": "CLAST\u6280\u672f\u80fd\u663e\u8457\u63d0\u5347\u5355\u5143\u6d4b\u8bd5\u7684\u8bed\u4e49\u6e05\u6670\u5ea6\uff0c\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u793a\u4f8b\u4f7f\u7528\u65f6\u80fd\u6709\u6548\u6539\u8fdb\u57fa\u4e8eICL\u7684\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u8df5\u4ef7\u503c\u548c\u7814\u7a76\u524d\u666f\u3002"}}
{"id": "2510.02002", "categories": ["cs.SE", "D.2.1; D.2.2; D.2.3; D.3.4; G.1.6"], "pdf": "https://arxiv.org/pdf/2510.02002", "abs": "https://arxiv.org/abs/2510.02002", "authors": ["Maximilian Kratz", "Steffen Zschaler", "Jens Kosiol", "Gabriele Taentzer"], "title": "Automatic Generation of Combinatorial Reoptimisation Problem Specifications: A Vision", "comment": null, "summary": "Once an optimisation problem has been solved, the solution may need\nadaptation when contextual factors change. This challenge, also known as\nreoptimisation, has been addressed in various problem domains, such as railway\ncrew rescheduling, nurse rerostering, or aircraft recovery. This requires a\nmodified problem to be solved again to ensure that the adapted solution is\noptimal in the new context. However, the new optimisation problem differs\nnotably from the original problem: (i) we want to make only minimal changes to\nthe original solution to minimise the impact; (ii) we may be unable to change\nsome parts of the original solution (e.g., because they refer to past\nallocations); and (iii) we need to derive a change script from the original\nsolution to the new solution. In this paper, we argue that Model-Driven\nEngineering (MDE) - in particular, the use of declarative modelling languages\nand model transformations for the high-level specification of optimisation\nproblems - offers new opportunities for the systematic derivation of\nreoptimisation problems from the original optimisation problem specification.\nWe focus on combinatorial reoptimisation problems and provide an initial\ncategorisation of changing problems and strategies for deriving the\ncorresponding reoptimisation specifications. We introduce an initial\nproof-of-concept implementation based on the GIPS (Graph-Based (Mixed) Integer\nLinear Programming Problem Specification) tool and apply it to an example\nresource-allocation problem: the allocation of teaching assistants to teaching\nsessions.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\uff08MDE\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u58f0\u660e\u5f0f\u5efa\u6a21\u8bed\u8a00\u548c\u6a21\u578b\u8f6c\u6362\u6280\u672f\uff0c\u4ece\u539f\u59cb\u4f18\u5316\u95ee\u9898\u89c4\u8303\u4e2d\u7cfb\u7edf\u63a8\u5bfc\u51fa\u518d\u4f18\u5316\u95ee\u9898\u89c4\u8303\uff0c\u4ee5\u89e3\u51b3\u4e0a\u4e0b\u6587\u53d8\u5316\u65f6\u7684\u89e3\u51b3\u65b9\u6848\u9002\u5e94\u95ee\u9898\u3002", "motivation": "\u5f53\u4f18\u5316\u95ee\u9898\u7684\u4e0a\u4e0b\u6587\u56e0\u7d20\u53d1\u751f\u53d8\u5316\u65f6\uff0c\u9700\u8981\u91cd\u65b0\u4f18\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u9762\u4e34\u4e09\u4e2a\u6311\u6218\uff1a\u9700\u8981\u6700\u5c0f\u5316\u5bf9\u539f\u59cb\u89e3\u51b3\u65b9\u6848\u7684\u66f4\u6539\u3001\u67d0\u4e9b\u90e8\u5206\u53ef\u80fd\u65e0\u6cd5\u66f4\u6539\u3001\u9700\u8981\u751f\u6210\u53d8\u66f4\u811a\u672c\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u518d\u4f18\u5316\u95ee\u9898\u63a8\u5bfc\u673a\u5236\u3002", "method": "\u91c7\u7528\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u65b9\u6cd5\uff0c\u4f7f\u7528\u58f0\u660e\u5f0f\u5efa\u6a21\u8bed\u8a00\u548c\u6a21\u578b\u8f6c\u6362\u6280\u672f\uff0c\u57fa\u4e8eGIPS\u5de5\u5177\u5b9e\u73b0\u6982\u5ff5\u9a8c\u8bc1\uff0c\u5bf9\u7ec4\u5408\u518d\u4f18\u5316\u95ee\u9898\u8fdb\u884c\u5206\u7c7b\u5e76\u63a8\u5bfc\u76f8\u5e94\u7684\u518d\u4f18\u5316\u89c4\u8303\u3002", "result": "\u5f00\u53d1\u4e86\u57fa\u4e8eGIPS\u5de5\u5177\u7684\u521d\u59cb\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u73b0\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u6559\u5b66\u52a9\u7406\u5206\u914d\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\u793a\u4f8b\u4e2d\u3002", "conclusion": "\u6a21\u578b\u9a71\u52a8\u5de5\u7a0b\u4e3a\u7cfb\u7edf\u5316\u63a8\u5bfc\u518d\u4f18\u5316\u95ee\u9898\u89c4\u8303\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\uff0c\u7279\u522b\u662f\u5728\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u9886\u57df\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0a\u4e0b\u6587\u53d8\u5316\u65f6\u7684\u89e3\u51b3\u65b9\u6848\u9002\u5e94\u9700\u6c42\u3002"}}
{"id": "2510.02007", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02007", "abs": "https://arxiv.org/abs/2510.02007", "authors": ["Justus Bogner", "Roberto Verdecchia"], "title": "ACM SIGSOFT SEN Empirical Software Engineering: Introducing Our New Regular Column", "comment": "Published in ACM SIGSOFT Software Engineering Notes (SIGSOFT-SEN).\n  Volume 50, Issue 4, 2025", "summary": "From its early foundations in the 1970s, empirical software engineering (ESE)\nhas evolved into a mature research discipline that embraces a plethora of\ndifferent topics, methodologies, and industrial practices. Despite its\nremarkable progress, the ESE research field still needs to keep evolving, as\nnew impediments, shortcoming, and technologies emerge. Research\nreproducibility, limited external validity, subjectivity of reviews, and\nporting research results to industrial practices are just some examples of the\ndrivers for improvements to ESE research. Additionally, several facets of ESE\nresearch are not documented very explicitly, which makes it difficult for\nnewcomers to pick them up. With this new regular ACM SIGSOFT SEN column\n(SEN-ESE), we introduce a venue for discussing meta-aspects of ESE research,\nranging from general topics such as the nature and best practices for\nreplication packages, to more nuanced themes such as statistical methods,\ninterview transcription tools, and publishing interdisciplinary research. Our\naim for the column is to be a place where we can regularly spark conversations\non ESE topics that might not often be touched upon or are left implicit.\nContributions to this column will be grounded in expert interviews, focus\ngroups, surveys, and position pieces, with the goal of encouraging reflection\nand improvement in how we conduct, communicate, teach, and ultimately improve\nESE research. Finally, we invite feedback from the ESE community on\nchallenging, controversial, or underexplored topics, as well as suggestions for\nvoices you would like to hear from. While we cannot promise to act on every\nidea, we aim to shape this column around the community interests and are\ngrateful for all contributions.", "AI": {"tldr": "\u4ecb\u7ecdACM SIGSOFT SEN\u65b0\u4e13\u680fSEN-ESE\uff0c\u65e8\u5728\u8ba8\u8bba\u5b9e\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u5143\u65b9\u9762\u95ee\u9898\uff0c\u5305\u62ec\u7814\u7a76\u53ef\u91cd\u590d\u6027\u3001\u5916\u90e8\u6709\u6548\u6027\u3001\u8bc4\u5ba1\u4e3b\u89c2\u6027\u7b49\u6311\u6218\uff0c\u901a\u8fc7\u4e13\u5bb6\u8bbf\u8c08\u3001\u7126\u70b9\u5c0f\u7ec4\u7b49\u65b9\u5f0f\u4fc3\u8fdbESE\u7814\u7a76\u7684\u6539\u8fdb\u3002", "motivation": "\u5b9e\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u867d\u7136\u6210\u719f\u4f46\u4ecd\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u5982\u7814\u7a76\u53ef\u91cd\u590d\u6027\u5dee\u3001\u5916\u90e8\u6709\u6548\u6027\u6709\u9650\u3001\u8bc4\u5ba1\u8fc7\u7a0b\u4e3b\u89c2\u6027\u5f3a\u3001\u7814\u7a76\u6210\u679c\u96be\u4ee5\u8f6c\u5316\u5230\u5de5\u4e1a\u5b9e\u8df5\u7b49\u95ee\u9898\uff0c\u4e14\u8bb8\u591a\u7814\u7a76\u7ec6\u8282\u7f3a\u4e4f\u660e\u786e\u6587\u6863\u5316\uff0c\u4e0d\u5229\u4e8e\u65b0\u4eba\u5b66\u4e60\u3002", "method": "\u901a\u8fc7\u65b0\u8bbe\u7acb\u7684ACM SIGSOFT SEN\u4e13\u680f(SEN-ESE)\uff0c\u91c7\u7528\u4e13\u5bb6\u8bbf\u8c08\u3001\u7126\u70b9\u5c0f\u7ec4\u3001\u8c03\u67e5\u548c\u7acb\u573a\u6587\u7ae0\u7b49\u591a\u79cd\u5f62\u5f0f\uff0c\u8ba8\u8bbaESE\u7814\u7a76\u7684\u5143\u65b9\u9762\u95ee\u9898\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u4e13\u95e8\u8ba8\u8bbaESE\u7814\u7a76\u5143\u95ee\u9898\u7684\u5e73\u53f0\uff0c\u6db5\u76d6\u7814\u7a76\u53ef\u91cd\u590d\u6027\u5305\u7684\u6700\u4f73\u5b9e\u8df5\u3001\u7edf\u8ba1\u65b9\u6cd5\u3001\u8bbf\u8c08\u8f6c\u5f55\u5de5\u5177\u3001\u8de8\u5b66\u79d1\u7814\u7a76\u53d1\u8868\u7b49\u4e3b\u9898\u3002", "conclusion": "\u8be5\u4e13\u680f\u65e8\u5728\u4fc3\u8fdbESE\u7814\u7a76\u793e\u533a\u7684\u53cd\u601d\u548c\u6539\u8fdb\uff0c\u9f13\u52b1\u5c31\u5177\u6709\u6311\u6218\u6027\u3001\u4e89\u8bae\u6027\u6216\u672a\u5145\u5206\u63a2\u7d22\u7684\u4e3b\u9898\u8fdb\u884c\u8ba8\u8bba\uff0c\u5e76\u6839\u636e\u793e\u533a\u5174\u8da3\u5851\u9020\u4e13\u680f\u5185\u5bb9\u3002"}}
{"id": "2510.02165", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.02165", "abs": "https://arxiv.org/abs/2510.02165", "authors": ["Peter Wauyo", "Dalia Bwiza", "Alain Murara", "Edwin Mugume", "Eric Umuhoza"], "title": "Towards fairer public transit: Real-time tensor-based multimodal fare evasion and fraud detection", "comment": "10 pages", "summary": "This research introduces a multimodal system designed to detect fraud and\nfare evasion in public transportation by analyzing closed circuit television\n(CCTV) and audio data. The proposed solution uses the Vision Transformer for\nVideo (ViViT) model for video feature extraction and the Audio Spectrogram\nTransformer (AST) for audio analysis. The system implements a Tensor Fusion\nNetwork (TFN) architecture that explicitly models unimodal and bimodal\ninteractions through a 2-fold Cartesian product. This advanced fusion technique\ncaptures complex cross-modal dynamics between visual behaviors (e.g.,\ntailgating,unauthorized access) and audio cues (e.g., fare transaction sounds).\nThe system was trained and tested on a custom dataset, achieving an accuracy of\n89.5%, precision of 87.2%, and recall of 84.0% in detecting fraudulent\nactivities, significantly outperforming early fusion baselines and exceeding\nthe 75% recall rates typically reported in state-of-the-art transportation\nfraud detection systems. Our ablation studies demonstrate that the tensor\nfusion approach provides a 7.0% improvement in the F1 score and an 8.8% boost\nin recall compared to traditional concatenation methods. The solution supports\nreal-time detection, enabling public transport operators to reduce revenue\nloss, improve passenger safety, and ensure operational compliance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eVision Transformer\u548cAudio Spectrogram Transformer\u7684\u591a\u6a21\u6001\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f20\u91cf\u878d\u5408\u7f51\u7edc\u68c0\u6d4b\u516c\u5171\u4ea4\u901a\u6b3a\u8bc8\u548c\u9003\u7968\u884c\u4e3a\uff0c\u51c6\u786e\u7387\u8fbe89.5%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u89e3\u51b3\u516c\u5171\u4ea4\u901a\u4e2d\u6b3a\u8bc8\u548c\u9003\u7968\u884c\u4e3a\u5bfc\u81f4\u7684\u6536\u5165\u635f\u5931\u95ee\u9898\uff0c\u4f20\u7edf\u7cfb\u7edf\u68c0\u6d4b\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5206\u6790\u65b9\u6cd5", "method": "\u4f7f\u7528ViViT\u6a21\u578b\u63d0\u53d6\u89c6\u9891\u7279\u5f81\uff0cAST\u6a21\u578b\u5206\u6790\u97f3\u9891\uff0c\u91c7\u7528Tensor Fusion Network\u67b6\u6784\u8fdb\u884c2\u6298\u7b1b\u5361\u5c14\u79ef\u878d\u5408\uff0c\u6355\u6349\u89c6\u89c9\u884c\u4e3a\u4e0e\u97f3\u9891\u7ebf\u7d22\u7684\u8de8\u6a21\u6001\u4ea4\u4e92", "result": "\u5728\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u4e0a\u8fbe\u523089.5%\u51c6\u786e\u7387\u300187.2%\u7cbe\u786e\u7387\u548c84.0%\u53ec\u56de\u7387\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5F1\u5206\u6570\u63d0\u53477.0%\uff0c\u53ec\u56de\u7387\u63d0\u53478.8%", "conclusion": "\u8be5\u7cfb\u7edf\u652f\u6301\u5b9e\u65f6\u68c0\u6d4b\uff0c\u80fd\u6709\u6548\u5e2e\u52a9\u516c\u5171\u4ea4\u901a\u8fd0\u8425\u5546\u51cf\u5c11\u6536\u5165\u635f\u5931\u3001\u63d0\u9ad8\u4e58\u5ba2\u5b89\u5168\u6027\u548c\u8fd0\u8425\u5408\u89c4\u6027\uff0c\u591a\u6a21\u6001\u878d\u5408\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u5355\u6a21\u6001\u548c\u65e9\u671f\u878d\u5408\u57fa\u51c6"}}
{"id": "2510.02166", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.02166", "abs": "https://arxiv.org/abs/2510.02166", "authors": ["Fatou Ndiaye Mbodji", "El-hacen Diallo", "Jordan Samhi", "Kui Liu", "Jacques Klein", "Tegawend\u00e9 F. Bissyande"], "title": "SIEVE: Towards Verifiable Certification for Code-datasets", "comment": "5", "summary": "Code agents and empirical software engineering rely on public code datasets,\nyet these datasets lack verifiable quality guarantees. Static 'dataset cards'\ninform, but they are neither auditable nor do they offer statistical\nguarantees, making it difficult to attest to dataset quality. Teams build\nisolated, ad-hoc cleaning pipelines. This fragments effort and raises cost. We\npresent SIEVE, a community-driven framework. It turns per-property checks into\nConfidence Cards-machine-readable, verifiable certificates with anytime-valid\nstatistical bounds. We outline a research plan to bring SIEVE to maturity,\nreplacing narrative cards with anytime-verifiable certification. This shift is\nexpected to lower quality-assurance costs and increase trust in code-datasets.", "AI": {"tldr": "SIEVE\u6846\u67b6\u901a\u8fc7\u53ef\u9a8c\u8bc1\u7684\u7edf\u8ba1\u8bc1\u4e66\u66ff\u4ee3\u4f20\u7edf\u6570\u636e\u96c6\u5361\u7247\uff0c\u4e3a\u4ee3\u7801\u6570\u636e\u96c6\u63d0\u4f9b\u53ef\u5ba1\u8ba1\u7684\u8d28\u91cf\u4fdd\u8bc1\uff0c\u964d\u4f4e\u8d28\u91cf\u4fdd\u8bc1\u6210\u672c\u5e76\u589e\u5f3a\u4fe1\u4efb\u5ea6", "motivation": "\u5f53\u524d\u516c\u5171\u4ee3\u7801\u6570\u636e\u96c6\u7f3a\u4e4f\u53ef\u9a8c\u8bc1\u7684\u8d28\u91cf\u4fdd\u8bc1\uff0c\u9759\u6001\u6570\u636e\u96c6\u5361\u7247\u4e0d\u53ef\u5ba1\u8ba1\u4e14\u65e0\u6cd5\u63d0\u4f9b\u7edf\u8ba1\u4fdd\u8bc1\uff0c\u56e2\u961f\u9700\u8981\u6784\u5efa\u5b64\u7acb\u7684\u4e34\u65f6\u6e05\u7406\u6d41\u7a0b\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u6210\u672c\u589e\u52a0", "method": "\u63d0\u51faSIEVE\u793e\u533a\u9a71\u52a8\u6846\u67b6\uff0c\u5c06\u5c5e\u6027\u68c0\u67e5\u8f6c\u5316\u4e3a\u7f6e\u4fe1\u5361\u7247\u2014\u2014\u673a\u5668\u53ef\u8bfb\u3001\u53ef\u9a8c\u8bc1\u7684\u8bc1\u4e66\uff0c\u5305\u542b\u968f\u65f6\u6709\u6548\u7684\u7edf\u8ba1\u8fb9\u754c", "result": "SIEVE\u6846\u67b6\u80fd\u591f\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u6570\u636e\u96c6\u8d28\u91cf\u8ba4\u8bc1\uff0c\u53d6\u4ee3\u53d9\u8ff0\u6027\u5361\u7247", "conclusion": "SIEVE\u6846\u67b6\u9884\u8ba1\u5c06\u964d\u4f4e\u8d28\u91cf\u4fdd\u8bc1\u6210\u672c\uff0c\u63d0\u9ad8\u5bf9\u4ee3\u7801\u6570\u636e\u96c6\u7684\u4fe1\u4efb\u5ea6\uff0c\u4e3a\u4ee3\u7801\u4ee3\u7406\u548c\u5b9e\u8bc1\u8f6f\u4ef6\u5de5\u7a0b\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u6570\u636e\u57fa\u7840"}}
{"id": "2510.02169", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.02169", "abs": "https://arxiv.org/abs/2510.02169", "authors": ["Vadim Safronov", "Anthony McCaigue", "Nicholas Allott", "Andrew Martin"], "title": "TAIBOM: Bringing Trustworthiness to AI-Enabled Systems", "comment": "This paper has been accepted at the First International Workshop on\n  Security and Privacy-Preserving AI/ML (SPAIML 2025), co-located with the 28th\n  European Conference on Artificial Intelligence (ECAI 2025)", "summary": "The growing integration of open-source software and AI-driven technologies\nhas introduced new layers of complexity into the software supply chain,\nchallenging existing methods for dependency management and system assurance.\nWhile Software Bills of Materials (SBOMs) have become critical for enhancing\ntransparency and traceability, current frameworks fall short in capturing the\nunique characteristics of AI systems -- namely, their dynamic, data-driven\nnature and the loosely coupled dependencies across datasets, models, and\nsoftware components. These challenges are compounded by fragmented governance\nstructures and the lack of robust tools for ensuring integrity, trust, and\ncompliance in AI-enabled environments.\n  In this paper, we introduce Trusted AI Bill of Materials (TAIBOM) -- a novel\nframework extending SBOM principles to the AI domain. TAIBOM provides (i) a\nstructured dependency model tailored for AI components, (ii) mechanisms for\npropagating integrity statements across heterogeneous AI pipelines, and (iii) a\ntrust attestation process for verifying component provenance. We demonstrate\nhow TAIBOM supports assurance, security, and compliance across AI workflows,\nhighlighting its advantages over existing standards such as SPDX and CycloneDX.\nThis work lays the foundation for trustworthy and verifiable AI systems through\nstructured software transparency.", "AI": {"tldr": "\u63d0\u51fa\u4e86Trusted AI Bill of Materials (TAIBOM)\u6846\u67b6\uff0c\u5c06SBOM\u539f\u5219\u6269\u5c55\u5230AI\u9886\u57df\uff0c\u89e3\u51b3AI\u7cfb\u7edf\u7279\u6709\u7684\u52a8\u6001\u6570\u636e\u9a71\u52a8\u7279\u6027\u548c\u677e\u6563\u8026\u5408\u4f9d\u8d56\u5173\u7cfb\u95ee\u9898", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u548cAI\u6280\u672f\u7684\u878d\u5408\u589e\u52a0\u4e86\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u7684\u590d\u6742\u6027\uff0c\u73b0\u6709SBOM\u6846\u67b6\u65e0\u6cd5\u6709\u6548\u6355\u6349AI\u7cfb\u7edf\u7684\u72ec\u7279\u7279\u6027\uff0c\u5305\u62ec\u52a8\u6001\u6570\u636e\u9a71\u52a8\u6027\u8d28\u548c\u8de8\u6570\u636e\u96c6\u3001\u6a21\u578b\u3001\u8f6f\u4ef6\u7ec4\u4ef6\u7684\u677e\u6563\u8026\u5408\u4f9d\u8d56\u5173\u7cfb", "method": "\u5f00\u53d1\u4e86TAIBOM\u6846\u67b6\uff0c\u5305\u542b\uff1a(i)\u9488\u5bf9AI\u7ec4\u4ef6\u7684\u7ed3\u6784\u5316\u4f9d\u8d56\u6a21\u578b\uff0c(ii)\u8de8\u5f02\u6784AI\u7ba1\u9053\u7684\u5b8c\u6574\u6027\u58f0\u660e\u4f20\u64ad\u673a\u5236\uff0c(iii)\u9a8c\u8bc1\u7ec4\u4ef6\u6765\u6e90\u7684\u4fe1\u4efb\u8bc1\u660e\u8fc7\u7a0b", "result": "TAIBOM\u5728AI\u5de5\u4f5c\u6d41\u4e2d\u652f\u6301\u4fdd\u8bc1\u3001\u5b89\u5168\u548c\u5408\u89c4\u6027\uff0c\u76f8\u6bd4SPDX\u548cCycloneDX\u7b49\u73b0\u6709\u6807\u51c6\u5177\u6709\u4f18\u52bf", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u7ed3\u6784\u5316\u8f6f\u4ef6\u900f\u660e\u5ea6\u4e3a\u53ef\u4fe1\u548c\u53ef\u9a8c\u8bc1\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840"}}
