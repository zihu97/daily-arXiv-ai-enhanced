{"id": "2601.08129", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.08129", "abs": "https://arxiv.org/abs/2601.08129", "authors": ["Roland Rodriguez"], "title": "Emergent Coordination in Multi-Agent Systems via Pressure Fields and Temporal Decay", "comment": "19 pages, 9 tables. Code available at https://github.com/Govcraft/latin-experiment", "summary": "Current multi-agent LLM frameworks rely on explicit orchestration patterns borrowed from human organizational structures: planners delegate to executors, managers coordinate workers, and hierarchical control flow governs agent interactions. These approaches suffer from coordination overhead that scales poorly with agent count and task complexity. We propose a fundamentally different paradigm inspired by natural coordination mechanisms: agents operate locally on a shared artifact, guided only by pressure gradients derived from measurable quality signals, with temporal decay preventing premature convergence. We formalize this as optimization over a pressure landscape and prove convergence guarantees under mild conditions.\n  Empirically, on Latin Square constraint satisfaction across 1,078 trials, pressure-field coordination matches hierarchical control (38.2% vs 38.8% aggregate solve rate, p=0.94, indicating statistical equivalence). Both significantly outperform sequential (23.3%), random (11.7%), and conversation-based multi-agent dialogue (8.6%, p<0.00001). Temporal decay is essential: disabling it increases final pressure 49-fold (d=4.15). On easy problems, pressure-field achieves 87% solve rate. The approach maintains consistent performance from 2 to 32 agents. Our key finding: implicit coordination through shared pressure gradients achieves parity with explicit hierarchical control while dramatically outperforming explicit dialogue-based coordination. This suggests that constraint-driven emergence offers a simpler, equally effective foundation for multi-agent AI.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53d7\u81ea\u7136\u534f\u8c03\u673a\u5236\u542f\u53d1\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u5de5\u4ef6\u4e0a\u7684\u538b\u529b\u68af\u5ea6\u5b9e\u73b0\u9690\u5f0f\u534f\u8c03\uff0c\u5728\u62c9\u4e01\u65b9\u7ea6\u675f\u6ee1\u8db3\u4efb\u52a1\u4e2d\u4e0e\u663e\u5f0f\u5206\u5c42\u63a7\u5236\u6548\u679c\u76f8\u5f53\u4e14\u663e\u8457\u4f18\u4e8e\u5bf9\u8bdd\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4eba\u7c7b\u7ec4\u7ec7\u7ed3\u6784\u7684\u663e\u5f0f\u534f\u8c03\u6a21\u5f0f\u5b58\u5728\u968f\u667a\u80fd\u4f53\u6570\u91cf\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u589e\u957f\u800c\u6076\u5316\u7684\u534f\u8c03\u5f00\u9500\u95ee\u9898\u3002", "method": "\u667a\u80fd\u4f53\u5728\u5171\u4eab\u5de5\u4ef6\u4e0a\u4f9d\u636e\u8d28\u91cf\u4fe1\u53f7\u5bfc\u51fa\u7684\u538b\u529b\u68af\u5ea6\u5c40\u90e8\u64cd\u4f5c\uff0c\u5e76\u5f15\u5165\u65f6\u95f4\u8870\u51cf\u9632\u6b62\u8fc7\u65e9\u6536\u655b\uff0c\u5f62\u5f0f\u5316\u4e3a\u538b\u529b\u666f\u89c2\u4f18\u5316\u5e76\u8bc1\u660e\u5176\u6536\u655b\u6027\u3002", "result": "\u57281078\u6b21\u62c9\u4e01\u65b9\u5b9e\u9a8c\u4e2d\uff0c\u538b\u529b\u573a\u65b9\u6cd5\u6c42\u89e3\u738738.2%\uff0c\u4e0e\u5206\u5c42\u63a7\u523638.8%\u7edf\u8ba1\u7b49\u4ef7\uff1b\u663e\u8457\u4f18\u4e8e\u987a\u5e8f\u3001\u968f\u673a\u53ca\u5bf9\u8bdd\u65b9\u6cd5\uff1b\u65f6\u95f4\u8870\u51cf\u5173\u952e\uff0c\u7981\u7528\u540e\u538b\u529b\u4e0a\u534749\u500d\uff1b2\u81f332\u667a\u80fd\u4f53\u6027\u80fd\u7a33\u5b9a\u3002", "conclusion": "\u901a\u8fc7\u5171\u4eab\u538b\u529b\u68af\u5ea6\u7684\u9690\u5f0f\u534f\u8c03\u53ef\u8fbe\u5230\u4e0e\u663e\u5f0f\u5206\u5c42\u63a7\u5236\u540c\u7b49\u6548\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u8d85\u8d8a\u5bf9\u8bdd\u5f0f\u534f\u8c03\uff0c\u8868\u660e\u7ea6\u675f\u9a71\u52a8\u7684\u6d8c\u73b0\u673a\u5236\u662f\u6784\u5efa\u591a\u667a\u80fd\u4f53AI\u66f4\u7b80\u6d01\u6709\u6548\u7684\u57fa\u7840\u3002"}}
{"id": "2601.08815", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.08815", "abs": "https://arxiv.org/abs/2601.08815", "authors": ["Qing Ye", "Jing Tan"], "title": "Agent Contracts: A Formal Framework for Resource-Bounded Autonomous AI Systems", "comment": null, "summary": "The Contract Net Protocol (1980) introduced coordination through contracts in multi-agent systems. Modern agent protocols standardize connectivity and interoperability; yet, none provide formal, resource governance-normative mechanisms to bound how much agents may consume or how long they may operate. We introduce Agent Contracts, a formal framework that extends the contract metaphor from task allocation to resource-bounded execution. An Agent Contract unifies input/output specifications, multi-dimensional resource constraints, temporal boundaries, and success criteria into a coherent governance mechanism with explicit lifecycle semantics. For multi-agent coordination, we establish conservation laws ensuring delegated budgets respect parent constraints, enabling hierarchical coordination through contract delegation. Empirical validation across four experiments demonstrates 90% token reduction with 525x lower variance in iterative workflows, zero conservation violations in multi-agent delegation, and measurable quality-resource tradeoffs through contract modes. Agent Contracts provide formal foundations for predictable, auditable, and resource-bounded autonomous AI deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAgent Contracts\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u8d44\u6e90\u53d7\u9650\u7684\u6267\u884c\u4e0e\u534f\u8c03\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u534f\u8bae\u7f3a\u4e4f\u5bf9\u8d44\u6e90\u6d88\u8017\u548c\u8fd0\u884c\u65f6\u957f\u7684\u5f62\u5f0f\u5316\u7ea6\u675f\u673a\u5236\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u5408\u540c\u9690\u55bb\uff0c\u6574\u5408\u8f93\u5165/\u8f93\u51fa\u89c4\u8303\u3001\u591a\u7ef4\u8d44\u6e90\u7ea6\u675f\u3001\u65f6\u95f4\u8fb9\u754c\u548c\u6210\u529f\u6807\u51c6\uff0c\u5efa\u7acb\u5177\u6709\u660e\u786e\u751f\u547d\u5468\u671f\u8bed\u4e49\u7684\u6cbb\u7406\u673a\u5236\uff0c\u5e76\u652f\u6301\u901a\u8fc7\u5408\u540c\u59d4\u6258\u5b9e\u73b0\u5206\u5c42\u534f\u8c03\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u5728\u8fed\u4ee3\u5de5\u4f5c\u6d41\u4e2d\u51cf\u5c1190%\u4ee4\u724c\u4f7f\u7528\u4e14\u65b9\u5dee\u964d\u4f4e525\u500d\uff0c\u591a\u667a\u80fd\u4f53\u59d4\u6258\u4e2d\u96f6\u8fdd\u53cd\u5b88\u6052\u5b9a\u5f8b\uff0c\u5e76\u53ef\u901a\u8fc7\u5408\u540c\u6a21\u5f0f\u8861\u91cf\u8d28\u91cf-\u8d44\u6e90\u6743\u8861\u3002", "conclusion": "Agent Contracts\u4e3a\u53ef\u9884\u6d4b\u3001\u53ef\u5ba1\u8ba1\u548c\u8d44\u6e90\u53d7\u9650\u7684\u81ea\u4e3bAI\u90e8\u7f72\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u7840\u3002"}}
{"id": "2601.08135", "categories": ["cs.NI", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08135", "abs": "https://arxiv.org/abs/2601.08135", "authors": ["Zengzipeng Tang", "Yuxuan Sun", "Wei Chen", "Jianwen Ding", "Bo Ai", "Yulin Shao"], "title": "Hierarchical Online-Scheduling for Energy-Efficient Split Inference with Progressive Transmission", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Device-edge collaborative inference with Deep Neural Networks (DNNs) faces fundamental trade-offs among accuracy, latency and energy consumption. Current scheduling exhibits two drawbacks: a granularity mismatch between coarse, task-level decisions and fine-grained, packet-level channel dynamics, and insufficient awareness of per-task complexity. Consequently, scheduling solely at the task level leads to inefficient resource utilization. This paper proposes a novel ENergy-ACcuracy Hierarchical optimization framework for split Inference, named ENACHI, that jointly optimizes task- and packet-level scheduling to maximize accuracy under energy and delay constraints. A two-tier Lyapunov-based framework is developed for ENACHI, with a progressive transmission technique further integrated to enhance adaptivity. At the task level, an outer drift-plus-penalty loop makes online decisions for DNN partitioning and bandwidth allocation, and establishes a reference power budget to manage the long-term energy-accuracy trade-off. At the packet level, an uncertainty-aware progressive transmission mechanism is employed to adaptively manage per-sample task complexity. This is integrated with a nested inner control loop implementing a novel reference-tracking policy, which dynamically adjusts per-slot transmit power to adapt to fluctuating channel conditions. Experiments on ImageNet dataset demonstrate that ENACHI outperforms state-of-the-art benchmarks under varying deadlines and bandwidths, achieving a 43.12\\% gain in inference accuracy with a 62.13\\% reduction in energy consumption under stringent deadlines, and exhibits high scalability by maintaining stable energy consumption in congested multi-user scenarios.", "AI": {"tldr": "ENACHI\u6846\u67b6\u901a\u8fc7\u4efb\u52a1\u7ea7\u548c\u5305\u7ea7\u8054\u5408\u8c03\u5ea6\u4f18\u5316\uff0c\u5728\u80fd\u8017\u4e0e\u5ef6\u8fdf\u7ea6\u675f\u4e0b\u663e\u8457\u63d0\u5347\u63a8\u7406\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u8bbe\u5907\u8fb9\u7f18\u534f\u540c\u63a8\u7406\u4e2d\u4efb\u52a1\u7ea7\u8c03\u5ea6\u4e0e\u4fe1\u9053\u52a8\u6001\u4e0d\u5339\u914d\u3001\u4efb\u52a1\u590d\u6742\u5ea6\u611f\u77e5\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e24\u5c42Lyapunov\u6846\u67b6\uff0c\u5916\u5c42\u8fdb\u884cDNN\u5206\u5272\u4e0e\u5e26\u5bbd\u5206\u914d\uff0c\u5185\u5c42\u91c7\u7528\u6e10\u8fdb\u4f20\u8f93\u673a\u5236\u52a8\u6001\u8c03\u6574\u53d1\u5c04\u529f\u7387\u3002", "result": "\u5728ImageNet\u6570\u636e\u96c6\u4e0a\uff0cENACHI\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63a8\u7406\u7cbe\u5ea6\u63d0\u534743.12%\uff0c\u80fd\u8017\u964d\u4f4e62.13%\uff0c\u4e14\u5728\u591a\u7528\u6237\u573a\u666f\u4fdd\u6301\u7a33\u5b9a\u80fd\u8017\u3002", "conclusion": "ENACHI\u6709\u6548\u5e73\u8861\u7cbe\u5ea6\u3001\u80fd\u8017\u4e0e\u5ef6\u8fdf\uff0c\u5177\u5907\u9ad8\u9002\u5e94\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2601.08368", "categories": ["cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.08368", "abs": "https://arxiv.org/abs/2601.08368", "authors": ["Marie Bolzer", "S\u00e9bastien Duval", "Marine Minier"], "title": "A New Tool to Find Lightweight (And, Xor) Implementations of Quadratic Vectorial Boolean Functions up to Dimension 9", "comment": null, "summary": "The problem of finding a minimal circuit to implement a given function is one of the oldest in electronics. It is known to be NP-hard. Still, many tools exist to find sub-optimal circuits to implement a function. In electronics, such tools are known as synthesisers. However, these synthesisers aim to implement very large functions (a whole electronic chip). In cryptography, the focus is on small functions, hence the necessity for new dedicated tools for small functions. Several tools exist to implement small functions. They differ by their algorithmic approach (some are based on Depth-First-Search as introduced by Ullrich in 2011, some are based on SAT-solvers like the tool desgined by Stoffelen in 2016, some non-generic tools use subfield decomposition) and by their optimisation criteria (some optimise for circuit size, others for circuit depth, and some for side-channel-protected implementations). However, these tools are limited to functions operating on less than 5 bits, sometimes 6 bits for quadratic functions, or to very simple functions. The limitation lies in a high computing time. We propose a new tool (The tool is provided alongside the IEEE article with CodeOcean and at https://github.com/seduval/implem-quad-sbox) to implement quadratic functions up to 9 bits within AND-depth 1, minimising the number of AND gates. This tool is more time-efficient than previous ones, allowing to explore larger implementations than others on 6 bits or less and allows to reach larger sizes, up to 9 bits.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u5de5\u5177\uff0c\u7528\u4e8e\u5728AND\u6df1\u5ea6\u4e3a1\u7684\u60c5\u51b5\u4e0b\u9ad8\u6548\u5b9e\u73b0\u6700\u591a9\u4f4d\u7684\u4e8c\u6b21\u51fd\u6570\uff0c\u5e76\u6700\u5c0f\u5316AND\u95e8\u6570\u91cf\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u53d7\u9650\u4e8e\u8ba1\u7b97\u65f6\u95f4\uff0c\u4ec5\u80fd\u5904\u74065\u4f4d\u62166\u4f4d\u4ee5\u4e0b\u7684\u5c0f\u51fd\u6570\uff0c\u65e0\u6cd5\u6ee1\u8db3\u66f4\u5927\u89c4\u6a21\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65f6\u95f4\u6548\u7387\u66f4\u9ad8\u7684\u4e13\u7528\u5de5\u5177\uff0c\u4f18\u5316AND\u95e8\u6570\u91cf\u5e76\u652f\u6301\u6700\u591a9\u4f4d\u7684\u4e8c\u6b21\u51fd\u6570\u5b9e\u73b0\u3002", "result": "\u8be5\u5de5\u5177\u76f8\u6bd4\u4ee5\u5f80\u65b9\u6cd5\u66f4\u9ad8\u6548\uff0c\u53ef\u5904\u74066\u4f4d\u53ca\u4ee5\u4e0b\u51fd\u6570\uff0c\u5e76\u6269\u5c55\u81f39\u4f4d\u89c4\u6a21\u3002", "conclusion": "\u65b0\u5de5\u5177\u7a81\u7834\u4e86\u5c0f\u51fd\u6570\u5b9e\u73b0\u7684\u4f4d\u6570\u9650\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u9002\u7528\u8303\u56f4\u3002"}}
{"id": "2601.08539", "categories": ["cs.PF", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08539", "abs": "https://arxiv.org/abs/2601.08539", "authors": ["Jeffrey Spaan", "Kuan-Hsun Chen", "Ana-Lucia Varbanescu"], "title": "Reducing Compute Waste in LLMs through Kernel-Level DVFS", "comment": null, "summary": "The rapid growth of AI has fueled the expansion of accelerator- or GPU-based data centers. However, the rising operational energy consumption has emerged as a critical bottleneck and a major sustainability concern. Dynamic Voltage and Frequency Scaling (DVFS) is a well-known technique used to reduce energy consumption, and thus improve energy-efficiency, since it requires little effort and works with existing hardware. Reducing the energy consumption of training and inference of Large Language Models (LLMs) through DVFS or power capping is feasible: related work has shown energy savings can be significant, but at the cost of significant slowdowns. In this work, we focus on reducing waste in LLM operations: i.e., reducing energy consumption without losing performance. We propose a fine-grained, kernel-level, DVFS approach that explores new frequency configurations, and prove these save more energy than previous, pass- or iteration-level solutions. For example, for a GPT-3 training run, a pass-level approach could reduce energy consumption by 2% (without losing performance), while our kernel-level approach saves as much as 14.6% (with a 0.6% slowdown). We further investigate the effect of data and tensor parallelism, and show our discovered clock frequencies translate well for both. We conclude that kernel-level DVFS is a suitable technique to reduce waste in LLM operations, providing significant energy savings with negligible slow-down.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ec6\u7c92\u5ea6\u3001\u5185\u6838\u7ea7\u7684\u52a8\u6001\u7535\u538b\u9891\u7387\u8c03\u8282\uff08DVFS\uff09\u65b9\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u80fd\u8017\u4e14\u51e0\u4e4e\u4e0d\u5f71\u54cd\u6027\u80fd\u3002", "motivation": "AI\u6570\u636e\u4e2d\u5fc3\u80fd\u8017\u6fc0\u589e\u5df2\u6210\u4e3a\u53ef\u6301\u7eed\u53d1\u5c55\u7684\u74f6\u9888\uff0c\u9700\u5728\u4e0d\u727a\u7272\u6027\u80fd\u524d\u63d0\u4e0b\u51cf\u5c11\u80fd\u6e90\u6d6a\u8d39\u3002", "method": "\u91c7\u7528\u5185\u6838\u7ea7DVFS\u7b56\u7565\uff0c\u63a2\u7d22\u65b0\u9891\u7387\u914d\u7f6e\uff0c\u5e76\u9a8c\u8bc1\u5176\u4f18\u4e8e\u4ee5\u5f80\u7684pass\u7ea7\u6216\u8fed\u4ee3\u7ea7\u65b9\u6848\u3002", "result": "\u5728GPT-3\u8bad\u7ec3\u4e2d\u5b9e\u73b014.6%\u80fd\u8017\u8282\u7701\uff08\u4ec50.6%\u6027\u80fd\u4e0b\u964d\uff09\uff0c\u4e14\u9002\u7528\u4e8e\u6570\u636e\u4e0e\u5f20\u91cf\u5e76\u884c\u573a\u666f\u3002", "conclusion": "\u5185\u6838\u7ea7DVFS\u662f\u51cf\u5c11LLM\u64cd\u4f5c\u80fd\u8017\u7684\u6709\u6548\u6280\u672f\uff0c\u517c\u987e\u8282\u80fd\u4e0e\u6027\u80fd\u3002"}}
{"id": "2601.07939", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07939", "abs": "https://arxiv.org/abs/2601.07939", "authors": ["Shireesh Reddy Pyreddy", "Khaja Valli Pathan", "Hasan Masum", "Tarannum Shaila Zaman"], "title": "SECite: Analyzing and Summarizing Citations in Software Engineering Literature", "comment": "Accepted at IEEE CCWC 2026", "summary": "Identifying the strengths and limitations of a research paper is a core component of any literature review. However, traditional summaries reflect only the authors' self-presented perspective. Analyzing how other researchers discuss and cite the paper can offer a deeper, more practical understanding of its contributions and shortcomings. In this research, we introduce SECite, a novel approach for evaluating scholarly impact through sentiment analysis of citation contexts. We develop a semi-automated pipeline to extract citations referencing nine research papers and apply advanced natural language processing (NLP) techniques with unsupervised machine learning to classify these citation statements as positive or negative. Beyond sentiment classification, we use generative AI to produce sentiment-specific summaries that capture the strengths and limitations of each target paper, derived both from clustered citation groups and from the full text. Our findings reveal meaningful patterns in how the academic community perceives these works, highlighting areas of alignment and divergence between external citation feedback and the authors' own presentation. By integrating citation sentiment analysis with LLM-based summarization, this study provides a comprehensive framework for assessing scholarly contributions.", "AI": {"tldr": "SECite\u901a\u8fc7\u5206\u6790\u5f15\u7528\u8bed\u5883\u7684\u60c5\u611f\uff0c\u7ed3\u5408NLP\u4e0e\u751f\u6210\u5f0fAI\uff0c\u8bc4\u4f30\u8bba\u6587\u7684\u5b66\u672f\u5f71\u54cd\u529b\u5e76\u603b\u7ed3\u5176\u4f18\u7f3a\u70b9\u3002", "motivation": "\u4f20\u7edf\u6458\u8981\u4ec5\u53cd\u6620\u4f5c\u8005\u89c6\u89d2\uff0c\u7f3a\u4e4f\u5916\u90e8\u8bc4\u4ef7\uff0c\u9700\u66f4\u5168\u9762\u7406\u89e3\u8bba\u6587\u8d21\u732e\u4e0e\u4e0d\u8db3\u3002", "method": "\u6784\u5efa\u534a\u81ea\u52a8\u6d41\u7a0b\u63d0\u53d6\u5f15\u7528\uff0c\u7528\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u60c5\u611f\uff0c\u5e76\u5229\u7528\u751f\u6210\u5f0fAI\u751f\u6210\u60c5\u611f\u5bfc\u5411\u6458\u8981\u3002", "result": "\u53d1\u73b0\u5b66\u672f\u754c\u5bf9\u76ee\u6807\u8bba\u6587\u7684\u8bc4\u4ef7\u6a21\u5f0f\uff0c\u63ed\u793a\u5916\u90e8\u53cd\u9988\u4e0e\u4f5c\u8005\u81ea\u8ff0\u4e4b\u95f4\u7684\u5f02\u540c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8bc4\u4f30\u5b66\u672f\u8d21\u732e\u63d0\u4f9b\u4e86\u6574\u5408\u5f15\u7528\u60c5\u611f\u4e0eLLM\u6458\u8981\u7684\u7efc\u5408\u6846\u67b6\u3002"}}
{"id": "2601.08142", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.08142", "abs": "https://arxiv.org/abs/2601.08142", "authors": ["Dilki Wijekoon", "Amine Mezghani", "Ekram Hossain"], "title": "Joint Communication and Sensing in RIS-Assisted MIMO System Under Mutual Coupling", "comment": null, "summary": "This paper considers a downlink Reconfigurable Intelligent Surface (RIS)-assisted Joint Communication and Sensing (JCAS) system within a physically-consistent setting, accounting for the effect of mutual coupling between RIS elements arising due to sub-element spacing. The system features a multiple-input multiple-output (MIMO) terrestrial base station (BS) and explores both monostatic and bistatic radar configurations to enable joint communication and sensing. In the monostatic configuration, both the transmitter and receiver are at the same location, while the bistatic configuration separates the transmitter and receiver spatially. System performance is evaluated using Fisher Information (FI) to quantify sensing accuracy and Mutual Information (MI) to measure communication efficiency. To achieve an optimal balance between communication and sensing, the RIS reflective coefficients and BS transmit beamforming are jointly optimized by maximizing a weighted sum of FI and MI. A novel solution approach is proposed for a single-user, single-object scenario, leveraging the mutual coupling model to enhance system realism. The impact of self-interference on sensing performance is also investigated through signal quantization. Numerical results reveal a fundamental trade-off between FI and MI and demonstrate that incorporating mutual coupling within a physically-consistent framework significantly improves both communication and sensing performance compared to conventional RIS-assisted JCAS models. Additionally, the analysis highlights how the choice of monostatic versus bistatic radar configuration affects system performance, offering valuable insights for the design of RIS-assisted JCAS systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8003\u8651\u4e92\u8026\u6548\u5e94\u7684RIS\u8f85\u52a9\u901a\u611f\u4e00\u4f53\u5316\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316RIS\u53cd\u5c04\u7cfb\u6570\u4e0e\u57fa\u7ad9\u6ce2\u675f\u6210\u5f62\uff0c\u5728\u5355\u7528\u6237\u5355\u76ee\u6807\u573a\u666f\u4e0b\u63d0\u5347\u901a\u4fe1\u4e0e\u611f\u77e5\u6027\u80fd\u3002", "motivation": "\u73b0\u6709RIS\u8f85\u52a9JCAS\u6a21\u578b\u5ffd\u7565\u5143\u4ef6\u95f4\u4e92\u8026\u6548\u5e94\uff0c\u5bfc\u81f4\u6027\u80fd\u8bc4\u4f30\u4e0d\u771f\u5b9e\uff0c\u672c\u6587\u65e8\u5728\u6784\u5efa\u7269\u7406\u4e00\u81f4\u6a21\u578b\u4ee5\u66f4\u8d34\u8fd1\u5b9e\u9645\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u8d39\u96ea\u4fe1\u606f\u4e0e\u4e92\u4fe1\u606f\u5206\u522b\u91cf\u5316\u611f\u77e5\u7cbe\u5ea6\u4e0e\u901a\u4fe1\u6548\u7387\uff0c\u8054\u5408\u4f18\u5316RIS\u53cd\u5c04\u7cfb\u6570\u4e0eBS\u6ce2\u675f\u6210\u5f62\uff0c\u5e76\u5f15\u5165\u4e92\u8026\u6a21\u578b\u4e0e\u4fe1\u53f7\u91cf\u5316\u5206\u6790\u81ea\u5e72\u6270\u5f71\u54cd\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u8003\u8651\u4e92\u8026\u53ef\u663e\u8457\u63d0\u5347\u901a\u4fe1\u4e0e\u611f\u77e5\u6027\u80fd\uff0c\u4e14\u5355/\u53cc\u57fa\u5730\u96f7\u8fbe\u914d\u7f6e\u5bf9\u7cfb\u7edf\u8868\u73b0\u6709\u4e0d\u540c\u5f71\u54cd\uff0c\u63ed\u793a\u4e86FI\u4e0eMI\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u7269\u7406\u4e00\u81f4\u5efa\u6a21\u5bf9RIS-JCAS\u7cfb\u7edf\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\uff0c\u4e92\u8026\u6548\u5e94\u4e0d\u53ef\u5ffd\u7565\uff0c\u7cfb\u7edf\u914d\u7f6e\u9700\u6839\u636e\u5e94\u7528\u573a\u666f\u6743\u8861\u901a\u4fe1\u4e0e\u611f\u77e5\u9700\u6c42\u3002"}}
{"id": "2601.08012", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08012", "abs": "https://arxiv.org/abs/2601.08012", "authors": ["Aarya Doshi", "Yining Hong", "Congying Xu", "Eunsuk Kang", "Alexandros Kapravelos", "Christian K\u00e4stner"], "title": "Towards Verifiably Safe Tool Use for LLM Agents", "comment": "4 pages, 1 figure; accepted to ICSE NIER 2026", "summary": "Large language model (LLM)-based AI agents extend LLM capabilities by enabling access to tools such as data sources, APIs, search engines, code sandboxes, and even other agents. While this empowers agents to perform complex tasks, LLMs may invoke unintended tool interactions and introduce risks, such as leaking sensitive data or overwriting critical records, which are unacceptable in enterprise contexts. Current approaches to mitigate these risks, such as model-based safeguards, enhance agents' reliability but cannot guarantee system safety. Methods like information flow control (IFC) and temporal constraints aim to provide guarantees but often require extensive human annotation. We propose a process that starts with applying System-Theoretic Process Analysis (STPA) to identify hazards in agent workflows, derive safety requirements, and formalize them as enforceable specifications on data flows and tool sequences. To enable this, we introduce a capability-enhanced Model Context Protocol (MCP) framework that requires structured labels on capabilities, confidentiality, and trust level. Together, these contributions aim to shift LLM-based agent safety from ad hoc reliability fixes to proactive guardrails with formal guarantees, while reducing dependence on user confirmation and making autonomy a deliberate design choice.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408STPA\u4e0e\u589e\u5f3a\u7248MCP\u6846\u67b6\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u6784\u5efa\u5177\u5907\u5f62\u5f0f\u5316\u4fdd\u969c\u7684\u4e3b\u52a8\u5b89\u5168\u673a\u5236\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u5de5\u5177\u8c03\u7528\u5b58\u5728\u6570\u636e\u6cc4\u9732\u4e0e\u8bef\u64cd\u4f5c\u98ce\u9669\uff0c\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u4e14\u65e0\u6cd5\u63d0\u4f9b\u5f62\u5f0f\u5316\u5b89\u5168\u4fdd\u969c\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u7406\u8bba\u8fc7\u7a0b\u5206\u6790\uff08STPA\uff09\u8bc6\u522b\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u5371\u5bb3\u5e76\u5bfc\u51fa\u5b89\u5168\u9700\u6c42\uff0c\u518d\u901a\u8fc7\u589e\u5f3a\u578bModel Context Protocol\u6846\u67b6\u7ed3\u6784\u5316\u6807\u6ce8\u80fd\u529b\u3001\u673a\u5bc6\u6027\u4e0e\u4fe1\u4efb\u7b49\u7ea7\u4ee5\u5f3a\u5236\u6267\u884c\u3002", "result": "\u5b9e\u73b0\u4ece\u4e34\u65f6\u53ef\u9760\u6027\u4fee\u8865\u5230\u5177\u5907\u5f62\u5f0f\u5316\u4fdd\u969c\u7684\u4e3b\u52a8\u9632\u62a4\u673a\u5236\u8f6c\u53d8\uff0c\u964d\u4f4e\u5bf9\u7528\u6237\u786e\u8ba4\u7684\u4f9d\u8d56\uff0c\u4f7f\u81ea\u4e3b\u6027\u6210\u4e3a\u53ef\u8bbe\u8ba1\u9009\u9879\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u671b\u5728\u4f01\u4e1a\u7ea7\u573a\u666f\u4e2d\u4e3aLLM\u667a\u80fd\u4f53\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u3001\u4f4e\u4eba\u5de5\u5e72\u9884\u7684\u5b89\u5168\u8fd0\u884c\u4fdd\u969c\u3002"}}
{"id": "2601.08152", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.08152", "abs": "https://arxiv.org/abs/2601.08152", "authors": ["Thakshila Perera", "Amine Mezghani", "Ekram Hossain"], "title": "Multi-Objective Optimization for Joint Communication and Sensing in Multi-user MIMO Systems: Characterizing the Pareto Boundary", "comment": null, "summary": "This paper investigates the Pareto boundary performance of a joint communication and sensing (JCAS) system that addresses both sensing and communication functions at the same time. In this scenario, a multiple-antenna base station (BS) transmits information to multiple single-antenna communication users while concurrently estimating the parameters of a single sensing object using the echo signal. We present an integrated beamforming approach for JCAS in a multi-user multiple-input and multiple-output (MIMO) system. The performance measures for communication and sensing are Fisher information (FI) and mutual information (MI). Our research considers two scenarios: multiple communication users with a single sensing object and a single communication user with a single sensing object. We formulate a multi-objective optimization problem to maximize the weighted sum of MI and FI, subject to a total transmit power budget for both cases. As a particular case, we address the equivalent isotropic radiated power (EIRP) for the single communication user scenario. We use the uplink-downlink duality for the multi-user case to simplify the problem and apply Lagrangian optimization and line search methods with a block-coordinate ascending technique. We use projected gradient descent (PGD) to solve the optimization problem in the single-user case. Our numerical results demonstrate that joint beamforming is optimal for the multi-user JCAS system, as opposed to independent beamforming for each user and the sensing object. Furthermore, we reveal the Pareto boundary for the multi-user case, with variations in the number of communication users and the number of transmitting and receiving antennas. We provide the Pareto boundary depending on EIRP limitations for the single-user case.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8054\u5408\u901a\u4fe1\u4e0e\u611f\u77e5\uff08JCAS\uff09\u7cfb\u7edf\u7684\u5e15\u7d2f\u6258\u8fb9\u754c\u6027\u80fd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u591a\u7528\u6237MIMO\u573a\u666f\u7684\u96c6\u6210\u6ce2\u675f\u6210\u5f62\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u52a0\u6743\u4e92\u4fe1\u606f\u4e0e\u8d39\u820d\u5c14\u4fe1\u606f\u4e4b\u548c\uff0c\u9a8c\u8bc1\u4e86\u8054\u5408\u6ce2\u675f\u6210\u5f62\u4f18\u4e8e\u72ec\u7acb\u6ce2\u675f\u6210\u5f62\u3002", "motivation": "\u540c\u65f6\u6ee1\u8db3\u901a\u4fe1\u4e0e\u611f\u77e5\u529f\u80fd\u7684JCAS\u7cfb\u7edf\u9700\u8981\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u5b9e\u73b0\u6027\u80fd\u5e73\u8861\uff0c\u63a2\u7d22\u5176\u5e15\u7d2f\u6258\u8fb9\u754c\u6709\u52a9\u4e8e\u6307\u5bfc\u5b9e\u9645\u7cfb\u7edf\u8bbe\u8ba1\u3002", "method": "\u6784\u5efa\u4ee5\u4e92\u4fe1\u606f\u548c\u8d39\u820d\u5c14\u4fe1\u606f\u4e3a\u6307\u6807\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u9488\u5bf9\u591a\u7528\u6237\u548c\u5355\u7528\u6237\u573a\u666f\u5206\u522b\u91c7\u7528\u4e0a\u884c-\u4e0b\u884c\u5bf9\u5076\u6027\u7ed3\u5408\u62c9\u683c\u6717\u65e5\u4f18\u5316\u3001\u7ebf\u641c\u7d22\u4e0e\u5757\u5750\u6807\u4e0a\u5347\u6cd5\uff0c\u4ee5\u53ca\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\u6cd5\u6c42\u89e3\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u591a\u7528\u6237\u573a\u666f\u4e2d\u8054\u5408\u6ce2\u675f\u6210\u5f62\u6700\u4f18\uff1b\u540c\u65f6\u63ed\u793a\u4e86\u4e0d\u540c\u5929\u7ebf\u6570\u3001\u7528\u6237\u6570\u53caEIRP\u9650\u5236\u4e0b\u7684\u5e15\u7d2f\u6258\u8fb9\u754c\u7279\u6027\u3002", "conclusion": "\u8054\u5408\u6ce2\u675f\u6210\u5f62\u80fd\u6709\u6548\u63d0\u5347JCAS\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\uff0c\u5e15\u7d2f\u6258\u8fb9\u754c\u5206\u6790\u4e3a\u7cfb\u7edf\u53c2\u6570\u914d\u7f6e\u4e0e\u6027\u80fd\u6743\u8861\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2601.08277", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.08277", "abs": "https://arxiv.org/abs/2601.08277", "authors": ["Yizhuo Rao", "Xingjian Cui", "Jiabin Xie", "Shangzhi Pang", "Guangnan Feng", "Jinhui Wei", "Zhiguang Chen", "Yutong Lu"], "title": "Matrix-PIC: Harnessing Matrix Outer-product for High-Performance Particle-in-Cell Simulations", "comment": "Accepted for publication at EuroSys 2026", "summary": "Particle-in-Cell (PIC) simulations spend most of their execution time on particle--grid interactions, where fine-grained atomic updates become a major bottleneck on traditional many-core CPUs. Recent CPU architectures integrate specialized Matrix Processing Units (MPUs) that efficiently support matrix outer-product operations, offering new opportunities to overcome this limitation. Leveraging this architectural shift, this work focuses on redesigning the current deposition step of PIC simulations under a matrix-centric execution model.\n  We present MatrixPIC, the first holistic co-design of the deposition kernel, data layout, and incremental particle sorting tailored to the hybrid MPU--VPU SIMD model on modern CPUs. MatrixPIC introduces: (i)~a block-matrix formulation of the current deposition algorithm that maps naturally to MPU outer-product primitives; (ii)~a hybrid execution pipeline that combines MPU-based high-density accumulation with VPU-based data preparation and control flow; and (iii)~an $O(1)$-amortized incremental sorter based on a gapped packed-memory array to preserve data locality for efficient MPU execution.\n  Evaluated on a next-generation HPC platform, MatrixPIC achieves significant performance gains. In Laser-Wakefield Acceleration (LWFA) simulations, it delivers up to $2.63\\times$ speedup in total runtime. For third-order deposition, the core kernel is accelerated by $8.7\\times$ over the baseline and $2.0\\times$ over the best hand-optimized VPU implementation. Moreover, MatrixPIC reaches $83.08\\%$ of theoretical CPU peak performance, nearly $2.8\\times$ higher than a highly optimized CUDA kernel on a data center GPU. These results demonstrate the effectiveness of matrix-oriented co-design for accelerating PIC simulations on emerging CPU architectures.", "AI": {"tldr": "MatrixPIC\u901a\u8fc7\u77e9\u9635\u4e2d\u5fc3\u5316\u8bbe\u8ba1\uff0c\u5728\u73b0\u4ee3CPU\u4e0a\u663e\u8457\u52a0\u901f\u7c92\u5b50\u7f51\u683c\u4ea4\u4e92\uff0c\u5c24\u5176\u5728LWFA\u6a21\u62df\u4e2d\u5b9e\u73b0\u6700\u9ad82.63\u500d\u603b\u52a0\u901f\u3002", "motivation": "\u4f20\u7edf\u591a\u6838CPU\u4e0a\u7ec6\u7c92\u5ea6\u539f\u5b50\u66f4\u65b0\u6210\u4e3aPIC\u6a21\u62df\u7684\u74f6\u9888\uff0c\u800c\u65b0\u578bCPU\u96c6\u6210\u7684\u77e9\u9635\u5904\u7406\u5355\u5143\uff08MPU\uff09\u63d0\u4f9b\u4e86\u7a81\u7834\u673a\u4f1a\u3002", "method": "\u63d0\u51faMatrixPIC\uff0c\u7ed3\u5408\u5757\u77e9\u9635\u7b97\u6cd5\u3001MPU-VPU\u6df7\u5408\u6267\u884c\u6d41\u6c34\u7ebf\u548c\u589e\u91cf\u6392\u5e8f\u5668\uff0c\u9002\u914d\u73b0\u4ee3CPU\u67b6\u6784\u3002", "result": "\u5728LWFA\u6a21\u62df\u4e2d\u603b\u8fd0\u884c\u65f6\u95f4\u52a0\u901f\u8fbe2.63\u500d\uff0c\u6838\u5fc3\u6838\u51fd\u6570\u6bd4\u57fa\u7ebf\u5feb8.7\u500d\uff0c\u6bd4\u6700\u4f18VPU\u5b9e\u73b0\u5feb2\u500d\uff0c\u8fbe\u5230CPU\u5cf0\u503c\u6027\u80fd83.08%\u3002", "conclusion": "\u77e9\u9635\u5bfc\u5411\u534f\u540c\u8bbe\u8ba1\u80fd\u6709\u6548\u5229\u7528\u65b0\u5174CPU\u67b6\u6784\u52a0\u901fPIC\u6a21\u62df\uff0c\u6027\u80fd\u751a\u81f3\u8d85\u8d8a\u6570\u636e\u4e2d\u5fc3GPU\u3002"}}
{"id": "2601.08374", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.08374", "abs": "https://arxiv.org/abs/2601.08374", "authors": ["Dali Chang", "Chong Zhang", "Kaiqi Zhang", "Mingguan Yang", "Huiyuan Li", "Weiqiang Kong"], "title": "Shifting the Sweet Spot: High-Performance Matrix-Free Method for High-Order Elasticity", "comment": null, "summary": "In high-order finite element analysis for elasticity, matrix-free (PA) methods are a key technology for overcoming the memory bottleneck of traditional Full Assembly (FA). However, existing implementations fail to fully exploit the special structure of modern CPU architectures and tensor-product elements, causing their performance \"sweet spot\" to anomalously remain at the low order of $p \\approx 2$, which severely limits the potential of high-order methods. To address this challenge, we design and implement a highly optimized PA operator within the MFEM framework, deeply integrated with a Geometric Multigrid (GMG) preconditioner. Our multi-level optimization strategy includes replacing the original $O(p^6)$ generic algorithm with an efficient $O(p^4)$ one based on tensor factorization, exploiting Voigt symmetry to reduce redundant computations for the elasticity problem, and employing macro-kernel fusion to enhance data locality and break the memory bandwidth bottleneck. Extensive experiments on mainstream x86 and ARM architectures demonstrate that our method successfully shifts the performance \"sweet spot\" to the higher-order region of $p \\ge 6$. Compared to the MFEM baseline, the optimized core operator (kernel) achieves speedups of 7x to 83x, which translates to a 3.6x to 16.8x end-to-end performance improvement in the complete solution process. This paper provides a validated and efficient practical path for conducting large-scale, high-order elasticity simulations on mainstream CPU hardware.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4f18\u5316\u77e9\u9635\u81ea\u7531\u65b9\u6cd5\uff0c\u5728MFEM\u6846\u67b6\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u5f39\u6027\u529b\u5b66\u9ad8\u9636\u6709\u9650\u5143\u8ba1\u7b97\uff0c\u663e\u8457\u63d0\u5347CPU\u786c\u4ef6\u4e0a\u7684\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u77e9\u9635\u81ea\u7531\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u73b0\u4ee3CPU\u67b6\u6784\u548c\u5f20\u91cf\u79ef\u5355\u5143\u7ed3\u6784\uff0c\u5bfc\u81f4\u6027\u80fd\u6700\u4f18\u9636\u6570\u504f\u4f4e\uff0c\u9650\u5236\u4e86\u9ad8\u9636\u65b9\u6cd5\u7684\u6f5c\u529b\u3002", "method": "\u8bbe\u8ba1\u591a\u7ea7\u4f18\u5316\u7b56\u7565\uff1a\u91c7\u7528O(p^4)\u5f20\u91cf\u5206\u89e3\u7b97\u6cd5\u3001\u5229\u7528Voigt\u5bf9\u79f0\u6027\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u3001\u5b8f\u5185\u6838\u878d\u5408\u63d0\u5347\u6570\u636e\u5c40\u90e8\u6027\u3002", "result": "\u5728x86\u548cARM\u67b6\u6784\u4e0a\uff0c\u6838\u5fc3\u7b97\u5b50\u52a0\u901f7x\u81f383x\uff0c\u7aef\u5230\u7aef\u6d41\u7a0b\u63d0\u901f3.6x\u81f316.8x\uff0c\u6027\u80fd\u6700\u4f18\u9636\u6570\u63d0\u5347\u81f3p\u22656\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5728\u4e3b\u6d41CPU\u4e0a\u5f00\u5c55\u5927\u89c4\u6a21\u9ad8\u9636\u5f39\u6027\u529b\u5b66\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2601.08036", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08036", "abs": "https://arxiv.org/abs/2601.08036", "authors": ["Bonan Kou", "Zijie Zhou", "Muhao Chen", "Tianyi Zhang"], "title": "Automating API Documentation from Crowdsourced Knowledge", "comment": "13 pages, 2 figures, Accepted to ICSE 2026", "summary": "API documentation is crucial for developers to learn and use APIs. However, it is known that many official API documents are obsolete and incomplete. To address this challenge, we propose a new approach called AutoDoc that generates API documents with API knowledge extracted from online discussions on Stack Overflow (SO). AutoDoc leverages a fine-tuned dense retrieval model to identify seven types of API knowledge from SO posts. Then, it uses GPT-4o to summarize the API knowledge in these posts into concise text. Meanwhile, we designed two specific components to handle LLM hallucination and redundancy in generated content. We evaluated AutoDoc against five comparison baselines on 48 APIs of different popularity levels. Our results indicate that the API documents generated by AutoDoc are up to 77.7% more accurate, 9.5% less duplicated, and contain 34.4% knowledge uncovered by the official documents. We also measured the sensitivity of AutoDoc to the choice of different LLMs. We found that while larger LLMs produce higher-quality API documents, AutoDoc enables smaller open-source models (e.g., Mistral-7B-v0.3) to achieve comparable results. Finally, we conducted a user study to evaluate the usefulness of the API documents generated by AutoDoc. All participants found API documents generated by AutoDoc to be more comprehensive, concise, and helpful than the comparison baselines. This highlights the feasibility of utilizing LLMs for API documentation with careful design to counter LLM hallucination and information redundancy.", "AI": {"tldr": "AutoDoc\u5229\u7528Stack Overflow\u8ba8\u8bba\u548cGPT-4o\u81ea\u52a8\u751f\u6210\u66f4\u51c6\u786e\u3001\u5168\u9762\u4e14\u7b80\u6d01\u7684API\u6587\u6863\uff0c\u6709\u6548\u7f13\u89e3LLM\u5e7b\u89c9\u4e0e\u5197\u4f59\u95ee\u9898\u3002", "motivation": "\u5b98\u65b9API\u6587\u6863\u5e38\u8fc7\u65f6\u6216\u4e0d\u5b8c\u6574\uff0c\u5f00\u53d1\u8005\u96be\u4ee5\u9ad8\u6548\u5b66\u4e60\u548c\u4f7f\u7528API\u3002", "method": "\u7ed3\u5408\u5fae\u8c03\u7a20\u5bc6\u68c0\u7d22\u6a21\u578b\u4eceSO\u63d0\u53d6\u4e03\u7c7bAPI\u77e5\u8bc6\uff0c\u5e76\u7528GPT-4o\u603b\u7ed3\uff1b\u8bbe\u8ba1\u4e24\u4e2a\u7ec4\u4ef6\u6291\u5236LLM\u5e7b\u89c9\u4e0e\u5197\u4f59\u3002", "result": "\u76f8\u6bd4\u57fa\u7ebf\uff0cAutoDoc\u751f\u6210\u6587\u6863\u51c6\u786e\u7387\u63d0\u534777.7%\uff0c\u91cd\u590d\u51cf\u5c119.5%\uff0c\u8865\u514534.4%\u5b98\u65b9\u672a\u8986\u76d6\u77e5\u8bc6\uff1b\u5c0f\u6a21\u578b\u7ecf\u4f18\u5316\u540e\u8868\u73b0\u63a5\u8fd1\u5927\u6a21\u578b\u3002", "conclusion": "\u5408\u7406\u8bbe\u8ba1\u53ef\u4f7fLLM\u6709\u6548\u7528\u4e8eAPI\u6587\u6863\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u6587\u6863\u8d28\u91cf\u4e0e\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.08217", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.08217", "abs": "https://arxiv.org/abs/2601.08217", "authors": ["Ali Mamaghani", "Ushasi Ghosh", "Ish Kumar Jain", "Srinivas Shakkottai", "Dinesh Bharadia"], "title": "Tiny-Twin: A CPU-Native Full-stack Digital Twin for NextG Cellular Networks", "comment": null, "summary": "Modern wireless applications demand testing environments that capture the full complexity of next-generation (NextG) cellular networks. While digital twins promise realistic emulation, existing solutions often compromise on physical-layer fidelity and scalability or depend on specialized hardware. We present Tiny-Twin, a CPU-Native, full-stack digital twin framework that enables realistic, repeatable 5G experimentation on commodity CPUs. Tiny-Twin integrates time-varying multi-tap convolution with a complete 5G protocol stack, supporting plug-and-play replay of diverse channel traces. Through a redesigned software architecture and system-level optimizations, Tiny-Twin supports fine-grained convolution entirely in software. With built-in real-time RIC integration and per User Equipment(UE) channel isolation, it facilitates rigorous testing of network algorithms and protocol designs. Our evaluation shows that Tiny-Twin scales to multiple concurrent UEs while preserving protocol timing and end-to-end behavior, delivering a practical middle ground between low-fidelity simulators and high-cost hardware emulators. We release Tiny-Twin as an open-source platform to enable accessible, high-fidelity experimentation for NextG cellular research.", "AI": {"tldr": "Tiny-Twin \u662f\u4e00\u4e2a\u57fa\u4e8e\u901a\u7528 CPU \u7684\u5168\u6808\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u652f\u6301\u9ad8\u4fdd\u771f\u3001\u53ef\u6269\u5c55\u7684 5G \u5b9e\u9a8c\u3002", "motivation": "\u73b0\u6709\u6570\u5b57\u5b6a\u751f\u65b9\u6848\u5728\u7269\u7406\u5c42\u4fdd\u771f\u5ea6\u3001\u53ef\u6269\u5c55\u6027\u6216\u786c\u4ef6\u4f9d\u8d56\u6027\u4e0a\u5b58\u5728\u59a5\u534f\uff0c\u4e9f\u9700\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6574\u5408\u65f6\u53d8\u591a\u62bd\u5934\u5377\u79ef\u4e0e\u5b8c\u6574 5G \u534f\u8bae\u6808\uff0c\u901a\u8fc7\u8f6f\u4ef6\u67b6\u6784\u91cd\u6784\u548c\u7cfb\u7edf\u7ea7\u4f18\u5316\u5b9e\u73b0\u5728\u7eaf\u8f6f\u4ef6\u4e2d\u6267\u884c\u7ec6\u7c92\u5ea6\u5377\u79ef\u3002", "result": "Tiny-Twin \u53ef\u652f\u6301\u591a\u4e2a\u5e76\u53d1\u7528\u6237\u8bbe\u5907\uff0c\u4fdd\u6301\u534f\u8bae\u65f6\u5e8f\u4e0e\u7aef\u5230\u7aef\u884c\u4e3a\uff0c\u5e73\u8861\u4e86\u4f4e\u4fdd\u771f\u6a21\u62df\u5668\u4e0e\u9ad8\u6210\u672c\u786c\u4ef6\u4eff\u771f\u5668\u4e4b\u95f4\u7684\u9700\u6c42\u3002", "conclusion": "Tiny-Twin \u4f5c\u4e3a\u5f00\u6e90\u5e73\u53f0\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u8702\u7a9d\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u4fdd\u771f\u3001\u6613\u8bbf\u95ee\u7684\u5b9e\u9a8c\u73af\u5883\u3002"}}
{"id": "2601.08045", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.08045", "abs": "https://arxiv.org/abs/2601.08045", "authors": ["Xinyi Zhou", "Zeinadsadat Saghi", "Sadra Sabouri", "Rahul Pandita", "Mollie McGuire", "Souti Chattopadhyay"], "title": "Cognitive Biases in LLM-Assisted Software Development", "comment": "13 pages, 6 figures, 7 tables", "summary": "The widespread adoption of Large Language Models (LLMs) in software development is transforming programming from a solution-generative to a solution-evaluative activity. This shift opens a pathway for new cognitive challenges that amplify existing decision-making biases or create entirely novel ones. One such type of challenge stems from cognitive biases, which are thinking patterns that lead people away from logical reasoning and result in sub-optimal decisions. How do cognitive biases manifest and impact decision-making in emerging AI-collaborative development? This paper presents the first comprehensive study of cognitive biases in LLM-assisted development. We employ a mixed-methods approach, combining observational studies with 14 student and professional developers, followed by surveys with 22 additional developers. We qualitatively compare categories of biases affecting developers against the traditional non-LLM workflows. Our findings suggest that LLM-related actions are more likely to be associated with novel biases. Through a systematic analysis of 90 cognitive biases specific to developer-LLM interactions, we develop a taxonomy of 15 bias categories validated by cognitive psychologists. We found that 48.8% of total programmer actions are biased, and developer-LLM interactions account for 56.4% of these biased actions. We discuss how these bias categories manifest, present tools and practices for developers, and recommendations for LLM tool builders to help mitigate cognitive biases in human-AI programming.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f85\u52a9\u5f00\u53d1\u4e2d\u7684\u8ba4\u77e5\u504f\u5dee\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u53d1\u73b056.4%\u7684\u504f\u5dee\u884c\u4e3a\u6e90\u4e8e\u4eba\u673a\u4ea4\u4e92\uff0c\u5e76\u63d0\u51fa15\u7c7b\u504f\u5dee\u5206\u7c7b\u53ca\u7f13\u89e3\u5efa\u8bae\u3002", "motivation": "LLM\u666e\u53ca\u4f7f\u7f16\u7a0b\u4ece\u751f\u6210\u89e3\u51b3\u65b9\u6848\u8f6c\u5411\u8bc4\u4f30\u65b9\u6848\uff0c\u5f15\u53d1\u65b0\u578b\u8ba4\u77e5\u504f\u5dee\uff0c\u4e9f\u9700\u7cfb\u7edf\u7814\u7a76\u5176\u5f71\u54cd\u4e0e\u5e94\u5bf9\u7b56\u7565\u3002", "method": "\u7ed3\u540814\u540d\u5f00\u53d1\u8005\u89c2\u5bdf\u7814\u7a76\u4e0e22\u540d\u5f00\u53d1\u8005\u95ee\u5377\u8c03\u67e5\uff0c\u5b9a\u6027\u5bf9\u6bd4\u4f20\u7edf\u4e0eLLM\u5de5\u4f5c\u6d41\u4e2d\u7684\u504f\u5dee\u7c7b\u522b\uff0c\u7ecf\u8ba4\u77e5\u5fc3\u7406\u5b66\u5bb6\u9a8c\u8bc1\u6784\u5efa\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u53d1\u73b048.8%\u7a0b\u5e8f\u5458\u884c\u4e3a\u5b58\u5728\u504f\u5dee\uff0c\u5176\u4e2d56.4%\u7531LLM\u4ea4\u4e92\u5f15\u53d1\uff1b\u5efa\u7acb\u542b15\u7c7b\u504f\u5dee\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u63d0\u4f9b\u5f00\u53d1\u8005\u5de5\u5177\u4e0eLLM\u8bbe\u8ba1\u8005\u6539\u8fdb\u5efa\u8bae\u3002", "conclusion": "LLM\u534f\u4f5c\u663e\u8457\u589e\u52a0\u65b0\u578b\u8ba4\u77e5\u504f\u5dee\u98ce\u9669\uff0c\u9700\u901a\u8fc7\u5de5\u5177\u4f18\u5316\u4e0e\u6d41\u7a0b\u6539\u8fdb\u51cf\u8f7b\u5176\u5bf9\u51b3\u7b56\u8d28\u91cf\u7684\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2601.08259", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.08259", "abs": "https://arxiv.org/abs/2601.08259", "authors": ["Yinqiu Liu", "Ruichen Zhang", "Dusit Niyato", "Abbas Jamalipour", "Trung Q. Duong", "Dong In Kim"], "title": "Unleashing Tool Engineering and Intelligence for Agentic AI in Next-Generation Communication Networks", "comment": null, "summary": "Nowadays, agentic AI is emerging as a transformative paradigm for next-generation communication networks, promising to evolve large language models (LLMs) from passive chatbots into autonomous operators. However, unleashing this potential requires bridging the critical gap between abstract reasoning and physical actuation, a capability we term tool intelligence. In this article, we explore the landscape of tool engineering to empower agentic AI in communications. We first analyze the functionalities of tool intelligence and its effects on communications. We then propose a systematic review for tool engineering, covering the entire lifecycle from tool creation and discovery to selection, learning, and benchmarking. Furthermore, we present a case study on tool-assisted uncrewed aerial vehicles (UAV) trajectory planning to demonstrate the realization of tool intelligence in communications. By introducing a teacher-guided reinforcement learning approach with a feasibility shield, we enable agents to intelligently operate tools. They utilize external tools to eliminate navigational uncertainty while mastering cost-aware scheduling under strict energy constraints. This article aims to provide a roadmap for building the tool-augmented intelligent agents of the 6G era.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5de5\u5177\u667a\u80fd\u5728\u901a\u4fe1\u9886\u57df\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u5957\u5b8c\u6574\u7684\u5de5\u5177\u5de5\u7a0b\u751f\u547d\u5468\u671f\uff0c\u5e76\u901a\u8fc7\u65e0\u4eba\u673a\u8f68\u8ff9\u89c4\u5212\u6848\u4f8b\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u4e3a6G\u65f6\u4ee3\u6784\u5efa\u5de5\u5177\u589e\u5f3a\u578b\u667a\u80fd\u4f53\u63d0\u4f9b\u8def\u7ebf\u56fe\u3002", "motivation": "\u5f25\u5408\u62bd\u8c61\u63a8\u7406\u4e0e\u7269\u7406\u6267\u884c\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u63a8\u52a8\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u88ab\u52a8\u804a\u5929\u673a\u5668\u4eba\u5411\u81ea\u4e3b\u64cd\u4f5c\u8005\u6f14\u8fdb\u3002", "method": "\u7cfb\u7edf\u6027\u56de\u987e\u5de5\u5177\u5de5\u7a0b\u751f\u547d\u5468\u671f\uff08\u521b\u5efa\u3001\u53d1\u73b0\u3001\u9009\u62e9\u3001\u5b66\u4e60\u3001\u8bc4\u4f30\uff09\uff0c\u5e76\u7ed3\u5408\u6559\u5e08\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u884c\u6027\u5c4f\u853d\u673a\u5236\u8fdb\u884c\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u667a\u80fd\u4f53\u80fd\u5229\u7528\u5916\u90e8\u5de5\u5177\u6d88\u9664\u5bfc\u822a\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5728\u4e25\u683c\u80fd\u8017\u7ea6\u675f\u4e0b\u5b9e\u73b0\u6210\u672c\u611f\u77e5\u8c03\u5ea6\u3002", "conclusion": "\u5de5\u5177\u667a\u80fd\u662f\u5b9e\u73b06G\u65f6\u4ee3\u81ea\u4e3b\u901a\u4fe1\u667a\u80fd\u4f53\u7684\u5173\u952e\uff0c\u9700\u6301\u7eed\u63a8\u8fdb\u5de5\u5177\u5de5\u7a0b\u4f53\u7cfb\u5316\u7814\u7a76\u3002"}}
{"id": "2601.08800", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.08800", "abs": "https://arxiv.org/abs/2601.08800", "authors": ["Bowen Zhou", "Jinrui Jia", "Wenhao He", "Yong Zhang", "Fang Dong"], "title": "MixServe: An Automatic Distributed Serving System for MoE Models with Hybrid Parallelism Based on Fused Communication Algorithm", "comment": "Submitted to ICDCS 2026", "summary": "The Mixture of Experts (MoE) models are emerging as the latest paradigm for Large Language Models (LLMs). However, due to memory constraints, MoE models with billions or even trillions of parameters can only be deployed in multi-GPU or even multi-node & multi-GPU based serving systems. Thus, communication has became a major bottleneck in distributed serving systems, especially inter-node communication. Contemporary distributed MoE models are primarily implemented using all-reduce (AR) based tensor parallelism (TP) and all-to-all (A2A) based expert parallelism (EP). However, TP generally exhibits low inter-node efficiency and is thus confined to high-speed intra-node bandwidth. In contrast, EP tends to suffer from load imbalance, especially when the parallel degree is high.\n  In this work, we introduce MixServe, a novel automatic distributed serving system for efficient deployment of MoE models by a novel TP-EP hybrid parallelism based on fused AR-A2A communication algorithm. MixServe begins by evaluating the communication overhead associated with various parallel strategies, taking into account the model hyperparameters and the configurations of network and hardware resources, and then automatically selects the most efficient parallel strategy. Then, we propose the TP-EP hybrid parallelism based on fused AR-A2A communication algorithm that overlaps intra-node AR communication and inter-node A2A communication. Extensive experiments on DeepSeek-R1 and Qwen3 models demonstrate that MixServe achieves superior inference performance, with 1.08~3.80x acceleration in time to first token (TTFT), 1.03~1.66x acceleration in inter-token latency (ITL), and 5.2%~50.3% throughput improvement compared to existing approaches.", "AI": {"tldr": "MixServe\u662f\u4e00\u79cd\u65b0\u578b\u81ea\u52a8\u5206\u5e03\u5f0f\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u878d\u5408AR-A2A\u901a\u4fe1\u7b97\u6cd5\u7684TP-EP\u6df7\u5408\u5e76\u884c\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347MoE\u6a21\u578b\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5206\u5e03\u5f0fMoE\u6a21\u578b\u56e0\u901a\u4fe1\u74f6\u9888\u548c\u8d1f\u8f7d\u4e0d\u5747\u5bfc\u81f4\u7684\u4f4e\u6548\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u591a\u8282\u70b9\u90e8\u7f72\u573a\u666f\u4e0b\u3002", "method": "\u63d0\u51faTP-EP\u6df7\u5408\u5e76\u884c\u7b56\u7565\uff0c\u7ed3\u5408\u878d\u5408AR-A2A\u901a\u4fe1\u7b97\u6cd5\uff0c\u5e76\u6839\u636e\u6a21\u578b\u53c2\u6570\u4e0e\u786c\u4ef6\u914d\u7f6e\u81ea\u52a8\u9009\u62e9\u6700\u4f18\u5e76\u884c\u65b9\u6848\u3002", "result": "\u5728DeepSeek-R1\u548cQwen3\u6a21\u578b\u4e0a\uff0cTTFT\u52a0\u901f1.08~3.80\u500d\uff0cITL\u52a0\u901f1.03~1.66\u500d\uff0c\u541e\u5410\u91cf\u63d0\u53475.2%~50.3%\u3002", "conclusion": "MixServe\u6709\u6548\u4f18\u5316\u4e86MoE\u6a21\u578b\u7684\u5206\u5e03\u5f0f\u63a8\u7406\u6027\u80fd\uff0c\u662f\u5f53\u524d\u9ad8\u6548\u90e8\u7f72\u5927\u89c4\u6a21MoE\u6a21\u578b\u7684\u6709\u529b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.08609", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08609", "abs": "https://arxiv.org/abs/2601.08609", "authors": ["Qurban Ali", "Andrea Stocco", "Leonardo Mariani", "Oliviero Riganelli"], "title": "Coverage-Guided Road Selection and Prioritization for Efficient Testing in Autonomous Driving Systems", "comment": "The IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER) 2026", "summary": "Autonomous Driving Assistance Systems (ADAS) rely on extensive testing to ensure safety and reliability, yet road scenario datasets often contain redundant cases that slow down the testing process without improving fault detection. To address this issue, we present a novel test prioritization framework that reduces redundancy while preserving geometric and behavioral diversity. Road scenarios are clustered based on geometric and dynamic features of the ADAS driving behavior, from which representative cases are selected to guarantee coverage. Roads are finally prioritized based on geometric complexity, driving difficulty, and historical failures, ensuring that the most critical and challenging tests are executed first. We evaluate our framework on the OPENCAT dataset and the Udacity self-driving car simulator using two ADAS models. On average, our approach achieves an 89% reduction in test suite size while retaining an average of 79% of failed road scenarios. The prioritization strategy improves early failure detection by up to 95x compared to random baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u51cf\u5c11\u5197\u4f59\u5e76\u4fdd\u6301\u591a\u6837\u6027\u7684\u81ea\u52a8\u9a7e\u9a76\u6d4b\u8bd5\u4f18\u5148\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u6545\u969c\u68c0\u6d4b\u6548\u7387\u3002", "motivation": "\u89e3\u51b3ADAS\u6d4b\u8bd5\u6570\u636e\u96c6\u4e2d\u5197\u4f59\u6848\u4f8b\u62d6\u6162\u6d4b\u8bd5\u901f\u5ea6\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u51e0\u4f55\u4e0e\u52a8\u6001\u7279\u5f81\u805a\u7c7b\u573a\u666f\uff0c\u6309\u590d\u6742\u5ea6\u3001\u96be\u5ea6\u548c\u5386\u53f2\u5931\u8d25\u7387\u4f18\u5148\u6392\u5e8f\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u5728OPENCAT\u548cUdacity\u6570\u636e\u96c6\u4e0a\u5e73\u5747\u51cf\u5c1189%\u6d4b\u8bd5\u89c4\u6a21\uff0c\u4fdd\u755979%\u5931\u8d25\u573a\u666f\uff0c\u65e9\u671f\u6545\u969c\u68c0\u6d4b\u6548\u7387\u63d0\u5347\u8fbe95\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u5e73\u8861\u6d4b\u8bd5\u6548\u7387\u4e0e\u8986\u76d6\u7387\uff0c\u663e\u8457\u4f18\u5316ADAS\u7cfb\u7edf\u9a8c\u8bc1\u6d41\u7a0b\u3002"}}
{"id": "2601.08691", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08691", "abs": "https://arxiv.org/abs/2601.08691", "authors": ["Shaznin Sultana", "Sadia Afreen", "Nasir U. Eisty"], "title": "LLMs in Code Vulnerability Analysis: A Proof of Concept", "comment": "Accepted for publication at the Fourth International Workshop on Software Vulnerability Management (SVM 2026) co-located with Intenational Conference in Software Engineering (ICSE 2026)", "summary": "Context: Traditional software security analysis methods struggle to keep pace with the scale and complexity of modern codebases, requiring intelligent automation to detect, assess, and remediate vulnerabilities more efficiently and accurately. Objective: This paper explores the incorporation of code-specific and general-purpose Large Language Models (LLMs) to automate critical software security tasks, such as identifying vulnerabilities, predicting severity and access complexity, and generating fixes as a proof of concept. Method: We evaluate five pairs of recent LLMs, including both code-based and general-purpose open-source models, on two recognized C/C++ vulnerability datasets, namely Big-Vul and Vul-Repair. Additionally, we compare fine-tuning and prompt-based approaches. Results: The results show that fine-tuning uniformly outperforms both zero-shot and few-shot approaches across all tasks and models. Notably, code-specialized models excel in zero-shot and few-shot settings on complex tasks, while general-purpose models remain nearly as effective. Discrepancies among CodeBLEU, CodeBERTScore, BLEU, and ChrF highlight the inadequacy of current metrics for measuring repair quality. Conclusions: This study contributes to the software security community by investigating the potential of advanced LLMs to improve vulnerability analysis and remediation.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4ee3\u7801\u4e13\u7528\u548c\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u8f6f\u4ef6\u5b89\u5168\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u5982\u6f0f\u6d1e\u8bc6\u522b\u3001\u4e25\u91cd\u6027\u9884\u6d4b\u548c\u4fee\u590d\u751f\u6210\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u5b89\u5168\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u73b0\u4ee3\u4ee3\u7801\u5e93\u7684\u89c4\u6a21\u4e0e\u590d\u6742\u6027\uff0c\u9700\u501f\u52a9\u667a\u80fd\u81ea\u52a8\u5316\u63d0\u5347\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "method": "\u8bc4\u4f30\u4e94\u5bf9\u8fd1\u671fLLM\uff08\u542b\u4ee3\u7801\u4e0e\u901a\u7528\u5f00\u6e90\u6a21\u578b\uff09\u5728Big-Vul\u4e0eVul-Repair\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u6bd4\u8f83\u5fae\u8c03\u4e0e\u63d0\u793a\u65b9\u6cd5\u3002", "result": "\u5fae\u8c03\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u96f6\u6837\u672c\u4e0e\u5c11\u6837\u672c\uff1b\u4ee3\u7801\u4e13\u7528\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f73\uff0c\u4f46\u901a\u7528\u6a21\u578b\u4ea6\u63a5\u8fd1\uff1b\u73b0\u6709\u4fee\u590d\u8d28\u91cf\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u8f6f\u4ef6\u5b89\u5168\u9886\u57df\u63d0\u4f9b\u4e86\u5229\u7528\u5148\u8fdbLLM\u6539\u8fdb\u6f0f\u6d1e\u5206\u6790\u4e0e\u4fee\u590d\u7684\u5b9e\u8bc1\u4f9d\u636e\u3002"}}
{"id": "2601.08513", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.08513", "abs": "https://arxiv.org/abs/2601.08513", "authors": ["Ana Julia Evangelista Andrade", "Flavio Cezar Amate"], "title": "A decentralized academic certificate issuance system using smart contracts on the tron network", "comment": "9 pages, 2 figures, 2 tables", "summary": "This paper presents the design, implementation, and evaluation of a decentralized system for issuing and verifying academic certificates based on blockchain technology. The proposed solution addresses common limitations of traditional certification models, such as susceptibility to forgery, reliance on centralized infrastructures, and inefficient verification processes. The system is built on the TRON blockchain and integrates smart contracts written in Solidity, a decentralized web application (dApp) for user interaction, and the InterPlanetary File System (IPFS) for decentralized storage of certificate metadata. The methodology comprised architectural design, smart contract development, and the implementation of a web-based interface, followed by functional, security, performance, and usability evaluations. Experimental results show that the system correctly supports certificate issuance and public verification, enforces access control, and resists common misuse scenarios. Performance analysis indicates low confirmation latency and negligible transaction costs, making the solution suitable for large-scale academic environments. Additionally, usability assessment using the System Usability Scale (SUS) resulted in a score of 76.67, indicating good user acceptance. Overall, the results demonstrate the technical feasibility and practical viability of the proposed approach, highlighting the TRON blockchain as an effective and cost-efficient infrastructure for decentralized academic certification systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eTRON\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u5b66\u672f\u8bc1\u4e66\u9881\u53d1\u4e0e\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u7ed3\u5408\u667a\u80fd\u5408\u7ea6\u4e0eIPFS\u5b58\u50a8\uff0c\u5b9e\u73b0\u9632\u4f2a\u3001\u9ad8\u6548\u9a8c\u8bc1\u4e0e\u4f4e\u6210\u672c\u8fd0\u884c\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u5b66\u672f\u8bc1\u4e66\u6613\u4f2a\u9020\u3001\u4f9d\u8d56\u4e2d\u5fc3\u5316\u673a\u6784\u3001\u9a8c\u8bc1\u6548\u7387\u4f4e\u7b49\u95ee\u9898\u3002", "method": "\u57fa\u4e8eTRON\u533a\u5757\u94fe\u5f00\u53d1\u667a\u80fd\u5408\u7ea6\uff0c\u642d\u914dIPFS\u5b58\u50a8\u5143\u6570\u636e\uff0c\u6784\u5efadApp\u524d\u7aef\uff0c\u5e76\u8fdb\u884c\u529f\u80fd\u3001\u5b89\u5168\u3001\u6027\u80fd\u53ca\u53ef\u7528\u6027\u8bc4\u4f30\u3002", "result": "\u7cfb\u7edf\u652f\u6301\u6b63\u786e\u53d1\u8bc1\u4e0e\u516c\u5f00\u9a8c\u8bc1\uff0c\u5177\u5907\u8bbf\u95ee\u63a7\u5236\u548c\u6297\u6ee5\u7528\u80fd\u529b\uff1b\u786e\u8ba4\u5ef6\u8fdf\u4f4e\u3001\u4ea4\u6613\u6210\u672c\u53ef\u5ffd\u7565\uff1bSUS\u8bc4\u5206\u4e3a76.67\uff0c\u7528\u6237\u63a5\u53d7\u5ea6\u826f\u597d\u3002", "conclusion": "\u65b9\u6848\u5728\u6280\u672f\u4e0a\u53ef\u884c\u4e14\u5b9e\u7528\u6027\u5f3a\uff0cTRON\u533a\u5757\u94fe\u662f\u6784\u5efa\u53bb\u4e2d\u5fc3\u5316\u5b66\u672f\u8ba4\u8bc1\u7cfb\u7edf\u7684\u9ad8\u6548\u4f4e\u6210\u672c\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2601.08706", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08706", "abs": "https://arxiv.org/abs/2601.08706", "authors": ["Maria Teresa Rossi", "Leonardo Mariani", "Oliviero Riganelli", "Giuseppe Filomento", "Danilo Giannone", "Paolo Gavazzo"], "title": "\"Where is My Troubleshooting Procedure?\": Studying the Potential of RAG in Assisting Failure Resolution of Large Cyber-Physical System", "comment": "This paper has been accepted at the Software Engineering in Practice track of the 48th International Conference on Software Engineering (ICSE 2026)", "summary": "In today's complex industrial environments, operators must often navigate through extensive technical manuals to identify troubleshooting procedures that may help react to some observed failure symptoms. These manuals, written in natural language, describe many steps in detail. Unfortunately, the number, magnitude, and articulation of these descriptions can significantly slow down and complicate the retrieval of the correct procedure during critical incidents. Interestingly, Retrieval Augmented Generation (RAG) enables the development of tools based on conversational interfaces that can assist operators in their retrieval tasks, improving their capability to respond to incidents. This paper presents the results of a set of experiments that derive from the analysis of the troubleshooting procedures available in Fincantieri, a large international company developing complex naval cyber-physical systems. Results show that RAG can assist operators in reacting promptly to failure symptoms, although specific measures have to be taken into consideration to cross-validate recommendations before actuating them.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86RAG\u6280\u672f\u5728\u590d\u6742\u5de5\u4e1a\u73af\u5883\u4e2d\u8f85\u52a9\u64cd\u4f5c\u5458\u5feb\u901f\u68c0\u7d22\u6545\u969c\u6392\u9664\u7a0b\u5e8f\u7684\u6f5c\u529b\u3002", "motivation": "\u64cd\u4f5c\u5458\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\u9700\u8981\u5feb\u901f\u4ece\u5927\u91cf\u6280\u672f\u624b\u518c\u4e2d\u627e\u5230\u6b63\u786e\u7684\u6545\u969c\u6392\u9664\u6b65\u9aa4\uff0c\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u901a\u8fc7\u5206\u6790Fincantieri\u516c\u53f8\u63d0\u4f9b\u7684\u6545\u969c\u6392\u9664\u7a0b\u5e8f\uff0c\u8fdb\u884c\u4e86\u4e00\u7cfb\u5217\u5b9e\u9a8c\u8bc4\u4f30RAG\u7684\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eRAG\u80fd\u6709\u6548\u5e2e\u52a9\u64cd\u4f5c\u5458\u5feb\u901f\u54cd\u5e94\u6545\u969c\u75c7\u72b6\uff0c\u4f46\u9700\u4ea4\u53c9\u9a8c\u8bc1\u63a8\u8350\u7ed3\u679c\u4ee5\u786e\u4fdd\u51c6\u786e\u6027\u3002", "conclusion": "RAG\u53ef\u63d0\u5347\u64cd\u4f5c\u5458\u5e94\u5bf9\u6545\u969c\u7684\u6548\u7387\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u65f6\u9700\u8f85\u4ee5\u9a8c\u8bc1\u673a\u5236\u4fdd\u969c\u5b89\u5168\u53ef\u9760\u3002"}}
{"id": "2601.08729", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08729", "abs": "https://arxiv.org/abs/2601.08729", "authors": ["Jinhan Kim", "Nargiz Humbatova", "Gunel Jahangirova", "Shin Yoo", "Paolo Tonella"], "title": "Revisiting \"Revisiting Neuron Coverage for DNN Testing: A Layer-Wise and Distribution-Aware Criterion\": A Critical Review and Implications on DNN Coverage Testing", "comment": "ICSE 2026", "summary": "We present a critical review of Neural Coverage (NLC), a state-of-the-art DNN coverage criterion by Yuan et al. at ICSE 2023. While NLC proposes to satisfy eight design requirements and demonstrates strong empirical performance, we question some of their theoretical and empirical assumptions. We observe that NLC deviates from core principles of coverage criteria, such as monotonicity and test suite order independence, and could more fully account for key properties of the covariance matrix. Additionally, we note threats to the validity of the empirical study, related to the ground truth ordering of test suites. Through our empirical validation, we substantiate our claims and propose improvements for future DNN coverage metrics. Finally, we conclude by discussing the implications of these insights.", "AI": {"tldr": "\u672c\u6587\u5bf9NLC\u8fd9\u4e00DNN\u8986\u76d6\u6807\u51c6\u8fdb\u884c\u4e86\u6279\u5224\u6027\u56de\u987e\uff0c\u6307\u51fa\u4e86\u5176\u7406\u8bba\u4e0e\u5b9e\u8bc1\u5047\u8bbe\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u8d28\u7591NLC\u5728\u6ee1\u8db3\u8bbe\u8ba1\u8981\u6c42\u548c\u5b9e\u8bc1\u8868\u73b0\u80cc\u540e\u7684\u7406\u8bba\u4e0e\u7ecf\u9a8c\u5047\u8bbe\u662f\u5426\u5145\u5206\u5408\u7406\u3002", "method": "\u901a\u8fc7\u5206\u6790NLC\u504f\u79bb\u8986\u76d6\u51c6\u5219\u6838\u5fc3\u539f\u5219\u7684\u73b0\u8c61\uff0c\u5e76\u9a8c\u8bc1\u5176\u5b9e\u8bc1\u7814\u7a76\u4e2d\u7684\u6709\u6548\u6027\u5a01\u80c1\uff0c\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u3002", "result": "\u8bc1\u5b9e\u4e86NLC\u5728\u5355\u8c03\u6027\u3001\u6d4b\u8bd5\u5957\u4ef6\u987a\u5e8f\u72ec\u7acb\u6027\u53ca\u534f\u65b9\u5dee\u77e9\u9635\u7279\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u5ea6\u91cf\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u672a\u6765DNN\u8986\u76d6\u6307\u6807\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2601.08734", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08734", "abs": "https://arxiv.org/abs/2601.08734", "authors": ["Prithwish Jana", "Sam Davidson", "Bhavana Bhasker", "Andrey Kan", "Anoop Deoras", "Laurent Callot"], "title": "TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback", "comment": "The paper has been published at the 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE 2026), Rio de Janeiro, Brazil, April 12-18, 2026", "summary": "Automating Infrastructure-as-Code (IaC) is challenging, and large language models (LLMs) often produce incorrect configurations from natural language (NL). We present TerraFormer, a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, and policy compliance. We curate two large, high-quality NL-to-IaC datasets, TF-Gen (152k instances) and TF-Mutn (52k instances), via multi-stage verification and iterative LLM self-correction. Evaluations against 17 state-of-the-art LLMs, including ~50x larger models like Sonnet 3.7, DeepSeek-R1, and GPT-4.1, show that TerraFormer improves correctness over its base LLM by 15.94% on IaC-Eval, 11.65% on TF-Gen (Test), and 19.60% on TF-Mutn (Test). It outperforms larger models on both TF-Gen (Test) and TF-Mutn (Test), ranks third on IaC-Eval, and achieves top best-practices and security compliance.", "AI": {"tldr": "TerraFormer\u662f\u4e00\u4e2a\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\u4e0e\u9a8c\u8bc1\u5668\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\u7684\u795e\u7ecf\u7b26\u53f7\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\uff08IaC\uff09\u751f\u6210\u4e0e\u53d8\u5f02\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210IaC\u65f6\u7ecf\u5e38\u4ea7\u751f\u9519\u8bef\u914d\u7f6e\uff0c\u4e9f\u9700\u66f4\u53ef\u9760\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\u63d0\u4f9b\u8bed\u6cd5\u3001\u53ef\u90e8\u7f72\u6027\u53ca\u7b56\u7565\u5408\u89c4\u6027\u53cd\u9988\uff0c\u5e76\u6784\u5efa\u9ad8\u8d28\u91cf\u6570\u636e\u96c6TF-Gen\u548cTF-Mutn\u652f\u6301\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u6a21\u578b\u53ca\u66f4\u5927\u89c4\u6a21LLM\uff0c\u5c24\u5176\u5728\u5b89\u5168\u5408\u89c4\u6027\u548c\u6700\u4f73\u5b9e\u8df5\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "TerraFormer\u6709\u6548\u63d0\u5347\u4e86IaC\u81ea\u52a8\u5316\u751f\u6210\u7684\u6b63\u786e\u7387\u4e0e\u53ef\u9760\u6027\uff0c\u5177\u5907\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2601.08773", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08773", "abs": "https://arxiv.org/abs/2601.08773", "authors": ["Manideep Reddy Chinthareddy"], "title": "Reliable Graph-RAG for Codebases: AST-Derived Graphs vs LLM-Extracted Knowledge Graphs", "comment": "46 pages, 2 figures", "summary": "Retrieval-Augmented Generation for software engineering often relies on vector similarity search, which captures topical similarity but can fail on multi-hop architectural reasoning such as controller to service to repository chains, interface-driven wiring, and inheritance. This paper benchmarks three retrieval pipelines on Java codebases (Shopizer, with additional runs on ThingsBoard and OpenMRS Core): (A) vector-only No-Graph RAG, (B) an LLM-generated knowledge graph RAG (LLM-KB), and (C) a deterministic AST-derived knowledge graph RAG (DKB) built with Tree-sitter and bidirectional traversal.\n  Using 15 architecture and code-tracing queries per repository, we measure indexing time, query latency, corpus coverage, cost, and answer correctness. DKB builds its graph in seconds, while LLM-KB requires much longer graph generation. LLM-KB also shows indexing incompleteness: on Shopizer, 377 files are skipped or missed, reducing embedded chunk coverage and graph size compared to DKB. End-to-end cost is modest for DKB relative to the vector-only baseline but much higher for LLM-KB, especially as repository scale increases. Query latency is similar for No-Graph and DKB, while LLM-KB is slower and more variable. On the Shopizer question suite, DKB achieves the highest correctness, LLM-KB is close behind, and the vector-only baseline performs worst on upstream architectural queries and has the highest hallucination risk. Overall, deterministic AST-derived graphs provide more reliable coverage and multi-hop grounding than LLM-extracted graphs at substantially lower indexing cost.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e09\u79cd\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u5728Java\u4ee3\u7801\u5e93\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u57fa\u4e8eAST\u7684\u786e\u5b9a\u6027\u77e5\u8bc6\u56fe\u8c31\u65b9\u6cd5\uff08DKB\uff09\u5728\u6210\u672c\u3001\u8986\u76d6\u7387\u548c\u591a\u8df3\u63a8\u7406\u51c6\u786e\u6027\u4e0a\u4f18\u4e8eLLM\u751f\u6210\u56fe\u8c31\u548c\u7eaf\u5411\u91cf\u68c0\u7d22\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5411\u91cf\u68c0\u7d22\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u96be\u4ee5\u5904\u7406\u591a\u8df3\u67b6\u6784\u63a8\u7406\u7684\u95ee\u9898\uff0c\u5982\u63a7\u5236\u5668\u5230\u670d\u52a1\u518d\u5230\u4ed3\u5e93\u7684\u94fe\u5f0f\u8c03\u7528\u3001\u63a5\u53e3\u9a71\u52a8\u8fde\u63a5\u548c\u7ee7\u627f\u5173\u7cfb\u3002", "method": "\u6784\u5efa\u5e76\u5bf9\u6bd4\u4e09\u79cd\u68c0\u7d22\u7ba1\u9053\uff1a\u7eaf\u5411\u91cf\u68c0\u7d22\uff08No-Graph\uff09\u3001LLM\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\uff08LLM-KB\uff09\u548c\u57fa\u4e8eAST\u7684\u786e\u5b9a\u6027\u77e5\u8bc6\u56fe\u8c31\uff08DKB\uff09\uff0c\u5728\u591a\u4e2aJava\u9879\u76ee\u4e0a\u8bc4\u4f30\u7d22\u5f15\u65f6\u95f4\u3001\u67e5\u8be2\u5ef6\u8fdf\u3001\u8986\u76d6\u7387\u3001\u6210\u672c\u548c\u7b54\u6848\u6b63\u786e\u6027\u3002", "result": "DKB\u7d22\u5f15\u901f\u5ea6\u5feb\u3001\u6210\u672c\u4f4e\u3001\u8986\u76d6\u7387\u9ad8\uff0c\u5728Shopizer\u6570\u636e\u96c6\u4e0a\u6b63\u786e\u7387\u6700\u9ad8\uff1bLLM-KB\u63a5\u8fd1\u4f46\u6210\u672c\u9ad8\u3001\u7d22\u5f15\u4e0d\u5b8c\u6574\uff1b\u7eaf\u5411\u91cf\u68c0\u7d22\u5728\u67b6\u6784\u7c7b\u95ee\u9898\u4e0a\u8868\u73b0\u6700\u5dee\u4e14\u5e7b\u89c9\u98ce\u9669\u6700\u9ad8\u3002", "conclusion": "\u76f8\u6bd4LLM\u63d0\u53d6\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u57fa\u4e8eAST\u7684\u786e\u5b9a\u6027\u56fe\u8c31\u80fd\u4ee5\u66f4\u4f4e\u6210\u672c\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u591a\u8df3\u63a8\u7406\u80fd\u529b\u548c\u8bed\u6599\u8986\u76d6\uff0c\u66f4\u9002\u5408\u8f6f\u4ef6\u5de5\u7a0b\u573a\u666f\u3002"}}
{"id": "2601.08806", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.08806", "abs": "https://arxiv.org/abs/2601.08806", "authors": ["Abhi Kottamasu", "Akul Datta", "Aakash Barthwal", "Chirag Mahapatra", "Ajay Arun", "Adarsh Hiremath", "Brendan Foody", "Bertie Vidgen"], "title": "APEX-SWE", "comment": null, "summary": "We introduce the AI Productivity Index for Software Engineering (APEX-SWE), a benchmark for assessing whether frontier AI models can execute economically valuable software engineering work. Unlike existing evaluations that focus on narrow, well-defined tasks, APEX-SWE assesses two novel task types that reflect real-world software engineering work: (1) Integration tasks (n=100), which require constructing end-to-end systems across heterogeneous cloud primitives, business applications, and infrastructure-as-code services, and (2) Observability tasks (n=100), which require debugging production failures using telemetry signals such as logs and dashboards, as well as unstructured context. We evaluated eight frontier models on APEX-SWE. Gemini 3 Pro (Thinking = High) performs best, with a Pass@1 score of 25\\%. Our analysis shows that strong performance is primarily driven by epistemic reasoning, defined as the ability to distinguish between assumptions and verified facts, combined with agency to resolve uncertainty prior to acting. We open-source the APEX-SWE evaluation harness and a dev set (n=50).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86APEX-SWE\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u524d\u6cbfAI\u6a21\u578b\u5728\u771f\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u7ecf\u6d4e\u4ef7\u503c\u8868\u73b0\uff0c\u5305\u542b\u96c6\u6210\u4e0e\u53ef\u89c2\u6d4b\u6027\u4e24\u7c7b\u4efb\u52a1\uff0c\u5e76\u53d1\u73b0Gemini 3 Pro\u8868\u73b0\u6700\u4f73\uff0c\u5173\u952e\u80fd\u529b\u4e3a\u8ba4\u77e5\u63a8\u7406\u4e0e\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u591a\u805a\u7126\u72ed\u7a84\u660e\u786e\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u771f\u5b9e\u590d\u6742\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u4f5c\u7684\u8861\u91cf\uff0c\u6545\u63d0\u51fa\u66f4\u8d34\u8fd1\u5b9e\u9645\u751f\u4ea7\u573a\u666f\u7684\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u5305\u542b100\u4e2a\u96c6\u6210\u4efb\u52a1\u4e0e100\u4e2a\u53ef\u89c2\u6d4b\u6027\u4efb\u52a1\u7684\u57fa\u51c6\uff0c\u8bc4\u4f308\u4e2a\u524d\u6cbf\u6a21\u578b\uff0c\u4ee5Pass@1\u4e3a\u6307\u6807\uff0c\u5e76\u5206\u6790\u6027\u80fd\u9a71\u52a8\u56e0\u7d20\u3002", "result": "Gemini 3 Pro\uff08\u9ad8\u601d\u8003\u6a21\u5f0f\uff09\u8868\u73b0\u6700\u4f18\uff0c\u5f97\u5206\u4e3a25%\uff0c\u5176\u4f18\u52bf\u6e90\u4e8e\u8ba4\u77e5\u63a8\u7406\u80fd\u529b\u4e0e\u4e3b\u52a8\u89e3\u51b3\u4e0d\u786e\u5b9a\u6027\u7684\u884c\u4e3a\u3002", "conclusion": "\u771f\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u9700\u6a21\u578b\u5177\u5907\u533a\u5206\u5047\u8bbe\u4e0e\u4e8b\u5b9e\u3001\u4e3b\u52a8\u6d88\u89e3\u4e0d\u786e\u5b9a\u6027\u7684\u80fd\u529b\uff0c\u672a\u6765\u6a21\u578b\u8bbe\u8ba1\u5e94\u5f3a\u5316\u6b64\u7c7b\u8ba4\u77e5\u4e0e\u6267\u884c\u80fd\u529b\u3002"}}
