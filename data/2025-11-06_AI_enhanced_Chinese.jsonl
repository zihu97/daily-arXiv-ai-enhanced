{"id": "2511.02952", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.02952", "abs": "https://arxiv.org/abs/2511.02952", "authors": ["Zhenzhou Qi", "Yuncheng Yao", "Yiming Li", "Chung-Hsuan Tung", "Junyao Zheng", "Danyang Zhuo", "Tingjun Chen"], "title": "DecodeX: Exploring and Benchmarking of LDPC Decoding across CPU, GPU, and ASIC Platforms", "comment": null, "summary": "Emerging virtualized radio access networks (vRANs) demand flexible and\nefficient baseband processing across heterogeneous compute substrates. In this\npaper, we present DecodeX, a unified benchmarking framework for evaluating\nlow-density parity-check (LDPC) decoding acceleration across different hardware\nplatforms. DecodeX integrates a comprehensive suite of LDPC decoder\nimplementations, including kernels, APIs, and test vectors for CPUs (FlexRAN),\nGPUs (Aerial and Sionna-RK), and ASIC (ACC100), and can be readily extended to\nadditional architectures and configurations. Using DecodeX, we systematically\ncharacterize how different platforms orchestrate computation-from threading and\nmemory management to data movement and accelerator offload-and quantify the\nresulting decoding latency under varying Physical layer parameters. Our\nobservations reveal distinct trade-offs in parallel efficiency and offload\noverhead, showing that accelerator gains strongly depend on data-movement and\nworkload granularity. Building on these insights, we discuss how cross-platform\nbenchmarking can inform adaptive scheduling and co-design for future\nheterogeneous vRANs, enabling scalable and energy-efficient baseband processing\nfor NextG wireless systems.", "AI": {"tldr": "DecodeX \u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e0d\u540c\u786c\u4ef6\u5e73\u53f0\uff08CPU\u3001GPU\u3001ASIC\uff09\u4e0a LDPC \u89e3\u7801\u52a0\u901f\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u5e76\u884c\u6548\u7387\u4e0e\u5378\u8f7d\u5f00\u9500\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u4e3a\u672a\u6765\u5f02\u6784 vRAN \u7684\u81ea\u9002\u5e94\u8c03\u5ea6\u4e0e\u534f\u540c\u8bbe\u8ba1\u63d0\u4f9b\u4f9d\u636e\u3002", "motivation": "\u65b0\u5174\u7684\u865a\u62df\u5316\u65e0\u7ebf\u63a5\u5165\u7f51\uff08vRAN\uff09\u9700\u8981\u5728\u5f02\u6784\u8ba1\u7b97\u5e73\u53f0\u4e0a\u5b9e\u73b0\u7075\u6d3b\u9ad8\u6548\u7684\u57fa\u5e26\u5904\u7406\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u57fa\u51c6\u5de5\u5177\u6765\u7cfb\u7edf\u8bc4\u4f30 LDPC \u89e3\u7801\u5728\u4e0d\u540c\u786c\u4ef6\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u63d0\u51fa DecodeX \u6846\u67b6\uff0c\u96c6\u6210\u591a\u79cd LDPC \u89e3\u7801\u5668\u5b9e\u73b0\uff08\u5305\u62ec CPU\u3001GPU \u548c ASIC\uff09\uff0c\u901a\u8fc7\u7edf\u4e00\u63a5\u53e3\u548c\u6d4b\u8bd5\u5411\u91cf\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5404\u5e73\u53f0\u5728\u8ba1\u7b97\u8c03\u5ea6\u3001\u5185\u5b58\u7ba1\u7406\u3001\u6570\u636e\u79fb\u52a8\u548c\u52a0\u901f\u5668\u5378\u8f7d\u7b49\u65b9\u9762\u7684\u6027\u80fd\uff0c\u5e76\u6d4b\u91cf\u4e0d\u540c\u7269\u7406\u5c42\u53c2\u6570\u4e0b\u7684\u89e3\u7801\u5ef6\u8fdf\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u4e0d\u540c\u5e73\u53f0\u5728\u5e76\u884c\u6548\u7387\u4e0e\u5378\u8f7d\u5f00\u9500\u65b9\u9762\u7684\u663e\u8457\u5dee\u5f02\uff0c\u8868\u660e\u52a0\u901f\u5668\u6536\u76ca\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u6570\u636e\u79fb\u52a8\u6210\u672c\u548c\u4efb\u52a1\u7c92\u5ea6\u3002", "conclusion": "\u8de8\u5e73\u53f0\u57fa\u51c6\u6d4b\u8bd5\u53ef\u4e3a\u672a\u6765\u5f02\u6784 vRAN \u4e2d\u7684\u81ea\u9002\u5e94\u8c03\u5ea6\u548c\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u63d0\u4f9b\u5173\u952e\u6307\u5bfc\uff0c\u4ece\u800c\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u80fd\u6548\u9ad8\u7684\u57fa\u5e26\u5904\u7406\uff0c\u652f\u6301\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u3002"}}
{"id": "2511.02854", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02854", "abs": "https://arxiv.org/abs/2511.02854", "authors": ["Yixiang Chen", "Tianshi Zheng", "Shijue Huang", "Zhitao He", "Yi R. Fung"], "title": "SELF-REDRAFT: Eliciting Intrinsic Exploration-Exploitation Balance in Test-Time Scaling for Code Generation", "comment": "15 pages, 8 figures,2 tables", "summary": "Test-time scaling without interpreter feedback is essential for real-world\ncode generation scenarios where test cases are not readily available. While\nexisting paradigms often rely on either greedy exploitation (i.e., iterative\nrefinement) or stochastic exploration (i.e., relying on sample-based voting or\nreranking mechanisms), the balance between these two dimensions remains\nunderexplored. To investigate the LLM's intrinsic ability to balance\nexploitation and exploration, we introduce SELF-REDRAFT, a framework built upon\nSelf-Refine that encourages the model to propose new drafts for solutions that\nare fundamentally flawed. Our results show that SELF-REDRAFT consistently\nachieves better performance than Self-Refine when converged under the same\nmaximum number of iterations. Still, we observe that significant room for\nimprovement remains, largely due to two core aspects of current self-redraft\ncapabilities: constrained capacity for generating instructive feedback and\nfragile discriminative judgment. We also find that balancing strategies vary\nnotably across different LLMs, reflecting distinct, model-specific behaviors.\nOverall, our study establishes a baseline for intrinsic\nexploration-exploitation balancing in test-time scaling and identifies feedback\nand discrimination as key areas with potential for future advances.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSELF-REDRAFT\u6846\u67b6\uff0c\u5728\u65e0\u6d4b\u8bd5\u53cd\u9988\u573a\u666f\u4e0b\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u81ea\u4e3b\u5e73\u8861\u201c\u5229\u7528\u201d\u4e0e\u201c\u63a2\u7d22\u201d\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5176\u4f18\u4e8eSelf-Refine\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u5173\u952e\u74f6\u9888\u5728\u4e8e\u53cd\u9988\u751f\u6210\u4e0e\u5224\u522b\u5224\u65ad\u80fd\u529b\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4ee3\u7801\u751f\u6210\u5e38\u7f3a\u4e4f\u5373\u65f6\u6d4b\u8bd5\u53cd\u9988\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u8d2a\u5a6a\u4f18\u5316\uff08\u8fed\u4ee3\u7cbe\u70bc\uff09\u4e0e\u968f\u673a\u63a2\u7d22\uff08\u91c7\u6837\u6295\u7968/\u91cd\u6392\u5e8f\uff09\u4e4b\u95f4\u7f3a\u4e4f\u6709\u6548\u5e73\u8861\uff0c\u4f5c\u8005\u5e0c\u671b\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u5426\u5185\u5728\u5730\u534f\u8c03\u8fd9\u4e24\u79cd\u7b56\u7565\u3002", "method": "\u57fa\u4e8eSelf-Refine\u6784\u5efaSELF-REDRAFT\u6846\u67b6\uff0c\u5f15\u5bfc\u6a21\u578b\u5bf9\u5b58\u5728\u6839\u672c\u7f3a\u9677\u7684\u89e3\u6cd5\u4e3b\u52a8\u63d0\u51fa\u5168\u65b0\u8349\u7a3f\uff0c\u4ece\u800c\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u53cd\u9988\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5185\u5728\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u5e73\u8861\u3002", "result": "SELF-REDRAFT\u5728\u76f8\u540c\u6700\u5927\u8fed\u4ee3\u6b21\u6570\u4e0b\u6027\u80fd\u6301\u7eed\u4f18\u4e8eSelf-Refine\uff1b\u4e0d\u540c\u5927\u6a21\u578b\u5c55\u73b0\u51fa\u5404\u5f02\u7684\u5e73\u8861\u7b56\u7565\uff1b\u5f53\u524d\u65b9\u6cd5\u53d7\u9650\u4e8e\u751f\u6210\u6307\u5bfc\u6027\u53cd\u9988\u7684\u80fd\u529b\u4e0d\u8db3\u548c\u5224\u522b\u5224\u65ad\u8106\u5f31\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6d4b\u8bd5\u65f6\u7f29\u653e\u4e2d\u7684\u5185\u5728\u63a2\u7d22-\u5229\u7528\u5e73\u8861\u5efa\u7acb\u4e86\u57fa\u7ebf\uff0c\u5e76\u6307\u51fa\u53cd\u9988\u751f\u6210\u4e0e\u5224\u522b\u80fd\u529b\u662f\u672a\u6765\u63d0\u5347\u7684\u5173\u952e\u65b9\u5411\u3002"}}
{"id": "2511.03029", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03029", "abs": "https://arxiv.org/abs/2511.03029", "authors": ["Kajol Kulkarni", "Samuel Kemmler", "Anna Schwarz", "Gulcin Gedik", "Yanxiang Chen", "Dimitrios Papageorgiou", "Ioannis Kavroulakis", "Roman Iakymchuk"], "title": "Harvesting energy consumption on European HPC systems: Sharing Experience from the CEEC project", "comment": "10 pages, 11 figures, conference", "summary": "Energy efficiency has emerged as a central challenge for modern\nhigh-performance computing (HPC) systems, where escalating computational\ndemands and architectural complexity have led to significant energy footprints.\nThis paper presents the collective experience of the EuroHPC JU Center of\nExcellence in Exascale CFD (CEEC) in measuring, analyzing, and optimizing\nenergy consumption across major European HPC systems. We briefly review key\nmethodologies and tools for energy measurement as well as define metrics for\nreporting results. Through case studies using representative CFD applications\n(waLBerla, FLEXI/GAL{\\AE}XI, Neko, and NekRS), we evaluate energy-to-solution\nand time-to-solution metrics on diverse architectures, including CPU- and\nGPU-based partitions of LUMI, MareNostrum5, MeluXina, and JUWELS Booster. Our\nresults highlight the advantages of accelerators and mixed-precision techniques\nfor reducing energy consumption while maintaining computational accuracy.\nFinally, we advocate the need to facilitate energy measurements on HPC systems\nin order to raise awareness, teach the community, and take actions toward more\nsustainable exascale computing.", "AI": {"tldr": "\u672c\u6587\u603b\u7ed3\u4e86EuroHPC CEEC\u4e2d\u5fc3\u5728\u6b27\u6d32\u4e3b\u8981HPC\u7cfb\u7edf\u4e0a\u6d4b\u91cf\u3001\u5206\u6790\u548c\u4f18\u5316CFD\u5e94\u7528\u80fd\u8017\u7684\u7ecf\u9a8c\uff0c\u5f3a\u8c03\u52a0\u901f\u5668\u548c\u6df7\u5408\u7cbe\u5ea6\u6280\u672f\u5728\u964d\u4f4e\u80fd\u8017\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u5e76\u547c\u5401\u52a0\u5f3aHPC\u7cfb\u7edf\u7684\u80fd\u8017\u76d1\u6d4b\u4ee5\u63a8\u52a8\u53ef\u6301\u7eed\u7684\u8d85\u7b97\u53d1\u5c55\u3002", "motivation": "\u73b0\u4ee3\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u7cfb\u7edf\u56e0\u8ba1\u7b97\u9700\u6c42\u6fc0\u589e\u548c\u67b6\u6784\u590d\u6742\u6027\u63d0\u5347\u800c\u9762\u4e34\u4e25\u5cfb\u7684\u80fd\u6548\u6311\u6218\uff0c\u4e9f\u9700\u7cfb\u7edf\u6027\u65b9\u6cd5\u6765\u8bc4\u4f30\u4e0e\u4f18\u5316\u80fd\u8017\u3002", "method": "\u901a\u8fc7\u56de\u987e\u4e3b\u6d41\u80fd\u8017\u6d4b\u91cf\u65b9\u6cd5\u4e0e\u5de5\u5177\uff0c\u5b9a\u4e49\u6807\u51c6\u5316\u6307\u6807\uff0c\u5e76\u5728\u591a\u4e2a\u6b27\u6d32HPC\u7cfb\u7edf\uff08\u5982LUMI\u3001MareNostrum5\u7b49\uff09\u4e0a\u5bf9\u4ee3\u8868\u6027CFD\u5e94\u7528\uff08waLBerla\u3001FLEXI/GAL\u00c6XI\u3001Neko\u3001NekRS\uff09\u5f00\u5c55\u6848\u4f8b\u7814\u7a76\uff0c\u8bc4\u4f30\u5176\u201c\u80fd\u8017-\u6c42\u89e3\u65f6\u95f4\u201d\u548c\u201c\u65f6\u95f4-\u6c42\u89e3\u65f6\u95f4\u201d\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u52a0\u901f\u5668\uff08\u5982GPU\uff09\u548c\u6df7\u5408\u7cbe\u5ea6\u8ba1\u7b97\u53ef\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u7cbe\u5ea6\u3002", "conclusion": "\u5e94\u63a8\u52a8\u5728HPC\u7cfb\u7edf\u4e2d\u666e\u53ca\u80fd\u8017\u6d4b\u91cf\uff0c\u63d0\u9ad8\u793e\u533a\u610f\u8bc6\uff0c\u57f9\u517b\u76f8\u5173\u80fd\u529b\uff0c\u5e76\u91c7\u53d6\u884c\u52a8\u5b9e\u73b0\u66f4\u53ef\u6301\u7eed\u7684exascale\u8ba1\u7b97\u3002"}}
{"id": "2511.03586", "categories": ["cs.PF", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03586", "abs": "https://arxiv.org/abs/2511.03586", "authors": ["Andrei Ivanov", "Siyuan Shen", "Gioele Gottardo", "Marcin Chrapek", "Afif Boudaoud", "Timo Schneider", "Luca Benini", "Torsten Hoefler"], "title": "PerfDojo: Automated ML Library Generation for Heterogeneous Architectures", "comment": null, "summary": "The increasing complexity of machine learning models and the proliferation of\ndiverse hardware architectures (CPUs, GPUs, accelerators) make achieving\noptimal performance a significant challenge. Heterogeneity in instruction sets,\nspecialized kernel requirements for different data types and model features\n(e.g., sparsity, quantization), and architecture-specific optimizations\ncomplicate performance tuning. Manual optimization is resource-intensive, while\nexisting automatic approaches often rely on complex hardware-specific\nheuristics and uninterpretable intermediate representations, hindering\nperformance portability. We introduce PerfLLM, a novel automatic optimization\nmethodology leveraging Large Language Models (LLMs) and Reinforcement Learning\n(RL). Central to this is PerfDojo, an environment framing optimization as an RL\ngame using a human-readable, mathematically-inspired code representation that\nguarantees semantic validity through transformations. This allows effective\noptimization without prior hardware knowledge, facilitating both human analysis\nand RL agent training. We demonstrate PerfLLM's ability to achieve significant\nperformance gains across diverse CPU (x86, Arm, RISC-V) and GPU architectures.", "AI": {"tldr": "PerfLLM \u662f\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u65b0\u578b\u81ea\u52a8\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u540d\u4e3a PerfDojo \u7684\u73af\u5883\uff0c\u5229\u7528\u4eba\u7c7b\u53ef\u8bfb\u4e14\u8bed\u4e49\u6709\u6548\u7684\u4ee3\u7801\u8868\u793a\uff0c\u5728\u65e0\u9700\u786c\u4ef6\u5148\u9a8c\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u8de8 CPU \u548c GPU \u67b6\u6784\u7684\u9ad8\u6027\u80fd\u4f18\u5316\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u65e5\u76ca\u590d\u6742\uff0c\u52a0\u4e0a\u786c\u4ef6\u67b6\u6784\uff08\u5982 CPU\u3001GPU\u3001\u52a0\u901f\u5668\uff09\u7684\u591a\u6837\u6027\uff0c\u4f7f\u5f97\u5b9e\u73b0\u6700\u4f18\u6027\u80fd\u6781\u5177\u6311\u6218\u3002\u73b0\u6709\u81ea\u52a8\u4f18\u5316\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7684\u786c\u4ef6\u7279\u5b9a\u542f\u53d1\u5f0f\u548c\u4e0d\u53ef\u89e3\u91ca\u7684\u4e2d\u95f4\u8868\u793a\uff0c\u96be\u4ee5\u5b9e\u73b0\u6027\u80fd\u53ef\u79fb\u690d\u6027\u3002", "method": "\u63d0\u51fa PerfLLM \u65b9\u6cd5\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5f3a\u5316\u5b66\u4e60\uff1b\u6838\u5fc3\u662f PerfDojo \u73af\u5883\uff0c\u5c06\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u4e3a RL \u6e38\u620f\uff0c\u4f7f\u7528\u6570\u5b66\u542f\u53d1\u3001\u4eba\u7c7b\u53ef\u8bfb\u4e14\u8bed\u4e49\u6709\u6548\u7684\u4ee3\u7801\u8868\u793a\u8fdb\u884c\u53d8\u6362\u3002", "result": "\u5728\u591a\u79cd CPU\uff08x86\u3001Arm\u3001RISC-V\uff09\u548c GPU \u67b6\u6784\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "PerfLLM \u80fd\u5728\u65e0\u9700\u786c\u4ef6\u5148\u9a8c\u77e5\u8bc6\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u5b9e\u73b0\u8de8\u67b6\u6784\u6027\u80fd\u4f18\u5316\uff0c\u540c\u65f6\u652f\u6301\u4eba\u7c7b\u5206\u6790\u4e0e RL \u8bad\u7ec3\uff0c\u63d0\u5347\u4e86\u4f18\u5316\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u53ef\u79fb\u690d\u6027\u3002"}}
{"id": "2511.03094", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.03094", "abs": "https://arxiv.org/abs/2511.03094", "authors": ["Longling Geng", "Edward Y. Chang"], "title": "ALAS: Transactional and Dynamic Multi-Agent LLM Planning", "comment": null, "summary": "Large language models enable flexible multi-agent planning but remain fragile\nin practice: verification is often circular, state changes are not tracked for\nrepair, and small faults trigger costly global recomputation. We present ALAS,\na stateful, disruption-aware framework that separates planning from\nnon-circular validation, records a versioned execution log for grounded checks\nand restore points, and performs localized repair that preserves work in\nprogress. The validator operates independently of the planning LLM with fresh,\nbounded context, avoiding self-check loops and mid-context attrition. The\nrepair protocol edits only the minimal affected region under explicit policies\n(retry, catch, timeout, backoff, idempotency keys, compensation, loop guards)\ndefined in a canonical workflow IR that maps to Amazon States Language and Argo\nWorkflows. On job-shop scheduling suites (DMU, TA) across five classical\nbenchmarks, ALAS matches or exceeds strong single-LLM and multi-agent\nbaselines, achieving 83.7% success, reducing token usage by 60%, and running\n1.82times faster under comparable settings. A minimal reliability study shows\nthat the validator detects injected structural faults with low overhead, and\nthat localized repair contains runtime perturbations with a bounded edit radius\nand less makespan degradation than global recompute. Results indicate that the\ncombination of validator isolation, versioned execution logs, and localized\nrepair provides measurable efficiency, feasibility, and scalability for\nmulti-agent LLM planning. Code and seeds will be released.", "AI": {"tldr": "ALAS is a stateful, disruption-aware framework for multi-agent LLM planning that improves reliability and efficiency by decoupling non-circular validation, maintaining versioned execution logs, and enabling localized repair\u2014outperforming baselines in success rate, speed, and token usage on job-shop scheduling benchmarks.", "motivation": "Existing large language model\u2013based multi-agent planning systems suffer from fragility: they often rely on circular verification, fail to track state changes for effective repair, and resort to expensive global recomputation when errors occur.", "method": "ALAS introduces a framework that separates planning from independent, non-circular validation using fresh bounded context; records a versioned execution log for grounded checks and restore points; and applies localized repair via minimal edits guided by explicit policies (e.g., retry, timeout, compensation) encoded in a canonical workflow IR compatible with Amazon States Language and Argo Workflows.", "result": "On job-shop scheduling benchmarks (DMU, TA), ALAS achieves 83.7% success rate, reduces token usage by 60%, and runs 1.82\u00d7 faster than strong single-LLM and multi-agent baselines. It also effectively detects injected faults with low overhead and limits makespan degradation through bounded, localized repairs.", "conclusion": "The integration of validator isolation, versioned execution logs, and policy-driven localized repair significantly enhances the efficiency, feasibility, and scalability of multi-agent LLM planning systems."}}
{"id": "2511.02866", "categories": ["cs.SE", "cs.AI", "cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.02866", "abs": "https://arxiv.org/abs/2511.02866", "authors": ["Ahmad Tahmasivand", "Noureldin Zahran", "Saba Al-Sayouri", "Mohammed Fouda", "Khaled N. Khasawneh"], "title": "LM-Fix: Lightweight Bit-Flip Detection and Rapid Recovery Framework for Language Models", "comment": "Accepted at IEEE ICCD 2025. Code: https://github.com/ata990/lm-fix.\n  Detects over 94 percent single-bit flips (near 100 percent multi-bit) with\n  about 1 to 7.7 percent overhead; recovery is over 100x faster than a full\n  reload. Keywords: LLMs, bit-flip, fault injection, reliability, security,\n  Rowhammer, SDC, Jailbreaking, Attack, Defense, GPU DRAM faults", "summary": "This paper presents LM-Fix, a lightweight detection and rapid recovery\nframework for faults in large language models (LLMs). Existing integrity\napproaches are often heavy or slow for modern LLMs. LM-Fix runs a short\ntest-vector pass and uses hash-guided checks to detect bit-flip faults, then\nrepairs them locally without a full reload. Across multiple models, it detects\nover 94% of single-bit flips at TVL=200 and nearly 100% of multi-bit flips with\napproximately 1% to 7.7% runtime overhead; recovery is more than 100x faster\nthan reloading. These results show a practical, low-overhead solution to keep\nLLMs reliable in production", "AI": {"tldr": "LM-Fix \u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6545\u969c\u68c0\u6d4b\u4e0e\u5feb\u901f\u6062\u590d\u6846\u67b6\uff0c\u80fd\u9ad8\u6548\u68c0\u6d4b\u5e76\u4fee\u590d\u4f4d\u7ffb\u8f6c\u9519\u8bef\uff0c\u663e\u8457\u964d\u4f4e\u8fd0\u884c\u5f00\u9500\u5e76\u52a0\u901f\u6062\u590d\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b8c\u6574\u6027\u4fdd\u969c\u65b9\u6cd5\u901a\u5e38\u8ba1\u7b97\u5f00\u9500\u5927\u6216\u54cd\u5e94\u6162\uff0c\u96be\u4ee5\u6ee1\u8db3\u5b9e\u9645\u90e8\u7f72\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u4e14\u9ad8\u6548\u7684\u6545\u969c\u68c0\u6d4b\u4e0e\u6062\u590d\u673a\u5236\u3002", "method": "LM-Fix \u901a\u8fc7\u77ed\u6d4b\u8bd5\u5411\u91cf\u4f20\u9012\u548c\u54c8\u5e0c\u5f15\u5bfc\u68c0\u67e5\u6765\u68c0\u6d4b\u4f4d\u7ffb\u8f6c\u6545\u969c\uff0c\u5e76\u5728\u4e0d\u91cd\u65b0\u52a0\u8f7d\u6574\u4e2a\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u5c40\u90e8\u4fee\u590d\u3002", "result": "\u5728\u591a\u79cd\u6a21\u578b\u4e0a\uff0cLM-Fix \u5728 TVL=200 \u65f6\u53ef\u68c0\u6d4b\u8d85\u8fc7 94% \u7684\u5355\u4f4d\u7ffb\u8f6c\u9519\u8bef\uff0c\u51e0\u4e4e 100% \u68c0\u6d4b\u591a\u4f4d\u7ffb\u8f6c\u9519\u8bef\uff0c\u8fd0\u884c\u65f6\u5f00\u9500\u4ec5\u4e3a 1% \u81f3 7.7%\uff0c\u6062\u590d\u901f\u5ea6\u6bd4\u5b8c\u6574\u91cd\u8f7d\u5feb 100 \u500d\u4ee5\u4e0a\u3002", "conclusion": "LM-Fix \u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u4f4e\u5f00\u9500\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.03203", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.03203", "abs": "https://arxiv.org/abs/2511.03203", "authors": ["Deyang Yu", "Chenchen Liu", "Chuanjie Zhang", "Xiao Fang", "Weisheng Zhao"], "title": "An Event-Driven Spiking Compute-In-Memory Macro based on SOT-MRAM", "comment": "5 pages, 7 figures. Under review for ISCAS", "summary": "The application of Magnetic Random-Access Memory (MRAM) in\ncomputing-in-memory (CIM) has gained significant attention. However, existing\ndesigns often suffer from high energy consumption due to their reliance on\ncomplex analog circuits for computation. In this work, we present a Spin-Orbit-\nTorque MRAM(SOT-MRAM)-based CIM macro that employs an event-driven spiking\nprocessing for high energy efficiency. The SOT-MRAM crossbar adopts a hybrid\nseries-parallel cell structure to efficiently support matrix-vector\nmultiplication (MVM). Signal information is (en) decoded as spikes using\nlightweight circuits, eliminating the need for conventional area- and\npowerintensive analog circuits. The SOT-MRAM macro is designed and evaluated in\n28nm technology, and experimental results show that it achieves a peak energy\nefficiency of 243.6 TOPS/W, significantly outperforming existing designs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSOT-MRAM\u7684\u4e8b\u4ef6\u9a71\u52a8\u578b\u5b58\u5185\u8ba1\u7b97\u5b8f\u67b6\u6784\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u8109\u51b2\u7f16\u7801\u7535\u8def\u548c\u6df7\u5408\u4e32\u5e76\u8054\u5355\u5143\u7ed3\u6784\u5b9e\u73b0\u9ad8\u6548\u80fd\u77e9\u9635\u5411\u91cf\u4e58\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u80fd\u8017\uff0c\u572828nm\u5de5\u827a\u4e0b\u8fbe\u5230243.6 TOPS/W\u7684\u80fd\u6548\u3002", "motivation": "\u73b0\u6709MRAM\u5b58\u5185\u8ba1\u7b97\u8bbe\u8ba1\u4f9d\u8d56\u590d\u6742\u7684\u6a21\u62df\u7535\u8def\u8fdb\u884c\u8fd0\u7b97\uff0c\u5bfc\u81f4\u9ad8\u80fd\u8017\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u8282\u80fd\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u81ea\u65cb\u8f68\u9053\u77e9MRAM\uff08SOT-MRAM\uff09\u4ea4\u53c9\u9635\u5217\uff0c\u7ed3\u5408\u6df7\u5408\u4e32\u5e76\u8054\u5b58\u50a8\u5355\u5143\u7ed3\u6784\uff0c\u5e76\u5229\u7528\u8f7b\u91cf\u7ea7\u7535\u8def\u5c06\u4fe1\u53f7\u4fe1\u606f\u4ee5\u8109\u51b2\u5f62\u5f0f\u7f16\u7801/\u89e3\u7801\uff0c\u5b9e\u73b0\u4e8b\u4ef6\u9a71\u52a8\u7684\u8109\u51b2\u5904\u7406\u673a\u5236\uff0c\u907f\u514d\u4f7f\u7528\u4f20\u7edf\u9ad8\u529f\u8017\u6a21\u62df\u7535\u8def\u3002", "result": "\u572828nm\u5de5\u827a\u4e0b\u5b9e\u73b0\u7684SOT-MRAM\u5b58\u5185\u8ba1\u7b97\u5b8f\u8fbe\u5230\u5cf0\u503c\u80fd\u6548243.6 TOPS/W\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u8bbe\u8ba1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684SOT-MRAM\u5b58\u5185\u8ba1\u7b97\u67b6\u6784\u901a\u8fc7\u4e8b\u4ef6\u9a71\u52a8\u4e0e\u8109\u51b2\u7f16\u7801\u65b9\u5f0f\u6709\u6548\u63d0\u5347\u4e86\u80fd\u6548\uff0c\u4e3a\u4f4e\u529f\u8017\u5b58\u5185\u8ba1\u7b97\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.02869", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.02869", "abs": "https://arxiv.org/abs/2511.02869", "authors": ["Amirreza Esmaeili", "Fahd Seddik", "Yongyi Ji", "Fatemeh Fard", "Fuxiang Chen"], "title": "Analysis of AdvFusion: Adapter-based Multilingual Learning for Code Large Language Models", "comment": null, "summary": "Programming languages can benefit from one another by utilizing a language\nmodel for software engineering tasks. Full fine-tuning and Parameter Efficient\nFine-Tuning (PEFT) of Code Language Models (Code-LMs) has been explored for\nmultilingual knowledge transfer. AdapterFusion is a PEFT architecture that aims\nto enhance task performance by leveraging information from multiple programming\nlanguages, but primarily focuses on the target programming language.\n  In our previous work, we proposed AdvFusion, a novel PEFT-based approach that\neffectively learns from other programming languages before adapting to the\ntarget task. Though previous experiments showed that AdvFusion outperformed\nAdapterFusion and LoRA, it was applied on pre-trained Code-LMs and was limited\nto only two tasks, code summarization and method name prediction. In this\nstudy, we expanded our work and investigated AdvFusion on Code Large Language\nModels (Code-LLMs), considering three new tasks: code generation, code\ntranslation, and commit message generation. We observed that different\nCode-LLMs/tasks exhibit different characteristics. In code generation,\nAdvFusion outperformed AdapterFusion but not other PEFT methods (LoRA,\nCompacter, and TaskAdapter). In commit message generation, AdapterFusion\nperformed better than AdvFusion, and contrary to code generation, we found that\nthe other PEFT methods do not have better performance. In code translation,\nAdvFusion performed worse than AdapterFusion overall, with the performance gap\nmarginally widening as the model size increases. However, consistent with code\ngeneration, other PEFT methods showed better performance.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5148\u524d\u63d0\u51fa\u7684AdvFusion\u65b9\u6cd5\uff0c\u5728\u66f4\u5927\u7684\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\uff08Code-LLMs\uff09\u4e0a\u8bc4\u4f30\u5176\u5728\u4e09\u79cd\u65b0\u4efb\u52a1\uff08\u4ee3\u7801\u751f\u6210\u3001\u4ee3\u7801\u7ffb\u8bd1\u548c\u63d0\u4ea4\u4fe1\u606f\u751f\u6210\uff09\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4e0e\u591a\u79cd\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u53d1\u73b0AdvFusion\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4e00\uff0c\u6709\u65f6\u4f18\u4e8e\u3001\u6709\u65f6\u52a3\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22AdvFusion\u8fd9\u4e00\u65b0\u578b\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5728\u66f4\u5e7f\u6cdb\u4efb\u52a1\u548c\u66f4\u5927\u89c4\u6a21\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u9002\u7528\u6027\u548c\u6709\u6548\u6027\uff0c\u4ee5\u9a8c\u8bc1\u5176\u8de8\u7f16\u7a0b\u8bed\u8a00\u77e5\u8bc6\u8fc1\u79fb\u80fd\u529b\u7684\u6cdb\u5316\u6027\u3002", "method": "\u5728\u591a\u4e2aCode-LLMs\u4e0a\u5e94\u7528AdvFusion\u65b9\u6cd5\uff0c\u9488\u5bf9\u4ee3\u7801\u751f\u6210\u3001\u4ee3\u7801\u7ffb\u8bd1\u548c\u63d0\u4ea4\u4fe1\u606f\u751f\u6210\u4e09\u9879\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u4e0eAdapterFusion\u3001LoRA\u3001Compacter\u548cTaskAdapter\u7b49PEFT\u65b9\u6cd5\u8fdb\u884c\u6027\u80fd\u5bf9\u6bd4\u3002", "result": "\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\uff0cAdvFusion\u4f18\u4e8eAdapterFusion\u4f46\u4e0d\u53ca\u5176\u4ed6PEFT\u65b9\u6cd5\uff1b\u5728\u63d0\u4ea4\u4fe1\u606f\u751f\u6210\u4efb\u52a1\u4e2d\uff0cAdapterFusion\u8868\u73b0\u66f4\u597d\uff0c\u4e14\u5176\u4ed6PEFT\u65b9\u6cd5\u672a\u663e\u793a\u51fa\u4f18\u52bf\uff1b\u5728\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e2d\uff0cAdvFusion\u6574\u4f53\u8868\u73b0\u4e0d\u5982AdapterFusion\uff0c\u4e14\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u5927\u5dee\u8ddd\u7565\u6709\u6269\u5927\uff0c\u4f46\u5176\u4ed6PEFT\u65b9\u6cd5\u4ecd\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "AdvFusion\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u8868\u73b0\u5b58\u5728\u5dee\u5f02\uff0c\u8bf4\u660e\u5176\u6709\u6548\u6027\u4f9d\u8d56\u4e8e\u5177\u4f53\u4efb\u52a1\u7279\u6027\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u63d0\u5347\u5176\u5728\u5404\u7c7b\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u901a\u7528\u6027\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.03427", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.03427", "abs": "https://arxiv.org/abs/2511.03427", "authors": ["Florentia Afentaki", "Maha Shatta", "Konstantinos Balaskas", "Georgios Panagopoulos", "Georgios Zervakis", "Mehdi B. Tahoori"], "title": "Design and Optimization of Mixed-Kernel Mixed-Signal SVMs for Flexible Electronics", "comment": "Accepted for publication at IEEE Design Automation & Testing in\n  Europe (DATE 2026)", "summary": "Flexible Electronics (FE) have emerged as a promising alternative to\nsilicon-based technologies, offering on-demand low-cost fabrication,\nconformality, and sustainability. However, their large feature sizes severely\nlimit integration density, imposing strict area and power constraints, thus\nprohibiting the realization of Machine Learning (ML) circuits, which can\nsignificantly enhance the capabilities of relevant near-sensor applications.\nSupport Vector Machines (SVMs) offer high accuracy in such applications at\nrelatively low computational complexity, satisfying FE technologies'\nconstraints. Existing SVM designs rely solely on linear or Radial Basis\nFunction (RBF) kernels, forcing a trade-off between hardware costs and\naccuracy. Linear kernels, implemented digitally, minimize overhead but\nsacrifice performance, while the more accurate RBF kernels are prohibitively\nlarge in digital, and their analog realization contains inherent functional\napproximation. In this work, we propose the first mixed-kernel and mixed-signal\nSVM design in FE, which unifies the advantages of both implementations and\nbalances the cost/accuracy trade-off. To that end, we introduce a\nco-optimization approach that trains our mixed-kernel SVMs and maps binary SVM\nclassifiers to the appropriate kernel (linear/RBF) and domain (digital/analog),\naiming to maximize accuracy whilst reducing the number of costly RBF\nclassifiers. Our designs deliver 7.7% higher accuracy than state-of-the-art\nsingle-kernel linear SVMs, and reduce area and power by 108x and 17x on average\ncompared to digital RBF implementations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u67d4\u6027\u7535\u5b50\uff08FE\uff09\u7684\u6df7\u5408\u6838\u4e0e\u6df7\u5408\u4fe1\u53f7\u652f\u6301\u5411\u91cf\u673a\uff08SVM\uff09\u8bbe\u8ba1\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8bad\u7ec3\u4e0e\u6620\u5c04\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u9762\u79ef\u548c\u529f\u8017\u3002", "motivation": "\u67d4\u6027\u7535\u5b50\u5668\u4ef6\u53d7\u9650\u4e8e\u8f83\u5927\u7684\u7279\u5f81\u5c3a\u5bf8\uff0c\u96be\u4ee5\u5b9e\u73b0\u9ad8\u96c6\u6210\u5ea6\u7684\u673a\u5668\u5b66\u4e60\u7535\u8def\uff1b\u73b0\u6709SVM\u8bbe\u8ba1\u5728\u786c\u4ef6\u6210\u672c\u4e0e\u51c6\u786e\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u7ebf\u6027\u6838\u7cbe\u5ea6\u4e0d\u8db3\uff0cRBF\u6838\u5219\u9762\u79ef\u548c\u529f\u8017\u8fc7\u9ad8\u3002", "method": "\u63d0\u51fa\u9996\u4e2a\u6df7\u5408\u6838\uff08\u7ebf\u6027+RBF\uff09\u4e0e\u6df7\u5408\u4fe1\u53f7\uff08\u6570\u5b57+\u6a21\u62df\uff09SVM\u67b6\u6784\uff0c\u5e76\u5f15\u5165\u534f\u540c\u4f18\u5316\u65b9\u6cd5\uff0c\u5c06\u4e8c\u5143\u5206\u7c7b\u5668\u667a\u80fd\u5206\u914d\u81f3\u5408\u9002\u7684\u6838\u7c7b\u578b\u4e0e\u4fe1\u53f7\u57df\uff0c\u4ee5\u5728\u63a7\u5236RBF\u4f7f\u7528\u6570\u91cf\u7684\u540c\u65f6\u6700\u5927\u5316\u51c6\u786e\u7387\u3002", "result": "\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5355\u4e00\u7ebf\u6027\u6838SVM\uff0c\u51c6\u786e\u7387\u63d0\u53477.7%\uff1b\u76f8\u6bd4\u5168\u6570\u5b57RBF\u5b9e\u73b0\uff0c\u5e73\u5747\u9762\u79ef\u51cf\u5c11108\u500d\uff0c\u529f\u8017\u964d\u4f4e17\u500d\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6df7\u5408\u6838\u6df7\u5408\u4fe1\u53f7SVM\u8bbe\u8ba1\u6709\u6548\u5e73\u8861\u4e86\u67d4\u6027\u7535\u5b50\u4e2d\u51c6\u786e\u7387\u4e0e\u8d44\u6e90\u5f00\u9500\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u4e3a\u8fd1\u4f20\u611f\u5668\u667a\u80fd\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u4f4e\u529f\u8017\u9ad8\u7cbe\u5ea6\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.03293", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03293", "abs": "https://arxiv.org/abs/2511.03293", "authors": ["Hai Huang", "Xuhong Qiang", "Weisheng Zhao", "Chenchen Liu"], "title": "UMDAM: A Unified Data Layout and DRAM Address Mapping for Heterogenous NPU-PIM", "comment": "5 pages, 5 figures, under review for IEEE ISCAS", "summary": "Large Language Models (LLMs) are increasingly deployed on edge devices with\nNeural Processing Units (NPUs), yet the decode phase remains memory-intensive,\nlimiting performance. Processing-in-Memory (PIM) offers a promising solution,\nbut co-executing NPU-PIM systems face challenges such as data layout\nmismatches, bandwidth loss, and redundant storage. To address these issues, we\npropose UMDAM, a unified memory-affinity data layout and DRAM address mapping\nscheme tailored for NPU-PIM co-execution. UMDAM employs a column-major,\ntile-based layout and a configurable DRAM mapping strategy to ensure\ncompatibility with NPU computation while maximizing PIM efficiency -- without\nintroducing extra memory overhead or bandwidth loss. Comprehensive evaluations\non OPT models demonstrate that UMDAM reduces time-to-first-token (TTFT) by up\nto 3.0x and time-to-last-token (TTLT) by 2.18x, significantly improving\nend-to-end LLM inference efficiency on edge devices.", "AI": {"tldr": "UMDAM \u662f\u4e00\u79cd\u9762\u5411 NPU-PIM \u534f\u540c\u6267\u884c\u7684\u7edf\u4e00\u5185\u5b58\u4eb2\u548c\u6027\u6570\u636e\u5e03\u5c40\u4e0e DRAM \u5730\u5740\u6620\u5c04\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u89e3\u7801\u9636\u6bb5\u5185\u5b58\u5bc6\u96c6\uff0c\u9650\u5236\u6027\u80fd\uff1b\u5c3d\u7ba1\u5b58\u5185\u8ba1\u7b97\uff08PIM\uff09\u6709\u6f5c\u529b\uff0c\u4f46 NPU-PIM \u534f\u540c\u6267\u884c\u9762\u4e34\u6570\u636e\u5e03\u5c40\u4e0d\u5339\u914d\u3001\u5e26\u5bbd\u635f\u5931\u548c\u5197\u4f59\u5b58\u50a8\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa UMDAM \u65b9\u6848\uff0c\u91c7\u7528\u5217\u4f18\u5148\u7684\u5206\u5757\u6570\u636e\u5e03\u5c40\u548c\u53ef\u914d\u7f6e\u7684 DRAM \u6620\u5c04\u7b56\u7565\uff0c\u5728\u4e0d\u589e\u52a0\u5185\u5b58\u5f00\u9500\u6216\u5e26\u5bbd\u635f\u5931\u7684\u524d\u63d0\u4e0b\uff0c\u517c\u987e NPU \u8ba1\u7b97\u517c\u5bb9\u6027\u4e0e PIM \u6548\u7387\u3002", "result": "\u5728 OPT \u6a21\u578b\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cUMDAM \u6700\u591a\u5c06\u9996 token \u5ef6\u8fdf\uff08TTFT\uff09\u964d\u4f4e 3.0 \u500d\uff0c\u672b token \u5ef6\u8fdf\uff08TTLT\uff09\u964d\u4f4e 2.18 \u500d\u3002", "conclusion": "UMDAM \u663e\u8457\u63d0\u5347\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5927\u8bed\u8a00\u6a21\u578b\u7aef\u5230\u7aef\u63a8\u7406\u6548\u7387\uff0c\u4e3a NPU-PIM \u534f\u540c\u67b6\u6784\u63d0\u4f9b\u4e86\u9ad8\u6548\u5185\u5b58\u7ba1\u7406\u65b9\u6848\u3002"}}
{"id": "2511.02874", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02874", "abs": "https://arxiv.org/abs/2511.02874", "authors": ["Jannatul Shefa", "Taylan G. Topcu"], "title": "An Analysis of Early-Stage Functional Safety Analysis Methods and Their Integration into Model-Based Systems Engineering", "comment": null, "summary": "As systems become increasingly complex, conducting effective safety analysis\nin the earlier phases of a system's lifecycle is essential to identify and\nmitigate risks before they escalate. To that end, this paper investigates the\ncapabilities of key safety analysis techniques, namely: Failure Mode and\nEffects Analysis (FMEA), Functional Hazard Analysis (FHA), and Functional\nFailure Identification and Propagation (FFIP), along with the current state of\nthe literature in terms of their integration into Model-Based Systems\nEngineering (MBSE). A two-phase approach is adopted. The first phase is focused\non contrasting FMEA, FHA, and FFIP techniques, examining their procedures,\nalong with a documentation of their relative strengths and limitations. Our\nanalysis highlights FFIP's capability in identifying emergent system behaviors,\nsecond-order effects, and fault propagation; thus, suggesting it is better\nsuited for the safety needs of modern interconnected systems. Second, we review\nthe existing research on the efforts to integrate each of these methods into\nMBSE. We find that MBSE integration efforts primarily focus on FMEA, and\nintegration of FHA and FFIP is nascent. Additionally, FMEA-MBSE integration\nefforts could be organized into four categories: model-to-model transformation,\nuse of external customized algorithms, built-in MBSE packages, and manual use\nof standard MBSE diagrams. While our findings indicate a variety of MBSE\nintegration approaches, there is no universally established framework or\nstandard. This leaves room for an integration approach that could support the\nongoing Digital Engineering transformation efforts by enabling a more\nsynergistic lifecycle safety management methods and tools.", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4e86FMEA\u3001FHA\u548cFFIP\u4e09\u79cd\u5b89\u5168\u5206\u6790\u6280\u672f\uff0c\u5e76\u7efc\u8ff0\u4e86\u5b83\u4eec\u5728\u57fa\u4e8e\u6a21\u578b\u7684\u7cfb\u7edf\u5de5\u7a0b\uff08MBSE\uff09\u4e2d\u7684\u96c6\u6210\u73b0\u72b6\uff0c\u6307\u51faFFIP\u66f4\u9002\u5408\u73b0\u4ee3\u4e92\u8054\u7cfb\u7edf\u7684\u5b89\u5168\u9700\u6c42\uff0c\u800c\u76ee\u524dMBSE\u96c6\u6210\u4e3b\u8981\u96c6\u4e2d\u5728FMEA\uff0c\u7f3a\u4e4f\u7edf\u4e00\u6807\u51c6\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u65e5\u76ca\u590d\u6742\uff0c\u5728\u7cfb\u7edf\u751f\u547d\u5468\u671f\u65e9\u671f\u5f00\u5c55\u6709\u6548\u7684\u5b89\u5168\u5206\u6790\u5bf9\u4e8e\u8bc6\u522b\u548c\u7f13\u89e3\u98ce\u9669\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u8bc4\u4f30\u4e3b\u6d41\u5b89\u5168\u5206\u6790\u65b9\u6cd5\u7684\u80fd\u529b\u53ca\u5176\u4e0eMBSE\u7684\u96c6\u6210\u7a0b\u5ea6\uff0c\u4ee5\u652f\u6301\u6570\u5b57\u5316\u5de5\u7a0b\u8f6c\u578b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5bf9\u6bd4FMEA\u3001FHA\u548cFFIP\u7684\u6280\u672f\u6d41\u7a0b\u3001\u4f18\u52bf\u4e0e\u5c40\u9650\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7efc\u8ff0\u73b0\u6709\u6587\u732e\u4e2d\u8fd9\u4e09\u79cd\u65b9\u6cd5\u4e0eMBSE\u96c6\u6210\u7684\u7814\u7a76\u8fdb\u5c55\u3002", "result": "\u5206\u6790\u8868\u660eFFIP\u5728\u8bc6\u522b\u6d8c\u73b0\u884c\u4e3a\u3001\u4e8c\u9636\u6548\u5e94\u548c\u6545\u969c\u4f20\u64ad\u65b9\u9762\u66f4\u5177\u4f18\u52bf\uff1bMBSE\u96c6\u6210\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u4e8eFMEA\uff0c\u53ef\u5206\u4e3a\u56db\u7c7b\u65b9\u6cd5\uff0c\u800cFHA\u548cFFIP\u7684\u96c6\u6210\u5c1a\u5904\u4e8e\u521d\u671f\u9636\u6bb5\uff0c\u4e14\u7f3a\u4e4f\u901a\u7528\u6846\u67b6\u6216\u6807\u51c6\u3002", "conclusion": "\u5f53\u524dMBSE\u4e0e\u5b89\u5168\u5206\u6790\u6280\u672f\u7684\u96c6\u6210\u5c1a\u4e0d\u6210\u719f\uff0c\u5c24\u5176\u5bf9FHA\u548cFFIP\u652f\u6301\u4e0d\u8db3\uff0c\u4e9f\u9700\u5f00\u53d1\u4e00\u79cd\u80fd\u652f\u6301\u5168\u751f\u547d\u5468\u671f\u5b89\u5168\u7ba1\u7406\u5e76\u4e0e\u6570\u5b57\u5de5\u7a0b\u8f6c\u578b\u534f\u540c\u7684\u7edf\u4e00\u96c6\u6210\u65b9\u6cd5\u3002"}}
{"id": "2511.03533", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03533", "abs": "https://arxiv.org/abs/2511.03533", "authors": ["Nils Japke", "Furat Hamdan", "Diana Baumann", "David Bermbach"], "title": "Investigating the Impact of Isolation on Synchronized Benchmarks", "comment": "Accepted for publication in 2025 IEEE/ACM 18th International\n  Conference on Utility and Cloud Computing", "summary": "Benchmarking in cloud environments suffers from performance variability from\nmulti-tenant resource contention. Duet benchmarking mitigates this by running\ntwo workload versions concurrently on the same VM, exposing them to identical\nexternal interference. However, intra-VM contention between synchronized\nworkloads necessitates additional isolation mechanisms.\n  This work evaluates three such strategies: cgroups and CPU pinning, Docker\ncontainers, and Firecracker MicroVMs. We compare all strategies with an\nunisolated baseline experiment, by running benchmarks with a duet setup\nalongside a noise generator. This noise generator \"steals\" compute resources to\ndegrade performance measurements.\n  All experiments showed different latency distributions while under the\neffects of noise generation, but results show that process isolation generally\nlowered false positives, except for our experiments with Docker containers.\nEven though Docker containers rely internally on cgroups and CPU pinning, they\nwere more susceptible to performance degradation due to noise influence.\nTherefore, we recommend to use process isolation for synchronized workloads,\nwith the exception of Docker containers.", "AI": {"tldr": "Duet benchmarking reduces cloud performance variability by running two synchronized workloads on the same VM; this paper evaluates three isolation strategies\u2014cgroups/CPU pinning, Docker containers, and Firecracker MicroVMs\u2014and finds that process-level isolation (except Docker) effectively reduces false positives under resource contention.", "motivation": "Cloud benchmarking is affected by performance variability due to multi-tenant interference; duet benchmarking addresses this by co-locating workloads but introduces intra-VM contention, necessitating effective isolation mechanisms.", "method": "The authors evaluate three isolation strategies\u2014cgroups with CPU pinning, Docker containers, and Firecracker MicroVMs\u2014using a duet benchmarking setup combined with a noise generator that simulates resource contention. Performance is compared against an unisolated baseline.", "result": "All isolation methods altered latency distributions under noise, but process isolation (cgroups/CPU pinning and Firecracker) reduced false positives. Docker containers, despite using cgroups internally, showed higher susceptibility to performance degradation.", "conclusion": "Process-level isolation is recommended for synchronized duet workloads in cloud benchmarking, but Docker containers should be avoided due to their vulnerability to noise-induced performance degradation."}}
{"id": "2511.02876", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02876", "abs": "https://arxiv.org/abs/2511.02876", "authors": ["Anjali Chouhan", "Sruti Srinivasa Ragavan", "Amey Karkare"], "title": "CS Educator challenges and their solutions : A systematic mapping study", "comment": null, "summary": "Computer Science (CS) education is expanding rapidly, but educators continue\nto face persistent challenges in teaching and learning environments.Despite\ngrowing interest, limited systematic work exists to categorize and synthesize\nthe specific challenges faced by CS educators and the remedies adopted in\nresponse.This is problematic because it remains unclear which areas have been\nthoroughly addressed and which still lack sufficient scholarly attention. In\nthis study, we conducted a structured literature review of peer-reviewed\nresearch papers published over the last five years, focusing on challenges and\nremedies across ten categorized themes, including pedagogical, emotional,\ntechnological, and institutional dimensions.Our analysis revealed recurring\nissues in areas such as assessment practices, teacher training, classroom\nmanagement, and emotional well-being, along with various strategies such as\nprofessional development programs and policy interventions adopted to mitigate\nthem while also revealing several areas that have received insufficient\nattention.This review offers a consolidated understanding of the CS education\nlandscape, providing valuable insights for researchers, curriculum designers,\nand policymakers aiming to improve teaching effectiveness and educator support.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7ed3\u6784\u5316\u6587\u732e\u7efc\u8ff0\uff0c\u7cfb\u7edf\u68b3\u7406\u4e86\u8fc7\u53bb\u4e94\u5e74\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u4e2d\u6559\u5e08\u9762\u4e34\u7684\u6311\u6218\u53ca\u5e94\u5bf9\u7b56\u7565\uff0c\u6db5\u76d6\u6559\u5b66\u3001\u60c5\u611f\u3001\u6280\u672f\u548c\u5236\u5ea6\u7b49\u5341\u4e2a\u4e3b\u9898\uff0c\u63ed\u793a\u4e86\u8bc4\u4f30\u5b9e\u8df5\u3001\u5e08\u8d44\u57f9\u8bad\u3001\u8bfe\u5802\u7ba1\u7406\u548c\u60c5\u7eea\u5065\u5eb7\u7b49\u65b9\u9762\u7684\u5e38\u89c1\u95ee\u9898\uff0c\u5e76\u6307\u51fa\u82e5\u5e72\u7814\u7a76\u4e0d\u8db3\u7684\u9886\u57df\u3002", "motivation": "\u5f53\u524d\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u867d\u5feb\u901f\u53d1\u5c55\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u6559\u5e08\u6240\u9762\u4e34\u5177\u4f53\u6311\u6218\u53ca\u5176\u5e94\u5bf9\u63aa\u65bd\u7684\u7cfb\u7edf\u6027\u5206\u7c7b\u4e0e\u6574\u5408\uff0c\u5bfc\u81f4\u96be\u4ee5\u5224\u65ad\u54ea\u4e9b\u95ee\u9898\u5df2\u88ab\u5145\u5206\u7814\u7a76\u3001\u54ea\u4e9b\u4ecd\u9700\u5173\u6ce8\u3002", "method": "\u5f00\u5c55\u7ed3\u6784\u5316\u6587\u732e\u7efc\u8ff0\uff0c\u5206\u6790\u8fd1\u4e94\u5e74\u53d1\u8868\u7684\u540c\u884c\u8bc4\u5ba1\u7814\u7a76\u8bba\u6587\uff0c\u805a\u7126\u4e8e\u5341\u5927\u4e3b\u9898\u4e0b\u7684\u6311\u6218\u4e0e\u5bf9\u7b56\u3002", "result": "\u53d1\u73b0\u8bc4\u4f30\u5b9e\u8df5\u3001\u6559\u5e08\u57f9\u8bad\u3001\u8bfe\u5802\u7ba1\u7406\u4e0e\u60c5\u7eea\u5065\u5eb7\u7b49\u9886\u57df\u5b58\u5728\u53cd\u590d\u51fa\u73b0\u7684\u95ee\u9898\uff0c\u5e76\u8bc6\u522b\u51fa\u4e13\u4e1a\u53d1\u5c55\u9879\u76ee\u548c\u653f\u7b56\u5e72\u9884\u7b49\u7f13\u89e3\u7b56\u7565\uff0c\u540c\u65f6\u63ed\u793a\u82e5\u5e72\u7814\u7a76\u4e0d\u8db3\u7684\u7a7a\u767d\u9886\u57df\u3002", "conclusion": "\u672c\u7efc\u8ff0\u4e3a\u7814\u7a76\u4eba\u5458\u3001\u8bfe\u7a0b\u8bbe\u8ba1\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u5bf9\u8ba1\u7b97\u673a\u79d1\u5b66\u6559\u80b2\u73b0\u72b6\u7684\u6574\u5408\u6027\u7406\u89e3\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u6559\u5b66\u6548\u679c\u4e0e\u6559\u5e08\u652f\u6301\u3002"}}
{"id": "2511.03609", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03609", "abs": "https://arxiv.org/abs/2511.03609", "authors": ["Cameron Calk", "Emmanuel Godard"], "title": "Stone Duality Proofs for Colorless Distributed Computability Theorems", "comment": null, "summary": "We introduce a new topological encoding by spectral spaces of executions of\n  round-based full-information adversaries, a model of distributed computations\nthat is functorially presented and that\n  contains many message adversaries. We give a characterization of the\nsolvability of colorless tasks against compact adversaries.\n  Message adversaries are distributed\n  models that are known to be very expressive despite being\n  round-based and crash-free. Colorless tasks are\n  an important class of distributed tasks. For a colorless task, the\n  specification does not depend upon the multiplicity of input or\n  output values, like the ubiquitous agreement tasks.\n  Therefore, our result is a significant\n  step toward unifying topological methods in distributed computing.\n  The main insight is to consider global states obtained after finite\nexecutions of a distributed protocol\n  not as abstract\n  simplicial complexes as previously done, but as spectral\n  spaces, considering the Alexandrov topology on the faces poset. Given\n  an adversary $\\mathcal M$ with a set of inputs $\\mathcal I$,\n  we define a limit object $\\Pi^\\infty_\\mathcal M(\\mathcal I)$\n  by projective limit in the category of spectral spaces. We derive a new\ngeneral distributed computability\n  theorem using Stone duality: there exists an algorithm solving a colorless\ntask $(\\mathcal I,\\mathcal O,\\Delta)$\n  against the compact adversary $\\mathcal M$ if and only if there exists a\nspectral\n  map $f:\\Pi^\\infty_\\mathcal M(\\mathcal I)\\longrightarrow\\mathcal O$ compatible\nwith $\\Delta$.\n  From this general characterization are derived many known colorless\ncomputability\n  theorems.\n  Quite surprisingly, colored and uncolored models have the same\n  computability power (they solve the same tasks). Our new proofs give\n  topological reasons for this equivalence, previously known through\n  algorithmic reductions.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u8c31\u7a7a\u95f4\u4f5c\u4e3a\u65b0\u7684\u62d3\u6251\u7f16\u7801\u5de5\u5177\uff0c\u5bf9\u57fa\u4e8e\u8f6e\u6b21\u7684\u5168\u4fe1\u606f\u654c\u624b\u6a21\u578b\u4e2d\u7684\u6267\u884c\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u7ed9\u51fa\u4e86\u9488\u5bf9\u7d27\u81f4\u654c\u624b\u7684\u65e0\u8272\u4efb\u52a1\u53ef\u89e3\u6027\u7684\u5b8c\u6574\u523b\u753b\u3002\u5229\u7528Alexandrov\u62d3\u6251\u548cStone\u5bf9\u5076\u6027\uff0c\u4f5c\u8005\u5efa\u7acb\u4e86\u65b0\u7684\u5206\u5e03\u5f0f\u53ef\u8ba1\u7b97\u6027\u5b9a\u7406\uff0c\u5e76\u63ed\u793a\u4e86\u6709\u8272\u4e0e\u65e0\u8272\u6a21\u578b\u5728\u53ef\u8ba1\u7b97\u80fd\u529b\u4e0a\u7684\u7b49\u4ef7\u6027\u5177\u6709\u6df1\u523b\u7684\u62d3\u6251\u6839\u6e90\u3002", "motivation": "\u4f20\u7edf\u4e0a\u4f7f\u7528\u62bd\u8c61\u5355\u7eaf\u590d\u5f62\u5bf9\u5206\u5e03\u5f0f\u534f\u8bae\u7684\u5168\u5c40\u72b6\u6001\u8fdb\u884c\u62d3\u6251\u5efa\u6a21\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5728\u5904\u7406\u67d0\u4e9b\u8868\u8fbe\u529b\u5f3a\u7684\u654c\u624b\u6a21\u578b\uff08\u5982\u6d88\u606f\u654c\u624b\uff09\u65f6\u5b58\u5728\u5c40\u9650\u3002\u4e3a\u7edf\u4e00\u5e76\u62d3\u5c55\u62d3\u6251\u65b9\u6cd5\u5728\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u5e94\u7528\uff0c\u4f5c\u8005\u5bfb\u6c42\u4e00\u79cd\u66f4\u5408\u9002\u7684\u62d3\u6251\u7ed3\u6784\u6765\u523b\u753b\u6267\u884c\u7a7a\u95f4\uff0c\u7279\u522b\u662f\u9488\u5bf9\u65e0\u8272\u4efb\u52a1\u5728\u7d27\u81f4\u654c\u624b\u4e0b\u7684\u53ef\u89e3\u6027\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u5c06\u6709\u9650\u6267\u884c\u540e\u7684\u5168\u5c40\u72b6\u6001\u89c6\u4e3a\u9762\u504f\u5e8f\u96c6\u4e0a\u7684Alexandrov\u62d3\u6251\u6240\u8bf1\u5bfc\u7684\u8c31\u7a7a\u95f4\uff0c\u800c\u975e\u4f20\u7edf\u7684\u62bd\u8c61\u5355\u7eaf\u590d\u5f62\u3002\u5bf9\u4e8e\u7ed9\u5b9a\u654c\u624b\u2133\u548c\u8f93\u5165\u96c6\u5408\u2110\uff0c\u4ed6\u4eec\u5728\u8c31\u7a7a\u95f4\u8303\u7574\u4e2d\u901a\u8fc7\u5c04\u5f71\u6781\u9650\u6784\u9020\u4e86\u4e00\u4e2a\u6781\u9650\u5bf9\u8c61\u03a0^\u221e_\u2133(\u2110)\u3002\u7136\u540e\u5229\u7528Stone\u5bf9\u5076\u6027\uff0c\u5c06\u4efb\u52a1\u53ef\u89e3\u6027\u95ee\u9898\u8f6c\u5316\u4e3a\u662f\u5426\u5b58\u5728\u4e00\u4e2a\u4e0e\u4efb\u52a1\u89c4\u8303\u0394\u517c\u5bb9\u7684\u8c31\u6620\u5c04f: \u03a0^\u221e_\u2133(\u2110) \u2192 \ud835\udcaa\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u901a\u7528\u5206\u5e03\u5f0f\u53ef\u8ba1\u7b97\u6027\u5b9a\u7406\uff1a\u65e0\u8272\u4efb\u52a1(\u2110,\ud835\udcaa,\u0394)\u5728\u7d27\u81f4\u654c\u624b\u2133\u4e0b\u53ef\u89e3\u5f53\u4e14\u4ec5\u5f53\u5b58\u5728\u6ee1\u8db3\u6761\u4ef6\u7684\u8c31\u6620\u5c04\u3002\u8be5\u6846\u67b6\u4e0d\u4ec5\u63a8\u5bfc\u51fa\u8bb8\u591a\u5df2\u77e5\u7684\u65e0\u8272\u53ef\u8ba1\u7b97\u6027\u5b9a\u7406\uff0c\u8fd8\u4ece\u62d3\u6251\u89d2\u5ea6\u89e3\u91ca\u4e86\u6709\u8272\u6a21\u578b\u4e0e\u65e0\u8272\u6a21\u578b\u5728\u53ef\u8ba1\u7b97\u80fd\u529b\u4e0a\u7684\u7b49\u4ef7\u6027\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528\u8c31\u7a7a\u95f4\u548cStone\u5bf9\u5076\u6027\uff0c\u672c\u6587\u4e3a\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u62d3\u6251\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u548c\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\uff0c\u6df1\u5316\u4e86\u5bf9\u65e0\u8272\u4efb\u52a1\u53ef\u89e3\u6027\u4ee5\u53ca\u4e0d\u540c\u8ba1\u7b97\u6a21\u578b\u95f4\u7b49\u4ef7\u6027\u7684\u7406\u89e3\u3002"}}
{"id": "2511.02885", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02885", "abs": "https://arxiv.org/abs/2511.02885", "authors": ["Gwendal Jouneaux", "Jordi Cabot"], "title": "AgentSLA : Towards a Service Level Agreement for AI Agents", "comment": null, "summary": "AI components are increasingly becoming a key element of all types of\nsoftware systems to enhance their functionality. These AI components are often\nimplemented as AI Agents, offering more autonomy than a plain integration of\nLarge Language Models (LLMs), moving from a Model-as-a-Service paradigm to an\nAgent-as-a-Service one, bringing new challenges to the development of smart\nsoftware systems. Indeed, while support for the design, implementation, and\ndeployment of those agents exist, the specification of Quality of Service (QoS)\nand definition of Service Level Agreements (SLAs) aspects for those agents,\nimportant to ensure the quality of the resulting systems, remains an open\nchallenge. Part of this is due to the difficulty to clearly define quality in\nthe context of AI components, resulting in a lack of consensus on how to best\napproach Quality Assurance (QA) for these types of systems. To address this\nchallenge, this paper proposes both a quality model for AI agents based on the\nISO/IEC 25010 standard, and a domain specific language to support the\ndefinition of SLAs for the services provided by these AI agents.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9AI\u667a\u80fd\u4f53\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\u4e0e\u670d\u52a1\u7b49\u7ea7\u534f\u8bae\uff08SLA\uff09\u7f3a\u4e4f\u89c4\u8303\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eISO/IEC 25010\u6807\u51c6\u7684\u8d28\u91cf\u6a21\u578b\u548c\u4e00\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u7528\u4e8e\u5b9a\u4e49AI\u667a\u80fd\u4f53\u7684SLA\u3002", "motivation": "\u968f\u7740AI\u667a\u80fd\u4f53\u5728\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u81ea\u4e3b\u6027\u589e\u5f3a\u5e26\u6765\u4e86\u65b0\u7684\u5f00\u53d1\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u670d\u52a1\u8d28\u91cf\uff08QoS\uff09\u89c4\u8303\u548c\u670d\u52a1\u7b49\u7ea7\u534f\u8bae\uff08SLA\uff09\u5b9a\u4e49\u65b9\u9762\u7f3a\u4e4f\u5171\u8bc6\u548c\u6709\u6548\u65b9\u6cd5\uff0c\u5bfc\u81f4AI\u7ec4\u4ef6\u7684\u8d28\u91cf\u4fdd\u969c\uff08QA\uff09\u96be\u4ee5\u5b9e\u65bd\u3002", "method": "\u4f5c\u8005\u57fa\u4e8eISO/IEC 25010\u6807\u51c6\u6784\u5efa\u4e86\u4e00\u4e2a\u9002\u7528\u4e8eAI\u667a\u80fd\u4f53\u7684\u8d28\u91cf\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff08DSL\uff09\u4ee5\u652f\u6301\u5bf9AI\u667a\u80fd\u4f53\u6240\u63d0\u4f9b\u670d\u52a1\u7684SLA\u8fdb\u884c\u5f62\u5f0f\u5316\u5b9a\u4e49\u3002", "result": "\u8be5\u7814\u7a76\u4e3aAI\u667a\u80fd\u4f53\u7684\u670d\u52a1\u8d28\u91cf\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u901a\u8fc7DSL\u5b9e\u73b0\u4e86SLA\u7684\u53ef\u64cd\u4f5c\u5316\u5b9a\u4e49\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u667a\u80fd\u8f6f\u4ef6\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u4e0e\u53ef\u63a7\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u8d28\u91cf\u6a21\u578b\u548cDSL\u4e3aAI\u667a\u80fd\u4f53\u7684QoS\u4e0eSLA\u89c4\u8303\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u586b\u8865\u4e86\u5f53\u524dAI\u7cfb\u7edf\u8d28\u91cf\u4fdd\u969c\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u667a\u80fd\u8f6f\u4ef6\u7cfb\u7edf\u7684\u5de5\u7a0b\u5316\u5f00\u53d1\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.03662", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03662", "abs": "https://arxiv.org/abs/2511.03662", "authors": ["Yannis Coutouly", "Emmanuel Godard"], "title": "A General Input-Dependent Colorless Computability Theorem and Applications to Core-Dependent Adversaries", "comment": "OPODIS-25 version", "summary": "Distributed computing tasks can be presented with a triple $(\\I,\\Ou,\\Delta)$.\nThe solvability of a colorless task on the Iterated Immediate Snapshot model\n(IIS) has been characterized by the Colorless Computability Theorem\n\\cite[Th.4.3.1]{HKRbook}. A recent paper~\\cite{CG-24} generalizes this theorem\nfor any message adversaries $\\ma \\subseteq IIS$ by geometric methods. In 2001,\nMost\\'efaoui, Rajsbaum, Raynal, and Roy \\cite{condbased} introduced\n\\emph{condition-based adversaries}. This setting considers a particular\nadversary that will be applied only to a subset of input configurations. In\nthis setting, they studied the $k$-set agreement task with condition-based\n$t$-resilient adversaries and obtained a sufficient condition on the conditions\nthat make $k$-Set Agreement solvable. In this paper we have three\ncontributions:\n  -We generalize the characterization of~\\cite{CG-24} to \\emph{input-dependent}\nadversaries, which means that the adversaries can change depending on the input\nconfiguration.\n  - We show that core-resilient adversaries of $IIS_n$ have the same\ncomputability power as the core-resilient adversaries of $IIS_n$ where crashes\nonly happen at the start.\n  - Using the two previous contributions, we provide a necessary and sufficient\ncharacterization of the condition-based, core-dependent adversaries that can\nsolve $k$-Set Agreement. We also distinguish four settings that may appear when\npresenting a distributed task as $(\\I,\\Ou,\\Delta)$. Finally, in a later\nsection, we present structural properties on the carrier map $\\Delta$. Such\nproperties allow simpler proof, without changing the computability power of the\ntask. Most of the proofs in this article leverage the topological framework\nused in distributed computing by using simple geometric constructions.", "AI": {"tldr": "\u672c\u6587\u5c06\u989c\u8272\u65e0\u5173\u53ef\u8ba1\u7b97\u6027\u5b9a\u7406\u63a8\u5e7f\u81f3\u8f93\u5165\u4f9d\u8d56\u7684\u654c\u624b\u6a21\u578b\uff0c\u8bc1\u660e\u4e86IIS_n\u4e2d\u6838\u5fc3\u5f39\u6027\u654c\u624b\u4e0e\u4ec5\u5728\u521d\u59cb\u65f6\u523b\u53d1\u751f\u5d29\u6e83\u7684\u6838\u5fc3\u5f39\u6027\u654c\u624b\u5177\u6709\u76f8\u540c\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u5e76\u57fa\u4e8e\u6b64\u7ed9\u51fa\u4e86\u6761\u4ef6\u9a71\u52a8\u3001\u6838\u5fc3\u4f9d\u8d56\u654c\u624b\u4e0bk-\u96c6\u5171\u8bc6\u95ee\u9898\u53ef\u89e3\u7684\u5145\u8981\u6761\u4ef6\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5df2\u5bf9IIS\u6a21\u578b\u4e2d\u7684\u65e0\u8272\u4efb\u52a1\u53ef\u89e3\u6027\u8fdb\u884c\u4e86\u523b\u753b\uff0c\u5e76\u63a8\u5e7f\u5230\u4efb\u610f\u6d88\u606f\u654c\u624b\uff1b\u540c\u65f6\uff0c\u6761\u4ef6\u654c\u624b\u6a21\u578b\u7814\u7a76\u4e86\u7279\u5b9a\u8f93\u5165\u5b50\u96c6\u4e0b\u7684k-\u96c6\u5171\u8bc6\u95ee\u9898\u3002\u7136\u800c\uff0c\u5c1a\u672a\u6709\u5de5\u4f5c\u5c06\u8fd9\u4e9b\u7ed3\u679c\u7edf\u4e00\u5e76\u6269\u5c55\u5230\u8f93\u5165\u4f9d\u8d56\u578b\u654c\u624b\u7684\u60c5\u5f62\uff0c\u4e5f\u7f3a\u4e4f\u5bf9\u6761\u4ef6\u9a71\u52a8\u3001\u6838\u5fc3\u4f9d\u8d56\u654c\u624b\u4e0bk-\u96c6\u5171\u8bc6\u95ee\u9898\u7684\u5b8c\u6574\u523b\u753b\u3002", "method": "\u5229\u7528\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u7684\u62d3\u6251\u6846\u67b6\u548c\u51e0\u4f55\u6784\u9020\u65b9\u6cd5\uff0c\u5c06\u5df2\u6709\u5b9a\u7406\u63a8\u5e7f\u5230\u8f93\u5165\u4f9d\u8d56\u654c\u624b\u6a21\u578b\uff0c\u5206\u6790\u6838\u5fc3\u5f39\u6027\u654c\u624b\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u5e76\u7ed3\u5408\u524d\u4e24\u9879\u8d21\u732e\u63a8\u5bfc\u51fak-\u96c6\u5171\u8bc6\u5728\u6761\u4ef6\u9a71\u52a8\u3001\u6838\u5fc3\u4f9d\u8d56\u654c\u624b\u4e0b\u53ef\u89e3\u7684\u5145\u8981\u6761\u4ef6\u3002", "result": "1\uff09\u6210\u529f\u5c06CG-24\u7684\u7ed3\u679c\u63a8\u5e7f\u81f3\u8f93\u5165\u4f9d\u8d56\u654c\u624b\uff1b2\uff09\u8bc1\u660eIIS_n\u4e2d\u4e24\u7c7b\u6838\u5fc3\u5f39\u6027\u654c\u624b\u8ba1\u7b97\u80fd\u529b\u7b49\u4ef7\uff1b3\uff09\u7ed9\u51fa\u6761\u4ef6\u9a71\u52a8\u3001\u6838\u5fc3\u4f9d\u8d56\u654c\u624b\u4e0bk-\u96c6\u5171\u8bc6\u53ef\u89e3\u7684\u5145\u8981\u6761\u4ef6\uff0c\u5e76\u8bc6\u522b\u51fa\u4efb\u52a1\u8868\u793a\u4e2d\u7684\u56db\u79cd\u60c5\u5f62\uff1b4\uff09\u63d0\u51fa\u8f7d\u4f53\u6620\u5c04\u0394\u7684\u7ed3\u6784\u6027\u8d28\u4ee5\u7b80\u5316\u8bc1\u660e\u3002", "conclusion": "\u901a\u8fc7\u62d3\u6251\u4e0e\u51e0\u4f55\u65b9\u6cd5\uff0c\u672c\u6587\u7cfb\u7edf\u5730\u6269\u5c55\u4e86\u65e0\u8272\u4efb\u52a1\u53ef\u8ba1\u7b97\u6027\u7406\u8bba\uff0c\u4e3a\u66f4\u590d\u6742\u7684\u654c\u624b\u6a21\u578b\uff08\u5982\u8f93\u5165\u4f9d\u8d56\u3001\u6761\u4ef6\u9a71\u52a8\u548c\u6838\u5fc3\u4f9d\u8d56\uff09\u4e0b\u7684\u5206\u5e03\u5f0f\u4efb\u52a1\u53ef\u89e3\u6027\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u523b\u753b\uff0c\u5c24\u5176\u89e3\u51b3\u4e86k-\u96c6\u5171\u8bc6\u95ee\u9898\u7684\u5224\u5b9a\u6761\u4ef6\u3002"}}
{"id": "2511.02922", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02922", "abs": "https://arxiv.org/abs/2511.02922", "authors": ["Yunhan Qiao", "Christopher Hundhausen", "Summit Haque", "Md Istiak Hossain Shihab"], "title": "Comprehension-Performance Gap in GenAI-Assisted Brownfield Programming: A Replication and Extension", "comment": "12 pages", "summary": "Code comprehension is essential for brownfield programming tasks, in which\ndevelopers maintain and enhance legacy code bases. Generative AI (GenAI) coding\nassistants such as GitHub Copilot have been shown to improve developer\nproductivity, but their impact on code understanding is less clear. We\nreplicate and extend a previous study by exploring both performance and\ncomprehension in GenAI-assisted brownfield programming tasks. In a\nwithin-subjects experimental study, 18 computer science graduate students\ncompleted feature implementation tasks with and without Copilot. Results show\nthat Copilot significantly reduced task time and increased the number of test\ncases passed. However, comprehension scores did not differ across conditions,\nrevealing a comprehension-performance gap: participants passed more test cases\nwith Copilot, but did not demonstrate greater understanding of the legacy\ncodebase. Moreover, we failed to find a correlation between comprehension and\ntask performance. These findings suggest that while GenAI tools can accelerate\nprogramming progress in a legacy codebase, such progress may come without an\nimproved understanding of that codebase. We consider the implications of these\nfindings for programming education and GenAI tool design.", "AI": {"tldr": "GitHub Copilot improves task performance in brownfield programming but does not enhance code comprehension, revealing a gap between performance and understanding.", "motivation": "To investigate whether generative AI coding assistants like GitHub Copilot improve not only developer productivity but also code comprehension during brownfield programming tasks involving legacy codebases.", "method": "A within-subjects experimental study with 18 computer science graduate students performing feature implementation tasks with and without GitHub Copilot, measuring task time, test cases passed, and comprehension scores.", "result": "Copilot significantly reduced task time and increased test cases passed, but comprehension scores showed no improvement, and no correlation was found between comprehension and performance.", "conclusion": "GenAI tools can accelerate programming in legacy codebases without necessarily improving developers' understanding, highlighting implications for programming education and AI tool design."}}
{"id": "2511.02927", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.02927", "abs": "https://arxiv.org/abs/2511.02927", "authors": ["Rafael Baez", "Alejandro Olivas", "Nathan K. Diamond", "Marcelo Frias", "Yannic Noller", "Saeid Tizpaz-Niari"], "title": "Risk Estimation in Differential Fuzzing via Extreme Value Theory", "comment": "In Proceedings of the 40th IEEE/ACM International Conference on\n  Automated Software Engineering (ASE 25), 13 Pages, 4 Figures, 5 Tables", "summary": "Differential testing is a highly effective technique for automatically\ndetecting software bugs and vulnerabilities when the specifications involve an\nanalysis over multiple executions simultaneously. Differential fuzzing, in\nparticular, operates as a guided randomized search, aiming to find (similar)\ninputs that lead to a maximum difference in software outputs or their\nbehaviors. However, fuzzing, as a dynamic analysis, lacks any guarantees on the\nabsence of bugs: from a differential fuzzing campaign that has observed no bugs\n(or a minimal difference), what is the risk of observing a bug (or a larger\ndifference) if we run the fuzzer for one or more steps?\n  This paper investigates the application of Extreme Value Theory (EVT) to\naddress the risk of missing or underestimating bugs in differential fuzzing.\nThe key observation is that differential fuzzing as a random process resembles\nthe maximum distribution of observed differences. Hence, EVT, a branch of\nstatistics dealing with extreme values, is an ideal framework to analyze the\ntail of the differential fuzzing campaign to contain the risk. We perform\nexperiments on a set of real-world Java libraries and use differential fuzzing\nto find information leaks via side channels in these libraries. We first\nexplore the feasibility of EVT for this task and the optimal hyperparameters\nfor EVT distributions. We then compare EVT-based extrapolation against baseline\nstatistical methods like Markov's as well as Chebyshev's inequalities, and the\nBayes factor. EVT-based extrapolations outperform the baseline techniques in\n14.3% of cases and tie with the baseline in 64.2% of cases. Finally, we\nevaluate the accuracy and performance gains of EVT-enabled differential fuzzing\nin real-world Java libraries, where we reported an average saving of tens of\nmillions of bytecode executions by an early stop.", "AI": {"tldr": "\u672c\u6587\u5c06\u6781\u503c\u7406\u8bba\uff08EVT\uff09\u5e94\u7528\u4e8e\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u4e2d\uff0c\u4ee5\u8bc4\u4f30\u9057\u6f0f\u6216\u4f4e\u4f30\u6f0f\u6d1e\u7684\u98ce\u9669\uff0c\u5e76\u5728\u771f\u5b9eJava\u5e93\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u7ed3\u679c\u8868\u660eEVT\u65b9\u6cd5\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u4f20\u7edf\u7edf\u8ba1\u65b9\u6cd5\uff0c\u5e76\u80fd\u663e\u8457\u51cf\u5c11\u5b57\u8282\u7801\u6267\u884c\u6b21\u6570\u3002", "motivation": "\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u867d\u80fd\u6709\u6548\u53d1\u73b0\u8f6f\u4ef6\u7f3a\u9677\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u201c\u672a\u53d1\u73b0\u7f3a\u9677\u201d\u98ce\u9669\u7684\u91cf\u5316\u4fdd\u8bc1\u3002\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u6781\u503c\u7406\u8bba\u5bf9\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u4e2d\u89c2\u5bdf\u5230\u7684\u6700\u5927\u5dee\u5f02\u5206\u5e03\u8fdb\u884c\u5efa\u6a21\uff0c\u4ece\u800c\u8bc4\u4f30\u7ee7\u7eed\u8fd0\u884c\u6a21\u7cca\u5668\u65f6\u53d1\u73b0\u66f4\u5927\u5dee\u5f02\u6216\u6f0f\u6d1e\u7684\u53ef\u80fd\u6027\u3002", "method": "\u4f5c\u8005\u5229\u7528\u6781\u503c\u7406\u8bba\uff08EVT\uff09\u5bf9\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u8f93\u51fa\u5dee\u5f02\u6781\u503c\u8fdb\u884c\u5efa\u6a21\uff0c\u901a\u8fc7\u5b9e\u9a8c\u786e\u5b9aEVT\u5206\u5e03\u7684\u6700\u4f73\u8d85\u53c2\u6570\uff0c\u5e76\u4e0e\u9a6c\u5c14\u53ef\u592b\u4e0d\u7b49\u5f0f\u3001\u5207\u6bd4\u96ea\u592b\u4e0d\u7b49\u5f0f\u548c\u8d1d\u53f6\u65af\u56e0\u5b50\u7b49\u57fa\u7ebf\u7edf\u8ba1\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u771f\u5b9eJava\u5e93\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEVT\u65b9\u6cd5\u572814.3%\u7684\u60c5\u51b5\u4e0b\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u572864.2%\u7684\u60c5\u51b5\u4e0b\u4e0e\u4e4b\u6301\u5e73\uff1b\u540c\u65f6\uff0c\u57fa\u4e8eEVT\u7684\u63d0\u524d\u7ec8\u6b62\u7b56\u7565\u5e73\u5747\u8282\u7701\u4e86\u6570\u5343\u4e07\u6b21\u5b57\u8282\u7801\u6267\u884c\u3002", "conclusion": "\u6781\u503c\u7406\u8bba\u4e3a\u5dee\u5206\u6a21\u7cca\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u7edf\u8ba1\u6846\u67b6\uff0c\u53ef\u7528\u4e8e\u91cf\u5316\u6f0f\u62a5\u98ce\u9669\u5e76\u4f18\u5316\u6d4b\u8bd5\u6548\u7387\uff0c\u5728\u5b9e\u8df5\u4e2d\u5177\u6709\u663e\u8457\u7684\u6027\u80fd\u6536\u76ca\u3002"}}
{"id": "2511.03026", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03026", "abs": "https://arxiv.org/abs/2511.03026", "authors": ["Logan Murphy", "Torin Viger", "Alessio Di Sandro", "Aren A. Babikian", "Marsha Chechik"], "title": "Assurance Case Development for Evolving Software Product Lines: A Formal Approach", "comment": null, "summary": "In critical software engineering, structured assurance cases (ACs) are used\nto demonstrate how key system properties are supported by evidence (e.g., test\nresults, proofs). Creating rigorous ACs is particularly challenging in the\ncontext of software product lines (SPLs), i.e, sets of software products with\noverlapping but distinct features and behaviours. Since SPLs can encompass very\nlarge numbers of products, developing a rigorous AC for each product\nindividually is infeasible. Moreover, if the SPL evolves, e.g., by the\nmodification or introduction of features, it can be infeasible to assess the\nimpact of this change. Instead, the development and maintenance of ACs ought to\nbe lifted such that a single AC can be developed for the entire SPL\nsimultaneously, and be analyzed for regression in a variability-aware fashion.\nIn this article, we describe a formal approach to lifted AC development and\nregression analysis. We formalize a language of variability-aware ACs for SPLs\nand study the lifting of template-based AC development. We also define a\nregression analysis to determine the effects of SPL evolutions on\nvariability-aware ACs. We describe a model-based assurance management tool\nwhich implements these techniques, and illustrate our contributions by\ndeveloping an AC for a product line of medical devices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u8f6f\u4ef6\u4ea7\u54c1\u7ebf\uff08SPL\uff09\u7684\u53ef\u53d8\u6027\u611f\u77e5\u4fdd\u969c\u6848\u4f8b\uff08AC\uff09\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u652f\u6301\u4e3a\u6574\u4e2a\u4ea7\u54c1\u7ebf\u7edf\u4e00\u6784\u5efaAC\uff0c\u5e76\u5728SPL\u6f14\u5316\u65f6\u8fdb\u884c\u56de\u5f52\u5206\u6790\uff0c\u4ee5\u5e94\u5bf9\u4e3a\u6bcf\u4e2a\u4ea7\u54c1\u5355\u72ec\u6784\u5efaAC\u4e0d\u53ef\u884c\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u8f6f\u4ef6\u4ea7\u54c1\u7ebf\uff08SPL\uff09\u4e2d\uff0c\u7531\u4e8e\u4ea7\u54c1\u6570\u91cf\u5e9e\u5927\u4e14\u5177\u6709\u5dee\u5f02\u5316\u7684\u529f\u80fd\u4e0e\u884c\u4e3a\uff0c\u4e3a\u6bcf\u4e2a\u4ea7\u54c1\u5355\u72ec\u6784\u5efa\u4e25\u8c28\u7684\u4fdd\u969c\u6848\u4f8b\uff08AC\uff09\u4e0d\u53ef\u884c\uff1b\u540c\u65f6\uff0c\u5f53SPL\u6f14\u5316\u65f6\uff0c\u96be\u4ee5\u8bc4\u4f30\u53d8\u66f4\u5bf9\u5df2\u6709AC\u7684\u5f71\u54cd\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u4e3a\u6574\u4e2aSPL\u7edf\u4e00\u5f00\u53d1\u5e76\u652f\u6301\u53ef\u53d8\u6027\u611f\u77e5\u56de\u5f52\u5206\u6790\u7684AC\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u5f62\u5f0f\u5316\u4e86\u4e00\u79cd\u652f\u6301\u53ef\u53d8\u6027\u7684\u4fdd\u969c\u6848\u4f8b\u8bed\u8a00\uff0c\u7814\u7a76\u4e86\u57fa\u4e8e\u6a21\u677f\u7684AC\u63d0\u5347\uff08lifting\uff09\u5f00\u53d1\u65b9\u6cd5\uff0c\u5e76\u5b9a\u4e49\u4e86\u7528\u4e8e\u8bc4\u4f30SPL\u6f14\u5316\u5bf9AC\u5f71\u54cd\u7684\u56de\u5f52\u5206\u6790\u6280\u672f\uff1b\u540c\u65f6\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6a21\u578b\u7684\u4fdd\u969c\u7ba1\u7406\u5de5\u5177\u6765\u652f\u6301\u8fd9\u4e9b\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u6210\u529f\u5e94\u7528\u4e8e\u4e00\u4e2a\u533b\u7597\u8bbe\u5907\u4ea7\u54c1\u7ebf\u7684\u4fdd\u969c\u6848\u4f8b\u5f00\u53d1\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u7edf\u4e00\u6784\u5efa\u548c\u7ef4\u62a4SPL\u4fdd\u969c\u6848\u4f8b\u65b9\u9762\u7684\u53ef\u884c\u6027\u4e0e\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u4fdd\u969c\u6848\u4f8b\u5f00\u53d1\u63d0\u5347\u5230\u8f6f\u4ef6\u4ea7\u54c1\u7ebf\u5c42\u9762\u5e76\u5f15\u5165\u53ef\u53d8\u6027\u611f\u77e5\u673a\u5236\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u5927\u89c4\u6a21\u4ea7\u54c1\u7ebf\u4e2d\u4fdd\u969c\u6848\u4f8b\u6784\u5efa\u4e0e\u6f14\u5316\u7ef4\u62a4\u7684\u96be\u9898\u3002"}}
{"id": "2511.03103", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03103", "abs": "https://arxiv.org/abs/2511.03103", "authors": ["Rafael Jos\u00e9 Moura", "Maria Gizele Nascimento", "Fumio Machida", "Ermeson Andrade"], "title": "Adaptive Detection of Software Aging under Workload Shift", "comment": "SIMP\\'OSIO EM SISTEMAS COMPUTACIONAIS DE ALTO DESEMPENHO (SSCAD)", "summary": "Software aging is a phenomenon that affects long-running systems, leading to\nprogressive performance degradation and increasing the risk of failures. To\nmitigate this problem, this work proposes an adaptive approach based on machine\nlearning for software aging detection in environments subject to dynamic\nworkload conditions. We evaluate and compare a static model with adaptive\nmodels that incorporate adaptive detectors, specifically the Drift Detection\nMethod (DDM) and Adaptive Windowing (ADWIN), originally developed for concept\ndrift scenarios and applied in this work to handle workload shifts. Experiments\nwith simulated sudden, gradual, and recurring workload transitions show that\nstatic models suffer a notable performance drop when applied to unseen workload\nprofiles, whereas the adaptive model with ADWIN maintains high accuracy,\nachieving an F1-Score above 0.93 in all analyzed scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u6761\u4ef6\u4e0b\u68c0\u6d4b\u8f6f\u4ef6\u8001\u5316\u3002\u901a\u8fc7\u5f15\u5165ADWIN\u7b49\u81ea\u9002\u5e94\u68c0\u6d4b\u5668\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\u573a\u666f\u4e0b\u5747\u4fdd\u6301\u9ad8\u4e8e0.93\u7684F1\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u9759\u6001\u6a21\u578b\u3002", "motivation": "\u8f6f\u4ef6\u8001\u5316\u4f1a\u5bfc\u81f4\u957f\u671f\u8fd0\u884c\u7cfb\u7edf\u6027\u80fd\u9010\u6e10\u4e0b\u964d\u5e76\u589e\u52a0\u6545\u969c\u98ce\u9669\uff0c\u5c24\u5176\u5728\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u73af\u5883\u4e0b\uff0c\u4f20\u7edf\u9759\u6001\u6a21\u578b\u96be\u4ee5\u6709\u6548\u5e94\u5bf9\u5de5\u4f5c\u8d1f\u8f7d\u53d8\u5316\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u9002\u5e94\u8c03\u6574\u7684\u8001\u5316\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6784\u5efa\u81ea\u9002\u5e94\u8001\u5316\u68c0\u6d4b\u6a21\u578b\uff0c\u7ed3\u5408Drift Detection Method\uff08DDM\uff09\u548cAdaptive Windowing\uff08ADWIN\uff09\u4e24\u79cd\u81ea\u9002\u5e94\u68c0\u6d4b\u5668\uff0c\u4ee5\u5e94\u5bf9\u5de5\u4f5c\u8d1f\u8f7d\u7a81\u53d8\u3001\u6e10\u53d8\u548c\u5468\u671f\u6027\u53d8\u5316\u7b49\u573a\u666f\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u9759\u6001\u6a21\u578b\u5728\u9762\u5bf9\u672a\u89c1\u8fc7\u7684\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u800c\u7ed3\u5408ADWIN\u7684\u81ea\u9002\u5e94\u6a21\u578b\u5728\u6240\u6709\u6d4b\u8bd5\u573a\u666f\u4e2d\u5747\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\uff0cF1-Score\u8d85\u8fc70.93\u3002", "conclusion": "\u5c06ADWIN\u7b49\u81ea\u9002\u5e94\u673a\u5236\u5f15\u5165\u8f6f\u4ef6\u8001\u5316\u68c0\u6d4b\u53ef\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u4fdd\u969c\u3002"}}
{"id": "2511.03136", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03136", "abs": "https://arxiv.org/abs/2511.03136", "authors": ["Kexing Ji", "Shiyun Fu", "Cuiyun Gao", "Yujia Chen", "Zezhou Yang", "Chaozheng Wang", "Yuetang Deng"], "title": "Automated Prompt Generation for Code Intelligence: An Empirical study and Experience in WeChat", "comment": "Accepted by ASE 2025 Industry Track", "summary": "Large Code Models (LCMs) show potential in code intelligence, but their\neffectiveness is greatly influenced by prompt quality. Current prompt design is\nmostly manual, which is time-consuming and highly dependent on specific LCMs\nand tasks. While automated prompt generation (APG) exists in NLP, it is\nunderexplored for code intelligence. This creates a gap, as automating the\nprompt process is essential for developers facing diverse tasks and black-box\nLCMs.\n  To mitigate this, we empirically investigate two important parts of APG:\nInstruction Generation (IG) and Multi-Step Reasoning (MSR). IG provides a\ntask-related description to instruct LCMs, while MSR guides them to produce\nlogical steps before the final answer. We evaluate widely-used APG methods for\neach part on four open-source LCMs and three code intelligence tasks: code\ntranslation (PL-PL), code summarization (PL-NL), and API recommendation\n(NL-PL).Experimental results indicate that both IG and MSR dramatically enhance\nperformance compared to basic prompts. Based on these results, we propose a\nnovel APG approach combining the best methods of the two parts. Experiments\nshow our approach achieves average improvements of 28.38% in CodeBLEU (code\ntranslation), 58.11% in ROUGE-L (code summarization), and 84.53% in\nSuccessRate@1 (API recommendation) over basic prompts. To validate its\neffectiveness in an industrial scenario, we evaluate our approach on\nWeChat-Bench, a proprietary dataset, achieving an average MRR improvement of\n148.89% for API recommendation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u81ea\u52a8\u63d0\u793a\u751f\u6210\uff08APG\uff09\u5728\u5927\u4ee3\u7801\u6a21\u578b\uff08LCM\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u8bc4\u4f30\u4e86\u6307\u4ee4\u751f\u6210\uff08IG\uff09\u548c\u591a\u6b65\u63a8\u7406\uff08MSR\uff09\u4e24\u4e2a\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u65b0\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u4ee3\u7801\u667a\u80fd\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7840\u63d0\u793a\u3002", "motivation": "\u5f53\u524d\u5927\u4ee3\u7801\u6a21\u578b\uff08LCM\uff09\u7684\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u63d0\u793a\u8d28\u91cf\uff0c\u800c\u73b0\u6709\u63d0\u793a\u8bbe\u8ba1\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\uff0c\u8017\u65f6\u4e14\u5bf9\u7279\u5b9a\u6a21\u578b\u548c\u4efb\u52a1\u654f\u611f\uff1b\u5c3d\u7ba1\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u5df2\u6709\u81ea\u52a8\u63d0\u793a\u751f\u6210\uff08APG\uff09\u65b9\u6cd5\uff0c\u4f46\u5728\u4ee3\u7801\u667a\u80fd\u9886\u57df\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u65b9\u6848\u4ee5\u5e94\u5bf9\u591a\u6837\u4efb\u52a1\u548c\u9ed1\u76d2LCM\u7684\u6311\u6218\u3002", "method": "\u4f5c\u8005\u5b9e\u8bc1\u8bc4\u4f30\u4e86\u4e24\u79cdAPG\u6838\u5fc3\u7ec4\u4ef6\u2014\u2014\u6307\u4ee4\u751f\u6210\uff08IG\uff09\u548c\u591a\u6b65\u63a8\u7406\uff08MSR\uff09\u2014\u2014\u5728\u56db\u4e2a\u5f00\u6e90LCM\u548c\u4e09\u9879\u4ee3\u7801\u667a\u80fd\u4efb\u52a1\uff08\u4ee3\u7801\u7ffb\u8bd1\u3001\u4ee3\u7801\u6458\u8981\u3001API\u63a8\u8350\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4e00\u79cd\u878d\u5408\u4e24\u8005\u6700\u4f18\u7b56\u7565\u7684\u65b0\u578bAPG\u65b9\u6cd5\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4\u57fa\u7840\u63d0\u793a\uff0c\u5728CodeBLEU\uff08\u4ee3\u7801\u7ffb\u8bd1\uff09\u3001ROUGE-L\uff08\u4ee3\u7801\u6458\u8981\uff09\u548cSuccessRate@1\uff08API\u63a8\u8350\uff09\u4e0a\u5206\u522b\u5e73\u5747\u63d0\u534728.38%\u300158.11%\u548c84.53%\uff1b\u5728\u5fae\u4fe1\u5185\u90e8\u6570\u636e\u96c6WeChat-Bench\u4e0a\u7684API\u63a8\u8350\u4efb\u52a1\u4e2d\uff0cMRR\u5e73\u5747\u63d0\u5347148.89%\u3002", "conclusion": "\u81ea\u52a8\u63d0\u793a\u751f\u6210\u80fd\u663e\u8457\u63d0\u5347\u5927\u4ee3\u7801\u6a21\u578b\u5728\u591a\u79cd\u4ee3\u7801\u667a\u80fd\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u7ed3\u5408\u6307\u4ee4\u751f\u6210\u4e0e\u591a\u6b65\u63a8\u7406\u7684\u7b56\u7565\u5c24\u4e3a\u6709\u6548\uff0c\u4e14\u5728\u5de5\u4e1a\u573a\u666f\u4e2d\u4e5f\u5c55\u73b0\u51fa\u5f3a\u5927\u6f5c\u529b\u3002"}}
{"id": "2511.03153", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03153", "abs": "https://arxiv.org/abs/2511.03153", "authors": ["Khouloud Oueslati", "Maxime Lamothe", "Foutse Khomh"], "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring", "comment": null, "summary": "Large Language Models (LLMs) have substantially influenced various software\nengineering tasks. Indeed, in the case of software refactoring, traditional\nLLMs have shown the ability to reduce development time and enhance code\nquality. However, these LLMs often rely on static, detailed instructions for\nspecific tasks. In contrast, LLM-based agents can dynamically adapt to evolving\ncontexts and autonomously make decisions by interacting with software tools and\nexecuting workflows. In this paper, we explore the potential of LLM-based\nagents in supporting refactoring activities. Specifically, we introduce\nRefAgent, a multi-agent LLM-based framework for end-to-end software\nrefactoring. RefAgent consists of specialized agents responsible for planning,\nexecuting, testing, and iteratively refining refactorings using self-reflection\nand tool-calling capabilities. We evaluate RefAgent on eight open-source Java\nprojects, comparing its effectiveness against a single-agent approach, a\nsearch-based refactoring tool, and historical developer refactorings. Our\nassessment focuses on: (1) the impact of generated refactorings on software\nquality, (2) the ability to identify refactoring opportunities, and (3) the\ncontribution of each LLM agent through an ablation study. Our results show that\nRefAgent achieves a median unit test pass rate of 90%, reduces code smells by a\nmedian of 52.5%, and improves key quality attributes (e.g., reusability) by a\nmedian of 8.6%. Additionally, it closely aligns with developer refactorings and\nthe search-based tool in identifying refactoring opportunities, attaining a\nmedian F1-score of 79.15% and 72.7%, respectively. Compared to single-agent\napproaches, RefAgent improves the median unit test pass rate by 64.7% and the\nmedian compilation success rate by 40.1%. These findings highlight the promise\nof multi-agent architectures in advancing automated software refactoring.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRefAgent\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7aef\u5230\u7aef\u8f6f\u4ef6\u91cd\u6784\u6846\u67b6\uff0c\u901a\u8fc7\u89c4\u5212\u3001\u6267\u884c\u3001\u6d4b\u8bd5\u548c\u81ea\u7701\u8fed\u4ee3\u4f18\u5316\u91cd\u6784\u4efb\u52a1\uff0c\u5728\u591a\u4e2a\u5f00\u6e90Java\u9879\u76ee\u4e2d\u663e\u8457\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u4e0e\u91cd\u6784\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u91cd\u6784\u4e2d\u4f9d\u8d56\u9759\u6001\u6307\u4ee4\uff0c\u7f3a\u4e4f\u5bf9\u52a8\u6001\u4e0a\u4e0b\u6587\u7684\u9002\u5e94\u80fd\u529b\uff1b\u800c\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u53ef\u81ea\u4e3b\u51b3\u7b56\u5e76\u4e0e\u5de5\u5177\u4ea4\u4e92\uff0c\u56e0\u6b64\u4f5c\u8005\u63a2\u7d22\u5176\u5728\u91cd\u6784\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faRefAgent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u8d1f\u8d23\u89c4\u5212\u3001\u6267\u884c\u3001\u6d4b\u8bd5\u548c\u8fed\u4ee3\u4f18\u5316\u7684\u4e13\u7528\u667a\u80fd\u4f53\uff0c\u5229\u7528\u81ea\u7701\u4e0e\u5de5\u5177\u8c03\u7528\u80fd\u529b\u8fdb\u884c\u7aef\u5230\u7aef\u91cd\u6784\uff0c\u5e76\u57288\u4e2a\u5f00\u6e90Java\u9879\u76ee\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "RefAgent\u4e2d\u4f4d\u5355\u5143\u6d4b\u8bd5\u901a\u8fc7\u7387\u8fbe90%\uff0c\u4ee3\u7801\u5f02\u5473\u51cf\u5c1152.5%\uff0c\u5173\u952e\u8d28\u91cf\u5c5e\u6027\uff08\u5982\u53ef\u91cd\u7528\u6027\uff09\u63d0\u53478.6%\uff1b\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u901a\u8fc7\u7387\u548c\u7f16\u8bd1\u6210\u529f\u7387\u5206\u522b\u63d0\u9ad864.7%\u548c40.1%\uff1b\u5728\u8bc6\u522b\u91cd\u6784\u673a\u4f1a\u65b9\u9762F1\u5206\u6570\u8fbe79.15%\uff08\u5bf9\u6bd4\u5f00\u53d1\u8005\uff09\u548c72.7%\uff08\u5bf9\u6bd4\u641c\u7d22\u5f0f\u5de5\u5177\uff09\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u67b6\u6784\u5728\u81ea\u52a8\u5316\u8f6f\u4ef6\u91cd\u6784\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u80fd\u6709\u6548\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u548c\u91cd\u6784\u51c6\u786e\u6027\uff0c\u5177\u6709\u5e7f\u9614\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.03182", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03182", "abs": "https://arxiv.org/abs/2511.03182", "authors": ["Vinaik Chhetri", "A. B Siddique", "Umar Farooq"], "title": "Understanding Robustness of Model Editing in Code LLMs: An Empirical Study", "comment": "26 pages, 2 figures, 15 tables", "summary": "Large language models (LLMs) are increasingly used in software development.\nHowever, while LLMs remain static after pretraining, programming languages and\nAPIs continue to evolve, leading to the generation of deprecated or\nincompatible code that undermines reliability. Retraining LLMs from scratch to\nreflect such changes is computationally expensive, making model editing a\npromising lightweight alternative that updates only a small subset of\nparameters. Despite its potential, it remains unclear whether model editing\nyields genuine syntactic and semantic adaptations or merely superficial fixes.\nIn this work, we present a systematic study of five state-of-the-art model\nediting methods: Constrained Fine-Tuning (FT), GRACE, MEMIT, PMET, and ROME. We\napply these methods to three leading open-source code LLMs, CodeLlama,\nCodeQwen1.5, and DeepSeek-Coder, under controlled API deprecation scenarios.\nOur evaluation covers both instant and sequential editing settings, using three\ndisjoint evaluation sets designed to assess reliability, generalization, and\nspecificity. We measure model correctness at three levels: successful\ncompilation, partial test case pass, and full test pass. Our findings show that\ninstant edits consistently degrade model performance, with syntactic validity\ndropping by up to 86 percentage points and functional correctness declining by\n45 points even in the best-performing setting. Sequential edits further amplify\nthis degradation, and in some cases, model performance collapses entirely.\nAcross all models, most passing generations relied on workarounds rather than\ncorrectly adopting the intended changes, while faulty adoptions that result in\ntest failures or compilation errors were significantly more frequent. Correct\nadoptions, where the model correctly integrates the intended change, occurred\nin only about 6% of cases.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e94\u79cd\u4e3b\u6d41\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u5728\u4ee3\u7801\u5927\u6a21\u578b\u5e94\u5bf9API\u53d8\u66f4\u65f6\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u8fd9\u4e9b\u65b9\u6cd5\u666e\u904d\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u7684\u8bed\u6cd5\u548c\u8bed\u4e49\u9002\u5e94\uff0c\u53cd\u800c\u663e\u8457\u964d\u4f4e\u6a21\u578b\u6027\u80fd\uff0c\u6b63\u786e\u91c7\u7eb3\u53d8\u66f4\u7684\u6bd4\u4f8b\u4ec5\u7ea66%\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9884\u8bad\u7ec3\u540e\u4fdd\u6301\u9759\u6001\uff0c\u800c\u7f16\u7a0b\u8bed\u8a00\u548cAPI\u6301\u7eed\u6f14\u8fdb\uff0c\u5bfc\u81f4\u6a21\u578b\u751f\u6210\u8fc7\u65f6\u6216\u4e0d\u517c\u5bb9\u7684\u4ee3\u7801\uff1b\u91cd\u65b0\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u8f7b\u91cf\u7ea7\u7684\u6a21\u578b\u7f16\u8f91\u6210\u4e3a\u6f5c\u5728\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5176\u662f\u5426\u80fd\u771f\u6b63\u5b9e\u73b0\u6709\u6548\u7684\u8bed\u6cd5\u4e0e\u8bed\u4e49\u9002\u5e94\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u5bf9\u4e09\u79cd\u4e3b\u6d41\u5f00\u6e90\u4ee3\u7801\u5927\u6a21\u578b\uff08CodeLlama\u3001CodeQwen1.5\u3001DeepSeek-Coder\uff09\u5e94\u7528\u4e94\u79cd\u5148\u8fdb\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\uff08FT\u3001GRACE\u3001MEMIT\u3001PMET\u3001ROME\uff09\uff0c\u5728\u53d7\u63a7\u7684API\u5f03\u7528\u573a\u666f\u4e0b\u8fdb\u884c\u5373\u65f6\u548c\u5e8f\u5217\u7f16\u8f91\u5b9e\u9a8c\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u4e92\u65a5\u8bc4\u4f30\u96c6\u4ece\u53ef\u9760\u6027\u3001\u6cdb\u5316\u6027\u548c\u7279\u5f02\u6027\u4e09\u65b9\u9762\u8bc4\u4f30\uff0c\u8861\u91cf\u6307\u6807\u5305\u62ec\u7f16\u8bd1\u6210\u529f\u3001\u90e8\u5206\u6d4b\u8bd5\u901a\u8fc7\u548c\u5b8c\u6574\u6d4b\u8bd5\u901a\u8fc7\u3002", "result": "\u5373\u65f6\u7f16\u8f91\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8bed\u6cd5\u6709\u6548\u6027\u6700\u591a\u4e0b\u964d86\u4e2a\u767e\u5206\u70b9\uff0c\u529f\u80fd\u6b63\u786e\u6027\u6700\u591a\u4e0b\u964d45\u4e2a\u767e\u5206\u70b9\uff1b\u5e8f\u5217\u7f16\u8f91\u8fdb\u4e00\u6b65\u52a0\u5267\u6027\u80fd\u9000\u5316\uff0c\u6709\u65f6\u751a\u81f3\u5b8c\u5168\u5d29\u6e83\uff1b\u5927\u591a\u6570\u901a\u8fc7\u6848\u4f8b\u4f9d\u8d56\u53d8\u901a\u65b9\u6848\u800c\u975e\u6b63\u786e\u91c7\u7eb3\u53d8\u66f4\uff0c\u6b63\u786e\u91c7\u7eb3\u7387\u4ec5\u7ea66%\u3002", "conclusion": "\u5f53\u524d\u4e3b\u6d41\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u5728\u4ee3\u7801\u5927\u6a21\u578b\u4e2d\u96be\u4ee5\u5b9e\u73b0\u6709\u6548\u7684API\u53d8\u66f4\u9002\u5e94\uff0c\u5f80\u5f80\u4ea7\u751f\u8868\u9762\u4fee\u590d\u751a\u81f3\u6709\u5bb3\u8f93\u51fa\uff0c\u8868\u660e\u8be5\u9886\u57df\u4e9f\u9700\u66f4\u9c81\u68d2\u3001\u8bed\u4e49\u611f\u77e5\u7684\u7f16\u8f91\u6280\u672f\u3002"}}
{"id": "2511.03404", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03404", "abs": "https://arxiv.org/abs/2511.03404", "authors": ["Qianhui Zhao", "Li Zhang", "Fang Liu", "Junhang Cheng", "Chengru Wu", "Junchen Ai", "Qiaoyuanhe Meng", "Lichen Zhang", "Xiaoli Lian", "Shubin Song", "Yuanping Guo"], "title": "Towards Realistic Project-Level Code Generation via Multi-Agent Collaboration and Semantic Architecture Modeling", "comment": null, "summary": "In recent years, Large Language Models (LLMs) have achieved remarkable\nprogress in automated code generation. In real-world software engineering, the\ngrowing demand for rapid iteration and continuous delivery underscores the\nimportance of project-level code generation, where LLMs are expected to\ngenerate complete software projects directly from complex user requirements.\nAlthough existing studies have made initial explorations, they still face key\nlimitations, including unrealistic datasets and unreliable evaluation metrics\nthat fail to reflect real-world complexity, the semantic gap between\nhuman-written requirements and machine-interpretable structures, and\ndifficulties in managing hierarchical dependencies and maintaining quality\nthroughout the generation process. To address these limitations, we first\nintroduce CodeProjectEval, a project-level code generation dataset built from\n18 real-world repositories with 12.7 files and 2,388.6 lines of code per task\non average, supplemented with documentation and executable test cases for\nautomatic evaluation. We further propose ProjectGen, a multi-agent framework\nthat decomposes projects into architecture design, skeleton generation, and\ncode filling stages with iterative refinement and memory-based context\nmanagement. Within this framework, we introduce the Semantic Software\nArchitecture Tree (SSAT), a structured and semantically rich representation\nthat effectively bridges user requirements and source code implementation.\nExperiments show that ProjectGen achieves state-of-the-art performance, passing\n52/124 test cases on the small-scale project-level code generation dataset\nDevBench, a 57% improvement over the baseline approaches, and 310 test cases on\nCodeProjectEval, representing an improvement of roughly tenfold compared to the\nbaselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aProjectGen\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u548c\u4e00\u4e2a\u65b0\u7684\u9879\u76ee\u7ea7\u4ee3\u7801\u751f\u6210\u6570\u636e\u96c6CodeProjectEval\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ece\u590d\u6742\u7528\u6237\u9700\u6c42\u751f\u6210\u5b8c\u6574\u8f6f\u4ef6\u9879\u76ee\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u9879\u76ee\u7ea7\u4ee3\u7801\u751f\u6210\u7814\u7a76\u5b58\u5728\u4e0d\u5207\u5b9e\u9645\u7684\u6570\u636e\u96c6\u3001\u4e0d\u53ef\u9760\u7684\u8bc4\u4f30\u6307\u6807\u3001\u7528\u6237\u9700\u6c42\u4e0e\u673a\u5668\u53ef\u89e3\u91ca\u7ed3\u6784\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\uff0c\u4ee5\u53ca\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u96be\u4ee5\u7ba1\u7406\u5c42\u6b21\u4f9d\u8d56\u548c\u4fdd\u6301\u4ee3\u7801\u8d28\u91cf\u7b49\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u57fa\u4e8e18\u4e2a\u771f\u5b9e\u4ed3\u5e93\u7684CodeProjectEval\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51faProjectGen\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u67b6\u6784\u8bbe\u8ba1\u3001\u9aa8\u67b6\u751f\u6210\u548c\u4ee3\u7801\u586b\u5145\u4e09\u4e2a\u9636\u6bb5\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\uff0c\u5e76\u5f15\u5165\u8bed\u4e49\u8f6f\u4ef6\u67b6\u6784\u6811\uff08SSAT\uff09\u6765\u8fde\u63a5\u7528\u6237\u9700\u6c42\u4e0e\u4ee3\u7801\u5b9e\u73b0\u3002", "result": "ProjectGen\u5728DevBench\u4e0a\u901a\u8fc752/124\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u6bd4\u57fa\u7ebf\u63d0\u534757%\uff1b\u5728CodeProjectEval\u4e0a\u901a\u8fc7310\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u7ea6\u4e3a\u57fa\u7ebf\u7684\u5341\u500d\u3002", "conclusion": "ProjectGen\u7ed3\u5408CodeProjectEval\u6709\u6548\u63a8\u52a8\u4e86\u9879\u76ee\u7ea7\u4ee3\u7801\u751f\u6210\u7684\u53d1\u5c55\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2511.03421", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03421", "abs": "https://arxiv.org/abs/2511.03421", "authors": ["Shihai Wang", "Tao Chen"], "title": "Light over Heavy: Automated Performance Requirements Quantification with Linguistic Inducement", "comment": "accepted by ICSE 2026", "summary": "Elicited performance requirements need to be quantified for compliance in\ndifferent engineering tasks, e.g., configuration tuning and performance\ntesting. Much existing work has relied on manual quantification, which is\nexpensive and error-prone due to the imprecision. In this paper, we present\nLQPR, a highly efficient automatic approach for performance requirements\nquantification.LQPR relies on a new theoretical framework that converts\nquantification as a classification problem. Despite the prevalent applications\nof Large Language Models (LLMs) for requirement analytics, LQPR takes a\ndifferent perspective to address the classification: we observed that\nperformance requirements can exhibit strong patterns and are often\nshort/concise, therefore we design a lightweight linguistically induced\nmatching mechanism. We compare LQPR against nine state-of-the-art\nlearning-based approaches over diverse datasets, demonstrating that it is\nranked as the sole best for 75% or more cases with two orders less cost. Our\nwork proves that, at least for performance requirement quantification,\nspecialized methods can be more suitable than the general LLM-driven\napproaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLQPR\uff0c\u4e00\u79cd\u9ad8\u6548\u81ea\u52a8\u91cf\u5316\u6027\u80fd\u9700\u6c42\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u91cf\u5316\u95ee\u9898\u8f6c\u5316\u4e3a\u5206\u7c7b\u4efb\u52a1\uff0c\u5e76\u91c7\u7528\u8f7b\u91cf\u7ea7\u8bed\u8a00\u5339\u914d\u673a\u5236\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u4e14\u6210\u672c\u964d\u4f4e\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "motivation": "\u73b0\u6709\u6027\u80fd\u9700\u6c42\u91cf\u5316\u65b9\u6cd5\u591a\u4f9d\u8d56\u4eba\u5de5\uff0c\u6210\u672c\u9ad8\u4e14\u6613\u51fa\u9519\uff1b\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5e7f\u6cdb\u7528\u4e8e\u9700\u6c42\u5206\u6790\uff0c\u4f46\u5728\u6027\u80fd\u9700\u6c42\u91cf\u5316\u4efb\u52a1\u4e2d\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7684\u8f7b\u91cf\u65b9\u6cd5\u53ef\u80fd\u66f4\u6709\u6548\u3002", "method": "LQPR\u57fa\u4e8e\u65b0\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u6027\u80fd\u9700\u6c42\u91cf\u5316\u8f6c\u5316\u4e3a\u5206\u7c7b\u95ee\u9898\uff0c\u5229\u7528\u6027\u80fd\u9700\u6c42\u901a\u5e38\u7b80\u77ed\u4e14\u5177\u6709\u5f3a\u6a21\u5f0f\u7684\u7279\u70b9\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u8bed\u8a00\u8bf1\u5bfc\u5339\u914d\u673a\u5236\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4e0e\u4e5d\u79cd\u5148\u8fdb\u5b66\u4e60\u65b9\u6cd5\u5bf9\u6bd4\uff0cLQPR\u572875%\u4ee5\u4e0a\u7684\u6848\u4f8b\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u9488\u5bf9\u6027\u80fd\u9700\u6c42\u91cf\u5316\u4efb\u52a1\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff08\u5982LQPR\uff09\u6bd4\u901a\u7528\u7684\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u66f4\u9ad8\u6548\u3001\u66f4\u9002\u7528\u3002"}}
{"id": "2511.03517", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03517", "abs": "https://arxiv.org/abs/2511.03517", "authors": ["Wencheng Ye", "Yan Liu"], "title": "U2F: Encouraging SWE-Agent to Seize Novelty without Losing Feasibility", "comment": null, "summary": "Large language models (LLMs) have shown strong capabilities in software\nengineering tasks, yet most existing LLM-based SWE-Agents mainly tackle\nwell-defined problems using conventional methods, often overlooking alternative\nor innovative solutions beyond their predefined frameworks. This limitation is\nevident in open-world software environments, where emerging challenges\ntranscend established paradigms.\n  We propose U2F (Unknown Unknowns to Functional solutions), a\ncognitive-inspired, uncertainty-embracing multi-agent framework that\nsystematically surfaces \"Unknown Unknowns\" - novel solution pathways absent\nfrom initial formulations but holding innovative potential. U2F consists of two\nkey components: (1) a Discovery-Exploration-Integration agent system for\nuncovering and synthesizing potential solutions, and (2) cognitive enhancement\nmechanisms across three dimensions: cross-domain analogical reasoning, reverse\nthinking, and external validation, which strategically reframe and extend\nconventional solution boundaries.\n  Applied to 218 real-world software enabler stories curated from authentic\nengineering tasks, U2F achieved notable improvements: human experts reported a\n14 percent increase in overall novelty, 51 percent improvement in semantic\nnovelty, and stable feasibility (4.02/5.0), corroborated by an LLM-based\nevaluator. These results highlight the potential of embracing uncertainty as a\ncatalyst for innovation in software engineering.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faU2F\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u8ba4\u77e5\u589e\u5f3a\u673a\u5236\uff0c\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u4e3b\u52a8\u63a2\u7d22\u201c\u672a\u77e5\u7684\u672a\u77e5\u201d\uff0c\u663e\u8457\u63d0\u5347\u89e3\u51b3\u65b9\u6848\u7684\u65b0\u9896\u6027\u800c\u4e0d\u727a\u7272\u53ef\u884c\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u591a\u5c40\u9650\u4e8e\u89e3\u51b3\u5b9a\u4e49\u660e\u786e\u7684\u95ee\u9898\uff0c\u5ffd\u89c6\u4e86\u5728\u5f00\u653e\u4e16\u754c\u8f6f\u4ef6\u73af\u5883\u4e2d\u8d85\u8d8a\u65e2\u6709\u8303\u5f0f\u7684\u521b\u65b0\u89e3\u6cd5\u3002", "method": "U2F\u662f\u4e00\u4e2a\u53d7\u8ba4\u77e5\u542f\u53d1\u3001\u62e5\u62b1\u4e0d\u786e\u5b9a\u6027\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u53d1\u73b0-\u63a2\u7d22-\u6574\u5408\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u7ed3\u5408\u8de8\u9886\u57df\u7c7b\u6bd4\u63a8\u7406\u3001\u9006\u5411\u601d\u7ef4\u548c\u5916\u90e8\u9a8c\u8bc1\u4e09\u79cd\u8ba4\u77e5\u589e\u5f3a\u673a\u5236\u3002", "result": "\u5728218\u4e2a\u771f\u5b9e\u8f6f\u4ef6\u9700\u6c42\u4efb\u52a1\u4e0a\uff0cU2F\u4f7f\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4f30\u7684\u6574\u4f53\u65b0\u9896\u6027\u63d0\u534714%\uff0c\u8bed\u4e49\u65b0\u9896\u6027\u63d0\u534751%\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u53ef\u884c\u6027\uff084.02/5.0\uff09\u3002", "conclusion": "\u5c06\u4e0d\u786e\u5b9a\u6027\u89c6\u4e3a\u521b\u65b0\u50ac\u5316\u5242\uff0cU2F\u5c55\u793a\u4e86\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7cfb\u7edf\u6027\u53d1\u6398\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.03549", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03549", "abs": "https://arxiv.org/abs/2511.03549", "authors": ["Ziv Nevo", "Orna Raz", "Karen Yorav"], "title": "Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding", "comment": "7 pages, 6 figures, to be published in AISM 2025, see\n  https://aism25.github.io/aism25/", "summary": "Understanding the purpose of source code is a critical task in software\nmaintenance, onboarding, and modernization. While large language models (LLMs)\nhave shown promise in generating code explanations, they often lack grounding\nin the broader software engineering context. We propose a novel approach that\nleverages natural language artifacts from GitHub -- such as pull request\ndescriptions, issue descriptions and discussions, and commit messages -- to\nenhance LLM-based code understanding. Our system consists of three components:\none that extracts and structures relevant GitHub context, another that uses\nthis context to generate high-level explanations of the code's purpose, and a\nthird that validates the explanation. We implemented this as a standalone tool,\nas well as a server within the Model Context Protocol (MCP), enabling\nintegration with other AI-assisted development tools. Our main use case is that\nof enhancing a standard LLM-based code explanation with code insights that our\nsystem generates. To evaluate explanations' quality, we conducted a small scale\nuser study, with developers of several open projects, as well as developers of\nproprietary projects. Our user study indicates that when insights are generated\nthey often are helpful and non trivial, and are free from hallucinations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5229\u7528GitHub\u81ea\u7136\u8bed\u8a00\u5de5\u4ef6\uff08\u5982PR\u63cf\u8ff0\u3001Issue\u8ba8\u8bba\u548c\u63d0\u4ea4\u4fe1\u606f\uff09\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u4e0a\u4e0b\u6587\u3001\u751f\u6210\u9ad8\u5c42\u89e3\u91ca\u5e76\u9a8c\u8bc1\u5176\u51c6\u786e\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u6709\u5e2e\u52a9\u4e14\u65e0\u5e7b\u89c9\u7684\u4ee3\u7801\u6d1e\u5bdf\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u91ca\u4ee3\u7801\u65f6\u7f3a\u4e4f\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u6574\u4f53\u4e0a\u4e0b\u6587\u7684\u7406\u89e3\uff0c\u5bfc\u81f4\u89e3\u91ca\u53ef\u80fd\u4e0d\u591f\u51c6\u786e\u6216\u7f3a\u4e4f\u6df1\u5ea6\u3002\u4e3a\u63d0\u5347\u4ee3\u7801\u89e3\u91ca\u7684\u8d28\u91cf\u4e0e\u5b9e\u7528\u6027\uff0c\u4f5c\u8005\u5e0c\u671b\u501f\u52a9GitHub\u4e0a\u4e30\u5bcc\u7684\u81ea\u7136\u8bed\u8a00\u5de5\u4ef6\u6765\u589e\u5f3aLLM\u7684\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u3002", "method": "\u7cfb\u7edf\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a1\uff09\u4eceGitHub\u63d0\u53d6\u5e76\u7ed3\u6784\u5316\u76f8\u5173\u4e0a\u4e0b\u6587\uff1b2\uff09\u5229\u7528\u8be5\u4e0a\u4e0b\u6587\u751f\u6210\u4ee3\u7801\u76ee\u7684\u7684\u9ad8\u5c42\u89e3\u91ca\uff1b3\uff09\u9a8c\u8bc1\u751f\u6210\u89e3\u91ca\u7684\u51c6\u786e\u6027\u3002\u8be5\u7cfb\u7edf\u65e2\u53ef\u4f5c\u4e3a\u72ec\u7acb\u5de5\u5177\uff0c\u4e5f\u53ef\u4f5c\u4e3aModel Context Protocol (MCP)\u4e2d\u7684\u670d\u52a1\u5668\uff0c\u4e0e\u5176\u4ed6AI\u5f00\u53d1\u5de5\u5177\u96c6\u6210\u3002", "result": "\u901a\u8fc7\u5c0f\u89c4\u6a21\u7528\u6237\u7814\u7a76\uff08\u6db5\u76d6\u5f00\u6e90\u9879\u76ee\u548c\u79c1\u6709\u9879\u76ee\u5f00\u53d1\u8005\uff09\uff0c\u7ed3\u679c\u8868\u660e\u7cfb\u7edf\u751f\u6210\u7684\u4ee3\u7801\u6d1e\u5bdf\u901a\u5e38\u5177\u6709\u5e2e\u52a9\u6027\u3001\u975e\u5e73\u51e1\u6027\uff0c\u5e76\u4e14\u6ca1\u6709\u5e7b\u89c9\u95ee\u9898\u3002", "conclusion": "\u7ed3\u5408GitHub\u81ea\u7136\u8bed\u8a00\u5de5\u4ef6\u80fd\u6709\u6548\u63d0\u5347LLM\u5bf9\u4ee3\u7801\u76ee\u7684\u7684\u7406\u89e3\uff0c\u751f\u6210\u66f4\u53ef\u9760\u3001\u5b9e\u7528\u7684\u89e3\u91ca\uff0c\u4e3a\u8f6f\u4ef6\u7ef4\u62a4\u3001\u65b0\u4eba\u5165\u804c\u548c\u7cfb\u7edf\u73b0\u4ee3\u5316\u7b49\u573a\u666f\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2511.03690", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03690", "abs": "https://arxiv.org/abs/2511.03690", "authors": ["Xingyao Wang", "Simon Rosenberg", "Juan Michelini", "Calvin Smith", "Hoang Tran", "Engel Nyst", "Rohit Malhotra", "Xuhui Zhou", "Valerie Chen", "Robert Brennan", "Graham Neubig"], "title": "The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents", "comment": null, "summary": "Agents are now used widely in the process of software development, but\nbuilding production-ready software engineering agents is a complex task.\nDeploying software agents effectively requires flexibility in implementation\nand experimentation, reliable and secure execution, and interfaces for users to\ninteract with agents. In this paper, we present the OpenHands Software Agent\nSDK, a toolkit for implementing software development agents that satisfy these\ndesiderata. This toolkit is a complete architectural redesign of the agent\ncomponents of the popular OpenHands framework for software development agents,\nwhich has 64k+ GitHub stars. To achieve flexibility, we design a simple\ninterface for implementing agents that requires only a few lines of code in the\ndefault case, but is easily extensible to more complex, full-featured agents\nwith features such as custom tools, memory management, and more. For security\nand reliability, it delivers seamless local-to-remote execution portability,\nintegrated REST/WebSocket services. For interaction with human users, it can\nconnect directly to a variety of interfaces, such as visual workspaces (VS\nCode, VNC, browser), command-line interfaces, and APIs. Compared with existing\nSDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native\nsandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and\nbuilt-in security analysis. Empirical results on SWE-Bench Verified and GAIA\nbenchmarks demonstrate strong performance. Put together, these elements allow\nthe OpenHands Software Agent SDK to provide a practical foundation for\nprototyping, unlocking new classes of custom applications, and reliably\ndeploying agents at scale.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86 OpenHands Software Agent SDK\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u6784\u5efa\u7075\u6d3b\u3001\u5b89\u5168\u3001\u53ef\u4ea4\u4e92\u7684\u8f6f\u4ef6\u5f00\u53d1\u667a\u80fd\u4f53\u7684\u65b0\u5de5\u5177\u5305\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u652f\u6301\u5927\u89c4\u6a21\u90e8\u7f72\u3002", "motivation": "\u6784\u5efa\u53ef\u7528\u4e8e\u751f\u4ea7\u7684\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u5341\u5206\u590d\u6742\uff0c\u73b0\u6709\u65b9\u6848\u5728\u7075\u6d3b\u6027\u3001\u5b89\u5168\u6027\u3001\u53ef\u9760\u6027\u53ca\u7528\u6237\u4ea4\u4e92\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u5f00\u53d1\u5de5\u5177\u5305\u6765\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\u3002", "method": "\u4f5c\u8005\u5bf9\u6d41\u884c\u7684 OpenHands \u6846\u67b6\u8fdb\u884c\u4e86\u5b8c\u6574\u7684\u67b6\u6784\u91cd\u6784\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b80\u6d01\u4f46\u53ef\u6269\u5c55\u7684\u667a\u80fd\u4f53\u63a5\u53e3\uff0c\u652f\u6301\u81ea\u5b9a\u4e49\u5de5\u5177\u3001\u5185\u5b58\u7ba1\u7406\u3001\u672c\u5730\u5230\u8fdc\u7a0b\u65e0\u7f1d\u6267\u884c\u3001REST/WebSocket \u670d\u52a1\u4ee5\u53ca\u591a\u79cd\u7528\u6237\u4ea4\u4e92\u754c\u9762\uff08\u5982 VS Code\u3001VNC\u3001CLI \u548c API\uff09\u3002\u8be5 SDK \u8fd8\u96c6\u6210\u4e86\u6c99\u7bb1\u6267\u884c\u3001\u751f\u547d\u5468\u671f\u63a7\u5236\u3001\u591a\u6a21\u578b\u8def\u7531\u548c\u5185\u7f6e\u5b89\u5168\u5206\u6790\u3002", "result": "\u5728 SWE-Bench Verified \u548c GAIA \u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOpenHands SDK \u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u4f18\u4e8e OpenAI\u3001Claude \u548c Google \u73b0\u6709\u7684 SDK\u3002", "conclusion": "OpenHands Software Agent SDK \u4e3a\u8f6f\u4ef6\u5f00\u53d1\u667a\u80fd\u4f53\u7684\u539f\u578b\u8bbe\u8ba1\u3001\u5b9a\u5236\u5316\u5e94\u7528\u5f00\u53d1\u548c\u5927\u89c4\u6a21\u53ef\u9760\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u5168\u9762\u7684\u57fa\u7840\u3002"}}
