<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 1]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.SE](#cs.SE) [Total: 17]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [2BRobust -- Overcoming TCP BBR Performance Degradation in Virtual Machines under CPU Contention](https://arxiv.org/abs/2601.05665)
*Kathrin Elmenhorst,Nils Aschenbruck*

Main category: cs.NI

TL;DR: 本文研究了BBR拥塞控制算法在CPU受限环境下的性能退化问题，提出了一种通过监控inflight字节数并调整pacing rate的补丁方案以提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 随着BBR算法的大规模部署，需评估其在云虚拟机等资源受限场景中的鲁棒性，尤其关注其与传统Cubic算法相比在CPU争用时的性能表现。

Method: 构建基于Linux deadline调度的框架模拟CPU争用环境，测量BBR在不同hypervisor和BDP条件下的吞吐量，并设计轻量级补丁动态调整发送速率。

Result: 实验证明BBR在CPU受限时吞吐量骤降至10-20Mbps以下，而所提补丁能有效缓解该问题，在关键场景中恢复吞吐性能。

Conclusion: 若不加谨慎部署，BBR全面替代Cubic可能降低互联网整体鲁棒性；所提补丁为解决CPU受限瓶颈提供了实用方案。

Abstract: Motivated by the recent introduction and large-scale deployment of BBR congestion control algorithms, multiple studies have investigated the performance and fairness implications of this shift from loss-based to delay-based congestion control. Given the potential Internet-wide adoption of BBR, we must also consider its robustness in network and system scenarios. One such scenario is Cloud-based Virtual Machine (VM) networking - highly relevant in today's CDN-centric Internet. Interestingly, previous work has shown significant performance problems of BBRv1-2 running in Xen VMs, with BBR performance dropping to almost zero when CPU credit is low. In this paper, we develop a framework for measuring TCP throughput under fully controlled CPU contention, which uses Linux deadline scheduling to emulate generalized CPU contention conditions. Our measurements reveal that - in stark contrast to Cubic! - BBR throughput can break down during CPU contention under any hypervisor and all tested BDP conditions. Characterizing this performance degradation on a fine-granular level, we show that CPU limited BBR senders are capped at very low throughput levels below 10-20 Mbps. This finding implies that an Internet-wide shift from Cubic to BBR could harm the Internet's overall robustness, if not deployed with caution. To detect and overcome CPU-limited throughput, we propose a minimal BBR patch which detects the problematic situation by monitoring inflight bytes and reacts by increasing the pacing rate to make better use of the available CPU time. We show that our BBR patch overcomes the throughput problem for the most critical cases.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [2] [Simulation-Free PSRO: Removing Game Simulation from Policy Space Response Oracles](https://arxiv.org/abs/2601.05279)
*Yingzhuo Liu,Shuodi Liu,Weijun Luo,Liuyu Xiang,Zhaofeng He*

Main category: cs.MA

TL;DR: 提出动态窗口机制的无模拟PSRO方法，显著降低可利用性并提升兼容性。


<details>
  <summary>Details</summary>
Motivation: 解决PSRO计算成本高、游戏模拟成为运行瓶颈的问题。

Method: 引入策略窗口和Nash聚类，限制策略数量并优化对手策略选择。

Result: 在多种环境中显著降低可利用性，同时保持良好兼容性。

Conclusion: 动态窗口机制有效提升了PSRO效率与鲁棒性，具有实际应用潜力。

Abstract: Policy Space Response Oracles (PSRO) combines game-theoretic equilibrium computation with learning and is effective in approximating Nash Equilibrium in zero-sum games. However, the computational cost of PSRO has become a significant limitation to its practical application. Our analysis shows that game simulation is the primary bottleneck in PSRO's runtime. To address this issue, we conclude the concept of Simulation-Free PSRO and summarize existing methods that instantiate this concept. Additionally, we propose a novel Dynamic Window-based Simulation-Free PSRO, which introduces the concept of a strategy window to replace the original strategy set maintained in PSRO. The number of strategies in the strategy window is limited, thereby simplifying opponent strategy selection and improving the robustness of the best response. Moreover, we use Nash Clustering to select the strategy to be eliminated, ensuring that the number of strategies within the strategy window is effectively limited. Our experiments across various environments demonstrate that the Dynamic Window mechanism significantly reduces exploitability compared to existing methods, while also exhibiting excellent compatibility. Our code is available at https://github.com/enochliu98/SF-PSRO.

</details>


### [3] [On the Transition to an Auction-based Intelligent Parking Assignment System](https://arxiv.org/abs/2601.05429)
*Levente Alekszejenkó,Dobrowiecki Tadeusz*

Main category: cs.MA

TL;DR: 拍卖式停车分配系统通过智能手机预约改善交通流并激励非参与者加入，但会增加参与者的停车费用。


<details>
  <summary>Details</summary>
Motivation: 评估拍卖式停车分配系统的优劣及其对交通和财务的影响，以促进其广泛接受。

Method: 使用Eclipse SUMO模拟不同市场渗透率下参与者与非参与者的交通流、系统性能及财务结果。

Result: 随着渗透率增加，交通流改善，参与者更接近理想车位，但支出增加；非参与者面临更高费用，从而被激励加入系统。

Conclusion: 拍卖式停车分配在提升效率的同时带来成本问题，但可通过激励机制推动普及。

Abstract: Finding a free parking space in a city has become a challenging task over the past decades. A recently proposed auction-based parking assignment can alleviate cruising for parking and also set a market-driven, demand-responsive parking price. However, the wide acceptance of such a system is far from certain.
  To evaluate the merits of auction-based parking assignment, we assume that drivers have access to a smartphone-based reservation system prior to its mandatory introduction and thus have the opportunity to test and experience its merits voluntarily. We set our experiment as Eclipse SUMO simulations with different rates of participants and non-participants to check how different market penetration levels affect the traffic flow, the performance of the auction-based assignment system, and the financial outcomes. The results show that the auction-based system improves traffic flow with increasing penetration rates, allowing participants to park gradually closer to their preferred parking lots. However, it comes with a price; the system also increases parking expenditures for participants. Interestingly, non-participating drivers will face even higher parking prices. Consequently, they will be motivated to use the new system.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [4] [Self-Evolving Distributed Memory Architecture for Scalable AI Systems](https://arxiv.org/abs/2601.05569)
*Zixuan Li,Chuanzhen Wang,Haotian Sun*

Main category: cs.DC

TL;DR: 提出一种自演化分布式内存架构，通过三层协同内存管理提升AI系统效率。


<details>
  <summary>Details</summary>
Motivation: 解决分布式AI系统在计算、通信和部署层缺乏协同内存管理的问题。

Method: 三层框架：基于设备特性的动态矩阵分区、考虑拓扑与算力的节点选择、运行时自适应部署优化，并采用双内存系统跟踪长期与短期负载。

Result: 在COCO 2017、ImageNet和SQuAD上实现87.3%内存利用率、142.5 ops/s，较Ray提升显著，通信延迟降低30.2%，资源利用率达82.7%。

Conclusion: 该架构实现了跨层协同内存管理，支持动态优化，显著提升分布式AI系统性能与效率。

Abstract: Distributed AI systems face critical memory management challenges across computation, communication, and deployment layers. RRAM based in memory computing suffers from scalability limitations due to device non idealities and fixed array sizes. Decentralized AI frameworks struggle with memory efficiency across NAT constrained networks due to static routing that ignores computational load. Multi agent deployment systems tightly couple application logic with execution environments, preventing adaptive memory optimization. These challenges stem from a fundamental lack of coordinated memory management across architectural layers. We introduce Self Evolving Distributed Memory Architecture for Scalable AI Systems, a three layer framework that unifies memory management across computation, communication, and deployment. Our approach features (1) memory guided matrix processing with dynamic partitioning based on device characteristics, (2) memory aware peer selection considering network topology and computational capacity, and (3) runtime adaptive deployment optimization through continuous reconfiguration. The framework maintains dual memory systems tracking both long term performance patterns and short term workload statistics. Experiments on COCO 2017, ImageNet, and SQuAD show that our method achieves 87.3 percent memory utilization efficiency and 142.5 operations per second compared to Ray Distributed at 72.1 percent and 98.7 operations per second, while reducing communication latency by 30.2 percent to 171.2 milliseconds and improving resource utilization to 82.7 percent. Our contributions include coordinated memory management across three architectural layers, workload adaptive resource allocation, and a dual memory architecture enabling dynamic system optimization.

</details>


### [5] [Multi-Modal Style Transfer-based Prompt Tuning for Efficient Federated Domain Generalization](https://arxiv.org/abs/2601.05955)
*Yuliang Chen,Xi Lin,Jun Wu,Xiangrui Cai,Qiaolun Zhang,Xichun Fan,Jiapeng Xu,Xiu Su*

Main category: cs.DC

TL;DR: FaST-PT是一种新型联邦域泛化框架，通过轻量级多模态风格迁移和双提示模块，在降低通信计算开销的同时提升对未见域的适应能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有FDG方法在跨客户端数据异构性下表现不佳及通信计算开销大的问题。

Method: 提出多模态风格迁移（MST）扩展数据分布，设计全局与域提示分解的双提示模块，并引入域感知提示生成（DPG）实现样本自适应知识融合。

Result: 在PACS和DomainNet等四个基准数据集上优于FedDG-GA和DiPrompt等SOTA方法，消融实验验证了其高效性与有效性。

Conclusion: FaST-PT有效提升了联邦域泛化性能，同时兼顾效率与适应性，为分布式跨域学习提供了新思路。

Abstract: Federated Domain Generalization (FDG) aims to collaboratively train a global model across distributed clients that can generalize well on unseen domains. However, existing FDG methods typically struggle with cross-client data heterogeneity and incur significant communication and computation overhead. To address these challenges, this paper presents a new FDG framework, dubbed FaST-PT, which facilitates local feature augmentation and efficient unseen domain adaptation in a distributed manner. First, we propose a lightweight Multi-Modal Style Transfer (MST) method to transform image embedding under text supervision, which could expand the training data distribution and mitigate domain shift. We then design a dual-prompt module that decomposes the prompt into global and domain prompts. Specifically, global prompts capture general knowledge from augmented embedding across clients, while domain prompts capture domain-specific knowledge from local data. Besides, Domain-aware Prompt Generation (DPG) is introduced to adaptively generate suitable prompts for each sample, which facilitates unseen domain adaptation through knowledge fusion. Extensive experiments on four cross-domain benchmark datasets, e.g., PACS and DomainNet, demonstrate the superior performance of FaST-PT over SOTA FDG methods such as FedDG-GA and DiPrompt. Ablation studies further validate the effectiveness and efficiency of FaST-PT.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [DafnyPro: LLM-Assisted Automated Verification for Dafny Programs](https://arxiv.org/abs/2601.05385)
*Debangshu Banerjee,Olivier Bouissou,Stefan Zetzsche*

Main category: cs.SE

TL;DR: DafnyPro是一个推理时框架，通过差分检查、剪枝和提示增强系统提升LLM在Dafny中生成验证注解的能力，并在多个基准测试中显著提高性能。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型在Dafny程序验证注解生成中的准确性和效率。

Method: 引入差分检查器防止修改基础逻辑、剪枝器移除冗余不变式、提示增强系统应用预定义证明策略，并对较小模型进行微调。

Result: Claude Sonnet 3.5在DafnyBench上正确率提升16个百分点至86%；Qwen 7B和14B模型分别达到68%和70%的正确率。

Conclusion: DafnyPro有效提升LLM在程序验证任务中的表现，且较小模型经微调后仍可保持高准确率。

Abstract: We present DafnyPro, an inference-time framework that enhances LLMs for generating verification annotations in Dafny. DafnyPro comprises three key components: a diff-checker that prevents modifications to base program logic, a pruner that removes unnecessary invariants, and a hint-augmentation system that retrieves and applies predefined, problem-independent proof strategies. We evaluate DafnyPro using Claude Sonnet 3.5 and 3.7 on four benchmarks: Clover, MBPP-Dafny, HumanEval-Dafny, and DafnyBench, achieving consistent performance gains in all cases. Notably, on DafnyBench, the most challenging benchmark, Claude Sonnet 3.5 enhanced with DafnyPro achieves 86% correct proofs, a 16 pp improvement over the base model. We also fine-tune two Qwen models on training data derived from verification attempts by larger models enhanced with DafnyPro. Our 7B and 14B models achieve 68% and 70% correct proofs on DafnyBench, respectively, demonstrating that smaller models can maintain high verification accuracy.

</details>


### [7] [Uncovering Failures in Cyber-Physical System State Transitions: A Fuzzing-Based Approach Applied to sUAS](https://arxiv.org/abs/2601.05449)
*Theodore Chambers,Arturo Miguel Russell Bernal,Michael Vierhauser,Jane Cleland-Huang*

Main category: cs.SE

TL;DR: SaFUZZ是一种面向状态感知的模糊测试框架，用于检测小型无人机系统在状态转换、自动故障保护和人机交互中的行为异常，并通过动态生成故障树辅助根因分析。


<details>
  <summary>Details</summary>
Motivation: 随着小型无人机在关键安全场景中的广泛应用，亟需对其决策逻辑在多变环境下的可靠性进行严格验证。

Method: 提出SaFUZZ框架，结合模糊测试规范与动态故障树生成，在高保真仿真和真实飞行环境中检测并可视化导致失效的状态、模式及环境因素。

Result: 在真实无人机系统中成功发现多个开发团队此前未识别的故障点，验证了方法的有效性和可扩展性。

Conclusion: SaFUZZ为实际应用中的无人机状态转换失效提供了实用、可扩展的自动化检测与根因分析手段。

Abstract: The increasing deployment of small Uncrewed Aerial Systems (sUAS) in diverse and often safety-critical environments demands rigorous validation of onboard decision logic under various conditions. In this paper, we present SaFUZZ, a state-aware fuzzing pipeline that validates core behavior associated with state transitions, automated failsafes, and human operator interactions in sUAS applications operating under various timing conditions and environmental disturbances. We create fuzzing specifications to detect behavioral deviations, and then dynamically generate associated Fault Trees to visualize states, modes, and environmental factors that contribute to the failure, thereby helping project stakeholders to analyze the failure and identify its root causes. We validated SaFUZZ against a real-world sUAS system and were able to identify several points of failure not previously detected by the system's development team. The fuzzing was conducted in a high-fidelity simulation environment, and outcomes were validated on physical sUAS in a real-world field testing setting. The findings from the study demonstrated SaFUZZ's ability to provide a practical and scalable approach to uncovering diverse state transition failures in a real-world sUAS application.

</details>


### [8] [Rethinking Basis Path Testing: Mixed Integer Programming Approach for Test Path Set Generation](https://arxiv.org/abs/2601.05463)
*Chao Wei,Xinyi Peng,Yawen Yan,Mao Luo,Ting Cai*

Main category: cs.SE

TL;DR: 本文提出一种基于混合整数规划的基路径生成框架，显著提升路径结构简洁性与生成成功率。


<details>
  <summary>Details</summary>
Motivation: 传统贪心算法生成的基路径结构次优，影响后续测试数据自动生成并增加人工认知负担。

Method: 将基路径生成建模为优化问题，采用整体MIP模型保证理论最优，并设计增量MIP策略应对大规模拓扑。

Result: 在真实代码与合成控制流图上，增量MIP策略100%成功生成完整基路径集且计算高效。

Conclusion: 该方法为后续测试生成提供高质量结构骨架，提升整体测试效率与效果。

Abstract: Basis path testing is a cornerstone of structural testing, yet traditional automated methods, relying on greedy graph-traversal algorithms (e.g., DFS/BFS), often generate sub-optimal paths. This structural inferiority is not a trivial issue; it directly impedes downstream testing activities by complicating automated test data generation and increasing the cognitive load for human engineers. This paper reframes basis path generation from a procedural search task into a declarative optimization problem. We introduce a Mixed Integer Programming (MIP) framework designed to produce a complete basis path set that is globally optimal in its structural simplicity. Our framework includes two complementary strategies: a Holistic MIP model that guarantees a theoretically optimal path set, and a scalable Incremental MIP strategy for large, complex topologies. The incremental approach features a multi-objective function that prioritizes path simplicity and incorporates a novelty penalty to maximize the successful generation of linearly independent paths. Empirical evaluations on both real-code and large-scale synthetic Control Flow Graphs demonstrate that our Incremental MIP strategy achieves a 100\% success rate in generating complete basis sets, while remaining computationally efficient. Our work provides a foundational method for generating a high-quality structural "scaffold" that can enhance the efficiency and effectiveness of subsequent test generation efforts.

</details>


### [9] [STELP: Secure Transpilation and Execution of LLM-Generated Programs](https://arxiv.org/abs/2601.05467)
*Swapnil Shinde,Sahil Wadhwa,Andy Luo,Emily Chen*

Main category: cs.SE

TL;DR: 本文提出STELP框架，安全执行LLM生成代码，解决生产环境中代码不稳定、漏洞和恶意攻击问题。


<details>
  <summary>Details</summary>
Motivation: LLM生成代码存在安全隐患，传统人工审查与测试工具难以适用生产环境，亟需自动化安全执行方案。

Method: 设计STELP系统，在受控环境中转译并执行LLM生成代码，结合安全检测机制防范风险。

Result: 在公开数据集上验证，STELP在正确性、安全性与延迟表现优于现有方法，尤其擅长安全执行高风险代码片段。

Conclusion: STELP填补了LLM代码自动化安全执行的空白，为无人值守代码生成与实时执行场景提供可靠保障。

Abstract: Rapid evolution of Large Language Models (LLMs) has achieved major advances in reasoning, planning, and function-calling capabilities. Multi-agentic collaborative frameworks using such LLMs place them at the center of solving software development-related tasks such as code generation. However, direct use of LLM generated code in production software development systems is problematic. The code could be unstable or erroneous and contain vulnerabilities such as data poisoning, malicious attacks, and hallucinations that could lead to widespread system malfunctions. This prohibits the adoption of LLM generated code in production AI systems where human code reviews and traditional secure testing tools are impractical or untrustworthy. In this paper, we discuss safety and reliability problems with the execution of LLM generated code and propose a Secure Transpiler and Executor of LLM-Generated Program (STELP), capable of executing LLM-generated code in a controlled and safe manner. STELP secures autonomous production AI systems involving code generation, filling the critical void left by the impracticality or limitations of traditional secure testing methodologies and human oversight. This includes applications such as headless code generation-execution and LLMs that produce executable code snippets as an action plan to be executed in real time. We contribute a human-validated dataset of insecure code snippets and benchmark our approach on publicly available datasets for correctness, safety, and latency. Our results demonstrate that our approach outperforms an existing method by a significant margin, particularly in its ability to safely execute risky code snippets. Warning: This paper contains malicious code snippets that should be run with caution.

</details>


### [10] [Readability-Robust Code Summarization via Meta Curriculum Learning](https://arxiv.org/abs/2601.05485)
*Wenhao Zeng,Yitian Chai,Hao Zhou,Fandong Meng,Jie Zhou,Xiaodong Gu*

Main category: cs.SE

TL;DR: 提出RoFTCodeSum方法，通过课程学习与元学习结合，提升代码摘要模型在低可读性代码上的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有代码摘要模型在面对低可读或混淆代码时性能显著下降，需提升其鲁棒性。

Method: 结合课程学习与元学习，构建渐进难度训练集（如混淆函数名），在训练中同时优化准确率与可读性鲁棒性。

Result: 实验表明RoFTCodeSum在保持原代码性能的同时，显著提升对语义扰动的鲁棒性。

Conclusion: RoFTCodeSum有效增强代码摘要模型在真实低可读场景下的适应能力。

Abstract: Code summarization has emerged as a fundamental technique in the field of program comprehension. While code language models have shown significant advancements, the current models and benchmarks are confined to high-readability code, which contains sufficient semantic cues such as function and variable names. In the real world, however, code is often poorly structured or obfuscated, significantly degrading model performance. In this paper, we first empirically evaluate the robustness of state-of-the-art language models on poor-readability code for the task of code summarization, focusing on (1) their effectiveness, (2) the impact of prompt engineering, and (3) the robustness of different variants. Experimental results reveal that state-of-the-art models-including GPT-4o and DeepSeek-V3 experience a substantial performance drop when faced with poorly readable code, and that prompt engineering and reasoning-enhanced models offer limited improvements. Motivated by these findings, we propose RoFTCodeSum, a novel fine-tuning method that enhances the robustness of code summarization against poorly readable code. RoFTCodeSum marries the concepts of curriculum learning and meta-learning: based on the original dataset for fine-tuning, it creates curricular training sets, e.g., obfuscating function names and identifiers from the code, respectively, that have progressive difficulty in code comprehension. In each training step, the approach meta-updates the gradients using these progressively challenging datasets, thereby optimizing both accuracy and readability robustness simultaneously. Experimental results demonstrate that RoFTCodeSum exhibits increased robustness against semantic perturbation while enhancing performance on the original code.

</details>


### [11] [LIDL: LLM Integration Defect Localization via Knowledge Graph-Enhanced Multi-Agent Analysis](https://arxiv.org/abs/2601.05539)
*Gou Tan,Zilong He,Min Li,Pengfei Chen,Jieke Shi,Zhensu Sun,Ting Zhang,Danwen Chen,Lwin Khin Shar,Chuanfu Zhang,David Lo*

Main category: cs.SE

TL;DR: LIDL是一个多智能体框架，用于定位LLM集成软件中的缺陷，通过构建代码知识图、融合错误证据和上下文验证显著提升准确率并降低成本。


<details>
  <summary>Details</summary>
Motivation: 现有缺陷定位技术无法有效识别LLM集成软件中特有的跨层依赖和语义推理问题。

Method: 构建含LLM感知注解的代码知识图，融合三类LLM推断的错误证据，并应用基于反事实推理的上下文验证。

Result: 在146个真实缺陷实例上，LIDL的Top-3准确率达0.64，MAP为0.48，较最佳基线提升64.1%，成本降低92.5%。

Conclusion: LIDL在准确性和成本效率方面均优于现有方法，适合LLM集成软件的缺陷定位。

Abstract: LLM-integrated software, which embeds or interacts with large language models (LLMs) as functional components, exhibits probabilistic and context-dependent behaviors that fundamentally differ from those of traditional software. This shift introduces a new category of integration defects that arise not only from code errors but also from misaligned interactions among LLM-specific artifacts, including prompts, API calls, configurations, and model outputs. However, existing defect localization techniques are ineffective at identifying these LLM-specific integration defects because they fail to capture cross-layer dependencies across heterogeneous artifacts, cannot exploit incomplete or misleading error traces, and lack semantic reasoning capabilities for identifying root causes.
  To address these challenges, we propose LIDL, a multi-agent framework for defect localization in LLM-integrated software. LIDL (1) constructs a code knowledge graph enriched with LLM-aware annotations that represent interaction boundaries across source code, prompts, and configuration files, (2) fuses three complementary sources of error evidence inferred by LLMs to surface candidate defect locations, and (3) applies context-aware validation that uses counterfactual reasoning to distinguish true root causes from propagated symptoms. We evaluate LIDL on 146 real-world defect instances collected from 105 GitHub repositories and 16 agent-based systems. The results show that LIDL significantly outperforms five state-of-the-art baselines across all metrics, achieving a Top-3 accuracy of 0.64 and a MAP of 0.48, which represents a 64.1% improvement over the best-performing baseline. Notably, LIDL achieves these gains while reducing cost by 92.5%, demonstrating both high accuracy and cost efficiency.

</details>


### [12] [Empirical Characterization of Logging Smells in Machine Learning Code](https://arxiv.org/abs/2601.05540)
*Patrick Loic Foalem,Leuson Da Silva,Foutse Khomh,Ettore Merlo,Heng Li*

Main category: cs.SE

TL;DR: 本研究旨在通过挖掘开源ML项目和从业者调查，识别并分析机器学习系统中的日志记录缺陷（logging smells），以改进实际开发中的日志实践。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习组件在软件系统中日益普及，有效的日志记录对可复现性、可追溯性和可观测性至关重要，但目前缺乏对其实际使用情况和常见缺陷的实证研究。

Method: 通过大规模挖掘GitHub上的开源ML仓库识别日志缺陷模式，并结合ML工程师问卷调查评估其相关性、严重性和频率。

Result: 尚未提供具体结果，但预期将建立首个ML系统日志缺陷分类体系并验证其在业界的实际影响。

Conclusion: 尽管研究可能不适用于闭源工业项目，但仍为理解与改进ML开发中的日志实践提供了重要基础。

Abstract: \underline{Context:} Logging is a fundamental yet complex practice in software engineering, essential for monitoring, debugging, and auditing software systems. With the increasing integration of machine learning (ML) components into software systems, effective logging has become critical to ensure reproducibility, traceability, and observability throughout model training and deployment. Although various general-purpose and ML-specific logging frameworks exist, little is known about how these tools are actually used in practice or whether ML practitioners adopt consistent and effective logging strategies. To date, no empirical study has systematically characterized recurring bad logging practices--or logging smells--in ML System. \underline{Goal:} This study aims to empirically identify and characterize logging smells in ML systems, providing an evidence-based understanding of how logging is implemented and challenged in practice. \underline{Method:} We propose to conduct a large-scale mining of open-source ML repositories hosted on GitHub to catalogue recurring logging smells. Subsequently, a practitioner survey involving ML engineers will be conducted to assess the perceived relevance, severity, and frequency of the identified smells. \underline{Limitations:} % While The study's limitations include that While our findings may not be generalizable to closed-source industrial projects, we believe our study provides an essential step toward understanding and improving logging practices in ML development.

</details>


### [13] [Understanding LLM-Driven Test Oracle Generation](https://arxiv.org/abs/2601.05542)
*Adam Bodicoat,Gunel Jahangirova,Valerio Terragni*

Main category: cs.SE

TL;DR: 本文研究了大语言模型（LLMs）在自动生成反映预期行为的测试断言方面的有效性，探讨不同提示策略和上下文输入对生成质量的影响。


<details>
  <summary>Details</summary>
Motivation: 现有自动化单元测试技术多基于已实现行为生成回归断言，未能解决区分程序正确与错误行为的‘断言问题’。

Method: 通过实证研究，评估不同提示策略和上下文信息对LLM生成测试断言质量的影响。

Result: 研究揭示了LLM在生成测试断言中的优势与局限，为Promptware范式下软件开发与测试提供洞见。

Conclusion: LLM有潜力推动自然语言驱动的测试断言生成，但仍需进一步研究以提升其稳定性和适用性。

Abstract: Automated unit test generation aims to improve software quality while reducing the time and effort required for creating tests manually. However, existing techniques primarily generate regression oracles that predicate on the implemented behavior of the class under test. They do not address the oracle problem: the challenge of distinguishing correct from incorrect program behavior. With the rise of Foundation Models (FMs), particularly Large Language Models (LLMs), there is a new opportunity to generate test oracles that reflect intended behavior. This positions LLMs as enablers of Promptware, where software creation and testing are driven by natural-language prompts. This paper presents an empirical study on the effectiveness of LLMs in generating test oracles that expose software failures. We investigate how different prompting strategies and levels of contextual input impact the quality of LLM-generated oracles. Our findings offer insights into the strengths and limitations of LLM-based oracle generation in the FM era, improving our understanding of their capabilities and fostering future research in this area.

</details>


### [14] [An Empirical Study of Policy-as-Code Adoption in Open-Source Software Projects](https://arxiv.org/abs/2601.05555)
*Patrick Loic Foalem,Foutse Khomh,Leuson Da Silva,Ettore Merlo*

Main category: cs.SE

TL;DR: 本文首次大规模研究开源软件中Policy-as-Code工具的实际使用情况，揭示其在治理、配置控制等场景的多样化应用，并构建分类体系以指导实践与工具改进。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对Policy-as-Code工具在真实开发实践中如何使用的实证理解，阻碍了其有效应用与工具优化。

Method: 分析399个GitHub仓库中9种主流PaC工具，结合定量统计与定性政策文件分析，并采用经专家验证的LLM辅助分类方法构建5类15子类的使用分类体系。

Result: PaC工具常用于早期项目，侧重治理、配置与文档；发现其在MLOps中的新兴应用及OPA与Gatekeeper等工具的强共用模式；分类体系揭示重复出现的治理意图。

Conclusion: 研究为从业者和工具开发者提供可操作洞见，强调实际使用模式，推动工具互操作性改进，奠定未来PaC实证研究基础。

Abstract: \textbf{Context:} Policy-as-Code (PaC) has become a foundational approach for embedding governance, compliance, and security requirements directly into software systems. While organizations increasingly adopt PaC tools, the software engineering community lacks an empirical understanding of how these tools are used in real-world development practices.
  \textbf{Objective:} This paper aims to bridge this gap by conducting the first large-scale study of PaC usage in open-source software. Our goal is to characterize how PaC tools are adopted, what purposes they serve, and what governance activities they support across diverse software ecosystems.
  \textbf{Method:} We analyzed 399 GitHub repositories using nine widely adopted PaC tools. Our mixed-methods approach combines quantitative analysis of tool usage and project characteristics with a qualitative investigation of policy files. We further employ a Large Language Model (LLM)--assisted classification pipeline, refined through expert validation, to derive a taxonomy of PaC usage consisting of 5 categories and 15 sub-categories.
  \textbf{Results:} Our study reveals substantial diversity in PaC adoption. PaC tools are frequently used in early-stage projects and are heavily oriented toward governance, configuration control, and documentation. We also observe emerging PaC usage in MLOps pipelines and strong co-usage patterns, such as between OPA and Gatekeeper. Our taxonomy highlights recurring governance intents.
  \textbf{Conclusion:} Our findings offer actionable insights for practitioners and tool developers. They highlight concrete usage patterns, emphasize actual PaC usage, and motivate opportunities for improving tool interoperability. This study lays the empirical foundation for future research on PaC practices and their role in ensuring trustworthy, compliant software systems.

</details>


### [15] [Package-Aware Approach for Repository-Level Code Completion in Pharo](https://arxiv.org/abs/2601.05617)
*Omar Abedelkader,Stéphane Ducasse,Oleksandr Zaitsev,Romain Robbes,Guillermo Polito*

Main category: cs.SE

TL;DR: 本文提出一种新的启发式方法，使Pharo的代码补全引擎能感知包结构，从而提升全局名称建议的相关性。


<details>
  <summary>Details</summary>
Motivation: 现有Pharo补全引擎未考虑仓库结构，对所有全局名称一视同仁，导致相关性不足。

Method: 新启发式按层级搜索：从请求类所在包开始，扩展至同仓库其他包，最后查询全局命名空间。

Result: 初步实验显示，平均倒数排名（MRR）提升，证明包感知补全比原有全局扁平方法更准确。

Conclusion: 引入包结构感知机制可有效提高代码补全系统的推荐质量。

Abstract: Pharo offers a sophisticated completion engine based on semantic heuristics, which coordinates specific fetchers within a lazy architecture. These heuristics can be recomposed to support various activities (e.g., live programming or history usage navigation). While this system is powerful, it does not account for the repository structure when suggesting global names such as class names, class variables, or global variables. As a result, it does not prioritize classes within the same package or project, treating all global names equally. In this paper, we present a new heuristic that addresses this limitation. Our approach searches variable names in a structured manner: it begins with the package of the requesting class, then expands to other packages within the same repository, and finally considers the global namespace. We describe the logic behind this heuristic and evaluate it against the default semantic heuristic and one that directly queries the global namespace. Preliminary results indicate that the Mean Reciprocal Rank (MRR) improves, confirming that package-awareness completions deliver more accurate and relevant suggestions than the previous flat global approach.

</details>


### [16] [A Large Scale Empirical Analysis on the Adherence Gap between Standards and Tools in SBOM](https://arxiv.org/abs/2601.05622)
*Chengjie Wang,Jingzheng Wu,Hao Lyu,Xiang Ling,Tianyue Luo,Yanjun Wu,Chen Zhao*

Main category: cs.SE

TL;DR: 本文首次对SBOM工具的合规性进行了大规模实证分析，发现当前工具在政策支持、一致性及信息准确性方面存在严重不足，并提出改进方案。


<details>
  <summary>Details</summary>
Motivation: 现有SBOM工具缺乏对其标准符合性的系统研究，可能导致合规失败与使用中断。

Method: 采用自动化评估框架SAP，分两阶段对6个工具生成的55,444份SBOM进行基线与纵向追踪分析。

Result: 发现工具普遍存在政策支持不足、跨工具一致性低（最低7.84%）、纵向版本不一致、许可证识别准确率低于20%等问题。

Conclusion: 当前SBOM工具存在根本性局限，需针对性改进以提升供应链透明度与安全性。

Abstract: A Software Bill of Materials (SBOM) is a machine-readable artifact that systematically organizes software information, enhancing supply chain transparency and security. To facilitate the exchange and utilization of SBOMs, organizations such as the Linux Foundation and OWASP have proposed SBOM standards. Following standards, organizations have developed tools for generating and utilizing SBOMs. However, limited research has examined the adherence of these SBOM tools to standard specifications, a gap that could lead to compliance failures and disruptions in SBOM utilization. This paper presents the first large-scale, two-stage empirical analysis of the adherence gap, using our automated evaluation framework, SAP. The evaluation, comprising a baseline evaluation and a one-year longitudinal follow-up, covers 55,444 SBOMs generated by six SBOM tools from 3,287 real-world repositories. Our analysis reveals persistent, fundamental limitations in current SBOM tools: (1) inadequate compliance support with policy requirements; (2) poor tool consistencies, including inter-tool consistency rates as low as 7.84% to 12.77% for package detection across languages, and significant longitudinal inconsistency, where tools show low consistency with their own prior versions; and (3) mediocre to poor accuracy for detailed software information, e.g., accuracy of package licenses below 20%. We analyze the root causes of these gaps and provide practical solutions. All the code, replication docker image, evaluation results are open sourced at [GitHub](https://github.com/dw763j/SAP) and [Zenodo](https://doi.org/10.5281/zenodo.14998624) for further researches.

</details>


### [17] [Tracing Stereotypes in Pre-trained Transformers: From Biased Neurons to Fairer Models](https://arxiv.org/abs/2601.05663)
*Gianmario Voria,Moses Openja,Foutse Khomh,Gemma Catolino,Fabio Palomba*

Main category: cs.SE

TL;DR: 通过识别和抑制预训练Transformer模型中的偏见神经元，可以在最小性能损失下有效减少软件工程任务中的社会偏见。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer语言模型在软件工程中可能复制或放大社会偏见的问题，提升AI系统的公平性。

Method: 构建包含九类偏见关系的数据集，利用神经元归因策略定位并抑制BERT模型中的偏见神经元。

Result: 偏见知识集中于少量神经元，抑制这些神经元可显著降低偏见且对任务性能影响极小。

Conclusion: 偏见可在神经元层面被追踪与缓解，为软件工程提供了一种可解释的公平性改进方法。

Abstract: The advent of transformer-based language models has reshaped how AI systems process and generate text. In software engineering (SE), these models now support diverse activities, accelerating automation and decision-making. Yet, evidence shows that these models can reproduce or amplify social biases, raising fairness concerns. Recent work on neuron editing has shown that internal activations in pre-trained transformers can be traced and modified to alter model behavior. Building on the concept of knowledge neurons, neurons that encode factual information, we hypothesize the existence of biased neurons that capture stereotypical associations within pre-trained transformers. To test this hypothesis, we build a dataset of biased relations, i.e., triplets encoding stereotypes across nine bias types, and adapt neuron attribution strategies to trace and suppress biased neurons in BERT models. We then assess the impact of suppression on SE tasks. Our findings show that biased knowledge is localized within small neuron subsets, and suppressing them substantially reduces bias with minimal performance loss. This demonstrates that bias in transformers can be traced and mitigated at the neuron level, offering an interpretable approach to fairness in SE.

</details>


### [18] [Drivora: A Unified and Extensible Infrastructure for Search-based Autonomous Driving Testing](https://arxiv.org/abs/2601.05685)
*Mingfei Cheng,Lionel Briand,Yuan Zhou*

Main category: cs.SE

TL;DR: Drivora是一个基于CARLA的统一可扩展自动驾驶系统测试框架，支持多ADS集成与高效并行仿真。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶测试方法依赖异构框架，难以复用和适配不同环境。

Method: 提出统一场景定义OpenScenario，解耦测试引擎、场景执行与ADS集成，采用进化算法搜索场景并支持并行仿真。

Result: 支持12种ADS接入，提供开源工具，提升测试灵活性与硬件利用率。

Conclusion: Drivora有效解决了现有测试方法的兼容性与扩展性问题，推动自动驾驶安全评估标准化。

Abstract: Search-based testing is critical for evaluating the safety and reliability of autonomous driving systems (ADSs). However, existing approaches are often built on heterogeneous frameworks (e.g., distinct scenario spaces, simulators, and ADSs), which require considerable effort to reuse and adapt across different settings. To address these challenges, we present Drivora, a unified and extensible infrastructure for search-based ADS testing built on the widely used CARLA simulator. Drivora introduces a unified scenario definition, OpenScenario, that specifies scenarios using low-level, actionable parameters to ensure compatibility with existing methods while supporting extensibility to new testing designs (e.g., multi-autonomous-vehicle testing). On top of this, Drivora decouples the testing engine, scenario execution, and ADS integration. The testing engine leverages evolutionary computation to explore new scenarios and supports flexible customization of core components. The scenario execution can run arbitrary scenarios using a parallel execution mechanism that maximizes hardware utilization for large-scale batch simulation. For ADS integration, Drivora provides access to 12 ADSs through a unified interface, streamlining configuration and simplifying the incorporation of new ADSs. Our tools are publicly available at https://github.com/MingfeiCheng/Drivora.

</details>


### [19] [AIBoMGen: Generating an AI Bill of Materials for Secure, Transparent, and Compliant Model Training](https://arxiv.org/abs/2601.05703)
*Wiebe Vandendriessche,Jordi Thijsman,Laurens D'hooge,Bruno Volckaert,Merlijn Sebrechts*

Main category: cs.SE

TL;DR: AIBoMGen平台通过自动生成带签名的AIBOM，确保AI模型训练过程的透明性与安全性，支持合规需求。


<details>
  <summary>Details</summary>
Motivation: 当前复杂AI系统的快速应用缺乏透明性、安全性和合规性保障工具。

Method: 构建AIBoMGen平台，利用加密哈希、数字签名和in-toto证明，在训练过程中自动捕获数据集、模型元数据和环境信息，强制生成可验证的AIBOM。

Result: 系统能可靠检测所有制品的未授权修改，且生成AIBOM性能开销可忽略。

Conclusion: AIBoMGen为构建安全透明的AI生态系统提供了基础，有助于满足如欧盟AI法案等监管框架要求。

Abstract: The rapid adoption of complex AI systems has outpaced the development of tools to ensure their transparency, security, and regulatory compliance. In this paper, the AI Bill of Materials (AIBOM), an extension of the Software Bill of Materials (SBOM), is introduced as a standardized, verifiable record of trained AI models and their environments. Our proof-of-concept platform, AIBoMGen, automates the generation of signed AIBOMs by capturing datasets, model metadata, and environment details during training. The training platform acts as a neutral, third-party observer and root of trust. It enforces verifiable AIBOM creation for every job. The system uses cryptographic hashing, digital signatures, and in-toto attestations to ensure integrity and protect against threats such as artifact tampering by dishonest model creators. Our evaluation demonstrates that AIBoMGen reliably detects unauthorized modifications to all artifacts and can generate AIBOMs with negligible performance overhead. These results highlight the potential of AIBoMGen as a foundational step toward building secure and transparent AI ecosystems, enabling compliance with regulatory frameworks like the EUs AI Act.

</details>


### [20] [From Issues to Insights: RAG-based Explanation Generation from Software Engineering Artifacts](https://arxiv.org/abs/2601.05721)
*Daniel Pöttgen,Mersedeh Sadeghi,Max Unterbusch,Andreas Vogelsang*

Main category: cs.SE

TL;DR: 本文首次提出利用检索增强生成（RAG）方法从问题跟踪系统中自动生成软件行为解释，实证表明其与人工解释一致性达90%，且具备高忠实度和指令遵循性。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统日益复杂，传统文档难以提供准确、情境化的解释，而问题跟踪系统蕴含丰富且持续更新的开发知识，尚未被用于可解释性研究。

Method: 采用开源工具与语言模型构建RAG原型系统，从GitHub问题数据中提取结构化信息生成解释。

Result: 在示例项目上评估显示，系统生成解释与人工撰写的一致性达90%，并展现出强忠实性和指令遵循能力。

Conclusion: RAG方法可将可解释性扩展至更广泛的软件系统，前提是存在可用的问题跟踪数据，从而提升系统行为的可理解性与透明度。

Abstract: The increasing complexity of modern software systems has made understanding their behavior increasingly challenging, driving the need for explainability to improve transparency and user trust. Traditional documentation is often outdated or incomplete, making it difficult to derive accurate, context-specific explanations. Meanwhile, issue-tracking systems capture rich and continuously updated development knowledge, but their potential for explainability remains untapped. With this work, we are the first to apply a Retrieval-Augmented Generation (RAG) approach for generating explanations from issue-tracking data. Our proof-of-concept system is implemented using open-source tools and language models, demonstrating the feasibility of leveraging structured issue data for explanation generation. Evaluating our approach on an exemplary project's set of GitHub issues, we achieve 90% alignment with human-written explanations. Additionally, our system exhibits strong faithfulness and instruction adherence, ensuring reliable and grounded explanations. These findings suggest that RAG-based methods can extend explainability beyond black-box ML models to a broader range of software systems, provided that issue-tracking data is available - making system behavior more accessible and interpretable.

</details>


### [21] [StriderSPD: Structure-Guided Joint Representation Learning for Binary Security Patch Detection](https://arxiv.org/abs/2601.05772)
*Qingyuan Li,Chenchen Yu,Chuanyi Li,Xin-Cheng Wen,Cheryl Lee,Cuiyun Gao,Bin Luo*

Main category: cs.SE

TL;DR: StriderSPD 是一种结合图结构与大语言模型的二进制安全补丁检测框架，通过结构引导提升闭源软件补丁识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有二进制安全补丁检测方法在语义表达和结构提取上存在不足，且评估数据集缺乏真实闭源场景代表性。

Method: 提出 StriderSPD 框架，在大语言模型中引入图分支，通过适配器对齐汇编与伪代码表征，并采用两阶段训练策略解决参数不平衡问题。

Result: 在全新构建的跨项目、跨领域二进制基准测试集上，StriderSPD 表现出优于现有方法的检测性能。

Conclusion: StriderSPD 有效融合结构信息与语言模型，为闭源软件安全补丁检测提供更准确、更贴近现实的解决方案。

Abstract: Vulnerabilities severely threaten software systems, making the timely application of security patches crucial for mitigating attacks. However, software vendors often silently patch vulnerabilities with limited disclosure, where Security Patch Detection (SPD) comes to protect software assets. Recently, most SPD studies have targeted Open-Source Software (OSS), yet a large portion of real-world software is closed-source, where patches are distributed as binaries without accessible source code. The limited binary SPD approaches often lift binaries to abstraction levels, i.e., assembly code or pseudo-code. However, assembly code is register-based instructions conveying limited semantics, while pseudo-code lacks parser-compatible grammar to extract structure, both hindering accurate vulnerability-fix representation learning. In addition, previous studies often obtain training and testing data from the same project for evaluation, which fails to reflect closed-source conditions. To alleviate the above challenges, we propose \textbf{\textit{StriderSPD}}, a \underline{Str}ucture-gu\underline{ide}d joint \underline{r}epresentation \underline{SPD} framework of binary code that integrates a graph branch into a large language model (LLM), leveraging structural information to guide the LLM in identifying security patches. Our novel design of the adapters in the graph branch effectively aligns the representations between assembly code and pseudo-code at the LLM's token level. We further present a two-stage training strategy to address the optimization imbalance caused by the large parameter disparity between StriderSPD's two branches, which enables proper branch fitting. To enable more realistic evaluation, we construct a binary SPD benchmark that is disjoint from prior datasets in both projects and domains and extensively evaluate StriderSPD on this benchmark.

</details>


### [22] [SSR: Safeguarding Staking Rewards by Defining and Detecting Logical Defects in DeFi Staking](https://arxiv.org/abs/2601.05827)
*Zewei Lin,Jiachi Chen,Jingwen Zhang,Zexu Wang,Yuming Feng,Weizhe Zhang,Zibin Zheng*

Main category: cs.SE

TL;DR: 本文提出SSR工具，利用大语言模型检测DeFi质押合约中的逻辑缺陷，准确率高且在真实合约中发现22.24%存在缺陷。


<details>
  <summary>Details</summary>
Motivation: DeFi质押中的逻辑缺陷可能被攻击者利用获取不当奖励，亟需系统化检测方法。

Method: 通过分析64起安全事件与144份审计报告归纳六类缺陷，构建基于LLM的静态分析工具SSR进行语义建模与缺陷识别。

Result: SSR在测试集上达到92.31%精确率、87.92%召回率；在15,992个真实合约中检出3,557个（22.24%）含缺陷合约。

Conclusion: SSR能有效识别DeFi质押合约中的逻辑缺陷，为提升智能合约安全性提供实用工具。

Abstract: Decentralized Finance (DeFi) staking is one of the most prominent applications within the DeFi ecosystem, where DeFi projects enable users to stake tokens on the platform and reward participants with additional tokens. However, logical defects in DeFi staking could enable attackers to claim unwarranted rewards by manipulating reward amounts, repeatedly claiming rewards, or engaging in other malicious actions. To mitigate these threats, we conducted the first study focused on defining and detecting logical defects in DeFi staking. Through the analysis of 64 security incidents and 144 audit reports, we identified six distinct types of logical defects, each accompanied by detailed descriptions and code examples. Building on this empirical research, we developed SSR (Safeguarding Staking Reward), a static analysis tool designed to detect logical defects in DeFi staking contracts. SSR utilizes a large language model (LLM) to extract fundamental information about staking logic and constructs a DeFi staking model. It then identifies logical defects by analyzing the model and the associated semantic features. We constructed a ground truth dataset based on known security incidents and audit reports to evaluate the effectiveness of SSR. The results indicate that SSR achieves an overall precision of 92.31%, a recall of 87.92%, and an F1-score of 88.85%. Additionally, to assess the prevalence of logical defects in real-world smart contracts, we compiled a large-scale dataset of 15,992 DeFi staking contracts. SSR detected that 3,557 (22.24%) of these contracts contained at least one logical defect.

</details>
