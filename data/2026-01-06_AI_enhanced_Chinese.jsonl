{"id": "2601.00974", "categories": ["cs.NI", "cs.DM", "cs.PF", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.00974", "abs": "https://arxiv.org/abs/2601.00974", "authors": ["Inna Voloshchuk", "Hayden Jananthan", "Chansup Byun", "Jeremy Kepner"], "title": "Improving the Graph Challenge Reference Implementation", "comment": "Presented at IEEE MIT URTC 2025", "summary": "The MIT/IEEE/Amazon Graph Challenge provides a venue for individuals and teams to showcase new innovations in large-scale graph and sparse data analysis. The Anonymized Network Sensing Graph Challenge processes over 100 billion network packets to construct privacy-preserving traffic matrices, with a GraphBLAS reference implementation demonstrating how hypersparse matrices can be applied to this problem. This work presents a refactoring and benchmarking of a section of the reference code to improve clarity, adaptability, and performance. The original Python implementation spanning approximately 1000 lines across 3 files has been streamlined to 325 lines across two focused modules, achieving a 67% reduction in code size while maintaining full functionality. Using pMatlab and pPython distributed array programming libraries, the addition of parallel maps allowed for parallel benchmarking of the data. Scalable performance is demonstrated for large-scale summation and analysis of traffic matrices. The resulting implementation increases the potential impact of the Graph Challenge by providing a clear and efficient foundation for participants.", "AI": {"tldr": "\u672c\u6587\u91cd\u6784\u5e76\u4f18\u5316\u4e86MIT/IEEE/Amazon\u56fe\u6311\u6218\u8d5b\u7684\u53c2\u8003\u4ee3\u7801\uff0c\u901a\u8fc7\u7cbe\u7b80\u4ee3\u7801\u3001\u5f15\u5165\u5e76\u884c\u8ba1\u7b97\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u4e0e\u53ef\u8bfb\u6027\u3002", "motivation": "\u63d0\u5347\u56fe\u6311\u6218\u8d5b\u53c2\u8003\u4ee3\u7801\u7684\u6e05\u6670\u5ea6\u3001\u9002\u5e94\u6027\u548c\u6027\u80fd\uff0c\u4ee5\u589e\u5f3a\u5176\u5bf9\u53c2\u8d5b\u8005\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "method": "\u5c06\u539fPython\u5b9e\u73b0\u4ece\u7ea61000\u884c\u7cbe\u7b80\u81f3325\u884c\uff0c\u5e76\u5229\u7528pMatlab\u548cpPython\u5e93\u5b9e\u73b0\u5e76\u884c\u6620\u5c04\u4e0e\u5206\u5e03\u5f0f\u8ba1\u7b97\u3002", "result": "\u4ee3\u7801\u89c4\u6a21\u51cf\u5c1167%\uff0c\u529f\u80fd\u5b8c\u6574\u4fdd\u7559\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u6d41\u91cf\u77e9\u9635\u6c42\u548c\u4e0e\u5206\u6790\u4e2d\u5c55\u73b0\u53ef\u6269\u5c55\u6027\u80fd\u3002", "conclusion": "\u91cd\u6784\u540e\u7684\u5b9e\u73b0\u4e3a\u56fe\u6311\u6218\u8d5b\u53c2\u4e0e\u8005\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u9ad8\u6548\u7684\u57fa\u51c6\uff0c\u63d0\u5347\u4e86\u8d5b\u4e8b\u5f71\u54cd\u529b\u3002"}}
{"id": "2601.01086", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.01086", "abs": "https://arxiv.org/abs/2601.01086", "authors": ["Jianpeng Qi", "Chao Liu", "Chengrui Wang", "Rui Wang", "Junyu Dong", "Yanwei Yu"], "title": "Decision-Aware Semantic State Synchronization in Compute-First Networking", "comment": "12 pages, 9 figures", "summary": "In Compute-First Networking (CFN), an Access Point (AP) makes task offloading decisions based on resource state information reported by a Service Node (SN). A fundamental challenge arises from the trade-off between update overhead and decision accuracy: Frequent state updates consume limited network resources, while infrequent updates lead to stale state views and degraded task performance, especially under high system load. Existing approaches based on periodic updates or Age of Information (AoI) mainly focus on temporal freshness and often overlook whether a state change is actually relevant to offloading decisions. This paper proposes SenseCFN, a decision-aware state synchronization framework for CFN. Instead of synchronizing raw resource states, SenseCFN focuses on identifying state changes that are likely to alter offloading decisions. To this end, we introduce a lightweight semantic state representation that captures decision-relevant system characteristics, along with a Semantic Deviation Index (SDI) to quantify the impact of state shifts on decision outcomes. Based on SDI, the SN triggers updates only when significant decision-impacting changes are detected. Meanwhile, the AP performs offloading decisions using cached semantic states with explicit awareness of potential staleness. The update and offloading policies are jointly optimized using a centralized training with distributed execution (CTDE) approach. Simulation results show that SenseCFN maintains a task success rate of up to 99.6% in saturation-prone scenarios, outperforming baseline methods by more than 25%, while reducing status update frequency by approximately 70% to 96%. These results indicate that decision-aware state synchronization provides an effective and practical alternative to purely time-based update strategies in CFN.", "AI": {"tldr": "SenseCFN\u662f\u4e00\u79cd\u9762\u5411\u51b3\u7b56\u611f\u77e5\u7684\u72b6\u6001\u540c\u6b65\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u72b6\u6001\u8868\u793a\u4e0e\u8bed\u4e49\u504f\u5dee\u6307\u6570\uff08SDI\uff09\u89e6\u53d1\u66f4\u65b0\uff0c\u5728\u4fdd\u8bc1\u4efb\u52a1\u6210\u529f\u7387\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u66f4\u65b0\u9891\u7387\u3002", "motivation": "\u73b0\u6709CFN\u7cfb\u7edf\u4e2d\u57fa\u4e8e\u5468\u671f\u6216\u4fe1\u606f\u5e74\u9f84\u7684\u72b6\u6001\u540c\u6b65\u7b56\u7565\u5ffd\u89c6\u4e86\u72b6\u6001\u53d8\u5316\u5bf9\u5378\u8f7d\u51b3\u7b56\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d6a\u8d39\u6216\u51b3\u7b56\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u8bed\u4e49\u72b6\u6001\u8868\u793a\u548cSDI\u6307\u6807\uff0c\u4ec5\u5728\u51b3\u7b56\u76f8\u5173\u72b6\u6001\u663e\u8457\u53d8\u5316\u65f6\u89e6\u53d1\u66f4\u65b0\uff1bAP\u7aef\u5229\u7528\u7f13\u5b58\u8bed\u4e49\u72b6\u6001\u5e76\u611f\u77e5\u5176\u9648\u65e7\u6027\u8fdb\u884c\u51b3\u7b56\uff1b\u91c7\u7528CTDE\u8054\u5408\u4f18\u5316\u66f4\u65b0\u4e0e\u5378\u8f7d\u7b56\u7565\u3002", "result": "\u4eff\u771f\u8868\u660e\uff0c\u5728\u9ad8\u8d1f\u8f7d\u573a\u666f\u4e0b\u4efb\u52a1\u6210\u529f\u7387\u53ef\u8fbe99.6%\uff0c\u8f83\u57fa\u7ebf\u65b9\u6cd5\u63d0\u5347\u8d8525%\uff0c\u540c\u65f6\u66f4\u65b0\u9891\u7387\u964d\u4f4e70%\u81f396%\u3002", "conclusion": "\u51b3\u7b56\u611f\u77e5\u7684\u72b6\u6001\u540c\u6b65\u673a\u5236\u4e3aCFN\u63d0\u4f9b\u4e86\u4e00\u79cd\u6bd4\u7eaf\u65f6\u95f4\u9a71\u52a8\u7b56\u7565\u66f4\u9ad8\u6548\u5b9e\u7528\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2601.01031", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.01031", "abs": "https://arxiv.org/abs/2601.01031", "authors": ["Bharadwaj Veeravalli"], "title": "A Multi-Port Concurrent Communication Model for handling Compute Intensive Tasks on Distributed Satellite System Constellations", "comment": null, "summary": "We develop an integrated Multi-Port Concurrent Communication Divisible Load Theory (MPCC-DLT) framework for relay-centric distributed satellite systems (DSS), capturing concurrent data dissemination, parallel computation, and result return under heterogeneous onboard processing and inter-satellite link conditions. We propose a formulation that yields closed-form expressions for optimal load allocation and completion time that explicitly quantify the joint impact of computation speed, link bandwidth, and result-size overhead. We further derive deadline feasibility conditions that enable explicit sizing of cooperative satellite clusters to meet time-critical task requirements. Extensive simulation results demonstrate that highly distributable tasks achieve substantial latency reduction, while communication-heavy tasks exhibit diminishing returns due to result-transfer overheads. To bridge theory and practice, we extend the MPCC-DLT framework with a real-time admission control mechanism that handles stochastic task arrivals and deadline constraints, enabling blocking-aware operation. Our real-time simulations illustrate how task structure and system parameters jointly govern deadline satisfaction and operating regimes. Overall, this work provides the first analytically tractable MPCC-DLT model for distributed satellite systems and offers actionable insights for application-aware scheduling and system-level design of future satellite constellations.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u536b\u661f\u7cfb\u7edf\u7684\u591a\u7aef\u53e3\u5e76\u53d1\u901a\u4fe1\u53ef\u5206\u8d1f\u8f7d\u7406\u8bba\u6a21\u578b\uff0c\u4f18\u5316\u4efb\u52a1\u5206\u914d\u4e0e\u5b8c\u6210\u65f6\u95f4\uff0c\u5e76\u652f\u6301\u5b9e\u65f6\u51c6\u5165\u63a7\u5236\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u536b\u661f\u7cfb\u7edf\u4e2d\u5f02\u6784\u8ba1\u7b97\u4e0e\u901a\u4fe1\u6761\u4ef6\u4e0b\u4efb\u52a1\u8c03\u5ea6\u4e0e\u65f6\u95f4\u7ea6\u675f\u7684\u6311\u6218\u3002", "method": "\u6784\u5efaMPCC-DLT\u6846\u67b6\uff0c\u63a8\u5bfc\u95ed\u5f0f\u6700\u4f18\u8d1f\u8f7d\u5206\u914d\u4e0e\u622a\u6b62\u671f\u53ef\u884c\u6027\u6761\u4ef6\uff0c\u7ed3\u5408\u4eff\u771f\u4e0e\u5b9e\u65f6\u51c6\u5165\u63a7\u5236\u673a\u5236\u9a8c\u8bc1\u3002", "result": "\u9ad8\u5ea6\u53ef\u5206\u4efb\u52a1\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\uff0c\u901a\u4fe1\u5bc6\u96c6\u578b\u4efb\u52a1\u56e0\u7ed3\u679c\u56de\u4f20\u5f00\u9500\u6536\u76ca\u9012\u51cf\uff1b\u7cfb\u7edf\u53c2\u6570\u51b3\u5b9a\u622a\u6b62\u671f\u6ee1\u8db3\u7387\u4e0e\u8fd0\u884c\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u672a\u6765\u536b\u661f\u661f\u5ea7\u7684\u5e94\u7528\u611f\u77e5\u8c03\u5ea6\u4e0e\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u652f\u6491\u4e0e\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2601.01042", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01042", "abs": "https://arxiv.org/abs/2601.01042", "authors": ["Zixiao Zhao", "Yanjie Jiang", "Hui Liu", "Kui Liu", "Lu Zhang"], "title": "SeRe: A Security-Related Code Review Dataset Aligned with Real-World Review Activities", "comment": "Accepted by ICSE 2026", "summary": "Software security vulnerabilities can lead to severe consequences, making early detection essential. Although code review serves as a critical defense mechanism against security flaws, relevant feedback remains scarce due to limited attention to security issues or a lack of expertise among reviewers. Existing datasets and studies primarily focus on general-purpose code review comments, either lacking security-specific annotations or being too limited in scale to support large-scale research. To bridge this gap, we introduce \\textbf{SeRe}, a \\textbf{security-related code review dataset}, constructed using an active learning-based ensemble classification approach. The proposed approach iteratively refines model predictions through human annotations, achieving high precision while maintaining reasonable recall. Using the fine-tuned ensemble classifier, we extracted 6,732 security-related reviews from 373,824 raw review instances, ensuring representativeness across multiple programming languages. Statistical analysis indicates that SeRe generally \\textbf{aligns with real-world security-related review distribution}. To assess both the utility of SeRe and the effectiveness of existing code review comment generation approaches, we benchmark state-of-the-art approaches on security-related feedback generation. By releasing SeRe along with our benchmark results, we aim to advance research in automated security-focused code review and contribute to the development of more effective secure software engineering practices.", "AI": {"tldr": "\u63d0\u51faSeRe\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u65b9\u6cd5\u4ece\u5927\u91cf\u4ee3\u7801\u8bc4\u5ba1\u4e2d\u63d0\u53d6\u5b89\u5168\u76f8\u5173\u8bc4\u8bba\uff0c\u4ee5\u652f\u6301\u81ea\u52a8\u5316\u5b89\u5168\u8bc4\u5ba1\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u8bc4\u5ba1\u6570\u636e\u7f3a\u4e4f\u5b89\u5168\u6807\u6ce8\u6216\u89c4\u6a21\u4e0d\u8db3\uff0c\u96be\u4ee5\u652f\u6491\u5927\u89c4\u6a21\u5b89\u5168\u7814\u7a76\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4e3b\u52a8\u5b66\u4e60\u7684\u96c6\u6210\u5206\u7c7b\u65b9\u6cd5\uff0c\u7ed3\u5408\u4eba\u5de5\u6807\u6ce8\u8fed\u4ee3\u4f18\u5316\u6a21\u578b\uff0c\u4ece\u539f\u59cb\u8bc4\u5ba1\u4e2d\u7b5b\u9009\u5b89\u5168\u76f8\u5173\u8bc4\u8bba\u3002", "result": "\u6784\u5efa\u5305\u542b6732\u6761\u5b89\u5168\u8bc4\u5ba1\u7684\u6570\u636e\u96c6SeRe\uff0c\u8986\u76d6\u591a\u8bed\u8a00\u4e14\u7b26\u5408\u771f\u5b9e\u5206\u5e03\uff0c\u5e76\u5b8c\u6210\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "SeRe\u6709\u52a9\u4e8e\u63a8\u52a8\u81ea\u52a8\u5316\u5b89\u5168\u4ee3\u7801\u8bc4\u5ba1\u7814\u7a76\uff0c\u63d0\u5347\u8f6f\u4ef6\u5de5\u7a0b\u5b89\u5168\u6027\u5b9e\u8df5\u3002"}}
{"id": "2601.01581", "categories": ["cs.MA", "cs.AI", "cs.GT", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.01581", "abs": "https://arxiv.org/abs/2601.01581", "authors": ["Rishav Sen", "Fangqi Liu", "Jose Paolo Talusan", "Ava Pettet", "Yoshinori Suzue", "Mark Bailey", "Ayan Mukhopadhyay", "Abhishek Dubey"], "title": "CONSENT: A Negotiation Framework for Leveraging User Flexibility in Vehicle-to-Building Charging under Uncertainty", "comment": "Submitted to AAMAS 2026. 25 pages, 13 figures, 14 tables", "summary": "The growth of Electric Vehicles (EVs) creates a conflict in vehicle-to-building (V2B) settings between building operators, who face high energy costs from uncoordinated charging, and drivers, who prioritize convenience and a full charge. To resolve this, we propose a negotiation-based framework that, by design, guarantees voluntary participation, strategy-proofness, and budget feasibility. It transforms EV charging into a strategic resource by offering drivers a range of incentive-backed options for modest flexibility in their departure time or requested state of charge (SoC). Our framework is calibrated with user survey data and validated using real operational data from a commercial building and an EV manufacturer. Simulations show that our negotiation protocol creates a mutually beneficial outcome: lowering the building operator's costs by over 3.5\\% compared to an optimized, non-negotiating smart charging policy, while simultaneously reducing user charging expenses by 22\\% below the utility's retail energy rate. By aligning operator and EV user objectives, our framework provides a strategic bridge between energy and mobility systems, transforming EV charging from a source of operational friction into a platform for collaboration and shared savings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u534f\u5546\u7684\u7535\u52a8\u6c7d\u8f66\u5145\u7535\u6846\u67b6\uff0c\u5b9e\u73b0\u5efa\u7b51\u8fd0\u8425\u5546\u4e0e\u7528\u6237\u53cc\u8d62\u3002", "motivation": "\u89e3\u51b3\u5efa\u7b51\u8fd0\u8425\u5546\u9ad8\u80fd\u8017\u6210\u672c\u4e0e\u7528\u6237\u5145\u7535\u4fbf\u5229\u6027\u4e4b\u95f4\u7684\u51b2\u7a81\u3002", "method": "\u8bbe\u8ba1\u4fdd\u8bc1\u81ea\u613f\u53c2\u4e0e\u3001\u9632\u7b56\u7565\u6027\u548c\u9884\u7b97\u53ef\u884c\u6027\u7684\u534f\u5546\u673a\u5236\uff0c\u7ed3\u5408\u7528\u6237\u8c03\u7814\u4e0e\u771f\u5b9e\u6570\u636e\u9a8c\u8bc1\u3002", "result": "\u5efa\u7b51\u8fd0\u8425\u6210\u672c\u964d\u4f4e\u8d853.5%\uff0c\u7528\u6237\u5145\u7535\u8d39\u7528\u51cf\u5c1122%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c06EV\u5145\u7535\u4ece\u8fd0\u8425\u6469\u64e6\u6e90\u8f6c\u53d8\u4e3a\u534f\u4f5c\u4e0e\u5171\u4eab\u8282\u7ea6\u5e73\u53f0\u3002"}}
{"id": "2601.01125", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.01125", "abs": "https://arxiv.org/abs/2601.01125", "authors": ["Mohammad Goudarzi", "Arash Shaghaghi", "Zhiyu Wang", "Rajkumar Buyya"], "title": "Performance and Security Aware Distributed Service Placement in Fog Computing", "comment": null, "summary": "The rapid proliferation of IoT applications has intensified the demand for efficient and secure service placement in Fog computing. However, heterogeneous resources, dynamic workloads, and diverse security requirements make optimal service placement highly challenging. Most solutions focus primarily on performance metrics while overlooking the security implications of deployment decisions. This paper proposes a Security and Performance-Aware Distributed Deep Reinforcement Learning (SPA-DDRL) framework for joint optimization of service response time and security compliance in Fog computing. The problem is formulated as a weighted multi-objective optimization task, minimizing latency while maximizing a security score derived from the security capabilities of Fog nodes. The security score features a new three-tier hierarchy, where configuration-level checks verify proper settings, capability-level assessments evaluate the resource security features, and control-level evaluations enforce stringent policies, thereby ensuring compliant solutions that align with performance objectives. SPA-DDRL adopts a distributed broker-learner architecture where multiple brokers perform autonomous service-placement decisions and a centralized learner coordinates global policy optimization through shared prioritized experiences. It integrates three key improvements, including Long Short-Term Memory networks, Prioritized Experience Replay, and off-policy correction mechanisms to improve the agent's performance. Experiments based on real IoT workloads show that SPA-DDRL significantly improves both service response time and placement security compared to current approaches, achieving a 16.3% improvement in response time and a 33% faster convergence rate. It also maintains consistent, feasible, security-compliant solutions across all system scales, while baseline techniques fail or show performance degradation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u517c\u987e\u5b89\u5168\u4e0e\u6027\u80fd\u7684\u5206\u5e03\u5f0f\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff08SPA-DDRL\uff09\uff0c\u7528\u4e8e\u96fe\u8ba1\u7b97\u4e2d\u670d\u52a1\u653e\u7f6e\u7684\u8054\u5408\u4f18\u5316\uff0c\u5728\u964d\u4f4e\u54cd\u5e94\u65f6\u95f4\u7684\u540c\u65f6\u63d0\u5347\u5b89\u5168\u5408\u89c4\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6848\u591a\u5173\u6ce8\u6027\u80fd\u6307\u6807\uff0c\u5ffd\u89c6\u90e8\u7f72\u51b3\u7b56\u4e2d\u7684\u5b89\u5168\u5f71\u54cd\uff0c\u800c\u7269\u8054\u7f51\u5e94\u7528\u5bf9\u9ad8\u6548\u3001\u5b89\u5168\u7684\u670d\u52a1\u653e\u7f6e\u9700\u6c42\u65e5\u76ca\u589e\u957f\u3002", "method": "\u6784\u5efa\u52a0\u6743\u591a\u76ee\u6807\u4f18\u5316\u6a21\u578b\uff0c\u5f15\u5165\u4e09\u5c42\u5b89\u5168\u8bc4\u5206\u673a\u5236\uff0c\u5e76\u91c7\u7528\u5206\u5e03\u5f0fbroker-learner\u67b6\u6784\u7ed3\u5408LSTM\u3001\u4f18\u5148\u7ecf\u9a8c\u56de\u653e\u4e0e\u79bb\u7b56\u7565\u6821\u6b63\u63d0\u5347\u667a\u80fd\u4f53\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSPA-DDRL\u5728\u771f\u5b9eIoT\u8d1f\u8f7d\u4e0b\u54cd\u5e94\u65f6\u95f4\u63d0\u534716.3%\uff0c\u6536\u655b\u901f\u5ea6\u52a0\u5feb33%\uff0c\u4e14\u5728\u6240\u6709\u7cfb\u7edf\u89c4\u6a21\u4e0b\u5747\u4fdd\u6301\u5b89\u5168\u5408\u89c4\u3002", "conclusion": "SPA-DDRL\u80fd\u6709\u6548\u5e73\u8861\u96fe\u8ba1\u7b97\u4e2d\u670d\u52a1\u653e\u7f6e\u7684\u5b89\u5168\u6027\u4e0e\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2601.01129", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.01129", "abs": "https://arxiv.org/abs/2601.01129", "authors": ["Kla Tantithamthavorn", "Yaotian Zou", "Andy Wong", "Michael Gupta", "Zhe Wang", "Mike Buller", "Ryan Jiang", "Matthew Watson", "Minwoo Jeong", "Kun Chen", "Ming Wu"], "title": "RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian", "comment": "Accepted at the 48th International Conference on Software Engineering (ICSE'26), SEIP Track. 12 Pages", "summary": "Large Language Models (LLMs)-powered code review automation has the potential to transform code review workflows. Despite the advances of LLM-powered code review comment generation approaches, several practical challenges remain for designing enterprise-grade code review automation tools. In particular, this paper aims at answering the practical question: how can we design a review-guided, context-aware, quality-checked code review comment generation without fine-tuning?\n  In this paper, we present RovoDev Code Reviewer, an enterprise-grade LLM-based code review automation tool designed and deployed at scale within Atlassian's development ecosystem with seamless integration into Atlassian's Bitbucket. Through the offline, online, user feedback evaluations over a one-year period, we conclude that RovoDev Code Reviewer is (1) effective in generating code review comments that could lead to code resolution for 38.70% (i.e., comments that triggered code changes in the subsequent commits); and (2) offers the promise of accelerating feedback cycles (i.e., decreasing the PR cycle time by 30.8%), alleviating reviewer workload (i.e., reducing the number of human-written comments by 35.6%), and improving overall software quality (i.e., finding errors with actionable suggestions).", "AI": {"tldr": "RovoDev Code Reviewer \u662f\u4e00\u4e2a\u4f01\u4e1a\u7ea7\u7684\u3001\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u5ba1\u67e5\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u751f\u6210\u9ad8\u8d28\u91cf\u8bc4\u8bba\uff0c\u6709\u6548\u7f29\u77ed PR \u5468\u671f\u5e76\u51cf\u8f7b\u4eba\u5de5\u8d1f\u62c5\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709 LLM \u4ee3\u7801\u5ba1\u67e5\u5de5\u5177\u5728\u4f01\u4e1a\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u7684\u5f15\u5bfc\u6027\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u4e0e\u8d28\u91cf\u63a7\u5236\u7b49\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u5e76\u90e8\u7f72 RovoDev Code Reviewer\uff0c\u65e0\u7f1d\u96c6\u6210\u81f3 Atlassian Bitbucket\uff0c\u901a\u8fc7\u79bb\u7ebf\u3001\u5728\u7ebf\u53ca\u7528\u6237\u53cd\u9988\u8bc4\u4f30\u5176\u6548\u679c\u3002", "result": "38.7% \u7684\u8bc4\u8bba\u5f15\u53d1\u4ee3\u7801\u4fee\u6539\uff1bPR \u5468\u671f\u7f29\u77ed 30.8%\uff1b\u4eba\u5de5\u8bc4\u8bba\u51cf\u5c11 35.6%\uff1b\u63d0\u5347\u8f6f\u4ef6\u8d28\u91cf\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u5efa\u8bae\u3002", "conclusion": "RovoDev Code Reviewer \u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u5207\u5b9e\u6709\u6548\uff0c\u80fd\u663e\u8457\u4f18\u5316\u4ee3\u7801\u5ba1\u67e5\u6d41\u7a0b\u5e76\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u3002"}}
{"id": "2601.01265", "categories": ["cs.AR", "cs.OS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.01265", "abs": "https://arxiv.org/abs/2601.01265", "authors": ["Nick Lindsay", "Caroline Trippel", "Anurag Khandelwal", "Abhishek Bhattacharjee"], "title": "CounterPoint: Using Hardware Event Counters to Refute and Refine Microarchitectural Assumptions (Extended Version)", "comment": "This is an extended version of a paper which has been accepted to the 31st ACM International Conference on Architectural Support for Programming Languages and Operating Systems conference (ASPLOS, March 2026). 20 pages, 20 figures, 8 tables", "summary": "Hardware event counters offer the potential to reveal not only performance bottlenecks but also detailed microarchitectural behavior. In practice, this promise is undermined by their vague specifications, opaque designs, and multiplexing noise, making event counter data hard to interpret.\n  We introduce CounterPoint, a framework that tests user-specified microarchitectural models - expressed as $\u03bc$path Decision Diagrams - for consistency with performance counter data. When mismatches occur, CounterPoint pinpoints plausible microarchitectural features that could explain them, using multi-dimensional counter confidence regions to mitigate multiplexing noise. We apply CounterPoint to the Haswell Memory Management Unit as a case study, shedding light on multiple undocumented and underdocumented microarchitectural behaviors. These include a load-store queue-side TLB prefetcher, merging page table walkers, abortable page table walks, and more.\n  Overall, CounterPoint helps experts reconcile noisy hardware performance counter measurements with their mental model of the microarchitecture - uncovering subtle, previously hidden hardware features along the way.", "AI": {"tldr": "CounterPoint\u662f\u4e00\u4e2a\u7528\u4e8e\u9a8c\u8bc1\u5fae\u67b6\u6784\u6a21\u578b\u4e0e\u6027\u80fd\u8ba1\u6570\u5668\u6570\u636e\u4e00\u81f4\u6027\u7684\u6846\u67b6\uff0c\u80fd\u63ed\u793a\u9690\u85cf\u7684\u786c\u4ef6\u7279\u6027\u3002", "motivation": "\u786c\u4ef6\u4e8b\u4ef6\u8ba1\u6570\u5668\u56e0\u89c4\u683c\u6a21\u7cca\u3001\u8bbe\u8ba1\u4e0d\u900f\u660e\u548c\u590d\u7528\u566a\u58f0\u5bfc\u81f4\u6570\u636e\u96be\u4ee5\u89e3\u91ca\u3002", "method": "\u4f7f\u7528\u03bc\u8def\u5f84\u51b3\u7b56\u56fe\u8868\u8fbe\u5fae\u67b6\u6784\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u591a\u7ef4\u7f6e\u4fe1\u533a\u57df\u7f13\u89e3\u590d\u7528\u566a\u58f0\u4ee5\u68c0\u6d4b\u4e0d\u5339\u914d\u3002", "result": "\u6210\u529f\u5e94\u7528\u4e8eHaswell\u5185\u5b58\u7ba1\u7406\u5355\u5143\uff0c\u53d1\u73b0\u591a\u4e2a\u672a\u6587\u6863\u5316\u884c\u4e3a\uff0c\u5982TLB\u9884\u53d6\u5668\u548c\u53ef\u4e2d\u6b62\u9875\u8868\u904d\u5386\u3002", "conclusion": "CounterPoint\u5e2e\u52a9\u4e13\u5bb6\u5c06\u566a\u58f0\u8ba1\u6570\u5668\u6570\u636e\u4e0e\u5fae\u67b6\u6784\u5fc3\u667a\u6a21\u578b\u5bf9\u9f50\uff0c\u63ed\u793a\u7ec6\u5fae\u9690\u85cf\u786c\u4ef6\u7279\u6027\u3002"}}
{"id": "2601.01968", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2601.01968", "abs": "https://arxiv.org/abs/2601.01968", "authors": ["Yuan Guo", "Yilong Chen", "Zixiang Ren", "Derrick Wing Kwan Ng", "Jie Xu"], "title": "Near-Field Multi-Cell ISCAP with Extremely Large-Scale Antenna Array", "comment": null, "summary": "This paper investigates a coordinated multi-cell integrated sensing, communication, and powering (ISCAP) system operating in the electromagnetic near field, where each base station (BS) employs an extremely large-scale antenna array (ELAA) to simultaneously support downlink communication, wireless power transfer (WPT), and environmental sensing. Three categories of communication users (CUs) with different interference cancellation capabilities are considered, and sensing is enabled through a distributed multiple-input multiple-output (MIMO) radar architecture. To address the resulting design challenges, a robust optimization framework is proposed by optimizing the beamforming strategy to maximize the worst-case detection probability over a prescribed sensing region, subject to per-user signal-to-interference-plus-noise ratio (SINR) constraints and energy harvesting requirements at energy receivers (ERs), while explicitly capturing the uncertainty in ER locations. By leveraging semidefinite relaxation (SDR), the original non-convex problem is reformulated as a convex semidefinite program with a provably tight relaxation. Furthermore, a low-complexity maximum ratio transmission (MRT)-based suboptimal scheme is developed, yielding a closed-form solution in the asymptotic regime as the number of antenna elements approaches infinity. Extensive numerical results reveal the fundamental trade-offs among sensing accuracy, communication reliability, and WPT efficiency.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u591a\u5c0f\u533a\u534f\u540c\u7684\u8fd1\u573a\u96c6\u6210\u611f\u77e5\u3001\u901a\u4fe1\u4e0e\u4f9b\u80fd\u7cfb\u7edf\uff0c\u901a\u8fc7\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u7b56\u7565\uff0c\u5728\u6ee1\u8db3\u901a\u4fe1\u548c\u80fd\u91cf\u6536\u96c6\u9700\u6c42\u7684\u540c\u65f6\u6700\u5927\u5316\u6700\u5dee\u60c5\u51b5\u4e0b\u7684\u68c0\u6d4b\u6982\u7387\u3002", "motivation": "\u89e3\u51b3\u8fd1\u573a\u73af\u5883\u4e0b\u591a\u5c0f\u533a\u7cfb\u7edf\u4e2d\u611f\u77e5\u3001\u901a\u4fe1\u4e0e\u65e0\u7ebf\u4f9b\u80fd\u4e09\u8005\u4e4b\u95f4\u7684\u8d44\u6e90\u5206\u914d\u4e0e\u6027\u80fd\u6743\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u9c81\u68d2\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u534a\u5b9a\u677e\u5f1b\uff08SDR\uff09\u5c06\u975e\u51f8\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u4f4e\u590d\u6742\u5ea6\u7684\u6700\u5927\u6bd4\u4f20\u8f93\uff08MRT\uff09\u6e10\u8fd1\u95ed\u5f0f\u89e3\u3002", "result": "\u6570\u503c\u7ed3\u679c\u63ed\u793a\u4e86\u611f\u77e5\u7cbe\u5ea6\u3001\u901a\u4fe1\u53ef\u9760\u6027\u548c\u4f9b\u80fd\u6548\u7387\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u5173\u7cfb\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6848\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u67b6\u6784\u4e0e\u4f18\u5316\u65b9\u6cd5\u4e3a\u672a\u6765\u8fd1\u573a\u667a\u80fd\u65e0\u7ebf\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6491\u4e0e\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01831", "categories": ["cs.MA", "cs.AI", "cs.IR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01831", "abs": "https://arxiv.org/abs/2601.01831", "authors": ["Aniket Wattamwar", "Sampson Akwafuo"], "title": "ARIES: A Scalable Multi-Agent Orchestration Framework for Real-Time Epidemiological Surveillance and Outbreak Monitoring", "comment": "6 pages, 14 figures, 1 table", "summary": "Global health surveillance is currently facing a challenge of Knowledge Gaps. While general-purpose AI has proliferated, it remains fundamentally unsuited for the high-stakes epidemiological domain due to chronic hallucinations and an inability to navigate specialized data silos. This paper introduces ARIES (Agentic Retrieval Intelligence for Epidemiological Surveillance), a specialized, autonomous multi-agent framework designed to move beyond static, disease-specific dashboards toward a dynamic intelligence ecosystem. Built on a hierarchical command structure, ARIES utilizes GPTs to orchestrate a scalable swarm of sub-agents capable of autonomously querying World Health Organization (WHO), Center for Disease Control and Prevention (CDC), and peer-reviewed research papers. By automating the extraction and logical synthesis of surveillance data, ARIES provides a specialized reasoning that identifies emergent threats and signal divergence in near real-time. This modular architecture proves that a task-specific agentic swarm can outperform generic models, offering a robust, extensible for next-generation outbreak response and global health intelligence.", "AI": {"tldr": "ARIES\u662f\u4e00\u4e2a\u4e13\u4e3a\u6d41\u884c\u75c5\u5b66\u76d1\u6d4b\u8bbe\u8ba1\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u80fd\u52a8\u6001\u6574\u5408WHO\u3001CDC\u53ca\u7814\u7a76\u6570\u636e\uff0c\u5b9e\u73b0\u5b9e\u65f6\u5a01\u80c1\u8bc6\u522b\u3002", "motivation": "\u901a\u7528AI\u5728\u9ad8\u98ce\u9669\u6d41\u884c\u75c5\u9886\u57df\u5b58\u5728\u5e7b\u89c9\u548c\u6570\u636e\u5b64\u5c9b\u95ee\u9898\uff0c\u9700\u4e13\u7528\u7cfb\u7edf\u63d0\u5347\u76d1\u6d4b\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5206\u5c42\u6307\u6325\u7ed3\u6784\uff0c\u5229\u7528GPT\u534f\u8c03\u5b50\u667a\u80fd\u4f53\u81ea\u52a8\u67e5\u8be2\u6743\u5a01\u6570\u636e\u6e90\u5e76\u5408\u6210\u903b\u8f91\u63a8\u7406\u3002", "result": "ARIES\u5728\u8fd1\u5b9e\u65f6\u8bc6\u522b\u65b0\u5174\u5a01\u80c1\u548c\u4fe1\u53f7\u5dee\u5f02\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u901a\u7528\u6a21\u578b\u3002", "conclusion": "\u4efb\u52a1\u4e13\u7528\u7684\u667a\u80fd\u4f53\u7fa4\u67b6\u6784\u53ef\u6210\u4e3a\u4e0b\u4e00\u4ee3\u75ab\u60c5\u54cd\u5e94\u548c\u5168\u7403\u5065\u5eb7\u60c5\u62a5\u7684\u53ef\u9760\u6269\u5c55\u65b9\u6848\u3002"}}
{"id": "2601.01199", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01199", "abs": "https://arxiv.org/abs/2601.01199", "authors": ["Logan Murphy", "Aren A. Babikian", "Marsha Chechik"], "title": "Abductive Vibe Coding (Extended Abstract)", "comment": null, "summary": "When software artifacts are generated by AI models (\"vibe coding\"), human engineers assume responsibility for validating them. Ideally, this validation would be done through the creation of a formal proof of correctness. However, this is infeasible for many real-world vibe coding scenarios, especially when requirements for the AI-generated artifacts resist formalization. This extended abstract describes ongoing work towards the extraction of analyzable, semi-formal rationales for the adequacy of vibe-coded artifacts. Rather than deciding correctness directly, our framework produces a set of conditions under which the generated code can be considered adequate. We describe current efforts towards implementing our framework and anticipated research opportunities.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u53d6AI\u751f\u6210\u4ee3\u7801\u7684\u534a\u5f62\u5f0f\u5316\u5408\u7406\u6027\u6761\u4ef6\uff0c\u4ee5\u8bc4\u4f30\u5176\u9002\u7528\u6027\u800c\u975e\u76f4\u63a5\u9a8c\u8bc1\u6b63\u786e\u6027\u3002", "motivation": "AI\u751f\u6210\u4ee3\u7801\uff08vibe coding\uff09\u7f3a\u4e4f\u53ef\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u9700\u6c42\uff0c\u9700\u65b0\u65b9\u6cd5\u8bc4\u4f30\u5176\u9002\u7528\u6027\u3002", "method": "\u6784\u5efa\u6846\u67b6\uff0c\u8f93\u51fa\u4ee3\u7801\u9002\u7528\u6027\u6240\u4f9d\u8d56\u7684\u6761\u4ef6\u96c6\u5408\uff0c\u800c\u975e\u76f4\u63a5\u8bc1\u660e\u6b63\u786e\u6027\u3002", "result": "\u6b63\u5728\u5b9e\u73b0\u8be5\u6846\u67b6\uff0c\u5e76\u63a2\u7d22\u76f8\u5173\u7814\u7a76\u673a\u4f1a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u65e0\u6cd5\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684AI\u751f\u6210\u4ee3\u7801\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u8bc4\u4f30\u8def\u5f84\u3002"}}
{"id": "2601.02053", "categories": ["cs.AR", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.02053", "abs": "https://arxiv.org/abs/2601.02053", "authors": ["Leandro Lanzieri", "Jiri Kral", "Goerschwin Fey", "Holger Schlarb", "Thomas C. Schmidt"], "title": "Ageing Monitoring for Commercial Microcontrollers Based on Timing Windows", "comment": null, "summary": "Microcontrollers are increasingly present in embedded deployments and dependable applications, for which malfunctions due to hardware ageing can have severe impact. The lack of deployable techniques for ageing monitoring on these devices has spread the application of guard bands to prevent timing errors due to degradation. Applying this static technique can limit performance and lead to sudden failures as devices age. In this paper, we follow a software-based self-testing approach to design monitoring of hardware degradation for microcontrollers. Deployable in the field, our technique leverages timing windows of variable lengths to determine the maximum operational frequency of the devices. We empirically validate the method on real hardware and find that it consistently detects temperature-induced degradations in maximum operating frequency of up to 13.79 % across devices for 60 \u00b0C temperature increase.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8f6f\u4ef6\u7684\u81ea\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7528\u4e8e\u76d1\u6d4b\u5fae\u63a7\u5236\u5668\u786c\u4ef6\u8001\u5316\uff0c\u901a\u8fc7\u53ef\u53d8\u957f\u5ea6\u7684\u65f6\u95f4\u7a97\u53e3\u786e\u5b9a\u8bbe\u5907\u6700\u9ad8\u5de5\u4f5c\u9891\u7387\uff0c\u5e76\u5728\u771f\u5b9e\u786c\u4ef6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5fae\u63a7\u5236\u5668\u5728\u5d4c\u5165\u5f0f\u548c\u9ad8\u53ef\u9760\u6027\u5e94\u7528\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u7f3a\u4e4f\u53ef\u884c\u7684\u8001\u5316\u76d1\u6d4b\u6280\u672f\uff0c\u5bfc\u81f4\u4f9d\u8d56\u9759\u6001\u4fdd\u62a4\u5e26\uff0c\u9650\u5236\u6027\u80fd\u5e76\u53ef\u80fd\u5f15\u53d1\u7a81\u53d1\u6545\u969c\u3002", "method": "\u91c7\u7528\u8f6f\u4ef6\u81ea\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5229\u7528\u53ef\u53d8\u957f\u5ea6\u65f6\u95f4\u7a97\u53e3\u6d4b\u91cf\u8bbe\u5907\u6700\u5927\u5de5\u4f5c\u9891\u7387\uff0c\u4ee5\u76d1\u6d4b\u786c\u4ef6\u9000\u5316\u60c5\u51b5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u7a33\u5b9a\u68c0\u6d4b\u6e29\u5ea6\u5347\u9ad860\u00b0C\u65f6\u8bbe\u5907\u6700\u9ad8\u5de5\u4f5c\u9891\u7387\u4e0b\u964d\u6700\u591a\u8fbe13.79%\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u53ef\u5728\u73b0\u573a\u90e8\u7f72\uff0c\u6709\u6548\u76d1\u6d4b\u5fae\u63a7\u5236\u5668\u56e0\u8001\u5316\u6216\u6e29\u5ea6\u53d8\u5316\u5f15\u8d77\u7684\u6027\u80fd\u9000\u5316\uff0c\u4f18\u4e8e\u4f20\u7edf\u9759\u6001\u4fdd\u62a4\u5e26\u65b9\u6848\u3002"}}
{"id": "2601.01310", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.01310", "abs": "https://arxiv.org/abs/2601.01310", "authors": ["Songyu Zhang", "Aaron Tam", "Myungjin Lee", "Shixiong Qi", "K. K. Ramakrishnan"], "title": "Making MoE based LLM inference resilient with Tarragon", "comment": null, "summary": "Mixture-of-Experts (MoE) models are increasingly used to serve LLMs at scale, but failures become common as deployment scale grows. Existing systems exhibit poor failure resilience: even a single worker failure triggers a coarse-grained, service-wide restart, discarding accumulated progress and halting the entire inference pipeline during recovery--an approach clearly ill-suited for latency-sensitive, LLM services.\n  We present Tarragon, a resilient MoE inference framework that confines the failures impact to individual workers while allowing the rest of the pipeline to continue making forward progress. Tarragon exploits the natural separation between the attention and expert computation in MoE-based transformers, treating attention workers (AWs) and expert workers (EWs) as distinct failure domains. Tarragon introduces a reconfigurable datapath to mask failures by rerouting requests to healthy workers. On top of this datapath, Tarragon implements a self-healing mechanism that relaxes the tightly synchronized execution of existing MoE frameworks. For stateful AWs, Tarragon performs asynchronous, incremental KV cache checkpointing with per-request restoration, and for stateless EWs, it leverages residual GPU memory to deploy shadow experts. These together keep recovery cost and recomputation overhead extremely low. Our evaluation shows that, compared to state-of-the-art MegaScale-Infer, Tarragon reduces failure-induced stalls by 160-213x (from ~64 s down to 0.3-0.4 s) while preserving performance when no failures occur.", "AI": {"tldr": "Tarragon\u662f\u4e00\u4e2a\u9488\u5bf9Mixture-of-Experts\u6a21\u578b\u7684\u9ad8\u5f39\u6027\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u9694\u79bb\u6545\u969c\u5f71\u54cd\u3001\u91cd\u8def\u7531\u8bf7\u6c42\u548c\u81ea\u6108\u673a\u5236\u663e\u8457\u964d\u4f4e\u6545\u969c\u6062\u590d\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u6709MoE\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u65f6\u6545\u969c\u6062\u590d\u6548\u7387\u4f4e\u4e0b\uff0c\u4e25\u91cd\u5f71\u54cd\u5ef6\u8fdf\u654f\u611f\u578bLLM\u670d\u52a1\u3002", "method": "Tarragon\u5c06\u6ce8\u610f\u529b\u4e0e\u4e13\u5bb6\u8ba1\u7b97\u5206\u79bb\u4e3a\u72ec\u7acb\u6545\u969c\u57df\uff0c\u91c7\u7528\u53ef\u91cd\u6784\u6570\u636e\u8def\u5f84\u3001\u5f02\u6b65KV\u7f13\u5b58\u68c0\u67e5\u70b9\u548c\u5f71\u5b50\u4e13\u5bb6\u5b9e\u73b0\u4f4e\u5f00\u9500\u6062\u590d\u3002", "result": "\u76f8\u6bd4MegaScale-Infer\uff0cTarragon\u5c06\u6545\u969c\u5bfc\u81f4\u7684\u505c\u987f\u51cf\u5c11160-213\u500d\uff08\u4ece\u7ea664\u79d2\u964d\u81f30.3-0.4\u79d2\uff09\uff0c\u4e14\u65e0\u6545\u969c\u65f6\u6027\u80fd\u65e0\u635f\u3002", "conclusion": "Tarragon\u6709\u6548\u63d0\u5347\u4e86MoE\u6a21\u578b\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u4e2d\u7684\u5bb9\u9519\u80fd\u529b\uff0c\u9002\u5408\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u3002"}}
{"id": "2601.01215", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01215", "abs": "https://arxiv.org/abs/2601.01215", "authors": ["Prateek Rajput", "Yewei Song", "Abdoul Aziz Bonkoungou", "Iyiola E. Olatunji", "Abdoul Kader Kabore", "Jacques Klein", "Tegawend\u00e9 F. Bissyand\u00e9"], "title": "Correctness isnt Efficiency: Runtime Memory Divergence in LLM-Generated Code", "comment": "11 Pages, 11 figures, Accepted at ICSE SEIP", "summary": "Large language models (LLMs) can generate programs that pass unit tests, but passing tests does not guarantee reliable runtime behavior. We find that different correct solutions to the same task can show very different memory and performance patterns, which can lead to hidden operational risks. We present a framework to measure execution-time memory stability across multiple correct generations. At the solution level, we introduce Dynamic Mean Pairwise Distance (DMPD), which uses Dynamic Time Warping to compare the shapes of memory-usage traces after converting them into Monotonic Peak Profiles (MPPs) to reduce transient noise. Aggregating DMPD across tasks yields a model-level Model Instability Score (MIS). Experiments on BigOBench and CodeContests show substantial runtime divergence among correct solutions. Instability often increases with higher sampling temperature even when pass@1 improves. We also observe correlations between our stability measures and software engineering indicators such as cognitive and cyclomatic complexity, suggesting links between operational behavior and maintainability. Our results support stability-aware selection among passing candidates in CI/CD to reduce operational risk without sacrificing correctness. Artifacts are available.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5185\u5b58\u7a33\u5b9a\u6027\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8861\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u5728\u8fd0\u884c\u65f6\u7684\u884c\u4e3a\u5dee\u5f02\uff0c\u4ee5\u964d\u4f4e\u64cd\u4f5c\u98ce\u9669\u3002", "motivation": "\u6b63\u786e\u901a\u8fc7\u5355\u5143\u6d4b\u8bd5\u7684\u4ee3\u7801\u4ecd\u53ef\u80fd\u5b58\u5728\u8fd0\u884c\u65f6\u6027\u80fd\u548c\u5185\u5b58\u884c\u4e3a\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u5e26\u6765\u6f5c\u5728\u64cd\u4f5c\u98ce\u9669\u3002", "method": "\u5f15\u5165\u52a8\u6001\u5747\u503c\u6210\u5bf9\u8ddd\u79bb\uff08DMPD\uff09\u548c\u6a21\u578b\u4e0d\u7a33\u5b9a\u6027\u8bc4\u5206\uff08MIS\uff09\uff0c\u7ed3\u5408\u5355\u8c03\u5cf0\u503c\u8f6e\u5ed3\u4e0e\u52a8\u6001\u65f6\u95f4\u89c4\u6574\u5206\u6790\u5185\u5b58\u8f68\u8ff9\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u4e0d\u540c\u6b63\u786e\u89e3\u6cd5\u95f4\u5b58\u5728\u663e\u8457\u8fd0\u884c\u65f6\u5dee\u5f02\uff0c\u4e14\u4e0d\u7a33\u5b9a\u6027\u968f\u91c7\u6837\u6e29\u5ea6\u5347\u9ad8\u800c\u589e\u52a0\uff0c\u540c\u65f6\u4e0e\u4ee3\u7801\u590d\u6742\u5ea6\u6307\u6807\u76f8\u5173\u3002", "conclusion": "\u652f\u6301\u5728CI/CD\u4e2d\u91c7\u7528\u7a33\u5b9a\u6027\u611f\u77e5\u7684\u9009\u62e9\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u6b63\u786e\u6027\u7684\u540c\u65f6\u964d\u4f4e\u8fd0\u884c\u98ce\u9669\u3002"}}
{"id": "2601.02135", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.02135", "abs": "https://arxiv.org/abs/2601.02135", "authors": ["Liu Shijie", "Zeng Zhenghao", "Jiao Han", "Huang Yihua"], "title": "HFRWKV: A High-Performance Fully On-Chip Hardware Accelerator for RWKV", "comment": null, "summary": "RWKV is a modern RNN architecture that approaches the performance of Transformers, with the advantage of processing long contexts at a linear memory cost. However, its sequential computation pattern struggles to efficiently leverage GPU parallelism, which leads to low compute resource utilization. Furthermore, frequent off-chip weight accesses create a memory bottleneck. To address these challenges, we propose HFRWKV, an FPGA-based hardware accelerator specifically designed for RWKV. Within the matrix operation module, we propose a novel hardware-friendly hybrid-precision quantization strategy, which enhances performance while maintaining acceptable accuracy. For the complex operations including exponentiation and division, we introduce a method featuring reusable architectures combined with lookup tables or piecewise linear approximation, which is algorithmically refined to effectively balance precision and hardware resource consumption. Based on this foundation, we adopt a fully on-chip computing system integrating parallel matrix-vector processing array and an efficient pipeline architecture. Through computation reordering and chunked double buffering, it effectively eliminates data transfer bottlenecks and improves overall throughput. We implement HFRWKV on the Alveo U50 and U280 platform. Experimental results show that compared to a CPU, a throughput improvement of 63.48$\\times$ and an energy efficiency improvement of 139.17$\\times$. Compared to GPUs, achieves a throughput improvement of 32.33$\\times$ and an energy efficiency improvement of 171.36$\\times$.", "AI": {"tldr": "HFRWKV\u662f\u4e13\u4e3aRWKV\u8bbe\u8ba1\u7684FPGA\u786c\u4ef6\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u3001\u53ef\u590d\u7528\u67b6\u6784\u4e0e\u7247\u4e0a\u8ba1\u7b97\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u4e0e\u80fd\u6548\u3002", "motivation": "RWKV\u867d\u5177\u7ebf\u6027\u5185\u5b58\u4f18\u52bf\uff0c\u4f46\u53d7\u9650\u4e8eGPU\u5e76\u884c\u6548\u7387\u4f4e\u53ca\u9891\u7e41\u8bbf\u5b58\u74f6\u9888\uff0c\u9700\u4e13\u7528\u786c\u4ef6\u4f18\u5316\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u7cbe\u5ea6\u91cf\u5316\u7b56\u7565\u3001\u590d\u7528\u67b6\u6784\u7ed3\u5408\u67e5\u8868/\u5206\u6bb5\u7ebf\u6027\u903c\u8fd1\u590d\u6742\u8fd0\u7b97\uff0c\u5e76\u6784\u5efa\u5168\u7247\u4e0a\u5e76\u884c\u6d41\u6c34\u7ebf\u7cfb\u7edf\u3002", "result": "\u5728Alveo\u5e73\u53f0\u5b9e\u73b0\u76f8\u6bd4CPU 63.48\u500d\u541e\u5410\u63d0\u5347\u3001139.17\u500d\u80fd\u6548\u63d0\u5347\uff1b\u76f8\u6bd4GPU\u8fbe32.33\u500d\u541e\u5410\u4e0e171.36\u500d\u80fd\u6548\u63d0\u5347\u3002", "conclusion": "HFRWKV\u6709\u6548\u514b\u670dRWKV\u786c\u4ef6\u6267\u884c\u74f6\u9888\uff0c\u5728\u541e\u5410\u4e0e\u80fd\u6548\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u901a\u7528CPU/GPU\u5e73\u53f0\u3002"}}
{"id": "2601.01500", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.01500", "abs": "https://arxiv.org/abs/2601.01500", "authors": ["Jinxiao Zhang", "Yunpu Xu", "Xiyong Wu", "Runmin Dong", "Shenggan Cheng", "Yi Zhao", "Mengxuan Chen", "Qinrui Zheng", "Jianting Liu", "Haohuan Fu"], "title": "DiT-HC: Enabling Efficient Training of Visual Generation Model DiT on HPC-oriented CPU Cluster", "comment": null, "summary": "Generative foundation models have become an important tool for data reconstruction and simulation in scientific computing, showing a tight integration with traditional numerical simulations. At the same time, with the development of new hardware features, such as matrix acceleration units and high-bandwidth memory, CPU-based clusters offer promising opportunities to accelerate and scale such models, facilitating the unification of artificial intelligence and scientific computing. We present DiT-HC, the first system to train and scale the generative model DiT on a next-generation HPC CPU cluster. DiT-HC introduces three key techniques: (1) communication-free tensor parallelism (CFTP) with AutoMem for automated memory-aware dataflow, (2) HCOps, a suite of optimized GEMM and operator kernels leveraging vector and matrix acceleration units, and (3) a custom MPI backend that overlaps computation, communication, and memory movement. Experiments show 8.2 to 87.7 times speedups over native or public CPU libraries and 90.6% weak scaling efficiency on 256 nodes. These results demonstrate the feasibility of large-scale generative model training on CPU clusters and provide new insights for future HPC-AI co-design.", "AI": {"tldr": "DiT-HC\u662f\u9996\u4e2a\u5728\u4e0b\u4e00\u4ee3HPC CPU\u96c6\u7fa4\u4e0a\u8bad\u7ec3\u548c\u6269\u5c55\u751f\u6210\u6a21\u578bDiT\u7684\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e09\u9879\u5173\u952e\u6280\u672f\u5b9e\u73b0\u9ad8\u6548\u80fd\u8ba1\u7b97\u4e0eAI\u878d\u5408\u3002", "motivation": "\u63a8\u52a8\u751f\u6210\u5f0f\u57fa\u7840\u6a21\u578b\u5728\u79d1\u5b66\u8ba1\u7b97\u4e2d\u7684\u5927\u89c4\u6a21\u8bad\u7ec3\uff0c\u5e76\u5229\u7528\u65b0\u578bCPU\u786c\u4ef6\u7279\u6027\u52a0\u901fAI\u4e0e\u9ad8\u6027\u80fd\u8ba1\u7b97\u7684\u534f\u540c\u8bbe\u8ba1\u3002", "method": "\u63d0\u51fa\u901a\u4fe1\u65e0\u5173\u5f20\u91cf\u5e76\u884c\uff08CFTP\uff09\u3001\u4f18\u5316\u7b97\u5b50\u5e93HCOps\u3001\u4ee5\u53ca\u5b9a\u5236MPI\u540e\u7aef\u4ee5\u91cd\u53e0\u8ba1\u7b97\u3001\u901a\u4fe1\u4e0e\u5185\u5b58\u79fb\u52a8\u3002", "result": "\u76f8\u6bd4\u539f\u751f\u6216\u516c\u5f00CPU\u5e93\u63d0\u901f8.2\u81f387.7\u500d\uff0c\u5728256\u8282\u70b9\u4e0a\u5b9e\u73b090.6%\u5f31\u6269\u5c55\u6548\u7387\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5728CPU\u96c6\u7fa4\u4e0a\u8bad\u7ec3\u5927\u89c4\u6a21\u751f\u6210\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u672a\u6765HPC-AI\u534f\u540c\u8bbe\u8ba1\u63d0\u4f9b\u65b0\u601d\u8def\u3002"}}
{"id": "2601.01219", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01219", "abs": "https://arxiv.org/abs/2601.01219", "authors": ["Hossein Amiri", "Joon-Seok Kim", "Hamdi Kavak", "Andrew Crooks", "Dieter Pfoser", "Carola Wenk", "Andreas Z\u00fcfle"], "title": "HD-GEN: A High-Performance Software System for Human Mobility Data Generation Based on Patterns of Life", "comment": null, "summary": "Understanding individual-level human mobility is critical for a wide range of applications. Real-world trajectory datasets provide valuable insights into actual movement behaviors but are often constrained by data sparsity and participant bias. Synthetic data, by contrast, offer scalability and flexibility but frequently lack realism. To address this gap, we introduce a comprehensive software pipeline for calibrating, generating, processing, and visualizing large-scale individual-level human mobility datasets that combine the realism of empirical data with the control and extensibility of Patterns-of-Life simulations. Our system consists of four integrated components. (1) a data generation engine constructs geographically grounded simulations using OpenStreetMap data to produce diverse mobility logs. (2) a genetic algorithm-based calibration module fine-tunes simulation parameters to align with real-world mobility characteristics, such as daily trip counts and radius of gyration, enabling realistic behavioral modeling. (3) a data processing suite transforms raw simulation logs into structured formats suitable for downstream applications, including model training and benchmarking. (4) a visualization module extracts key mobility patterns and insights from the processed datasets and presents them through intuitive visual analytics for improved interpretability.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u771f\u5b9e\u6570\u636e\u4e0e\u6a21\u62df\u7075\u6d3b\u6027\u7684\u7efc\u5408\u8f6f\u4ef6\u7ba1\u9053\uff0c\u7528\u4e8e\u751f\u6210\u5927\u89c4\u6a21\u4e2a\u4f53\u7ea7\u4eba\u7c7b\u79fb\u52a8\u6570\u636e\u96c6\u3002", "motivation": "\u89e3\u51b3\u771f\u5b9e\u8f68\u8ff9\u6570\u636e\u7a00\u758f\u6027\u548c\u504f\u5dee\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347\u5408\u6210\u6570\u636e\u7684\u771f\u5b9e\u6027\u3002", "method": "\u6784\u5efa\u5305\u542b\u56db\u4e2a\u6a21\u5757\u7684\u7cfb\u7edf\uff1a\u57fa\u4e8eOpenStreetMap\u7684\u5730\u7406\u4eff\u771f\u5f15\u64ce\u3001\u9057\u4f20\u7b97\u6cd5\u6821\u51c6\u6a21\u5757\u3001\u6570\u636e\u5904\u7406\u5957\u4ef6\u548c\u53ef\u89c6\u5316\u5206\u6790\u6a21\u5757\u3002", "result": "\u751f\u6210\u7684\u6570\u636e\u96c6\u517c\u5177\u771f\u5b9e\u6027\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u4e0e\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "\u8be5\u7ba1\u9053\u6709\u6548\u5f25\u5408\u4e86\u771f\u5b9e\u6570\u636e\u4e0e\u5408\u6210\u6570\u636e\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63d0\u5347\u4e86\u4eba\u7c7b\u79fb\u52a8\u5efa\u6a21\u7684\u5b9e\u7528\u6027\u4e0e\u89e3\u91ca\u6027\u3002"}}
{"id": "2601.01596", "categories": ["cs.DC", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2601.01596", "abs": "https://arxiv.org/abs/2601.01596", "authors": ["Congrong Ren", "Robert Underwood", "Sheng Di", "Emrecan Kutay", "Zarija Lukic", "Aylin Yener", "Franck Cappello", "Hanqi Guo"], "title": "FFCz: Fast Fourier Correction for Spectrum-Preserving Lossy Compression of Scientific Data", "comment": null, "summary": "This paper introduces a novel technique to preserve spectral features in lossy compression based on a novel fast Fourier correction algorithm\\added{ for regular-grid data}. Preserving both spatial and frequency representations of data is crucial for applications such as cosmology, turbulent combustion, and X-ray diffraction, where spatial and frequency views provide complementary scientific insights. In particular, many analysis tasks rely on frequency-domain representations to capture key features, including the power spectrum of cosmology simulations, the turbulent energy spectrum in combustion, and diffraction patterns in reciprocal space for ptychography. However, existing compression methods guarantee accuracy only in the spatial domain while disregarding the frequency domain. To address this limitation, we propose an algorithm that corrects the errors produced by off-the-shelf ``base'' compressors such as SZ3, ZFP, and SPERR, thereby preserving both spatial and frequency representations by bounding errors in both domains. By expressing frequency-domain errors as linear combinations of spatial-domain errors, we derive a region that jointly bounds errors in both domains. Given as input the spatial errors from a base compressor and user-defined error bounds in the spatial and frequency domains, we iteratively project the spatial error vector onto the regions defined by the spatial and frequency constraints until it lies within their intersection. We further accelerate the algorithm using GPU parallelism to achieve practical performance. We validate our approach with datasets from cosmology simulations, X-ray diffraction, combustion simulation, and electroencephalography demonstrating its effectiveness in preserving critical scientific information in both spatial and frequency domains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5feb\u901f\u5085\u91cc\u53f6\u6821\u6b63\u7684\u65b0\u7b97\u6cd5\uff0c\u5728\u6709\u635f\u538b\u7f29\u4e2d\u540c\u65f6\u4fdd\u7559\u7a7a\u95f4\u4e0e\u9891\u57df\u7279\u5f81\u3002", "motivation": "\u73b0\u6709\u538b\u7f29\u65b9\u6cd5\u4ec5\u4fdd\u8bc1\u7a7a\u95f4\u57df\u7cbe\u5ea6\uff0c\u5ffd\u89c6\u9891\u57df\u4fdd\u771f\uff0c\u800c\u8bb8\u591a\u79d1\u5b66\u5e94\u7528\u9700\u53cc\u57df\u7cbe\u786e\u8868\u793a\u3002", "method": "\u901a\u8fc7\u5c06\u9891\u57df\u8bef\u5dee\u8868\u8fbe\u4e3a\u7a7a\u95f4\u8bef\u5dee\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u8fed\u4ee3\u6295\u5f71\u81f3\u53cc\u57df\u7ea6\u675f\u4ea4\u96c6\u533a\u57df\uff0c\u5e76\u5229\u7528GPU\u52a0\u901f\u5b9e\u73b0\u9ad8\u6548\u6821\u6b63\u3002", "result": "\u5728\u5b87\u5b99\u5b66\u3001X\u5c04\u7ebf\u884d\u5c04\u3001\u71c3\u70e7\u6a21\u62df\u7b49\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u5728\u53cc\u57df\u5747\u6709\u6548\u4fdd\u7559\u5173\u952e\u79d1\u5b66\u4fe1\u606f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5f25\u8865\u73b0\u6709\u538b\u7f29\u5668\u9891\u57df\u5931\u771f\u7f3a\u9677\uff0c\u4e3a\u591a\u9886\u57df\u79d1\u5b66\u6570\u636e\u538b\u7f29\u63d0\u4f9b\u65b0\u65b9\u6848\u3002"}}
{"id": "2601.01233", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01233", "abs": "https://arxiv.org/abs/2601.01233", "authors": ["Kangchen Zhu", "Zhiliang Tian", "Shangwen Wang", "Mingyue Leng", "Xiaoguang Mao"], "title": "Atomizer: An LLM-based Collaborative Multi-Agent Framework for Intent-Driven Commit Untangling", "comment": "Accepted by ICSE 2026", "summary": "Composite commits, which entangle multiple unrelated concerns, are prevalent in software development and significantly hinder program comprehension and maintenance. Existing automated untangling methods, particularly state-of-the-art graph clustering-based approaches, are fundamentally limited by two issues. (1) They over-rely on structural information, failing to grasp the crucial semantic intent behind changes, and (2) they operate as ``single-pass'' algorithms, lacking a mechanism for the critical reflection and refinement inherent in human review processes. To overcome these challenges, we introduce Atomizer, a novel collaborative multi-agent framework for composite commit untangling. To address the semantic deficit, Atomizer employs an Intent-Oriented Chain-of-Thought (IO-CoT) strategy, which prompts large language models (LLMs) to infer the intent of each code change according to both the structure and the semantic information of code. To overcome the limitations of ``single-pass'' grouping, we employ two agents to establish a grouper-reviewer collaborative refinement loop, which mirrors human review practices by iteratively refining groupings until all changes in a cluster share the same underlying semantic intent. Extensive experiments on two benchmark C# and Java datasets demonstrate that Atomizer significantly outperforms several representative baselines. On average, it surpasses the state-of-the-art graph-based methods by over 6.0% on the C# dataset and 5.5% on the Java dataset. This superiority is particularly pronounced on complex commits, where Atomizer's performance advantage widens to over 16%.", "AI": {"tldr": "Atomizer\u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u8026\u590d\u5408\u63d0\u4ea4\uff0c\u901a\u8fc7\u8bed\u4e49\u610f\u56fe\u63a8\u7406\u548c\u8fed\u4ee3\u4f18\u5316\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u7ed3\u6784\u4fe1\u606f\u4e14\u7f3a\u4e4f\u8bed\u4e49\u7406\u89e3\u4e0e\u8fed\u4ee3\u4f18\u5316\u80fd\u529b\uff0c\u96be\u4ee5\u6709\u6548\u89e3\u8026\u590d\u5408\u63d0\u4ea4\u3002", "method": "\u5f15\u5165\u610f\u56fe\u5bfc\u5411\u601d\u7ef4\u94fe\uff08IO-CoT\uff09\u7b56\u7565\u7ed3\u5408LLM\u63a8\u65ad\u4ee3\u7801\u53d8\u66f4\u8bed\u4e49\uff0c\u5e76\u91c7\u7528\u5206\u7ec4-\u8bc4\u5ba1\u53cc\u667a\u80fd\u4f53\u5faa\u73af\u673a\u5236\u5b9e\u73b0\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728C#\u548cJava\u6570\u636e\u96c6\u4e0a\u5206\u522b\u5e73\u5747\u8d85\u8d8a\u5f53\u524d\u6700\u4f18\u56fe\u805a\u7c7b\u65b9\u6cd56.0%\u548c5.5%\uff0c\u590d\u6742\u63d0\u4ea4\u573a\u666f\u4f18\u52bf\u8d8516%\u3002", "conclusion": "Atomizer\u6709\u6548\u89e3\u51b3\u8bed\u4e49\u7f3a\u5931\u4e0e\u5355\u6b21\u5206\u7ec4\u7f3a\u9677\uff0c\u5728\u590d\u5408\u63d0\u4ea4\u89e3\u8026\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002"}}
{"id": "2601.01712", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.01712", "abs": "https://arxiv.org/abs/2601.01712", "authors": ["Jiarui Wang", "Huichao Chai", "Yuanhang Zhang", "Zongjin Zhou", "Wei Guo", "Xingkun Yang", "Qiang Tang", "Bo Pan", "Jiawei Zhu", "Ke Cheng", "Yuting Yan", "Shulan Wang", "Yingjie Zhu", "Zhengfan Yuan", "Jiaqi Huang", "Yuhan Zhang", "Xiaosong Sun", "Zhinan Zhang", "Hong Zhu", "Yongsheng Zhang", "Tiantian Dong", "Zhong Xiao", "Deliang Liu", "Chengzhou Lu", "Yuan Sun", "Zhiyuan Chen", "Xinming Han", "Zaizhu Liu", "Yaoyuan Wang", "Ziyang Zhang", "Yong Liu", "Jinxin Xu", "Yajing Sun", "Zhoujun Yu", "Wenting Zhou", "Qidong Zhang", "Zhengyong Zhang", "Zhonghai Gu", "Yibo Jin", "Yongxiang Feng", "Pengfei Zuo"], "title": "RelayGR: Scaling Long-Sequence Generative Recommendation via Cross-Stage Relay-Race Inference", "comment": null, "summary": "Real-time recommender systems execute multi-stage cascades (retrieval, pre-processing, fine-grained ranking) under strict tail-latency SLOs, leaving only tens of milliseconds for ranking. Generative recommendation (GR) models can improve quality by consuming long user-behavior sequences, but in production their online sequence length is tightly capped by the ranking-stage P99 budget. We observe that the majority of GR tokens encode user behaviors that are independent of the item candidates, suggesting an opportunity to pre-infer a user-behavior prefix once and reuse it during ranking rather than recomputing it on the critical path. Realizing this idea at industrial scale is non-trivial: the prefix cache must survive across multiple pipeline stages before the final ranking instance is determined, the user population implies cache footprints far beyond a single device, and indiscriminate pre-inference would overload shared resources under high QPS. We present RelayGR, a production system that enables in-HBM relay-race inference for GR. RelayGR selectively pre-infers long-term user prefixes, keeps their KV caches resident in HBM over the request lifecycle, and ensures the subsequent ranking can consume them without remote fetches. RelayGR combines three techniques: 1) a sequence-aware trigger that admits only at-risk requests under a bounded cache footprint and pre-inference load, 2) an affinity-aware router that co-locates cache production and consumption by routing both the auxiliary pre-infer signal and the ranking request to the same instance, and 3) a memory-aware expander that uses server-local DRAM to capture short-term cross-request reuse while avoiding redundant reloads. We implement RelayGR on Huawei Ascend NPUs and evaluate it with real queries. Under a fixed P99 SLO, RelayGR supports up to 1.5$\\times$ longer sequences and improves SLO-compliant throughput by up to 3.6$\\times$.", "AI": {"tldr": "RelayGR\u901a\u8fc7\u9884\u63a8\u7406\u7528\u6237\u884c\u4e3a\u524d\u7f00\u5e76\u7f13\u5b58\u4e8eHBM\uff0c\u663e\u8457\u63d0\u5347\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u5728\u5b9e\u65f6\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u5e8f\u5217\u957f\u5ea6\u4e0e\u541e\u5410\u91cf\u3002", "motivation": "\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u867d\u80fd\u63d0\u5347\u8d28\u91cf\uff0c\u4f46\u53d7\u9650\u4e8e\u7ebf\u4e0aP99\u5ef6\u8fdf\u9884\u7b97\uff0c\u65e0\u6cd5\u5904\u7406\u957f\u5e8f\u5217\uff1bRelayGR\u65e8\u5728\u7a81\u7834\u6b64\u74f6\u9888\u3002", "method": "\u7ed3\u5408\u5e8f\u5217\u611f\u77e5\u89e6\u53d1\u5668\u3001\u4eb2\u548c\u611f\u77e5\u8def\u7531\u4e0e\u5185\u5b58\u611f\u77e5\u6269\u5c55\u5668\uff0c\u5728Ascend NPU\u4e0a\u5b9e\u73b0HBM\u5185\u63a5\u529b\u63a8\u7406\uff0c\u907f\u514d\u8fdc\u7a0b\u83b7\u53d6\u7f13\u5b58\u3002", "result": "\u5728\u56fa\u5b9aP99 SLO\u4e0b\uff0c\u5e8f\u5217\u957f\u5ea6\u652f\u6301\u63d0\u53471.5\u500d\uff0cSLO\u5408\u89c4\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53473.6\u500d\u3002", "conclusion": "RelayGR\u6709\u6548\u89e3\u51b3\u5de5\u4e1a\u7ea7\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u4e2d\u957f\u5e8f\u5217\u63a8\u7406\u7684\u5ef6\u8fdf\u4e0e\u8d44\u6e90\u74f6\u9888\u95ee\u9898\u3002"}}
{"id": "2601.01271", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01271", "abs": "https://arxiv.org/abs/2601.01271", "authors": ["Qingxiao Tao", "Xiaodong Gu", "Hao Zhong", "Beijun Shen"], "title": "CatchAll: Repository-Aware Exception Handling with Knowledge-Guided LLMs", "comment": null, "summary": "Exception handling is a vital forward error-recovery mechanism in many programming languages, enabling developers to manage runtime anomalies through structured constructs (e.g., try-catch blocks). Improper or missing exception handling often leads to severe consequences, including system crashes and resource leaks. While large language models (LLMs) have demonstrated strong capabilities in code generation, they struggle with exception handling at the repository level, due to complex dependencies and contextual constraints. In this work, we propose CatchAll, a novel LLM-based approach for repository-aware exception handling. CatchAll equips LLMs with three complementary layers of exception-handling knowledge: (1) API-level exception knowledge, obtained from an empirically constructed API-exception mapping that characterizes the exception-throwing behaviors of APIs in real-world codebases; (2) repository-level execution context, which captures exception propagation by modeling contextual call traces around the target code; and (3) cross-repository handling knowledge, distilled from reusable exception-handling patterns mined from historical code across projects. The knowledge is encoded into structured prompts to guide the LLM in generating accurate and context-aware exception-handling code. To evaluate CatchAll, we construct two new benchmarks for repository-aware exception handling: a large-scale dataset RepoExEval and an executable subset RepoExEval-Exec. Experiments demonstrate that RepoExEval consistently outperforms state-of-the-art baselines, achieving a CodeBLEU score of 0.31 (vs. 0.27% for the best baseline), intent prediction accuracy of 60.1% (vs. 48.0%), and Pass@1 of 29% (vs. 25%). These results affirm RepoExEval's effectiveness in real-world repository-level exception handling.", "AI": {"tldr": "CatchAll\u662f\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u4ed3\u5e93\u7ea7\u5f02\u5e38\u5904\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7API\u3001\u4ed3\u5e93\u4e0a\u4e0b\u6587\u548c\u8de8\u4ed3\u5e93\u6a21\u5f0f\u4e09\u5c42\u77e5\u8bc6\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709LLM\u5728\u4ed3\u5e93\u7ea7\u5f02\u5e38\u5904\u7406\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5e38\u56e0\u590d\u6742\u4f9d\u8d56\u4e0e\u4e0a\u4e0b\u6587\u5bfc\u81f4\u7cfb\u7edf\u5d29\u6e83\u6216\u8d44\u6e90\u6cc4\u6f0f\u3002", "method": "\u6784\u5efaAPI-\u5f02\u5e38\u6620\u5c04\u3001\u8c03\u7528\u94fe\u4e0a\u4e0b\u6587\u5efa\u6a21\u4e0e\u8de8\u9879\u76ee\u5904\u7406\u6a21\u5f0f\u6316\u6398\uff0c\u5e76\u7f16\u7801\u4e3a\u7ed3\u6784\u5316\u63d0\u793a\u5f15\u5bfcLLM\u751f\u6210\u3002", "result": "\u5728RepoExEval\u57fa\u51c6\u4e0a\uff0cCodeBLEU\u8fbe0.31\uff0c\u610f\u56fe\u9884\u6d4b\u51c6\u786e\u738760.1%\uff0cPass@1\u8fbe29%\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "CatchAll\u6709\u6548\u63d0\u5347\u4e86LLM\u5728\u771f\u5b9e\u4ed3\u5e93\u73af\u5883\u4e2d\u751f\u6210\u51c6\u786e\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u5f02\u5e38\u5904\u7406\u4ee3\u7801\u7684\u80fd\u529b\u3002"}}
{"id": "2601.01787", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.01787", "abs": "https://arxiv.org/abs/2601.01787", "authors": ["Yuxiao Li", "Mingze Xia", "Xin Liang", "Bei Wang", "Robert Underwood", "Sheng Di", "Hemant Sharma", "Dishant Beniwal", "Franck Cappello", "Hanqi Guo"], "title": "pMSz: A Distributed Parallel Algorithm for Correcting Extrema and Morse Smale Segmentations in Lossy Compression", "comment": null, "summary": "Lossy compression, widely used by scientists to reduce data from simulations, experiments, and observations, can distort features of interest even under bounded error. Such distortions may compromise downstream analyses and lead to incorrect scientific conclusions in applications such as combustion and cosmology. This paper presents a distributed and parallel algorithm for correcting topological features, specifically, piecewise linear Morse Smale segmentations (PLMSS), which decompose the domain into monotone regions labeled by their corresponding local minima and maxima. While a single GPU algorithm (MSz) exists for PLMSS correction after compression, no methodology has been developed that scales beyond a single GPU for extreme scale data. We identify the key bottleneck in scaling PLMSS correction as the parallel computation of integral paths, a communication-intensive computation that is notoriously difficult to scale. Instead of explicitly computing and correcting integral paths, our algorithm simplifies MSz by preserving steepest ascending and descending directions across all locations, thereby minimizing interprocess communication while introducing negligible additional storage overhead. With this simplified algorithm and relaxed synchronization, our method achieves over 90% parallel efficiency on 128 GPUs on the Perlmutter supercomputer for real world datasets.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5206\u5e03\u5f0f\u5e76\u884c\u7b97\u6cd5\uff0c\u9ad8\u6548\u4fee\u6b63\u538b\u7f29\u540e\u6570\u636e\u7684\u62d3\u6251\u7279\u5f81\uff08PLMSS\uff09\uff0c\u5728128\u4e2aGPU\u4e0a\u5b9e\u73b0\u8d8590%\u5e76\u884c\u6548\u7387\u3002", "motivation": "\u6709\u635f\u538b\u7f29\u4f1a\u626d\u66f2\u5173\u952e\u62d3\u6251\u7279\u5f81\uff0c\u5f71\u54cd\u4e0b\u6e38\u79d1\u5b66\u5206\u6790\u51c6\u786e\u6027\uff0c\u73b0\u6709\u5355GPU\u65b9\u6cd5\u65e0\u6cd5\u6269\u5c55\u81f3\u8d85\u5927\u89c4\u6a21\u6570\u636e\u3002", "method": "\u901a\u8fc7\u4fdd\u7559\u6700\u9661\u5347\u964d\u65b9\u5411\u66ff\u4ee3\u663e\u5f0f\u79ef\u5206\u8def\u5f84\u8ba1\u7b97\uff0c\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u4e0e\u540c\u6b65\u9700\u6c42\uff0c\u5b9e\u73b0\u591aGPU\u9ad8\u6548\u5e76\u884c\u5316\u3002", "result": "\u5728Perlmutter\u8d85\u7b97128 GPU\u4e0a\u5bf9\u771f\u5b9e\u6570\u636e\u96c6\u5b9e\u73b0\u8d85\u8fc790%\u5e76\u884c\u6548\u7387\uff0c\u5b58\u50a8\u5f00\u9500\u53ef\u5ffd\u7565\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u6570\u636e\u62d3\u6251\u7279\u5f81\u4fee\u6b63\u7684\u6269\u5c55\u74f6\u9888\uff0c\u517c\u987e\u7cbe\u5ea6\u4e0e\u9ad8\u6027\u80fd\u3002"}}
{"id": "2601.01320", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01320", "abs": "https://arxiv.org/abs/2601.01320", "authors": ["Muntasir Adnan", "Carlos C. N. Kuhn"], "title": "Adaptive Hierarchical Evaluation of LLMs and SAST tools for CWE Prediction in Python", "comment": null, "summary": "Large Language Models have become integral to software development, yet they frequently generate vulnerable code. Existing code vulnerability detection benchmarks employ binary classification, lacking the CWE-level specificity required for actionable feedback in iterative correction systems. We present ALPHA (Adaptive Learning via Penalty in Hierarchical Assessment), the first function-level Python benchmark that evaluates both LLMs and SAST tools using hierarchically aware, CWE-specific penalties. ALPHA distinguishes between over-generalisation, over-specification, and lateral errors, reflecting practical differences in diagnostic utility. Evaluating seven LLMs and two SAST tools, we find LLMs substantially outperform SAST, though SAST demonstrates higher precision when detections occur. Critically, prediction consistency varies dramatically across models (8.26%-81.87% agreement), with significant implications for feedback-driven systems. We further outline a pathway for future work incorporating ALPHA penalties into supervised fine-tuning, which could provide principled hierarchy-aware vulnerability detection pending empirical validation.", "AI": {"tldr": "ALPHA\u662f\u4e00\u4e2a\u65b0\u7684Python\u51fd\u6570\u7ea7\u57fa\u51c6\uff0c\u901a\u8fc7\u5c42\u6b21\u5316CWE\u7279\u5b9a\u60e9\u7f5a\u8bc4\u4f30LLM\u548cSAST\u5de5\u5177\u7684\u6f0f\u6d1e\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u4e8c\u5206\u7c7b\u6f0f\u6d1e\u68c0\u6d4b\u57fa\u51c6\u7f3a\u4e4fCWE\u7ea7\u522b\u7ec6\u7c92\u5ea6\uff0c\u65e0\u6cd5\u652f\u6301\u8fed\u4ee3\u4fee\u6b63\u7cfb\u7edf\u3002", "method": "\u63d0\u51faALPHA\u57fa\u51c6\uff0c\u533a\u5206\u8fc7\u5ea6\u6cdb\u5316\u3001\u8fc7\u5ea6\u5177\u4f53\u5316\u548c\u6a2a\u5411\u9519\u8bef\uff0c\u91c7\u7528\u5206\u5c42CWE\u60e9\u7f5a\u673a\u5236\u8bc4\u4f30\u6a21\u578b\u3002", "result": "LLM\u6574\u4f53\u4f18\u4e8eSAST\u5de5\u5177\uff0c\u4f46SAST\u5728\u68c0\u51fa\u65f6\u7cbe\u5ea6\u66f4\u9ad8\uff1b\u6a21\u578b\u9884\u6d4b\u4e00\u81f4\u6027\u5dee\u5f02\u663e\u8457\uff088.26%-81.87%\uff09\u3002", "conclusion": "ALPHA\u4e3a\u5c42\u6b21\u5316\u6f0f\u6d1e\u68c0\u6d4b\u63d0\u4f9b\u65b0\u6846\u67b6\uff0c\u672a\u6765\u53ef\u7ed3\u5408\u5176\u60e9\u7f5a\u673a\u5236\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u4ee5\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2601.01413", "categories": ["cs.SE", "cs.MS", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.01413", "abs": "https://arxiv.org/abs/2601.01413", "authors": ["Yingjie Ma", "Jing Guo", "Richard D. Braatz"], "title": "GlycoPy: An Equation-Oriented and Object-Oriented Software for Hierarchical Modeling, Optimization, and Control in Python", "comment": null, "summary": "Most existing model predictive control (MPC) applications in process industries employ lin-ear models, although real-world (bio)chemical processes are typically nonlinear. The use of linear models limits the performance and applicability of MPC for processes that span a wide range of operating conditions. A challenge in employing nonlinear models in MPC for com-plex systems is the lack of tools that facilitate hierarchical model development, as well as lack of efficient implementations of the corresponding nonlinear MPC (NMPC) algorithms. As a step towards making NMPC more practical for hierarchical systems, we introduce Gly-coPy, an equation-oriented, object-oriented software framework for process modeling, opti-mization, and NMPC in Python. GlycoPy enables users to focus on writing equations for modeling while supporting hierarchical modeling. GlycoPy includes algorithms for parame-ter estimation, dynamic optimization, and NMPC, and allows users to customize the simula-tion, optimization, and control algorithms. Three case studies, ranging from a simple differ-ential algebraic equation system to a multiscale bioprocess model, validate the modeling, optimization, and NMPC capabilities of GlycoPy. GlycoPy has the potential to bridge the gap between advanced NMPC algorithms and their practical application in real-world (bio)chemical processes.", "AI": {"tldr": "GlycoPy\u662f\u4e00\u4e2a\u9762\u5411\u65b9\u7a0b\u548c\u5bf9\u8c61\u7684Python\u6846\u67b6\uff0c\u652f\u6301\u975e\u7ebf\u6027\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u5728\u590d\u6742\u5316\u5de5\u8fc7\u7a0b\u4e2d\u7684\u5efa\u6a21\u3001\u4f18\u5316\u4e0e\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u5de5\u4e1aMPC\u591a\u4f9d\u8d56\u7ebf\u6027\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5176\u5728\u975e\u7ebf\u6027\u3001\u5bbd\u5de5\u51b5\u8fc7\u7a0b\u4e2d\u7684\u6027\u80fd\u4e0e\u9002\u7528\u6027\u3002", "method": "\u5f00\u53d1GlycoPy\u6846\u67b6\uff0c\u652f\u6301\u5206\u5c42\u5efa\u6a21\u3001\u53c2\u6570\u4f30\u8ba1\u3001\u52a8\u6001\u4f18\u5316\u4e0eNMPC\uff0c\u5e76\u5141\u8bb8\u7528\u6237\u81ea\u5b9a\u4e49\u7b97\u6cd5\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u9a8c\u8bc1\u4e86GlycoPy\u5728\u5efa\u6a21\u3001\u4f18\u5316\u4e0e\u63a7\u5236\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u6db5\u76d6\u4ece\u7b80\u5355\u5fae\u5206\u4ee3\u6570\u7cfb\u7edf\u5230\u591a\u5c3a\u5ea6\u751f\u7269\u8fc7\u7a0b\u3002", "conclusion": "GlycoPy\u6709\u671b\u5f25\u5408\u5148\u8fdbNMPC\u7b97\u6cd5\u4e0e\u5b9e\u9645\uff08\u751f\u5316\uff09\u5de5\u4e1a\u8fc7\u7a0b\u5e94\u7528\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002"}}
{"id": "2601.01426", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.01426", "abs": "https://arxiv.org/abs/2601.01426", "authors": ["Chaofan Tao", "Jierun Chen", "Yuxin Jiang", "Kaiqi Kou", "Shaowei Wang", "Ruoyu Wang", "Xiaohui Li", "Sidi Yang", "Yiming Du", "Jianbo Dai", "Zhiming Mao", "Xinyu Wang", "Lifeng Shang", "Haoli Bai"], "title": "SWE-Lego: Pushing the Limits of Supervised Fine-tuning for Software Issue Resolving", "comment": "Project website: https://github.com/SWE-Lego/SWE-Lego", "summary": "We present SWE-Lego, a supervised fine-tuning (SFT) recipe designed to achieve state-ofthe-art performance in software engineering (SWE) issue resolving. In contrast to prevalent methods that rely on complex training paradigms (e.g., mid-training, SFT, reinforcement learning, and their combinations), we explore how to push the limits of a lightweight SFT-only approach for SWE tasks. SWE-Lego comprises three core building blocks, with key findings summarized as follows: 1) the SWE-Lego dataset, a collection of 32k highquality task instances and 18k validated trajectories, combining real and synthetic data to complement each other in both quality and quantity; 2) a refined SFT procedure with error masking and a difficulty-based curriculum, which demonstrably improves action quality and overall performance. Empirical results show that with these two building bricks alone,the SFT can push SWE-Lego models to state-of-the-art performance among open-source models of comparable size on SWE-bench Verified: SWE-Lego-Qwen3-8B reaches 42.2%, and SWE-Lego-Qwen3-32B attains 52.6%. 3) We further evaluate and improve test-time scaling (TTS) built upon the SFT foundation. Based on a well-trained verifier, SWE-Lego models can be significantly boosted--for example, 42.2% to 49.6% and 52.6% to 58.8% under TTS@16 for the 8B and 32B models, respectively.", "AI": {"tldr": "SWE-Lego \u662f\u4e00\u79cd\u4ec5\u4f9d\u8d56\u76d1\u7763\u5fae\u8c03\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u5728\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u4e2d\u8fbe\u5230\u5f00\u6e90\u6a21\u578b\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u7b80\u5316\u8bad\u7ec3\u8303\u5f0f\uff0c\u4ec5\u7528\u76d1\u7763\u5fae\u8c03\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u89e3\u51b3\u80fd\u529b\u3002", "method": "\u6784\u5efa\u5305\u542b\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3001\u9519\u8bef\u63a9\u853d\u4e0e\u96be\u5ea6\u8bfe\u7a0b\u7684\u7cbe\u70bcSFT\u6d41\u7a0b\uff0c\u5e76\u7ed3\u5408\u6d4b\u8bd5\u65f6\u6269\u5c55\u7b56\u7565\u63d0\u5347\u6027\u80fd\u3002", "result": "SWE-Lego-Qwen3-8B \u548c 32B \u5728 SWE-bench Verified \u4e0a\u5206\u522b\u8fbe\u5230 42.2% \u548c 52.6%\uff0c\u7ecf TTS@16 \u63d0\u5347\u81f3 49.6% \u548c 58.8%\u3002", "conclusion": "\u4ec5\u7528\u76d1\u7763\u5fae\u8c03\u914d\u5408\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u636e\u4e0e\u8bad\u7ec3\u7b56\u7565\uff0c\u5373\u53ef\u5728SWE\u4efb\u52a1\u4e2d\u5b9e\u73b0\u5ab2\u7f8e\u590d\u6742\u8bad\u7ec3\u8303\u5f0f\u7684\u6548\u679c\u3002"}}
{"id": "2601.02286", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.02286", "abs": "https://arxiv.org/abs/2601.02286", "authors": ["Rahul Sengupta", "Nooshin Yousefzadeh", "Manav Sanghvi", "Yash Ranjan", "Anand Rangarajan", "Sanjay Ranka", "Yashaswi Karnati", "Jeremy Dilmore", "Tushar Patel", "Ryan Casburn"], "title": "BigSUMO: A Scalable Framework for Big Data Traffic Analytics and Parallel Simulation", "comment": "6 pages, 10 figures", "summary": "With growing urbanization worldwide, efficient management of traffic infrastructure is critical for transportation agencies and city planners. It is essential to have tools that help analyze large volumes of stored traffic data and make effective interventions. To address this need, we present ``BigSUMO\", an end-to-end, scalable, open-source framework for analytics, interruption detection, and parallel traffic simulation. Our system ingests high-resolution loop detector and signal state data, along with sparse probe trajectory data. It first performs descriptive analytics and detects potential interruptions. It then uses the SUMO microsimulator for prescriptive analytics, testing hundreds of what-if scenarios to optimize traffic performance. The modular design allows integration of different algorithms for data processing and outlier detection. Built using open-source software and libraries, the pipeline is cost-effective, scalable, and easy to deploy. We hope BigSUMO will be a valuable aid in developing smart city mobility solutions.", "AI": {"tldr": "BigSUMO\u662f\u4e00\u4e2a\u5f00\u6e90\u3001\u53ef\u6269\u5c55\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u7528\u4e8e\u4ea4\u901a\u6570\u636e\u5206\u6790\u3001\u5f02\u5e38\u68c0\u6d4b\u4e0e\u5e76\u884c\u4eff\u771f\uff0c\u52a9\u529b\u667a\u6167\u57ce\u5e02\u4ea4\u901a\u7ba1\u7406\u3002", "motivation": "\u5e94\u5bf9\u5168\u7403\u57ce\u5e02\u5316\u5e26\u6765\u7684\u4ea4\u901a\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u6311\u6218\uff0c\u9700\u9ad8\u6548\u5206\u6790\u6d77\u91cf\u4ea4\u901a\u6570\u636e\u5e76\u5236\u5b9a\u5e72\u9884\u63aa\u65bd\u3002", "method": "\u6574\u5408\u9ad8\u5206\u8fa8\u7387\u68c0\u6d4b\u5668\u6570\u636e\u4e0e\u7a00\u758f\u8f68\u8ff9\u6570\u636e\uff0c\u5148\u505a\u63cf\u8ff0\u6027\u5206\u6790\u548c\u5f02\u5e38\u68c0\u6d4b\uff0c\u518d\u5229\u7528SUMO\u5fae\u4eff\u771f\u5668\u8fdb\u884c\u6570\u767e\u79cd\u573a\u666f\u4f18\u5316\u3002", "result": "\u7cfb\u7edf\u6a21\u5757\u5316\u8bbe\u8ba1\u652f\u6301\u7075\u6d3b\u7b97\u6cd5\u96c6\u6210\uff0c\u57fa\u4e8e\u5f00\u6e90\u5de5\u5177\u6784\u5efa\uff0c\u6210\u672c\u4f4e\u3001\u6613\u90e8\u7f72\u3001\u53ef\u6269\u5c55\u3002", "conclusion": "BigSUMO\u6709\u671b\u6210\u4e3a\u5f00\u53d1\u667a\u6167\u57ce\u5e02\u51fa\u884c\u89e3\u51b3\u65b9\u6848\u7684\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2601.01514", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01514", "abs": "https://arxiv.org/abs/2601.01514", "authors": ["Matej Kucera", "Marco Castelluccio", "Daniel Feitosa", "Ayushi Rastogi"], "title": "Group versus Individual Review Requests: Tradeoffs in Speed and Quality at Mozilla Firefox", "comment": "11 pages, 1 figure, 4 tables. To be published in ICSE-SEIP 2026 conference proceedings", "summary": "The speed at which code changes are integrated into the software codebase, also referred to as code review velocity, is a prevalent industry metric for improved throughput and developer satisfaction. While prior studies have explored factors influencing review velocity, the role of the review assignment process, particularly the `group review request', is unclear. In group review requests, available on platforms like Phabricator, GitHub, and Bitbucket, a code change is assigned to a reviewer group, allowing any member to review it, unlike individual review assignments to specific reviewers. Drawing parallels with shared task queues in Management Sciences, this study examines the effects of group versus individual review requests on velocity and quality. We investigate approximately 66,000 revisions in the Mozilla Firefox project, combining statistical modeling with practitioner views from a focus group discussion. Our study associates group reviews with improved review quality, characterized by fewer regressions, while having a negligible association with review velocity. Additional perceived benefits include balanced work distribution and training opportunities for new reviewers.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u7fa4\u4f53\u8bc4\u5ba1\u4e0e\u4e2a\u4eba\u8bc4\u5ba1\u5bf9\u4ee3\u7801\u5ba1\u67e5\u901f\u5ea6\u548c\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u7fa4\u4f53\u8bc4\u5ba1\u80fd\u63d0\u5347\u8d28\u91cf\u4f46\u5bf9\u901f\u5ea6\u5f71\u54cd\u4e0d\u5927\u3002", "motivation": "\u660e\u786e\u7fa4\u4f53\u8bc4\u5ba1\u5728\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u4f5c\u7528\uff0c\u4ee5\u4f18\u5316\u5f00\u53d1\u6d41\u7a0b\u548c\u63d0\u5347\u5f00\u53d1\u8005\u6ee1\u610f\u5ea6\u3002", "method": "\u7ed3\u5408\u7edf\u8ba1\u5efa\u6a21\u4e0e\u7126\u70b9\u5c0f\u7ec4\u8ba8\u8bba\uff0c\u5206\u6790Mozilla Firefox\u9879\u76ee\u4e2d\u7ea666,000\u6b21\u4fee\u8ba2\u6570\u636e\u3002", "result": "\u7fa4\u4f53\u8bc4\u5ba1\u4e0e\u66f4\u5c11\u7684\u56de\u5f52\u95ee\u9898\u76f8\u5173\uff0c\u8868\u660e\u8d28\u91cf\u63d0\u5347\uff1b\u4f46\u5bf9\u5ba1\u67e5\u901f\u5ea6\u65e0\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u7fa4\u4f53\u8bc4\u5ba1\u6709\u52a9\u4e8e\u5e73\u8861\u5de5\u4f5c\u5206\u914d\u548c\u57f9\u8bad\u65b0\u8bc4\u5ba1\u8005\uff0c\u662f\u63d0\u9ad8\u4ee3\u7801\u8d28\u91cf\u7684\u6709\u6548\u7b56\u7565\u3002"}}
{"id": "2601.02311", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02311", "abs": "https://arxiv.org/abs/2601.02311", "authors": ["Deep Pankajbhai Mehta"], "title": "Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies", "comment": "8 pages, 3 tables", "summary": "Training large language models requires distributing computation across many accelerators, yet practitioners select parallelism strategies (data, tensor, pipeline, ZeRO) through trial and error because no unified systematic framework predicts their behavior. We introduce placement semantics: each strategy is specified by how it places four training states (parameters, optimizer, gradients, activations) across devices using five modes (replicated, sharded, sharded-with-gather, materialized, offloaded). From placement alone, without implementation details, we derive memory consumption and communication volume. Our predictions match published results exactly: ZeRO-3 uses 8x less memory than data parallelism at 1.5x communication cost, as reported in the original paper. We prove two conditions (gradient integrity, state consistency) are necessary and sufficient for distributed training to match single-device results, and provide composition rules for combining strategies safely. The framework unifies ZeRO Stages 1-3, Fully Sharded Data Parallel (FSDP), tensor parallelism, and pipeline parallelism as instances with different placement choices.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u72b6\u6001\u653e\u7f6e\u8bed\u4e49\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u548c\u7ec4\u5408\u5206\u5e03\u5f0f\u8bad\u7ec3\u7b56\u7565\u7684\u5185\u5b58\u4e0e\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u5e76\u884c\u7b56\u7565\u9009\u62e9\u4f9d\u8d56\u8bd5\u9519\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7406\u8bba\u6846\u67b6\u9884\u6d4b\u5176\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u53c2\u6570\u3001\u4f18\u5316\u5668\u3001\u68af\u5ea6\u3001\u6fc0\u6d3b\u56db\u7c7b\u72b6\u6001\u5728\u8bbe\u5907\u4e0a\u7684\u4e94\u79cd\u653e\u7f6e\u6a21\u5f0f\uff0c\u63a8\u5bfc\u5185\u5b58\u4e0e\u901a\u4fe1\u91cf\uff0c\u5e76\u5efa\u7acb\u6b63\u786e\u6027\u6761\u4ef6\u4e0e\u7ec4\u5408\u89c4\u5219\u3002", "result": "\u7cbe\u786e\u590d\u73b0ZeRO-3\u7b49\u7b56\u7565\u7684\u5185\u5b58\u4e0e\u901a\u4fe1\u5f00\u9500\uff0c\u7edf\u4e00\u89e3\u91ca\u591a\u79cd\u4e3b\u6d41\u5e76\u884c\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5206\u5e03\u5f0f\u8bad\u7ec3\u7b56\u7565\u7684\u8bbe\u8ba1\u4e0e\u7ec4\u5408\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2601.01780", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01780", "abs": "https://arxiv.org/abs/2601.01780", "authors": ["Arsham Khosravani", "Alireza Hosseinpour", "Arshia Akhavan", "Mehdi Keshani", "Abbas Heydarnoori"], "title": "LIA: Supervised Fine-Tuning of Large Language Models for Automatic Issue Assignment", "comment": null, "summary": "Issue assignment is a critical process in software maintenance, where new issue reports are validated and assigned to suitable developers. However, manual issue assignment is often inconsistent and error-prone, especially in large open-source projects where thousands of new issues are reported monthly. Existing automated approaches have shown promise, but many rely heavily on large volumes of project-specific training data or relational information that is often sparse and noisy, which limits their effectiveness. To address these challenges, we propose LIA (LLM-based Issue Assignment), which employs supervised fine-tuning to adapt an LLM, DeepSeek-R1-Distill-Llama-8B in this work, for automatic issue assignment. By leveraging the LLM's pretrained semantic understanding of natural language and software-related text, LIA learns to generate ranked developer recommendations directly from issue titles and descriptions. The ranking is based on the model's learned understanding of historical issue-to-developer assignments, using patterns from past tasks to infer which developers are most likely to handle new issues. Through comprehensive evaluation, we show that LIA delivers substantial improvements over both its base pretrained model and state-of-the-art baselines. It achieves up to +187.8% higher Hit@1 compared to the DeepSeek-R1-Distill-Llama-8B pretrained base model, and outperforms four leading issue assignment methods by as much as +211.2% in Hit@1 score. These results highlight the effectiveness of domain-adapted LLMs for software maintenance tasks and establish LIA as a practical, high-performing solution for issue assignment.", "AI": {"tldr": "LIA\u901a\u8fc7\u5fae\u8c03LLM\u5b9e\u73b0\u81ea\u52a8\u95ee\u9898\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\u3002", "motivation": "\u624b\u52a8\u95ee\u9898\u5206\u914d\u6548\u7387\u4f4e\u4e14\u6613\u51fa\u9519\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u9879\u76ee\u6570\u636e\u6216\u7a00\u758f\u5173\u7cfb\u4fe1\u606f\uff0c\u6548\u679c\u53d7\u9650\u3002", "method": "\u57fa\u4e8eDeepSeek-R1-Distill-Llama-8B\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u5229\u7528LLM\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u4ece\u6807\u9898\u548c\u63cf\u8ff0\u76f4\u63a5\u751f\u6210\u5f00\u53d1\u8005\u63a8\u8350\u6392\u5e8f\u3002", "result": "\u76f8\u6bd4\u57fa\u6a21\u578bHit@1\u63d0\u5347187.8%\uff0c\u8d85\u8d8a\u56db\u4e2aSOTA\u65b9\u6cd5\u6700\u9ad8\u8fbe211.2%\u3002", "conclusion": "\u9886\u57df\u9002\u914d\u7684LLM\u5728\u8f6f\u4ef6\u7ef4\u62a4\u4efb\u52a1\u4e2d\u9ad8\u6548\u5b9e\u7528\uff0cLIA\u662f\u9ad8\u6027\u80fd\u7684\u95ee\u9898\u5206\u914d\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01839", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.01839", "abs": "https://arxiv.org/abs/2601.01839", "authors": ["Martin Prause"], "title": "The Machine Learning Canvas: Empirical Findings on Why Strategy Matters More Than AI Code Generation", "comment": "Dataset available: https://ieee-dataport.org/documents/machine-learning-canvas-success-determinants", "summary": "Despite the growing popularity of AI coding assistants, over 80% of machine learning (ML) projects fail to deliver real business value. This study creates and tests a Machine Learning Canvas, a practical framework that combines business strategy, software engineering, and data science in order to determine the factors that lead to the success of ML projects. We surveyed 150 data scientists and analyzed their responses using statistical modeling. We identified four key success factors: Strategy (clear goals and planning), Process (how work gets done), Ecosystem (tools and infrastructure), and Support (organizational backing and resources). Our results show that these factors are interconnected - each one affects the next. For instance, strong organizational support results in a clearer strategy (\u03b2= 0.432, p < 0.001), which improves work processes (\u03b2= 0.428, p < 0.001) and builds better infrastructure (\u03b2= 0.547, p < 0.001). Together, these elements determine whether a project succeeds. The surprising finding? Although AI assistants make coding faster, they don't guarantee project success. AI assists with the \"how\" of coding but cannot replace the \"why\" and \"what\" of strategic thinking.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u673a\u5668\u5b66\u4e60\u753b\u5e03\u6846\u67b6\uff0c\u63ed\u793a\u9879\u76ee\u6210\u529f\u7684\u56db\u5927\u5173\u952e\u56e0\u7d20\uff1a\u6218\u7565\u3001\u6d41\u7a0b\u3001\u751f\u6001\u7cfb\u7edf\u4e0e\u652f\u6301\uff0c\u5e76\u6307\u51faAI\u7f16\u7801\u52a9\u624b\u867d\u63d0\u5347\u6548\u7387\uff0c\u4f46\u65e0\u6cd5\u66ff\u4ee3\u6218\u7565\u601d\u8003\u3002", "motivation": "\u89e3\u51b380%\u4ee5\u4e0a\u673a\u5668\u5b66\u4e60\u9879\u76ee\u672a\u80fd\u5b9e\u73b0\u5546\u4e1a\u4ef7\u503c\u7684\u95ee\u9898\uff0c\u63a2\u7d22\u6210\u529f\u7684\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u3002", "method": "\u901a\u8fc7\u8c03\u7814150\u540d\u6570\u636e\u79d1\u5b66\u5bb6\u5e76\u4f7f\u7528\u7edf\u8ba1\u5efa\u6a21\u5206\u6790\u5176\u53cd\u9988\uff0c\u6784\u5efa\u5e76\u9a8c\u8bc1\u673a\u5668\u5b66\u4e60\u753b\u5e03\u6846\u67b6\u3002", "result": "\u53d1\u73b0\u56db\u5927\u6210\u529f\u56e0\u7d20\u76f8\u4e92\u5173\u8054\uff0c\u7ec4\u7ec7\u652f\u6301\u663e\u8457\u5f71\u54cd\u6218\u7565\u5236\u5b9a\uff08\u03b2=0.432\uff09\uff0c\u8fdb\u800c\u4f18\u5316\u6d41\u7a0b\uff08\u03b2=0.428\uff09\u548c\u57fa\u7840\u8bbe\u65bd\uff08\u03b2=0.547\uff09\u3002", "conclusion": "AI\u7f16\u7801\u52a9\u624b\u4ec5\u8f85\u52a9\u6280\u672f\u5b9e\u73b0\uff0c\u9879\u76ee\u6210\u529f\u4ecd\u4f9d\u8d56\u6e05\u6670\u7684\u6218\u7565\u89c4\u5212\u4e0e\u7ec4\u7ec7\u534f\u540c\u3002"}}
{"id": "2601.01921", "categories": ["cs.SE", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.01921", "abs": "https://arxiv.org/abs/2601.01921", "authors": ["Mikel Robredo", "Matteo Esposito", "Fabio Palomba", "Rafael Pe\u00f1aloza", "Valentina Lenarduzzi"], "title": "A Defect is Being Born: How Close Are We? A Time Sensitive Forecasting Approach", "comment": "ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026", "summary": "Background. Defect prediction has been a highly active topic among researchers in the Empirical Software Engineering field. Previous literature has successfully achieved the most accurate prediction of an incoming fault and identified the features and anomalies that precede it through just-in-time prediction. As software systems evolve continuously, there is a growing need for time-sensitive methods capable of forecasting defects before they manifest.\n  Aim. Our study seeks to explore the effectiveness of time-sensitive techniques for defect forecasting. Moreover, we aim to investigate the early indicators that precede the occurrence of a defect.\n  Method. We will train multiple time-sensitive forecasting techniques to forecast the future bug density of a software project, as well as identify the early symptoms preceding the occurrence of a defect.\n  Expected results. Our expected results are translated into empirical evidence on the effectiveness of our approach for early estimation of bug proneness.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u65f6\u95f4\u654f\u611f\u6280\u672f\u5728\u7f3a\u9677\u9884\u6d4b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u8bc6\u522b\u7f3a\u9677\u53d1\u751f\u524d\u7684\u65e9\u671f\u6307\u6807\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u7cfb\u7edf\u7684\u6301\u7eed\u6f14\u8fdb\uff0c\u4e9f\u9700\u80fd\u591f\u63d0\u524d\u9884\u6d4b\u7f3a\u9677\u7684\u65f6\u95f4\u654f\u611f\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u8bad\u7ec3\u591a\u79cd\u65f6\u95f4\u654f\u611f\u9884\u6d4b\u6280\u672f\uff0c\u9884\u6d4b\u8f6f\u4ef6\u9879\u76ee\u7684\u672a\u6765\u7f3a\u9677\u5bc6\u5ea6\u5e76\u8bc6\u522b\u7f3a\u9677\u524d\u5146\u3002", "result": "\u9884\u671f\u7ed3\u679c\u5c06\u63d0\u4f9b\u5173\u4e8e\u8be5\u65b9\u6cd5\u5728\u65e9\u671f\u7f3a\u9677\u503e\u5411\u4f30\u8ba1\u4e2d\u6709\u6548\u6027\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002", "conclusion": "\u7814\u7a76\u6709\u671b\u4e3a\u7f3a\u9677\u9884\u6d4b\u9886\u57df\u63d0\u4f9b\u66f4\u9ad8\u6548\u7684\u65f6\u95f4\u654f\u611f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.01944", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.01944", "abs": "https://arxiv.org/abs/2601.01944", "authors": ["Matteo Esposito", "Andrea Janes", "Valentina Lenarduzzi", "Davide Taibi"], "title": "The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities", "comment": "ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026", "summary": "In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.\n  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u5206\u6790AI\u5e93\u5728Python\u548cJava\u5f00\u6e90\u9879\u76ee\u4e2d\u7684\u91c7\u7528\u60c5\u51b5\u53ca\u5176\u5bf9\u5f00\u53d1\u6d3b\u52a8\u3001\u793e\u533a\u53c2\u4e0e\u548c\u4ee3\u7801\u590d\u6742\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u5f00\u6e90\u8f6f\u4ef6\u4e2d\u7684\u91cd\u8981\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u4f46\u5176\u5bf9\u5f00\u6e90\u9879\u76ee\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u5bf9157.7k\u4e2a\u6f5c\u5728\u5f00\u6e90\u4ed3\u5e93\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\uff0c\u6bd4\u8f83\u91c7\u7528\u4e0e\u672a\u91c7\u7528AI\u5e93\u9879\u76ee\u7684\u5404\u9879\u6307\u6807\u3002", "result": "\u9884\u671f\u53d1\u73b0\u91c7\u7528AI\u5e93\u7684\u9879\u76ee\u5728\u5f00\u53d1\u6d3b\u8dc3\u5ea6\u3001\u793e\u533a\u53c2\u4e0e\u5ea6\u548c\u4ee3\u7801\u590d\u6742\u6027\u65b9\u9762\u5b58\u5728\u53ef\u6d4b\u91cf\u5dee\u5f02\u3002", "conclusion": "AI\u96c6\u6210\u6b63\u5728\u91cd\u5851\u5f00\u6e90\u8f6f\u4ef6\u5f00\u53d1\u5b9e\u8df5\uff0c\u63d0\u4f9b\u57fa\u4e8e\u8bc1\u636e\u7684\u6d1e\u89c1\u3002"}}
{"id": "2601.01952", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01952", "abs": "https://arxiv.org/abs/2601.01952", "authors": ["Max Unterbusch", "Andreas Vogelsang"], "title": "Context-Adaptive Requirements Defect Prediction through Human-LLM Collaboration", "comment": "Accepted at ICSE-NIER 2026", "summary": "Automated requirements assessment traditionally relies on universal patterns as proxies for defectiveness, implemented through rule-based heuristics or machine learning classifiers trained on large annotated datasets. However, what constitutes a \"defect\" is inherently context-dependent and varies across projects, domains, and stakeholder interpretations. In this paper, we propose a Human-LLM Collaboration (HLC) approach that treats defect prediction as an adaptive process rather than a static classification task. HLC leverages LLM Chain-of-Thought reasoning in a feedback loop: users validate predictions alongside their explanations, and these validated examples adaptively guide future predictions through few-shot learning. We evaluate this approach using the weak word smell on the QuRE benchmark of 1,266 annotated Mercedes-Benz requirements. Our results show that HLC effectively adapts to the provision of validated examples, with rapid performance gains from as few as 20 validated examples. Incorporating validated explanations, not just labels, enables HLC to substantially outperform both standard few-shot prompting and fine-tuned BERT models while maintaining high recall. These results highlight how the in-context and Chain-of-Thought learning capabilities of LLMs enable adaptive classification approaches that move beyond one-size-fits-all models, creating opportunities for tools that learn continuously from stakeholder feedback.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u4eba\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u534f\u4f5c\uff08HLC\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u94fe\u5f0f\u601d\u7ef4\u4e0e\u7528\u6237\u53cd\u9988\u5b9e\u73b0\u9700\u6c42\u7f3a\u9677\u9884\u6d4b\u7684\u81ea\u9002\u5e94\u5b66\u4e60\uff0c\u5728\u5c11\u91cf\u6807\u6ce8\u6837\u672c\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u9700\u6c42\u7f3a\u9677\u8bc4\u4f30\u4f9d\u8d56\u901a\u7528\u6a21\u5f0f\uff0c\u5ffd\u89c6\u9879\u76ee\u548c\u8bed\u5883\u5dee\u5f02\uff0c\u96be\u4ee5\u9002\u5e94\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u201c\u7f3a\u9677\u201d\u5b9a\u4e49\u3002", "method": "\u91c7\u7528HLC\u6846\u67b6\uff0c\u7ed3\u5408LLM\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u4e0e\u7528\u6237\u9a8c\u8bc1\u53cd\u9988\uff0c\u901a\u8fc7\u5c11\u6837\u672c\u5b66\u4e60\u52a8\u6001\u8c03\u6574\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u5728QuRE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4ec5\u970020\u4e2a\u9a8c\u8bc1\u6837\u672c\u5373\u53ef\u5feb\u901f\u63d0\u5347\u6027\u80fd\uff0c\u4e14\u7ed3\u5408\u89e3\u91ca\u7684\u9884\u6d4b\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u5c11\u6837\u672c\u63d0\u793a\u4e0e\u5fae\u8c03BERT\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u53ec\u56de\u7387\u3002", "conclusion": "LLM\u7684\u4e0a\u4e0b\u6587\u4e0e\u94fe\u5f0f\u601d\u7ef4\u80fd\u529b\u652f\u6301\u6784\u5efa\u53ef\u968f\u7528\u6237\u53cd\u9988\u6301\u7eed\u8fdb\u5316\u7684\u81ea\u9002\u5e94\u5206\u7c7b\u5de5\u5177\uff0c\u7a81\u7834\u4f20\u7edf\u9759\u6001\u6a21\u578b\u5c40\u9650\u3002"}}
{"id": "2601.01954", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.01954", "abs": "https://arxiv.org/abs/2601.01954", "authors": ["Alexander Korn", "Lea Zaruchas", "Chetan Arora", "Andreas Metzger", "Sven Smolka", "Fanyu Wang", "Andreas Vogelsang"], "title": "Reporting LLM Prompting in Automated Software Engineering: A Guideline Based on Current Practices and Expectations", "comment": "To be published at The 3rd ACM International Conference on AI Foundation Models and Software Engineering FORGE 2026", "summary": "Large Language Models, particularly decoder-only generative models such as GPT, are increasingly used to automate Software Engineering tasks. These models are primarily guided through natural language prompts, making prompt engineering a critical factor in system performance and behavior. Despite their growing role in SE research, prompt-related decisions are rarely documented in a systematic or transparent manner, hindering reproducibility and comparability across studies. To address this gap, we conducted a two-phase empirical study. First, we analyzed nearly 300 papers published at the top-3 SE conferences since 2022 to assess how prompt design, testing, and optimization are currently reported. Second, we surveyed 105 program committee members from these conferences to capture their expectations for prompt reporting in LLM-driven research. Based on the findings, we derived a structured guideline that distinguishes essential, desirable, and exceptional reporting elements. Our results reveal significant misalignment between current practices and reviewer expectations, particularly regarding version disclosure, prompt justification, and threats to validity. We present our guideline as a step toward improving transparency, reproducibility, and methodological rigor in LLM-based SE research.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u63d0\u793a\u8bbe\u8ba1\u62a5\u544a\u73b0\u72b6\uff0c\u63d0\u51fa\u4e86\u4e00\u5957\u7ed3\u6784\u5316\u6307\u5357\u4ee5\u63d0\u5347\u900f\u660e\u5ea6\u548c\u53ef\u590d\u73b0\u6027\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u5bf9\u63d0\u793a\u8bbe\u8ba1\u7684\u62a5\u544a\u7f3a\u4e4f\u7cfb\u7edf\u6027\u548c\u900f\u660e\u5ea6\uff0c\u5f71\u54cd\u7814\u7a76\u7684\u53ef\u590d\u73b0\u6027\u548c\u53ef\u6bd4\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8fd1300\u7bc7\u9876\u4f1a\u8bba\u6587\u5e76\u8c03\u67e5105\u4f4d\u7a0b\u5e8f\u59d4\u5458\u4f1a\u6210\u5458\uff0c\u5f52\u7eb3\u51fa\u63d0\u793a\u62a5\u544a\u7684\u5173\u952e\u8981\u7d20\u3002", "result": "\u53d1\u73b0\u5f53\u524d\u5b9e\u8df5\u4e0e\u5ba1\u7a3f\u4eba\u671f\u671b\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u7248\u672c\u62ab\u9732\u3001\u63d0\u793a\u5408\u7406\u6027\u53ca\u6709\u6548\u6027\u5a01\u80c1\u65b9\u9762\u3002", "conclusion": "\u63d0\u51fa\u7684\u7ed3\u6784\u5316\u6307\u5357\u6709\u52a9\u4e8e\u63d0\u5347\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u900f\u660e\u5ea6\u3001\u53ef\u590d\u73b0\u6027\u548c\u65b9\u6cd5\u4e25\u8c28\u6027\u3002"}}
{"id": "2601.02066", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02066", "abs": "https://arxiv.org/abs/2601.02066", "authors": ["Al Muttakin", "Saikat Mondal", "Chanchal Roy"], "title": "The State of Open Science in Software Engineering Research: A Case Study of ICSE Artifacts", "comment": "To appear in Proc. IEEE/ACM 48th International Conference on Software Engineering (ICSE 2026), Rio de Janeiro, Brazil, 12-18 Apr 2026", "summary": "Replication packages are crucial for enabling transparency, validation, and reuse in software engineering (SE) research. While artifact sharing is now a standard practice and even expected at premier SE venues such as ICSE, the practical usability of these replication packages remains underexplored. In particular, there is a marked lack of studies that comprehensively examine the executability and reproducibility of replication packages in SE research. In this paper, we aim to fill this gap by evaluating 100 replication packages published as part of ICSE proceedings over the past decade (2015--2024). We assess the (1) executability of the replication packages, (2) efforts and modifications required to execute them, (3) challenges that prevent executability, and (4) reproducibility of the original findings. We spent approximately 650 person-hours in total executing the artifacts and reproducing the study findings. Our findings reveal that only 40\\% of the 100 evaluated artifacts were executable, of which 32.5\\% (13 out of 40) ran without any modification. Regarding effort levels, 17.5\\% (7 out of 40) required low effort, while 82.5\\% (33 out of 40) required moderate to high effort to execute successfully. We identified five common types of modifications and 13 challenges leading to execution failure, spanning environmental, documentation, and structural issues. Among the executable artifacts, only 35\\% (14 out of 40) reproduced the original results. These findings highlight a notable gap between artifact availability, executability, and reproducibility. Our study proposes three actionable guidelines to improve the preparation, documentation, and review of research artifacts, thereby strengthening the rigor and sustainability of open science practices in SE research.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e862015-2024\u5e74\u95f4ICSE\u4f1a\u8bae\u7684100\u4e2a\u590d\u5236\u5305\uff0c\u53d1\u73b0\u4ec540%\u53ef\u6267\u884c\u300135%\u80fd\u590d\u73b0\u7ed3\u679c\uff0c\u63ed\u793a\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u590d\u5236\u5305\u53ef\u7528\u6027\u4e0e\u5b9e\u7528\u6027\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u4e09\u9879\u6539\u8fdb\u6307\u5357\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u867d\u666e\u904d\u5171\u4eab\u590d\u5236\u5305\uff0c\u4f46\u5176\u5b9e\u9645\u53ef\u6267\u884c\u6027\u4e0e\u53ef\u590d\u73b0\u6027\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\uff0c\u963b\u788d\u4e86\u79d1\u7814\u900f\u660e\u4e0e\u91cd\u7528\u3002", "method": "\u4eba\u5de5\u6295\u5165\u7ea6650\u5c0f\u65f6\uff0c\u5bf9100\u4e2aICSE\u590d\u5236\u5305\u8fdb\u884c\u6267\u884c\u6d4b\u8bd5\uff0c\u8bb0\u5f55\u6240\u9700\u4fee\u6539\u3001\u5931\u8d25\u539f\u56e0\u53ca\u7ed3\u679c\u590d\u73b0\u60c5\u51b5\uff0c\u5f52\u7eb3\u6311\u6218\u7c7b\u578b\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "result": "\u4ec540%\u590d\u5236\u5305\u53ef\u6267\u884c\uff08\u5176\u4e2d32.5%\u65e0\u9700\u4fee\u6539\uff09\uff0c82.5%\u9700\u4e2d\u9ad8\u7a0b\u5ea6\u4fee\u6539\uff1b\u4ec535%\u6210\u529f\u590d\u73b0\u539f\u7ed3\u679c\uff1b\u8bc6\u522b\u51fa5\u7c7b\u5e38\u89c1\u4fee\u6539\u548c13\u9879\u6267\u884c\u969c\u788d\u3002", "conclusion": "\u590d\u5236\u5305\u7684\u53ef\u7528\u6027\u4e0d\u7b49\u4e8e\u53ef\u6267\u884c\u6027\u6216\u53ef\u590d\u73b0\u6027\uff0c\u4e9f\u9700\u901a\u8fc7\u6807\u51c6\u5316\u6587\u6863\u3001\u73af\u5883\u5c01\u88c5\u548c\u5ba1\u7a3f\u6d41\u7a0b\u4f18\u5316\u63d0\u5347\u5f00\u653e\u79d1\u5b66\u5b9e\u8df5\u8d28\u91cf\u3002"}}
{"id": "2601.02215", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.02215", "abs": "https://arxiv.org/abs/2601.02215", "authors": ["Nenad Petrovic", "Vahid Zolfaghari", "Fengjunjie Pan", "Alois Knoll"], "title": "LLM-Empowered Functional Safety and Security by Design in Automotive Systems", "comment": null, "summary": "This paper presents LLM-empowered workflow to support Software Defined Vehicle (SDV) software development, covering the aspects of security-aware system topology design, as well as event-driven decision-making code analysis. For code analysis we adopt event chains model which provides formal foundations to systematic validation of functional safety, taking into account the semantic validity of messages exchanged between key components, including both CAN and Vehicle Signal Specification (VSS). Analysis of security aspects for topology relies on synergy with Model-Driven Engineering (MDE) approach and Object Constraint Language (OCL) rules. Both locally deployable and proprietary solution are taken into account for evaluation within Advanced Driver-Assistance Systems (ADAS)-related scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u652f\u6301\u8f6f\u4ef6\u5b9a\u4e49\u6c7d\u8f66\u7684\u5f00\u53d1\uff0c\u6db5\u76d6\u5b89\u5168\u611f\u77e5\u62d3\u6251\u8bbe\u8ba1\u4e0e\u4e8b\u4ef6\u9a71\u52a8\u4ee3\u7801\u5206\u6790\u3002", "motivation": "\u63d0\u5347\u8f6f\u4ef6\u5b9a\u4e49\u6c7d\u8f66\u5728\u529f\u80fd\u5b89\u5168\u4e0e\u4fe1\u606f\u5b89\u5168\u65b9\u9762\u7684\u7cfb\u7edf\u5316\u9a8c\u8bc1\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e8b\u4ef6\u94fe\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u8bed\u4e49\u5206\u6790\uff0c\u7ed3\u5408MDE\u4e0eOCL\u89c4\u5219\u8fdb\u884c\u62d3\u6251\u5b89\u5168\u5206\u6790\uff0c\u8bc4\u4f30\u672c\u5730\u90e8\u7f72\u4e0e\u4e13\u6709\u65b9\u6848\u5728ADAS\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9CAN\u4e0eVSS\u6d88\u606f\u8bed\u4e49\u7684\u6709\u6548\u9a8c\u8bc1\uff0c\u5e76\u901a\u8fc7MDE/OCL\u589e\u5f3a\u4e86\u62d3\u6251\u5b89\u5168\u6027\u5206\u6790\u80fd\u529b\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6d41\u80fd\u6709\u6548\u652f\u6301SDV\u5f00\u53d1\u4e2d\u5b89\u5168\u4e0e\u529f\u80fd\u6b63\u786e\u6027\u7684\u534f\u540c\u4fdd\u969c\u3002"}}
{"id": "2601.02238", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02238", "abs": "https://arxiv.org/abs/2601.02238", "authors": ["Nils Bosbach", "Alwalid Salama", "Lukas J\u00fcnger", "Mark Burton", "Niko Zurstra\u00dfen", "Rebecca Pelke", "Rainer Leupers"], "title": "NQC2: A Non-Intrusive QEMU Code Coverage Plugin", "comment": "PREPRINT - accepted by the Rapid Simulation and Performance Evaluation for Design Workshop (RAPIDO '24)", "summary": "Code coverage analysis has become a standard approach in software development, facilitating the assessment of test suite effectiveness, the identification of under-tested code segments, and the discovery of performance bottlenecks. When code coverage of software for embedded systems needs to be measured, conventional approaches quickly meet their limits. A commonly used approach involves instrumenting the source files with added code that collects and dumps coverage information during runtime. This inserted code usually relies on the existence of an operating and a file system to dump the collected data. These features are not available for bare-metal programs that are executed on embedded systems.\n  To overcome this issue, we present NQC2, a plugin for QEMU.NQC2 extracts coverage information from QEMU during runtime and stores them into a file on the host machine. This approach is even compatible with modified QEMU versions and does not require target-software instrumentation. NQC2 outperforms a comparable approach from Xilinx by up to 8.5 x.", "AI": {"tldr": "NQC2\u662f\u4e00\u4e2a\u7528\u4e8e\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4ee3\u7801\u8986\u76d6\u7387\u5206\u6790\u7684QEMU\u63d2\u4ef6\uff0c\u65e0\u9700\u76ee\u6807\u8f6f\u4ef6\u63d2\u6869\uff0c\u6027\u80fd\u4f18\u4e8eXilinx\u65b9\u68488.5\u500d\u3002", "motivation": "\u4f20\u7edf\u4ee3\u7801\u8986\u76d6\u7387\u5de5\u5177\u4f9d\u8d56\u64cd\u4f5c\u7cfb\u7edf\u548c\u6587\u4ef6\u7cfb\u7edf\uff0c\u65e0\u6cd5\u9002\u7528\u4e8e\u88f8\u673a\u5d4c\u5165\u5f0f\u7a0b\u5e8f\u3002", "method": "\u901a\u8fc7QEMU\u8fd0\u884c\u65f6\u63d0\u53d6\u8986\u76d6\u7387\u4fe1\u606f\u5e76\u5b58\u50a8\u4e8e\u5bbf\u4e3b\u673a\uff0c\u907f\u514d\u5bf9\u76ee\u6807\u8f6f\u4ef6\u8fdb\u884c\u63d2\u6869\u3002", "result": "NQC2\u517c\u5bb9\u4fee\u6539\u7248QEMU\uff0c\u6027\u80fd\u6bd4Xilinx\u65b9\u6848\u6700\u9ad8\u63d0\u53478.5\u500d\u3002", "conclusion": "NQC2\u4e3a\u5d4c\u5165\u5f0f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u65e0\u4fb5\u5165\u7684\u4ee3\u7801\u8986\u76d6\u7387\u5206\u6790\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.02248", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02248", "abs": "https://arxiv.org/abs/2601.02248", "authors": ["Mohammad Reza Heidari Iman", "Giorgio Di Natale", "Katell Morin-Allory"], "title": "Automatic Assertion Mining in Assertion-Based Verification: Techniques, Challenges, and Future Directions", "comment": "6 pages", "summary": "Functional verification increasingly relies on Assertion-Based Verification (ABV), which has become a key approach for verifying hardware designs due to its efficiency and effectiveness. Central to ABV are automatic assertion miners, which apply different techniques to generate assertions automatically. This paper reviews the most recent, advanced, and widely adopted assertion miners, offering a comparative analysis of their methodologies. The goal is to provide researchers and verification practitioners with insights into the capabilities and limitations of existing miners. By identifying their shortcomings, this work also points toward directions for developing more powerful and advanced assertion miners in the future.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5f53\u524d\u4e3b\u6d41\u7684\u81ea\u52a8\u65ad\u8a00\u6316\u6398\u6280\u672f\uff0c\u6bd4\u8f83\u5176\u65b9\u6cd5\u4f18\u52a3\uff0c\u4e3a\u672a\u6765\u66f4\u5f3a\u5927\u7684\u65ad\u8a00\u6316\u6398\u5668\u53d1\u5c55\u63d0\u4f9b\u65b9\u5411\u3002", "motivation": "\u529f\u80fd\u9a8c\u8bc1\u65e5\u76ca\u4f9d\u8d56\u57fa\u4e8e\u65ad\u8a00\u7684\u9a8c\u8bc1\uff0c\u800c\u81ea\u52a8\u65ad\u8a00\u6316\u6398\u5668\u662f\u5176\u6838\u5fc3\uff0c\u9700\u7cfb\u7edf\u8bc4\u4f30\u73b0\u6709\u6280\u672f\u4ee5\u63a8\u52a8\u8fdb\u6b65\u3002", "method": "\u5bf9\u8fd1\u671f\u5148\u8fdb\u4e14\u5e7f\u6cdb\u5e94\u7528\u7684\u65ad\u8a00\u6316\u6398\u5668\u8fdb\u884c\u56de\u987e\u4e0e\u65b9\u6cd5\u5b66\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u63ed\u793a\u4e86\u73b0\u6709\u65ad\u8a00\u6316\u6398\u5668\u7684\u80fd\u529b\u4e0e\u5c40\u9650\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u5b9e\u7528\u6d1e\u5bdf\u3002", "conclusion": "\u6307\u51fa\u73b0\u6709\u6280\u672f\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u5f00\u53d1\u66f4\u5f3a\u5927\u65ad\u8a00\u6316\u6398\u5668\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2601.02345", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.02345", "abs": "https://arxiv.org/abs/2601.02345", "authors": ["Parham Khamsepour", "Mark Cole", "Ish Ashraf", "Sandeep Puri", "Mehrdad Sabetzadeh", "Shiva Nejati"], "title": "Question Answering for Multi-Release Systems: A Case Study at Ciena", "comment": "Accepted for publication in SANER 2026", "summary": "Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.", "AI": {"tldr": "QAMR\u662f\u4e00\u4e2a\u4e13\u4e3a\u591a\u7248\u672c\u7cfb\u7edf\u6587\u6863\u8bbe\u8ba1\u7684\u95ee\u7b54\u804a\u5929\u673a\u5668\u4eba\uff0c\u901a\u8fc7\u6539\u8fdb\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u63d0\u5347\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u95ee\u7b54\u6280\u672f\u5728\u5904\u7406\u591a\u7248\u672c\u7cfb\u7edf\u6587\u6863\u65f6\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u9700\u9488\u5bf9\u6027\u4f18\u5316\u3002", "method": "\u7ed3\u5408\u9884\u5904\u7406\u3001\u67e5\u8be2\u91cd\u5199\u3001\u4e0a\u4e0b\u6587\u9009\u62e9\u53ca\u53cc\u5206\u5757\u7b56\u7565\uff0c\u4f18\u5316\u68c0\u7d22\u4e0e\u751f\u6210\u8fc7\u7a0b\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u548c\u5b9e\u9645\u6570\u636e\u4e2d\uff0cQAMR\u663e\u8457\u63d0\u5347\u7b54\u6848\u6b63\u786e\u7387\uff08+16.5%\uff09\u548c\u68c0\u7d22\u51c6\u786e\u7387\uff08+12%\uff09\uff0c\u5e76\u7f29\u77ed\u54cd\u5e94\u65f6\u95f48%\u3002", "conclusion": "QAMR\u6709\u6548\u89e3\u51b3\u591a\u7248\u672c\u6587\u6863\u95ee\u7b54\u96be\u9898\uff0c\u5176\u8bc4\u4f30\u6307\u6807\u4e0e\u4eba\u5de5\u8bc4\u4f30\u9ad8\u5ea6\u4e00\u81f4\uff0c\u65b9\u6cd5\u53ef\u9760\u3002"}}
