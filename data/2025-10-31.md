<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 18]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.NI](#cs.NI) [Total: 4]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.PF](#cs.PF) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [Internal Vulnerabilities, External Threats: A Grounded Framework for Enterprise Open Source Risk Governance](https://arxiv.org/abs/2510.25882)
*Wenhao Yang,Minghui Zhou,Daniel Izquierdo Cortázar,Yehui Wang*

Main category: cs.SE

TL;DR: 本文提出一个面向企业开源风险治理的整体框架（OTVM），通过“目标—威胁—脆弱性—缓解”逻辑链，将风险管理从技术层面提升至战略治理层面，并通过实证研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统开源风险管理过于聚焦技术工具，无法应对上游静默修复、社区冲突或许可证突变等系统性风险，导致企业在战略层面临治理盲区。

Method: 采用扎根理论方法，对15位从业者进行访谈，构建并验证了一个基于“外部威胁-内部脆弱性”互动原理的风险治理框架，并通过三位行业专家的回溯案例研究验证其实用性。

Result: 提出了包含战略目标矩阵、外部威胁与内部脆弱性双重分类法（Ex-Tech/Comm/Eco 与 In-Strat/Ops/Tech）以及对应缓解措施的能力构建框架，形成可操作的OTVM模型。

Conclusion: 该框架为企业提供了一种从被动响应转向主动构建组织“免疫系统”的系统路径，填补了开源战略整合中的风险治理空白。

Abstract: Enterprise engagement with open source has evolved from tactical adoption to
strategic deep integration, exposing them to a complex risk landscape far
beyond mere code. However, traditional risk management, narrowly focused on
technical tools, is structurally inadequate for systemic threats like upstream
"silent fixes", community conflicts, or sudden license changes, creating a
dangerous governance blind spot. To address this governance vacuum and enable
the necessary shift from tactical risk management to holistic risk governance,
we conducted a grounded theory study with 15 practitioners to develop a
holistic risk governance framework. Our study formalizes an analytical
framework built on a foundational risk principle: an uncontrollable External
Threat (e.g., a sudden license change in a key dependency) only becomes a
critical risk when it exploits a controllable Internal Vulnerability (e.g., an
undefined risk appetite for single-vendor projects), which then amplifies the
impact.The framework operationalizes this principle through a clear logical
chain: "Objectives -> Threats -> Vulnerabilities -> Mitigation" (OTVM). This
provides a holistic decision model that transcends mere technical checklists.
Based on this logic, our contributions are: (1) a "Strategic Objectives Matrix"
to clarify goals; (2) a systematic dual taxonomy of External Threats (Ex-Tech,
Ex-Comm, Ex-Eco) and Internal Vulnerabilities (In-Strat, In-Ops, In-Tech); and
(3) an actionable mitigation framework mapping capability-building to these
vulnerabilities. The framework's analytical utility was validated by three
industry experts through retrospective case studies on real-world incidents.
This work provides a novel diagnostic lens and a systematic path for
enterprises to shift from reactive "firefighting" to proactively building an
organizational "immune system".

</details>


### [2] [A Process Mining-Based System For The Analysis and Prediction of Software Development Workflows](https://arxiv.org/abs/2510.25935)
*Antía Dorado,Iván Folgueira,Sofía Martín,Gonzalo Martín,Álvaro Porto,Alejandro Ramos,John Wallace*

Main category: cs.SE

TL;DR: CodeSight 是一个端到端系统，结合过程挖掘与 LSTM 模型，通过分析 GitHub 数据预测 PR 解决时间，从而提前识别是否可能违反截止期限。


<details>
  <summary>Details</summary>
Motivation: 软件开发中难以及时预测是否能按时完成任务，现有方法缺乏对开发流程动态行为的细粒度建模，因此需要一个能整合开发活动数据并提前预警截止期限风险的系统。

Method: 从 GitHub 获取开发与部署数据，转化为过程挖掘日志；基于日志提取指标并构建仪表盘；利用 LSTM 模型结合序列活动轨迹与静态特征预测 PR 剩余解决时间。

Result: 系统在预测截止期限合规性方面表现出高精确率和 F1 分数，验证了过程挖掘与机器学习结合的有效性。

Conclusion: 将过程挖掘与深度学习相结合，可有效支持软件项目管理中的截止期限预测与风险预警，提升项目可控性。

Abstract: CodeSight is an end-to-end system designed to anticipate deadline compliance
in software development workflows. It captures development and deployment data
directly from GitHub, transforming it into process mining logs for detailed
analysis. From these logs, the system generates metrics and dashboards that
provide actionable insights into PR activity patterns and workflow efficiency.
Building on this structured representation, CodeSight employs an LSTM model
that predicts remaining PR resolution times based on sequential activity traces
and static features, enabling early identification of potential deadline
breaches. In tests, the system demonstrates high precision and F1 scores in
predicting deadline compliance, illustrating the value of integrating process
mining with machine learning for proactive software project management.

</details>


### [3] [Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation](https://arxiv.org/abs/2510.26130)
*Musfiqur Rahman,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 该论文提出一个基于真实开源项目的类级别代码生成新基准，发现大语言模型（LLMs）在真实场景中表现远逊于合成基准，仅25%-34%正确率，并揭示了文档完整性、检索增强等策略的实际效果及主要错误类型。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在函数级代码生成上表现良好，但在真实软件项目中生成正确的类级别实现的能力尚不清楚；现有评估多依赖合成数据，缺乏对实际工程场景泛化能力的衡量。

Method: 构建一个源自开源仓库的真实类级别代码基准，划分为“见过”与“未见过”两部分；在不同输入规范、检索增强配置和文档完整度下，评估多个LLM的表现，并进行错误模式分析。

Result: LLM在真实类任务中正确率仅为25%-34%，远低于合成基准的84%-89%；完整文档仅带来1%-3%的微弱提升；检索增强在文档不全时最有效，可提升4%-7%正确率；主要错误为AttributeError、TypeError和AssertionError（占84%）。

Conclusion: 当前LLM在类级别代码生成方面存在显著局限，需改进上下文建模、文档策略和检索集成，以提升其在实际代码辅助工具中的实用性。

Abstract: Large language models (LLMs) have advanced code generation at the function
level, yet their ability to produce correct class-level implementations in
authentic software projects remains poorly understood. This work introduces a
novel benchmark derived from open-source repositories, comprising real-world
classes divided into seen and unseen partitions to evaluate generalization
under practical conditions. The evaluation examines multiple LLMs under varied
input specifications, retrieval-augmented configurations, and documentation
completeness levels.
  Results reveal a stark performance disparity: LLMs achieve 84% to 89%
correctness on established synthetic benchmarks but only 25% to 34% on
real-world class tasks, with negligible differences between familiar and novel
codebases. Comprehensive docstrings yield modest gains of 1% to 3% in
functional accuracy, though statistical significance is rare.
Retrieval-augmented generation proves most effective with partial
documentation, improving correctness by 4% to 7% by supplying concrete
implementation patterns absent from specifications. Error profiling identifies
AttributeError, TypeError, and AssertionError as dominant failure modes (84% of
cases), with synthetic tests overemphasizing assertion issues and real-world
scenarios highlighting type and attribute mismatches. Retrieval augmentation
reduces logical flaws but can introduce dependency conflicts.
  The benchmark and analysis expose critical limitations in current LLM
capabilities for class-level engineering, offering actionable insights for
enhancing context modelling, documentation strategies, and retrieval
integration in production code assistance tools.

</details>


### [4] [The "4W+1H" of Software Supply Chain Security Checklist for Critical Infrastructure](https://arxiv.org/abs/2510.26174)
*Liming Dong,Sung Une Lee,Zhenchang Xing,Muhammad Ejaz Ahmed,Stefan Avgoustakis*

Main category: cs.SE

TL;DR: 本文通过多视角文献综述，识别并整合适用于关键基础设施领域的软件供应链安全实践，提出一个包含80个问题的多层次检查清单，以弥合现有框架与行业特定需求之间的差距。


<details>
  <summary>Details</summary>
Motivation: 软件供应链攻击日益频繁且复杂，对关键基础设施构成严重威胁，而现有安全实践碎片化、缺乏针对性，难以满足关键基础设施部门的实际需求。

Method: 采用多视角文献综述方法，结合国际框架、澳大利亚监管资料和学术研究，运用“4W+1H”分析法，系统归纳出十大核心安全实践类别，并映射其在生命周期阶段（when）、利益相关者角色（who）和实施层级（how）中的分布。

Result: 发现现有框架极少专门针对关键基础设施领域；基于分析结果构建了一个结构化的80项问题检查清单，用于评估和提升软件供应链安全性。

Conclusion: 需发展整合性、情境感知的安全方法，以应对不断演变的软件供应链风险，保障关键基础设施安全。

Abstract: The increasing frequency and sophistication of software supply chain attacks
pose severe risks to critical infrastructure sectors, threatening national
security, economic stability, and public safety. Despite growing awareness,
existing security practices remain fragmented and insufficient, with most
frameworks narrowly focused on isolated life cycle stages or lacking alignment
with the specific needs of critical infrastructure (CI) sectors. In this paper,
we conducted a multivocal literature review across international frameworks,
Australian regulatory sources, and academic studies to identify and analyze
security practices across the software supply chain, especially specific CI
sector. Our analysis found that few existing frameworks are explicitly tailored
to CI domains. We systematically leveraged identified software supply chain
security frameworks, using a "4W+1H" analytical approach, we synthesized ten
core categories (what) of software supply chain security practices, mapped them
across life-cycle phases (when), stakeholder roles (who), and implementation
levels (how), and examined their coverage across existing frameworks (where).
Building on these insights, the paper culminates in structured, multi-layered
checklist of 80 questions designed to relevant stakeholders evaluate and
enhance their software supply chain security. Our findings reveal gaps between
framework guidance and sector-specific needs, highlight the need for
integrated, context-aware approaches to safeguard critical infrastructure from
evolving software supply chain risks.

</details>


### [5] [Environmental Impact of CI/CD Pipelines](https://arxiv.org/abs/2510.26413)
*Nuno Saavedra,Alexandra Mendes,João F. Ferreira*

Main category: cs.SE

TL;DR: 该论文评估了 GitHub Actions 在开源项目中的碳足迹和水足迹，发现其环境影响显著，并提出了通过优化运行区域、调度策略和仓库大小来减少资源浪费的缓解策略。


<details>
  <summary>Details</summary>
Motivation: 由于 CI/CD 服务提供商通常不披露其环境影响数据，开发者对其碳足迹和水足迹缺乏认知，而随着云计算环境影响日益加剧，有必要量化并理解 GitHub Actions 等主流 CI/CD 平台的生态代价。

Method: 基于 Cloud Carbon Footprint 框架的方法论，利用包含超过 220 万次工作流运行、来自 18,000 多个仓库的迄今最大规模数据集，估算 GitHub Actions 的碳和水足迹。

Result: 2024 年 GitHub Actions 的碳足迹估计在 150.5 至 994.9 公吨二氧化碳当量之间（最可能值为 456.9），水足迹在 1,989.6 至 37,664.5 千升之间（最可能值为 5,738.2）。这些数值分别相当于 7,615 棵城市树木一年的固碳量和一个美国家庭 5,053 年的用水量。

Conclusion: GitHub Actions 的环境影响不容忽视，但可通过将运行器部署在低碳能源区域、优化调度策略以及减小仓库体积等方式有效降低其碳和水足迹。

Abstract: CI/CD pipelines are widely used in software development, yet their
environmental impact, particularly carbon and water footprints (CWF), remains
largely unknown to developers, as CI service providers typically do not
disclose such information. With the growing environmental impact of cloud
computing, understanding the CWF of CI/CD services has become increasingly
important.
  This work investigates the CWF of using GitHub Actions, focusing on
open-source repositories where usage is free and unlimited for standard
runners. We build upon a methodology from the Cloud Carbon Footprint framework
and we use the largest dataset of workflow runs reported in the literature to
date, comprising over 2.2 million workflow runs from more than 18,000
repositories.
  Our analysis reveals that the GitHub Actions ecosystem results in a
substantial CWF. Our estimates for the carbon footprint in 2024 range from
150.5 MTCO2e in the most optimistic scenario to 994.9 MTCO2e in the most
pessimistic scenario, while the water footprint ranges from 1,989.6 to 37,664.5
kiloliters. The most likely scenario estimates are 456.9 MTCO2e for carbon
footprint and 5,738.2 kiloliters for water footprint. To provide perspective,
the carbon footprint in the most likely scenario is equivalent to the carbon
captured by 7,615 urban trees in a year, and the water footprint is comparable
to the water consumed by an average American family over 5,053 years.
  We explore strategies to mitigate this impact, primarily by reducing wasted
computational resources. Key recommendations include deploying runners in
regions whose energy production has a low environmental impact such as France
and the United Kingdom, implementing stricter deactivation policies for
scheduled runs and aligning their execution with periods when the regional
energy mix is more environmentally favorable, and reducing the size of
repositories.

</details>


### [6] [A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI](https://arxiv.org/abs/2510.26275)
*Domenico Amalfitano,Andreas Metzger,Marco Autili,Tommaso Fulcini,Tobias Hey,Jan Keim,Patrizio Pelliccione,Vincenzo Scotti,Anne Koziolek,Raffaela Mirandola,Andreas Vogelsang*

Main category: cs.SE

TL;DR: 本文通过设计科学研究方法，构建了一个关于生成式人工智能（GenAI）增强软件工程（SE）的路线图，识别出四种基本的GenAI增强形式，并提出了相关研究挑战、机遇及2030年SE领域的十大预测。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI迅速改变软件工程实践，亟需系统性理解其对SE流程、方法、工具及软件产品的影响，并为未来研究提供清晰方向。

Method: 采用设计科学研究方法，通过三个迭代周期整合多方证据，包括FSE 2025“Software Engineering 2030”研讨会的协作讨论、快速文献综述和同行外部反馈；使用麦克卢汉四元论（McLuhan's tetrads）作为概念工具系统分析GenAI对SE的影响。

Result: 识别出GenAI在SE中的四种基本增强形式，系统刻画了相关研究挑战与机遇，形成未来研究方向，并提出关于2030年软件工程的十大预测。

Conclusion: 本研究通过严谨的多周期流程和多方交叉验证，为理解和引导GenAI在软件工程中的发展提供了透明、可复现的基础框架。

Abstract: Generative AI (GenAI) is rapidly transforming software engineering (SE)
practices, influencing how SE processes are executed, as well as how software
systems are developed, operated, and evolved. This paper applies design science
research to build a roadmap for GenAI-augmented SE. The process consists of
three cycles that incrementally integrate multiple sources of evidence,
including collaborative discussions from the FSE 2025 "Software Engineering
2030" workshop, rapid literature reviews, and external feedback sessions
involving peers. McLuhan's tetrads were used as a conceptual instrument to
systematically capture the transforming effects of GenAI on SE processes and
software products.The resulting roadmap identifies four fundamental forms of
GenAI augmentation in SE and systematically characterizes their related
research challenges and opportunities. These insights are then consolidated
into a set of future research directions. By grounding the roadmap in a
rigorous multi-cycle process and cross-validating it among independent author
teams and peers, the study provides a transparent and reproducible foundation
for analyzing how GenAI affects SE processes, methods and tools, and for
framing future research within this rapidly evolving area. Based on these
findings, the article finally makes ten predictions for SE in the year 2030.

</details>


### [7] [Empowering RepoQA-Agent based on Reinforcement Learning Driven by Monte-carlo Tree Search](https://arxiv.org/abs/2510.26287)
*Guochang Li,Yuchen Liu,Zhen Qin,Yunkun Wang,Jianping Zhong,Chen Zhi,Binhua Li,Fei Huang,Yongbin Li,Shuiguang Deng*

Main category: cs.SE

TL;DR: 本文提出RepoSearch-R1，一种基于蒙特卡洛树搜索（MCTS）的智能体强化学习框架，用于提升大语言模型在代码库级问答任务中的信息检索与推理能力，无需模型蒸馏或外部监督即可实现高效自训练，在答案完整性上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在代码库级软件工程任务中存在局限：无训练的上下文学习方法难以有效引导智能体利用工具并根据环境反馈做决策，而基于训练的方法通常依赖昂贵的大模型蒸馏，在企业环境中引发数据合规问题。

Method: 提出RepoSearch-R1框架，结合蒙特卡洛树搜索（MCTS）实现智能体的自训练，生成多样且高质量的推理路径；并基于此构建专用于代码库问答任务的RepoQA-Agent，采用冷启动训练策略避免数据合规风险。

Result: 在代码库问答任务上的综合评估表明，RepoSearch-R1相比无检索方法提升答案完整性16.0%，相比迭代检索方法提升19.5%，训练效率比通用智能体强化学习方法提高33%。

Conclusion: RepoSearch-R1通过无蒸馏的自训练机制有效解决了工具调用与环境反馈下的决策难题，在保障数据合规的同时显著提升了代码库级问答任务的答案完整性与训练效率。

Abstract: Repository-level software engineering tasks require large language models
(LLMs) to efficiently navigate and extract information from complex codebases
through multi-turn tool interactions. Existing approaches face significant
limitations: training-free, in-context learning methods struggle to guide
agents effectively in tool utilization and decision-making based on
environmental feedback, while training-based approaches typically rely on
costly distillation from larger LLMs, introducing data compliance concerns in
enterprise environments. To address these challenges, we introduce
RepoSearch-R1, a novel agentic reinforcement learning framework driven by
Monte-carlo Tree Search (MCTS). This approach allows agents to generate
diverse, high-quality reasoning trajectories via self-training without
requiring model distillation or external supervision. Based on RepoSearch-R1,
we construct a RepoQA-Agent specifically designed for repository
question-answering tasks. Comprehensive evaluation on repository
question-answering tasks demonstrates that RepoSearch-R1 achieves substantial
improvements of answer completeness: 16.0% enhancement over no-retrieval
methods, 19.5% improvement over iterative retrieval methods, and 33% increase
in training efficiency compared to general agentic reinforcement learning
approaches. Our cold-start training methodology eliminates data compliance
concerns while maintaining robust exploration diversity and answer completeness
across repository-level reasoning tasks.

</details>


### [8] [Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis](https://arxiv.org/abs/2510.26423)
*Dong Huang,Mingzhe Du,Jie M. Zhang,Zheng Lin,Meng Luo,Qianru Zhang,See-Kiong Ng*

Main category: cs.SE

TL;DR: 本文提出了Nexus，一种基于多智能体的测试预言生成框架，通过协作审议、执行验证和自动自优化机制显著提升了非回归测试中预言的准确性及下游任务（如缺陷检测与程序修复）的效果。


<details>
  <summary>Details</summary>
Motivation: 非回归测试中的测试预言生成长期存在挑战，现有方法难以准确判断被测函数是否按预期行为执行，亟需更可靠、自动化的解决方案。

Method: Nexus采用多智能体架构：首先由四位具有不同测试理念的专家智能体协同审议并优化初始预言；随后在安全沙箱中对被测函数的候选实现执行这些预言进行验证；对失败的预言，利用运行时错误信息触发自动调试与修正循环，直至通过验证。

Result: 在七个基准上的实验表明，Nexus显著优于现有最先进方法。例如，在LiveCodeBench上将GPT-4.1-Mini的预言准确率从46.30%提升至57.73%；在HumanEval上缺陷检测率从90.91%提升至95.45%；自动程序修复成功率从35.23%提升至69.32%。

Conclusion: Nexus通过多智能体协作与迭代自优化机制有效解决了测试预言生成难题，不仅提高了预言准确性，还显著增强了下游软件工程任务的性能。

Abstract: Test oracle generation in non-regression testing is a longstanding challenge
in software engineering, where the goal is to produce oracles that can
accurately determine whether a function under test (FUT) behaves as intended
for a given input. In this paper, we introduce Nexus, a novel multi-agent
framework to address this challenge. Nexus generates test oracles by leveraging
a diverse set of specialized agents that synthesize test oracles through a
structured process of deliberation, validation, and iterative self-refinement.
During the deliberation phase, a panel of four specialist agents, each
embodying a distinct testing philosophy, collaboratively critiques and refines
an initial set of test oracles. Then, in the validation phase, Nexus generates
a plausible candidate implementation of the FUT and executes the proposed
oracles against it in a secure sandbox. For any oracle that fails this
execution-based check, Nexus activates an automated selfrefinement loop, using
the specific runtime error to debug and correct the oracle before
re-validation. Our extensive evaluation on seven diverse benchmarks
demonstrates that Nexus consistently and substantially outperforms
state-of-theart baselines. For instance, Nexus improves the test-level oracle
accuracy on the LiveCodeBench from 46.30% to 57.73% for GPT-4.1-Mini. The
improved accuracy also significantly enhances downstream tasks: the bug
detection rate of GPT4.1-Mini generated test oracles on HumanEval increases
from 90.91% to 95.45% for Nexus compared to baselines, and the success rate of
automated program repair improves from 35.23% to 69.32%.

</details>


### [9] [CHCVerif: A Portfolio-Based Solver for Constrained Horn Clauses](https://arxiv.org/abs/2510.26431)
*Mihály Dobos-Kovács,Levente Bajczi,András Vörös*

Main category: cs.SE

TL;DR: 本文提出CHCVERIF，一种基于软件验证工具组合的约束Horn子句（CHC）求解器，特别适用于处理涉及位向量和底层语义的问题。


<details>
  <summary>Details</summary>
Motivation: 约束Horn子句（CHCs）被广泛用于各类验证任务，但现有求解器在处理位向量和低层语义时存在局限，因此作者希望借助成熟的软件验证工具提升CHC求解能力。

Method: 提出CHCVERIF，采用基于组合（portfolio-based）的方法，将软件验证工具作为后端来求解CHC问题。

Result: 该方法在线性整数算术问题上表现一般，但在位向量基准测试中取得了一定成功，验证了软件验证工具用于CHC求解的可行性。

Conclusion: 使用软件验证工具作为CHC求解的后端是可行且有潜力的，尤其是在精心构建的工具组合支持下。

Abstract: Constrained Horn Clauses (CHCs) are widely adopted as intermediate
representations for a variety of verification tasks, including safety checking,
invariant synthesis, and interprocedural analysis. This paper introduces
CHCVERIF, a portfolio-based CHC solver that adopts a software verification
approach for solving CHCs. This approach enables us to reuse mature software
verification tools to tackle CHC benchmarks, particularly those involving
bitvectors and low-level semantics. Our evaluation shows that while the method
enjoys only moderate success with linear integer arithmetic, it achieves modest
success on bitvector benchmarks. Moreover, our results demonstrate the
viability and potential of using software verification tools as backends for
CHC solving, particularly when supported by a carefully constructed portfolio.

</details>


### [10] [SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning](https://arxiv.org/abs/2510.26457)
*Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang*

Main category: cs.SE

TL;DR: 本文提出SecureReviewer，一种面向安全问题的LLM代码审查方法，通过构建专用数据集、安全感知微调策略和RAG技术提升模型在识别与修复安全漏洞方面的能力，并引入新评估指标SecureBLEU。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLM）的自动代码审查方法主要关注通用问题，对安全相关问题的识别与处理能力不足，且面临数据稀缺和评估指标不完善等挑战。

Method: 构建面向安全代码审查的专用数据集；采用安全感知微调策略对LLM进行训练；结合RAG技术以减少模型幻觉并增强输出可靠性；提出新评估指标SecureBLEU。

Result: SecureReviewer在安全问题检测准确率、评论质量和实用性方面均优于当前最先进的基线方法。

Conclusion: SecureReviewer有效提升了LLM在代码审查中识别和解决安全问题的能力，为安全导向的自动化代码审查提供了可行方案。

Abstract: Identifying and addressing security issues during the early phase of the
development lifecycle is critical for mitigating the long-term negative impacts
on software systems. Code review serves as an effective practice that enables
developers to check their teammates' code before integration into the codebase.
To streamline the generation of review comments, various automated code review
approaches have been proposed, where LLM-based methods have significantly
advanced the capabilities of automated review generation. However, existing
models primarily focus on general-purpose code review, their effectiveness in
identifying and addressing security-related issues remains underexplored.
Moreover, adapting existing code review approaches to target security issues
faces substantial challenges, including data scarcity and inadequate evaluation
metrics. To address these limitations, we propose SecureReviewer, a new
approach designed for enhancing LLMs' ability to identify and resolve
security-related issues during code review. Specifically, we first construct a
dataset tailored for training and evaluating secure code review capabilities.
Leveraging this dataset, we fine-tune LLMs to generate code review comments
that can effectively identify security issues and provide fix suggestions with
our proposed secure-aware fine-tuning strategy. To mitigate hallucination in
LLMs and enhance the reliability of their outputs, we integrate the RAG
technique, which grounds the generated comments in domain-specific security
knowledge. Additionally, we introduce SecureBLEU, a new evaluation metric
designed to assess the effectiveness of review comments in addressing security
issues. Experimental results demonstrate that SecureReviewer outperforms
state-of-the-art baselines in both security issue detection accuracy and the
overall quality and practical utility of generated review comments.

</details>


### [11] [Automated Extract Method Refactoring with Open-Source LLMs: A Comparative Study](https://arxiv.org/abs/2510.26480)
*Sivajeet Chand,Melih Kilic,Roland Würsching,Sushant Kumar Pandey,Alexander Pretschner*

Main category: cs.SE

TL;DR: 本文评估了五种开源大语言模型在Python代码中自动执行Extract Method重构（EMR）任务的表现，发现基于递归批评与改进（RCI）提示策略的模型显著优于单次提示方法，在功能正确性、代码质量和开发者接受度方面表现优异。


<details>
  <summary>Details</summary>
Motivation: Extract Method重构对提升代码可读性和可维护性至关重要，但其自动化仍具挑战性；随着高效开源大语言模型的发展，有必要系统评估其在该高阶编程任务中的潜力。

Method: 作者对参数规模在3B至8B之间的五种先进开源LLM进行了系统评估，采用自动化指标衡量功能正确性与代码质量，并比较单次提示与递归批评与改进（RCI）提示策略的效果；同时通过开发者调查收集人类对生成重构结果的主观评价。

Result: RCI提示策略在测试通过率和重构质量上始终优于单次提示；Deepseek-Coder-RCI和Qwen2.5-Coder-RCI表现最佳，TPP分别达0.829和0.808，显著降低每方法行数和圈复杂度；开发者对RCI生成结果接受度超70%，其中Qwen2.5-Coder评分最高；传统指标与人类判断存在差异，凸显人机协同评估的重要性。

Conclusion: 开源大语言模型结合高质量提示策略（如RCI）能有效实现Extract Method重构，显著提升代码质量并获得开发者认可；研究强调需结合人类反馈进行评估，并提供了开源基准以推动后续工作。

Abstract: Automating the Extract Method refactoring (EMR) remains challenging and
largely manual despite its importance in improving code readability and
maintainability. Recent advances in open-source, resource-efficient Large
Language Models (LLMs) offer promising new approaches for automating such
high-level tasks. In this work, we critically evaluate five state-of-the-art
open-source LLMs, spanning 3B to 8B parameter sizes, on the EMR task for Python
code. We systematically assess functional correctness and code quality using
automated metrics and investigate the impact of prompting strategies by
comparing one-shot prompting to a Recursive criticism and improvement (RCI)
approach. RCI-based prompting consistently outperforms one-shot prompting in
test pass rates and refactoring quality. The best-performing models,
Deepseek-Coder-RCI and Qwen2.5-Coder-RCI, achieve test pass percentage (TPP)
scores of 0.829 and 0.808, while reducing lines of code (LOC) per method from
12.103 to 6.192 and 5.577, and cyclomatic complexity (CC) from 4.602 to 3.453
and 3.294, respectively. A developer survey on RCI-generated refactorings shows
over 70% acceptance, with Qwen2.5-Coder rated highest across all evaluation
criteria. In contrast, the original code scored below neutral, particularly in
readability and maintainability, underscoring the benefits of automated
refactoring guided by quality prompts. While traditional metrics like CC and
LOC provide useful signals, they often diverge from human judgments,
emphasizing the need for human-in-the-loop evaluation. Our open-source
benchmark offers a foundation for future research on automated refactoring with
LLMs.

</details>


### [12] [Envisioning Future Interactive Web Development: Editing Webpage with Natural Language](https://arxiv.org/abs/2510.26516)
*Truong Hai Dang,Jingyu Xiao,Yintong Huo*

Main category: cs.SE

TL;DR: 本文提出了一种名为 Instruct4Edit 的自动化数据生成流程，用于构建高质量的网页编辑微调数据集，通过指令生成、代码修改和视觉验证，显著提升了开源小模型在自然语言驱动的网页编辑任务中的性能，并开源了全部数据与模型。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在根据新设计需求（如“居中 Logo”）编辑已有网页代码方面表现不佳，主要原因是缺乏大规模、高质量的对齐人类期望的微调数据。

Method: 提出一种自动化数据生成管道，利用大语言模型合成多样化的编辑指令，执行对应代码修改，并通过视觉验证确保修改正确性，构建名为 Instruct4Edit 的微调数据集。

Result: 在 Instruct4Edit 上微调的模型在将人类意图转化为结构一致、视觉准确的代码修改方面表现显著提升，且开源小模型可与闭源系统性能相当。

Conclusion: 该研究为基于自然语言的网页编辑提供了可扩展、透明的基础，证明了高质量微调数据对提升模型编辑能力的关键作用，并全面开源以促进复现与后续研究。

Abstract: The evolution of web applications relies on iterative code modifications, a
process that is traditionally manual and time-consuming. While Large Language
Models (LLMs) can generate UI code, their ability to edit existing code from
new design requirements (e.g., "center the logo") remains a challenge. This is
largely due to the absence of large-scale, high-quality tuning data to align
model performance with human expectations. In this paper, we introduce a novel,
automated data generation pipeline that uses LLMs to synthesize a high-quality
fine-tuning dataset for web editing, named Instruct4Edit. Our approach
generates diverse instructions, applies the corresponding code modifications,
and performs visual verification to ensure correctness. By fine-tuning models
on Instruct4Edit, we demonstrate consistent improvement in translating human
intent into precise, structurally coherent, and visually accurate code changes.
This work provides a scalable and transparent foundation for natural language
based web editing, demonstrating that fine-tuning smaller open-source models
can achieve competitive performance with proprietary systems. We release all
data, code implementations, and model checkpoints for reproduction.

</details>


### [13] [Reflecting on Empirical and Sustainability Aspects of Software Engineering Research in the Era of Large Language Models](https://arxiv.org/abs/2510.26538)
*David Williams,Max Hort,Maria Kechagia,Aldeida Aleti,Justyna Petke,Federica Sarro*

Main category: cs.SE

TL;DR: 本文探讨了在软件工程研究中使用大语言模型（LLMs）所带来的基准测试严谨性、数据污染、可复现性及可持续性等新挑战，并对ICSE会议中相关研究进行了系统梳理，提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在软件工程研究中的广泛应用，出现了基准测试不严谨、数据污染、结果难以复现以及高昂的经济与环境成本等问题，亟需社区反思和规范。

Method: 对ICSE会议中基于大语言模型的软件工程研究进行结构化综述，识别当前实践中的良好做法与不足之处。

Result: 发现当前研究在基准设计、实验可复现性和可持续性方面存在明显短板，同时也识别出一些值得推广的良好实践。

Conclusion: 建议加强基准测试的严谨性、提升研究可复现性，并重视大语言模型应用所带来的经济与环境影响，以推动更负责任的软件工程研究。

Abstract: Software Engineering (SE) research involving the use of Large Language Models
(LLMs) has introduced several new challenges related to rigour in benchmarking,
contamination, replicability, and sustainability. In this paper, we invite the
research community to reflect on how these challenges are addressed in SE. Our
results provide a structured overview of current LLM-based SE research at ICSE,
highlighting both encouraging practices and persistent shortcomings. We
conclude with recommendations to strengthen benchmarking rigour, improve
replicability, and address the financial and environmental costs of LLM-based
SE.

</details>


### [14] ["Show Me You Comply... Without Showing Me Anything": Zero-Knowledge Software Auditing for AI-Enabled Systems](https://arxiv.org/abs/2510.26576)
*Filippo Scaramuzza,Renato Cordeiro Ferreira,Tomaz Maia Suller,Giovanni Quattrocchi,Damian Andrew Tamburri,Willem-Jan van den Heuvel*

Main category: cs.SE

TL;DR: 本文提出ZKMLOps框架，将零知识证明（ZKP）融入MLOps流程，在不泄露敏感信息的前提下实现AI系统的可验证合规性，以应对法规对透明度与资产保护之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在关键领域广泛应用，但其“黑箱”特性使得传统软件验证方法难以适用；同时，法规要求高可审计性，而透明化又可能泄露机密数据或专有模型，形成信任与保密之间的冲突。

Method: 提出ZKMLOps框架，将零知识证明（ZKP）与成熟的软件工程模式结合，构建模块化、可重复的MLOps验证流程，用于生成合规性的密码学可验证证明。

Result: 通过金融风险审计中的合规性案例研究验证了框架实用性，并对主流ZKP协议进行实证评估，分析了其在不同复杂度机器学习模型下的性能权衡。

Conclusion: ZKMLOps为AI系统提供了一种兼顾法规合规性与数据/模型保密性的可行路径，展示了零知识证明在MLOps中实现可验证问责的潜力。

Abstract: The increasing exploitation of Artificial Intelligence (AI) enabled systems
in critical domains has made trustworthiness concerns a paramount showstopper,
requiring verifiable accountability, often by regulation (e.g., the EU AI Act).
Classical software verification and validation techniques, such as procedural
audits, formal methods, or model documentation, are the mechanisms used to
achieve this. However, these methods are either expensive or heavily manual and
ill-suited for the opaque, "black box" nature of most AI models. An intractable
conflict emerges: high auditability and verifiability are required by law, but
such transparency conflicts with the need to protect assets being audited-e.g.,
confidential data and proprietary models-leading to weakened accountability. To
address this challenge, this paper introduces ZKMLOps, a novel MLOps
verification framework that operationalizes Zero-Knowledge Proofs
(ZKPs)-cryptographic protocols allowing a prover to convince a verifier that a
statement is true without revealing additional information-within
Machine-Learning Operations lifecycles. By integrating ZKPs with established
software engineering patterns, ZKMLOps provides a modular and repeatable
process for generating verifiable cryptographic proof of compliance. We
evaluate the framework's practicality through a study of regulatory compliance
in financial risk auditing and assess feasibility through an empirical
evaluation of top ZKP protocols, analyzing performance trade-offs for ML models
of increasing complexity.

</details>


### [15] [Online and Interactive Bayesian Inference Debugging](https://arxiv.org/abs/2510.26579)
*Nathanael Nussbaumer,Markus Böck,Jürgen Cito*

Main category: cs.SE

TL;DR: 本文提出了一种新颖的贝叶斯推理调试方法，通过在开发环境中集成交互式调试工具，显著减少了调试时间和所需专业知识。


<details>
  <summary>Details</summary>
Motivation: 概率编程虽能简化贝叶斯建模与推理，但其调试过程耗时且需要深厚的专业知识，因此亟需更高效的调试支持。

Method: 作者设计并实现了一个满足关键需求的贝叶斯推理调试框架，该工具直接集成于开发环境中，支持在线和交互式调试。

Result: 在一项包含18名有经验参与者的用户研究中，该方法显著降低了贝叶斯推理调试任务的时间和难度。

Conclusion: 所提出的调试方法有效提升了概率编程中贝叶斯推理的可访问性和可用性，为实践者提供了实用支持。

Abstract: Probabilistic programming is a rapidly developing programming paradigm which
enables the formulation of Bayesian models as programs and the automation of
posterior inference. It facilitates the development of models and conducting
Bayesian inference, which makes these techniques available to practitioners
from multiple fields. Nevertheless, probabilistic programming is notoriously
difficult as identifying and repairing issues with inference requires a lot of
time and deep knowledge. Through this work, we introduce a novel approach to
debugging Bayesian inference that reduces time and required knowledge
significantly. We discuss several requirements a Bayesian inference debugging
framework has to fulfill, and propose a new tool that meets these key
requirements directly within the development environment. We evaluate our
results in a study with 18 experienced participants and show that our approach
to online and interactive debugging of Bayesian inference significantly reduces
time and difficulty on inference debugging tasks.

</details>


### [16] [Stitch: Step-by-step LLM Guided Tutoring for Scratch](https://arxiv.org/abs/2510.26634)
*Yuan Si,Kyle Qi,Daming Li,Hanyuan Shi,Jialu Zhang*

Main category: cs.SE

TL;DR: Stitch 是一个用于 Scratch 等块编程环境的交互式辅导系统，通过逐步引导而非直接展示正确答案来帮助初学者调试程序，实证研究表明该方法显著优于现有自动反馈工具。


<details>
  <summary>Details</summary>
Motivation: 在块编程教学中，尽管语法错误减少，但语义错误仍普遍存在且难以解决；当前调试方法常直接展示正确程序，不利于培养学习者的问题解决能力。

Method: Stitch 系统包含 Diff-Analyze 模块，通过对比学生程序与参考实现，识别关键差异，并利用大语言模型解释这些差异的重要性；学习者通过自定义渲染引擎查看高亮代码块、理解解释并选择性应用部分修复，逐步达成目标功能。

Result: 实证研究表明，相比直接展示正确答案或现有自动反馈工具，Stitch 的逐步引导方式显著提升了学习效果。

Conclusion: 有效的块编程反馈应注重交互式、逐步引导，而非直接提供答案；Stitch 为提升编程教育中的调试学习效果提供了新证据和可行方案。

Abstract: Block-based environments such as Scratch are increasingly popular in
programming education. While block syntax reduces surface errors, semantic bugs
remain common and challenging for novices to resolve. Existing debugging
workflows typically show the correct program directly to learners, a strategy
that may fix errors but undermines the development of problem-solving skills.
  We present Stitch, an interactive tutoring system that replaces "showing the
answer" with step-by-step scaffolding. The system's Diff-Analyze module
contrasts a student's project with a reference implementation, identifies the
most critical differences, and uses a large language model to explain why these
changes matter. Learners inspect highlighted blocks through a custom rendering
engine, understand the explanations, and selectively apply partial fixes. This
iterative process continues until the intended functionality is achieved.
  We evaluate Stitch in an empirical study, comparing it against a
state-of-the-art automated feedback generation tool for Scratch. Our key
insight is that simply presenting the correct program is pedagogically
ineffective. In contrast, our interactive, step-by-step guided system promotes
a more effective learning experience. More broadly, what constitutes effective
feedback in block-based programming remains an open question. Our evaluation
provides new evidence that step-by-step tutoring significantly enhances
learning outcomes, outperforming both direct-answer approaches and current
automated feedback generation tools.

</details>


### [17] [Process-based Indicators of Vulnerability Re-Introducing Code Changes: An Exploratory Case Study](https://arxiv.org/abs/2510.26676)
*Samiha Shimmi,Nicholas M. Synovic,Mona Rahimi,George K. Thiruvathukal*

Main category: cs.SE

TL;DR: 该论文研究了软件漏洞重现问题，强调开发过程指标（如巴士因子、问题密度和问题腐坏率）与代码变更共同作用对漏洞重现的影响，通过ImageMagick项目的76个漏洞重现案例发现，问题管理效率低下和团队响应波动是关键诱因。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注代码度量指标，较少探讨软件工程过程指标是否能揭示随时间推移引入漏洞的高风险开发活动，而理解这些过程因素对预测和缓解漏洞重现至关重要。

Method: 在提交级别分析安全修复，结合纵向过程指标（如巴士因子、问题密度、问题腐坏率）与代码变更，对ImageMagick项目中76个漏洞重现实例进行案例研究。

Result: 漏洞重现常与问题腐坏率上升和问题密度波动相关，反映出问题管理和团队响应方面的短期低效。

Conclusion: 漏洞重现是累积性开发活动和社技因素共同作用的结果，结合过程与代码指标可为预测高风险修复、提升软件安全性提供基础。

Abstract: Software vulnerabilities often persist or re-emerge even after being fixed,
revealing the complex interplay between code evolution and socio-technical
factors. While source code metrics provide useful indicators of
vulnerabilities, software engineering process metrics can uncover patterns that
lead to their introduction. Yet few studies have explored whether process
metrics can reveal risky development activities over time -- insights that are
essential for anticipating and mitigating software vulnerabilities. This work
highlights the critical role of process metrics along with code changes in
understanding and mitigating vulnerability reintroduction. We move beyond
file-level prediction and instead analyze security fixes at the commit level,
focusing not only on whether a single fix introduces a vulnerability but also
on the longer sequences of changes through which vulnerabilities evolve and
re-emerge. Our approach emphasizes that reintroduction is rarely the result of
one isolated action, but emerges from cumulative development activities and
socio-technical conditions. To support this analysis, we conducted a case study
on the ImageMagick project by correlating longitudinal process metrics such as
bus factor, issue density, and issue spoilage with vulnerability reintroduction
activities, encompassing 76 instances of reintroduced vulnerabilities. Our
findings show that reintroductions often align with increased issue spoilage
and fluctuating issue density, reflecting short-term inefficiencies in issue
management and team responsiveness. These observations provide a foundation for
broader studies that combine process and code metrics to predict risky fixes
and strengthen software security.

</details>


### [18] [Optimized Log Parsing with Syntactic Modifications](https://arxiv.org/abs/2510.26793)
*Nafid Enan,Gias Uddin*

Main category: cs.SE

TL;DR: 本文对基于语法和语义的日志解析器以及单阶段与两阶段解析架构进行了全面的实证比较，发现语义方法在模板识别上更准确，而语法方法效率更高且分组更准；两阶段架构优于单阶段。基于此，作者提出SynLog+作为两阶段架构的第二阶段模块，显著提升各类解析器的准确率，且几乎不增加运行开销。


<details>
  <summary>Details</summary>
Motivation: 日志解析是自动化日志分析的关键第一步，现有解析器采用多种技术，亟需系统评估以理解其性能与特性。

Method: 开展实证研究，对比基于语法与语义的日志解析方法，以及单阶段与两阶段解析架构；并在此基础上设计并实现SynLog+作为两阶段架构中的第二阶段模板识别模块。

Result: 语义方法在模板识别上更准确，语法方法效率高10–1000倍且分组准确率更高；两阶段架构始终优于单阶段；SynLog+使语法和语义解析器的解析准确率分别平均提升236%和20%，几乎无额外运行开销。

Conclusion: 结合两阶段架构与SynLog+模块可显著提升日志解析准确率，同时保持高效性，为日志解析器设计提供了实用指导。

Abstract: Logs provide valuable insights into system runtime and assist in software
development and maintenance. Log parsing, which converts semi-structured log
data into structured log data, is often the first step in automated log
analysis. Given the wide range of log parsers utilizing diverse techniques, it
is essential to evaluate them to understand their characteristics and
performance. In this paper, we conduct a comprehensive empirical study
comparing syntax- and semantic-based log parsers, as well as single-phase and
two-phase parsing architectures. Our experiments reveal that semantic-based
methods perform better at identifying the correct templates and syntax-based
log parsers are 10 to 1,000 times more efficient and provide better grouping
accuracy although they fall short in accurate template identification.
Moreover, two-phase architecture consistently improves accuracy compared to
single-phase architecture. Based on the findings of this study, we propose
SynLog+, a template identification module that acts as the second phase in a
two-phase log parsing architecture. SynLog+ improves the parsing accuracy of
syntax-based and semantic-based log parsers by 236\% and 20\% on average,
respectively, with virtually no additional runtime cost.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [19] [Multi-Agent Reinforcement Learning for Market Making: Competition without Collusion](https://arxiv.org/abs/2510.25929)
*Ziyi Wang,Carmine Ventre,Maria Polukarov*

Main category: cs.MA

TL;DR: 本文提出一种分层多智能体强化学习框架，研究算法共谋在做市中的表现，发现具有对抗目标的智能体（B2）在零和博弈中占据主导地位，而混合策略智能体（B*）则在保持市场效率的同时实现更可持续的共存。


<details>
  <summary>Details</summary>
Motivation: 探究AI智能体在市场中交互是否会导致算法共谋，并理解由此产生的新兴行为（如卡特尔或市场支配）对整体市场的影响。

Method: 构建一个分层多智能体强化学习框架，包含一个自利的做市商（Agent A）和三个底层竞争者（B1、B2 和 B*），并设计交互层面的指标来量化行为不对称性和系统动态。

Result: 实验表明，B2 在零和环境中显著优于 B1，通过紧缩价差和抢占订单流提升执行效率；B* 则展现出自利倾向，通过自适应报价获得主导市场份额，但对其他智能体收益的负面影响较小。

Conclusion: 自适应激励控制有助于在异构智能体环境中实现更可持续的战略共存，为算法交易系统的行为设计提供评估视角。

Abstract: Algorithmic collusion has emerged as a central question in AI: Will the
interaction between different AI agents deployed in markets lead to collusion?
More generally, understanding how emergent behavior, be it a cartel or market
dominance from more advanced bots, affects the market overall is an important
research question.
  We propose a hierarchical multi-agent reinforcement learning framework to
study algorithmic collusion in market making. The framework includes a
self-interested market maker (Agent~A), which is trained in an uncertain
environment shaped by an adversary, and three bottom-layer competitors: the
self-interested Agent~B1 (whose objective is to maximize its own PnL), the
competitive Agent~B2 (whose objective is to minimize the PnL of its opponent),
and the hybrid Agent~B$^\star$, which can modulate between the behavior of the
other two. To analyze how these agents shape the behavior of each other and
affect market outcomes, we propose interaction-level metrics that quantify
behavioral asymmetry and system-level dynamics, while providing signals
potentially indicative of emergent interaction patterns.
  Experimental results show that Agent~B2 secures dominant performance in a
zero-sum setting against B1, aggressively capturing order flow while tightening
average spreads, thus improving market execution efficiency. In contrast,
Agent~B$^\star$ exhibits a self-interested inclination when co-existing with
other profit-seeking agents, securing dominant market share through adaptive
quoting, yet exerting a milder adverse impact on the rewards of Agents~A and B1
compared to B2. These findings suggest that adaptive incentive control supports
more sustainable strategic co-existence in heterogeneous agent environments and
offers a structured lens for evaluating behavioral design in algorithmic
trading systems.

</details>


### [20] [Stop Wasting Your Tokens: Towards Efficient Runtime Multi-Agent Systems](https://arxiv.org/abs/2510.26585)
*Fulin Lin,Shaowen Chen,Ruishan Fang,Hongwei Wang,Tao Lin*

Main category: cs.MA

TL;DR: 本文提出了SupervisorAgent，一种轻量级、模块化的运行时自适应监督框架，无需修改基础智能体架构，即可在多智能体系统中通过LLM-free的自适应过滤器实时干预，有效降低令牌消耗并提升系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统（MAS）在处理复杂任务时，由于自主性增强和操作复杂性提高，常导致令牌消耗过多和因错误信息引发的失败；现有方法多依赖事后归因，缺乏实时主动干预机制。

Method: 引入SupervisorAgent框架，通过一个不依赖大语言模型（LLM-free）的自适应过滤器，在关键节点对智能体行为进行实时干预，包括纠错、引导低效行为和净化观测信息，且无需改动基础智能体架构。

Result: 在GAIA基准上，SupervisorAgent将Smolagent框架的令牌消耗平均降低29.45%，同时保持成功率不变；在五个其他基准（数学推理、代码生成、问答等）和多种前沿基础模型上的实验进一步验证了该方法的通用性和鲁棒性。

Conclusion: SupervisorAgent提供了一种高效、通用且无需修改原智能体结构的运行时监督机制，显著提升了多智能体系统的效率与可靠性。

Abstract: While Multi-Agent Systems (MAS) excel at complex tasks, their growing
autonomy with operational complexity often leads to critical inefficiencies,
such as excessive token consumption and failures arising from misinformation.
Existing methods primarily focus on post-hoc failure attribution, lacking
proactive, real-time interventions to enhance robustness and efficiency. To
this end, we introduce SupervisorAgent, a lightweight and modular framework for
runtime, adaptive supervision that operates without altering the base agent's
architecture. Triggered by an LLM-free adaptive filter, SupervisorAgent
intervenes at critical junctures to proactively correct errors, guide
inefficient behaviors, and purify observations. On the challenging GAIA
benchmark, SupervisorAgent reduces the token consumption of the Smolagent
framework by an average of 29.45% without compromising its success rate.
Extensive experiments across five additional benchmarks (math reasoning, code
generation, and question answering) and various SoTA foundation models validate
the broad applicability and robustness of our approach. The code is available
at https://github.com/LINs-lab/SupervisorAgent.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [21] [Symmetry-Driven Asynchronous Forwarding for Reliable Distributed Coordination in Toroidal Networks](https://arxiv.org/abs/2510.26071)
*Shenshen Luan,Yumo Tian,Xinyu Zhang,Qingwen Zhang,Tianheng Wang,Yan Yang,Shuguo Xie*

Main category: cs.NI

TL;DR: 本文提出一种基于环面拓扑对称性的异步转发机制，无需控制平面协调即可在链路故障下实现可靠数据包投递，显著降低丢包率。


<details>
  <summary>Details</summary>
Motivation: 大规模分布式系统（如卫星星座和高性能计算集群）中，传统路由方案在链路故障后因控制平面同步问题导致严重丢包，亟需更鲁棒的通信机制。

Method: 利用环面拓扑的几何对称性，通过拓扑势梯度建模数据流，并设计两种本地转发策略（RF-CF 和 RF-LF），在不修改协议或增加包开销的前提下，利用对称性破缺引发的反向流实现故障规避。

Result: 在16×16环面上的渗流分析与包级仿真表明，在1%链路故障率下，该机制最多可减少17.5%的丢包，其中RF-LF策略贡献了28%的成功投递包。

Conclusion: 本工作建立了拓扑对称性与通信韧性之间的基础联系，为提升分布式系统的可靠性提供了一种轻量、协议无关的底层机制。

Abstract: The proliferation of large-scale distributed systems, such as satellite
constellations and high-performance computing clusters, demands robust
communication primitives that maintain coordination under unreliable links. The
torus topology, with its inherent rotational and reflection symmetries, is a
prevalent architecture in these domains. However, conventional routing schemes
suffer from substantial packet loss during control-plane synchronization after
link failures. This paper introduces a symmetry-driven asynchronous forwarding
mechanism that leverages the torus's geometric properties to achieve reliable
packet delivery without control-plane coordination. We model packet flow using
a topological potential gradient and demonstrate that symmetry-breaking
failures naturally induce a reverse flow, which we harness for fault
circumvention. We propose two local forwarding strategies, Reverse Flow with
Counter-facing Priority (RF-CF) and Lateral-facing Priority (RF-LF), that
guarantee reachability to the destination via forward-flow phase transition
points, without protocol modifications or additional in-packet overhead.
Through percolation analysis and packet-level simulations on a 16 x 16 torus,
we show that our mechanism reduces packet loss by up to 17.5% under a 1% link
failure rate, with the RF-LF strategy contributing to 28% of successfully
delivered packets. This work establishes a foundational link between
topological symmetry and communication resilience, providing a lightweight,
protocol-agnostic substrate for enhancing distributed systems.

</details>


### [22] [Joint Computing Resource Allocation and Task Offloading in Vehicular Fog Computing Systems Under Asymmetric Information](https://arxiv.org/abs/2510.26256)
*Geng Sun,Siyi Chen,Zemin Sun,Long He,Jiacheng Wang,Dusit Niyato,Zhu Han,Dong In Kim*

Main category: cs.NI

TL;DR: 本文提出了一种用于车联网雾计算（VFC）的联合计算资源分配与任务卸载方法（JCRATOA），通过分层架构、凸优化、契约理论激励机制和双边匹配算法，有效降低任务完成延迟并提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 车联网雾计算面临路边单元（RSU）资源有限、车辆不愿共享私有信息导致的信息不对称，以及任务需求与计算能力异构性带来的任务卸载效率低下等问题，亟需高效资源分配与任务调度机制。

Method: 作者构建了一个融合RSU与雾车辆（FV）计算能力的分层VFC架构，将延迟最小化问题建模为NP难的混合整数非线性规划问题，并提出JCRATOA方法：利用凸优化分配RSU资源，基于契约理论设计FV资源激励机制，并采用匹配博弈实现任务卸载。

Result: 仿真实验表明，所提JCRATOA在任务完成延迟、任务完成率、系统吞吐量和资源利用公平性等方面均优于现有方法，同时满足各类约束条件。

Conclusion: 该研究有效缓解了VFC中因信息不对称和资源异构带来的挑战，通过联合优化资源分配与任务卸载显著提升了系统整体性能。

Abstract: Vehicular fog computing (VFC) has emerged as a promising paradigm, which
leverages the idle computational resources of nearby fog vehicles (FVs) to
complement the computing capabilities of conventional vehicular edge computing.
However, utilizing VFC to meet the delay-sensitive and computation-intensive
requirements of the FVs poses several challenges. First, the limited resources
of road side units (RSUs) struggle to accommodate the growing and diverse
demands of vehicles. This limitation is further exacerbated by the information
asymmetry between the controller and FVs due to the reluctance of FVs to
disclose private information and to share resources voluntarily. This
information asymmetry hinders the efficient resource allocation and
coordination. Second, the heterogeneity in task requirements and the varying
capabilities of RSUs and FVs complicate efficient task offloading, thereby
resulting in inefficient resource utilization and potential performance
degradation. To address these challenges, we first present a hierarchical VFC
architecture that incorporates the computing capabilities of both RSUs and FVs.
Then, we formulate a delay minimization optimization problem (DMOP), which is
an NP-hard mixed integer nonlinear programming problem. To solve the DMOP, we
propose a joint computing resource allocation and task offloading approach
(JCRATOA). Specifically, we propose a convex optimization-based method for RSU
resource allocation and a contract theory-based incentive mechanism for FV
resource allocation. Moreover, we present a two-sided matching method for task
offloading by employing the matching game. Simulation results demonstrate that
the proposed JCRATOA is able to achieve superior performances in task
completion delay, task completion ratio, system throughput, and resource
utilization fairness, while effectively meeting the satisfying constraints.

</details>


### [23] [Wireless Memory Approximation for Energy-efficient Task-specific IoT Data Retrieval](https://arxiv.org/abs/2510.26473)
*Junya Shiraishi,Shashi Raj Pandey,Israel Leyva-Mayorga,Petar Popovski*

Main category: cs.NI

TL;DR: 本文提出两种新方法——无线内存激活与无线内存近似，以降低物联网设备在待机期间因DRAM刷新造成的能耗，同时满足模型检索精度要求。


<details>
  <summary>Details</summary>
Motivation: DRAM在存储机器学习模型时需周期性刷新，导致资源受限的物联网设备在待机期间产生大量不必要的能耗。

Method: 提出无线内存激活和无线内存近似两种方法，通过考虑ML模型使用的时间特性和相关性，高效管理可用内存。

Result: 数值结果表明，所提方案相比始终开启的方式能耗更低，同时满足检索精度约束。

Conclusion: 所提出的无线内存管理策略能有效降低物联网设备在ML推理中的DRAM能耗，兼顾能效与模型精度。

Abstract: The use of Dynamic Random Access Memory (DRAM) for storing Machine Learning
(ML) models plays a critical role in accelerating ML inference tasks in the
next generation of communication systems. However, periodic refreshment of DRAM
results in wasteful energy consumption during standby periods, which is
significant for resource-constrained Internet of Things (IoT) devices. To solve
this problem, this work advocates two novel approaches: 1) wireless memory
activation and 2) wireless memory approximation. These enable the wireless
devices to efficiently manage the available memory by considering the timing
aspects and relevance of ML model usage; hence, reducing the overall energy
consumption. Numerical results show that our proposed scheme can realize
smaller energy consumption than the always-on approach while satisfying the
retrieval accuracy constraint.

</details>


### [24] [Low-Altitude UAV-Carried Movable Antenna for Joint Wireless Power Transfer and Covert Communications](https://arxiv.org/abs/2510.26628)
*Chuang Zhang,Geng Sun,Jiahui Li,Jiacheng Wang,Qingqing Wu,Dusit Niyato,Shiwen Mao,Tony Q. S. Quek*

Main category: cs.NI

TL;DR: 本文提出一种结合无线能量传输（WPT）与隐蔽通信的低空无人机移动天线系统，通过混合专家增强的软演员-评论家（MoE-SAC）算法优化能量收集、隐蔽通信速率与无人机能耗。


<details>
  <summary>Details</summary>
Motivation: 物联网节点受电池限制，亟需可持续供能方案；低空无人机虽可通过无线能量传输供能，但视距信道易泄露敏感数据，因此需兼顾供能与隐蔽通信。

Method: 构建多目标优化问题，联合最大化物联网节点总收获能量与隐蔽用户可达速率，同时最小化无人机推进能耗；提出MoE-SAC算法，采用稀疏Top-K门控浅层专家混合架构建模多模态策略，并引入动作投影模块满足功率与天线位置约束。

Result: 仿真实验表明，所提方法在性能上显著优于现有基线方法及其他先进深度强化学习算法。

Conclusion: 该方案有效实现了低空无人机在为物联网节点供能的同时保障隐蔽通信，兼顾能效与安全性，具有实际应用潜力。

Abstract: The proliferation of Internet of Things (IoT) networks has created an urgent
need for sustainable energy solutions, particularly for the battery-constrained
spatially distributed IoT nodes. While low-altitude uncrewed aerial vehicles
(UAVs) employed with wireless power transfer (WPT) capabilities offer a
promising solution, the line-of-sight channels that facilitate efficient energy
delivery also expose sensitive operational data to adversaries. This paper
proposes a novel low-altitude UAV-carried movable antenna-enhanced transmission
system joint WPT and covert communications, which simultaneously performs
energy supplements to IoT nodes and establishes transmission links with a
covert user by leveraging wireless energy signals as a natural cover. Then, we
formulate a multi-objective optimization problem that jointly maximizes the
total harvested energy of IoT nodes and sum achievable rate of the covert user,
while minimizing the propulsion energy consumption of the low-altitude UAV. To
address the non-convex and temporally coupled optimization problem, we propose
a mixture-of-experts-augmented soft actor-critic (MoE-SAC) algorithm that
employs a sparse Top-K gated mixture-of-shallow-experts architecture to
represent multimodal policy distributions arising from the conflicting
optimization objectives. We also incorporate an action projection module that
explicitly enforces per-time-slot power budget constraints and antenna position
constraints. Simulation results demonstrate that the proposed approach
significantly outperforms some baseline approaches and other state-of-the-art
deep reinforcement learning algorithms.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [25] [MIREDO: MIP-Driven Resource-Efficient Dataflow Optimization for Computing-in-Memory Accelerator](https://arxiv.org/abs/2510.26463)
*Xiaolin He,Cenlin Duan,Yingjie Qi,Xiao Ma,Jianlei Yang*

Main category: cs.AR

TL;DR: MIREDO 是一个用于 CIM 架构的数据流优化框架，通过将优化问题建模为混合整数规划（MIP），结合分层硬件抽象与延迟模型，在多种 DNN 模型和硬件配置上实现最高 3.2 倍的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有 CIM 架构的数据流优化方法难以充分挖掘硬件潜力，导致理论效率与实际系统效率之间存在显著差距，主要受限于庞大的设计空间和严格的架构约束。

Method: 提出 MIREDO 框架，将数据流优化建模为混合整数规划（MIP）问题，引入分层硬件抽象和分析型延迟模型，联合建模工作负载特性、数据流策略与 CIM 特定约束，以系统化搜索最优配置。

Result: 在多种 DNN 模型和硬件设置下，MIREDO 实现了最高达 3.2 倍的性能提升。

Conclusion: MIREDO 能有效提升 CIM 架构的实际系统效率，显著缩小理论与实际性能之间的差距，为 CIM 加速器的数据流优化提供了系统化且高效的解决方案。

Abstract: Computing-in-Memory (CIM) architectures have emerged as a promising solution
for accelerating Deep Neural Networks (DNNs) by mitigating data movement
bottlenecks. However, realizing the potential of CIM requires specialized
dataflow optimizations, which are challenged by an expansive design space and
strict architectural constraints. Existing optimization approaches often fail
to fully exploit CIM accelerators, leading to noticeable gaps between
theoretical and actual system-level efficiency. To address these limitations,
we propose the MIREDO framework, which formulates dataflow optimization as a
Mixed-Integer Programming (MIP) problem. MIREDO introduces a hierarchical
hardware abstraction coupled with an analytical latency model designed to
accurately reflect the complex data transfer behaviors within CIM systems. By
jointly modeling workload characteristics, dataflow strategies, and
CIM-specific constraints, MIREDO systematically navigates the vast design space
to determine the optimal dataflow configurations. Evaluation results
demonstrate that MIREDO significantly enhances performance, achieving up to
$3.2\times$ improvement across various DNN models and hardware setups.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [26] [ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference](https://arxiv.org/abs/2510.26730)
*Zixu Shen,Kexin Chu,Yifan Zhang,Dawei Xiang,Runxin Wu,Wei Zhang*

Main category: cs.DC

TL;DR: ExpertFlow 是一种用于 Mixture-of-Experts（MoE）模型推理的运行时系统，通过自适应专家预取和缓存感知路由，显著降低因专家参数频繁换入带来的延迟，在内存受限条件下将模型停滞时间减少至基线的 0.1% 以下。


<details>
  <summary>Details</summary>
Motivation: 现代 GPU 内存容量限制了大语言模型的扩展，而传统 MoE 推理方法因每层独立选择专家导致频繁的参数传输，引入高延迟；现有跨层预测策略缺乏对不同硬件和工作负载的适应性，影响其鲁棒性和效率。

Method: ExpertFlow 结合自适应专家预取与缓存感知路由，利用运行时统计信息（如传输带宽、参数维度和模型反馈）动态调整专家激活的预测范围，并采用融合预门控信息与中间计算状态的混合跨层预测机制，以精准预判未来专家需求。

Result: 实验表明，ExpertFlow 将模型停滞时间降低至基线的 0.1% 以下，显著减少了缓存未命中和专家换入带来的延迟。

Conclusion: ExpertFlow 能有效优化内存受限场景下的 MoE 推理性能，通过自适应预取和缓存对齐策略，大幅提升推理效率与系统鲁棒性。

Abstract: The expansion of large language models is increasingly limited by the
constrained memory capacity of modern GPUs. To mitigate this,
Mixture-of-Experts (MoE) architectures activate only a small portion of
parameters during inference, significantly lowering both memory demand and
computational overhead. However, conventional MoE inference approaches, which
select active experts independently at each layer, often introduce considerable
latency because of frequent parameter transfers between host and GPU memory. In
addition, current cross-layer prediction strategies, which are typically based
on fixed steps, lack adaptability across different hardware platforms and
workloads, thereby reducing their robustness and effectiveness.
  To address these challenges, we present ExpertFlow, a runtime system for MoE
inference that combines adaptive expert prefetching and cache-aware routing.
ExpertFlow continuously adjusts its prediction horizon for expert activation by
leveraging runtime statistics such as transfer bandwidth, parameter
dimensionality, and model feedback signals. Furthermore, it incorporates a
hybrid cross-layer prediction scheme that fuses pregating information with
intermediate computational states to anticipate future expert needs. By
adaptively refining prefetching decisions and aligning them with actual usage
behavior, ExpertFlow effectively decreases cache misses and removes latency
caused by expert swap-ins. Our evaluation demonstrates that ExpertFlow reduces
model stall time to less than 0.1% of the baseline, highlighting its capability
to optimize MoE inference under stringent memory constraints.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [27] [Approximating Heavy-Tailed Distributions with a Mixture of Bernstein Phase-Type and Hyperexponential Models](https://arxiv.org/abs/2510.26524)
*Abdelhakim Ziani,András Horváth,Paolo Ballarini*

Main category: cs.PF

TL;DR: 本文提出了一种结合Bernstein相型（BPH）与超指数（HE）分布的新型混合模型，以更准确地拟合重尾分布的整体（主体与尾部）特征。


<details>
  <summary>Details</summary>
Motivation: 重尾分布在金融、通信、排队论和自然语言处理等领域广泛存在，但现有模型如BPH无法精确再现尾部行为，而HE模型虽适应重尾但对主体拟合不佳且对初始参数敏感。

Method: 提出一种BPH与HE的混合模型，利用优化方法为HE组件设置初始参数，提高其鲁棒性并避免无效模型。

Result: 实验表明，该混合模型在拟合重尾分布的主体和尾部方面优于单独使用BPH或HE模型，并在均值和变异系数等参数匹配上显著提升；排队论实验进一步验证了其实际有效性与精度。

Conclusion: 所提出的混合模型有效结合了BPH和HE的优点，显著提升了对重尾分布整体的建模能力，具有良好的实际应用价值。

Abstract: Heavy-tailed distributions, prevalent in a lot of real-world applications
such as finance, telecommunications, queuing theory, and natural language
processing, are challenging to model accurately owing to their slow tail decay.
Bernstein phase-type (BPH) distributions, through their analytical tractability
and good approximations in the non-tail region, can present a good solution,
but they suffer from an inability to reproduce these heavy-tailed behaviors
exactly, thus leading to inadequate performance in important tail areas. On the
contrary, while highly adaptable to heavy-tailed distributions,
hyperexponential (HE) models struggle in the body part of the distribution.
Additionally, they are highly sensitive to initial parameter selection,
significantly affecting their precision.
  To solve these issues, we propose a novel hybrid model of BPH and HE
distributions, borrowing the most desirable features from each for enhanced
approximation quality. Specifically, we leverage an optimization to set initial
parameters for the HE component, significantly enhancing its robustness and
reducing the possibility that the associated procedure results in an invalid HE
model. Experimental validation demonstrates that the novel hybrid approach is
more performant than individual application of BPH or HE models. More
precisely, it can capture both the body and the tail of heavy-tailed
distributions, with a considerable enhancement in matching parameters such as
mean and coefficient of variation. Additional validation through experiments
utilizing queuing theory proves the practical usefulness, accuracy, and
precision of our hybrid approach.

</details>
