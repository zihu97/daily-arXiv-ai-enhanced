{"id": "2601.04523", "categories": ["cs.DC", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.04523", "abs": "https://arxiv.org/abs/2601.04523", "authors": ["Ajay Singh", "Nikos Metaxakis", "Panagiota Fatourou"], "title": "Sharded Elimination and Combining for Highly-Efficient Concurrent Stacks", "comment": "extended version of paper in PPoPP 2026", "summary": "We present a new blocking linearizable stack implementation which utilizes sharding and fetch&increment to achieve significantly better performance than all existing concurrent stacks. The proposed implementation is based on a novel elimination mechanism and a new combining approach that are efficiently blended to gain high performance. Our implementation results in enhanced parallelism and low contention when accessing the shared stack. Experiments show that the proposed stack implementation outperforms all existing concurrent stacks by up to 2X in most workloads. It is particularly efficient in systems supporting a large number of threads and in high contention scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u7247\u548cfetch&increment\u7684\u9ad8\u6027\u80fd\u5e76\u53d1\u6808\u5b9e\u73b0\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "motivation": "\u63d0\u5347\u5e76\u53d1\u6808\u5728\u9ad8\u7ade\u4e89\u548c\u591a\u7ebf\u7a0b\u73af\u5883\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u7ed3\u5408\u65b0\u9896\u7684\u6d88\u9664\u673a\u5236\u4e0e\u7ec4\u5408\u65b9\u6cd5\uff0c\u5229\u7528\u5206\u7247\u548cfetch&increment\u6280\u672f\u964d\u4f4e\u7ade\u4e89\u3001\u589e\u5f3a\u5e76\u884c\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u591a\u6570\u8d1f\u8f7d\u4e0b\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe2\u500d\uff0c\u5c24\u5176\u9002\u5408\u9ad8\u7ebf\u7a0b\u6570\u548c\u9ad8\u7ade\u4e89\u573a\u666f\u3002", "conclusion": "\u8be5\u5b9e\u73b0\u901a\u8fc7\u9ad8\u6548\u6df7\u5408\u65b0\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u5f53\u524d\u6700\u4f18\u7684\u5e76\u53d1\u6808\u6027\u80fd\u3002"}}
{"id": "2601.04659", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04659", "abs": "https://arxiv.org/abs/2601.04659", "authors": ["Gijun Park"], "title": "Quantifying Autoscaler Vulnerabilities: An Empirical Study of Resource Misallocation Induced by Cloud Infrastructure Faults", "comment": null, "summary": "Resource autoscaling mechanisms in cloud environments depend on accurate performance metrics to make optimal provisioning decisions. When infrastructure faults including hardware malfunctions, network disruptions, and software anomalies corrupt these metrics, autoscalers may systematically over- or under-provision resources, resulting in elevated operational expenses or degraded service reliability. This paper conducts controlled simulation experiments to measure how four prevalent fault categories affect both vertical and horizontal autoscaling behaviors across multiple instance configurations and service level objective (SLO) thresholds. Experimental findings demonstrate that storage-related faults generate the largest cost overhead, adding up to $258 monthly under horizontal scaling policies, whereas routing anomalies consistently bias autoscalers toward insufficient resource allocation. The sensitivity to fault-induced metric distortions differs markedly between scaling strategies: horizontal autoscaling exhibits greater susceptibility to transient anomalies, particularly near threshold boundaries. These empirically-grounded insights offer actionable recommendations for designing fault-tolerant autoscaling policies that distinguish genuine workload fluctuations from failure artifacts.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6a21\u62df\u5b9e\u9a8c\u7814\u7a76\u57fa\u7840\u8bbe\u65bd\u6545\u969c\u5bf9\u4e91\u73af\u5883\u4e2d\u81ea\u52a8\u6269\u7f29\u5bb9\u673a\u5236\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5b58\u50a8\u6545\u969c\u5bfc\u81f4\u6700\u9ad8\u6210\u672c\u5f00\u9500\uff0c\u800c\u8def\u7531\u5f02\u5e38\u6613\u5f15\u53d1\u8d44\u6e90\u5206\u914d\u4e0d\u8db3\u3002", "motivation": "\u57fa\u7840\u8bbe\u65bd\u6545\u969c\u4f1a\u626d\u66f2\u6027\u80fd\u6307\u6807\uff0c\u5bfc\u81f4\u81ea\u52a8\u6269\u7f29\u5bb9\u51b3\u7b56\u5931\u8bef\uff0c\u589e\u52a0\u6210\u672c\u6216\u964d\u4f4e\u670d\u52a1\u53ef\u9760\u6027\uff0c\u4e9f\u9700\u7814\u7a76\u5176\u5f71\u54cd\u4ee5\u6539\u8fdb\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u63a7\u5236\u6a21\u62df\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u56db\u7c7b\u5e38\u89c1\u6545\u969c\u5bf9\u5782\u76f4\u4e0e\u6c34\u5e73\u6269\u7f29\u5bb9\u884c\u4e3a\u5728\u4e0d\u540c\u5b9e\u4f8b\u914d\u7f6e\u548cSLO\u9608\u503c\u4e0b\u7684\u5f71\u54cd\u3002", "result": "\u5b58\u50a8\u6545\u969c\u5728\u6c34\u5e73\u6269\u7f29\u5bb9\u4e0b\u6bcf\u6708\u6700\u591a\u589e\u52a0258\u7f8e\u5143\u6210\u672c\uff1b\u8def\u7531\u5f02\u5e38\u5bfc\u81f4\u6301\u7eed\u6027\u8d44\u6e90\u5206\u914d\u4e0d\u8db3\uff1b\u6c34\u5e73\u6269\u7f29\u5bb9\u5bf9\u77ac\u6001\u5f02\u5e38\u66f4\u654f\u611f\uff0c\u5c24\u5176\u5728\u9608\u503c\u8fb9\u754c\u9644\u8fd1\u3002", "conclusion": "\u5e94\u8bbe\u8ba1\u80fd\u533a\u5206\u771f\u5b9e\u8d1f\u8f7d\u6ce2\u52a8\u4e0e\u6545\u969c\u4f2a\u5f71\u7684\u5bb9\u9519\u6269\u7f29\u5bb9\u7b56\u7565\uff0c\u4ee5\u63d0\u5347\u4e91\u7cfb\u7edf\u7ecf\u6d4e\u6027\u4e0e\u53ef\u9760\u6027\u3002"}}
{"id": "2601.04252", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04252", "abs": "https://arxiv.org/abs/2601.04252", "authors": ["Daoan Zhang", "Shuo Zhang", "Zijian Jin", "Jiebo Luo", "Shengyu Fu", "Elsie Nallipogu"], "title": "Sphinx: Benchmarking and Modeling for LLM-Driven Pull Request Review", "comment": null, "summary": "Pull request (PR) review is essential for ensuring software quality, yet automating this task remains challenging due to noisy supervision, limited contextual understanding, and inadequate evaluation metrics. We present Sphinx, a unified framework for LLM-based PR review that addresses these limitations through three key components: (1) a structured data generation pipeline that produces context-rich, semantically grounded review comments by comparing pseudo-modified and merged code; (2) a checklist-based evaluation benchmark that assesses review quality based on structured coverage of actionable verification points, moving beyond surface-level metrics like BLEU; and (3) Checklist Reward Policy Optimization (CRPO), a novel training paradigm that uses rule-based, interpretable rewards to align model behavior with real-world review practices. Extensive experiments show that models trained with Sphinx achieve state-of-the-art performance on review completeness and precision, outperforming both proprietary and open-source baselines by up to 40\\% in checklist coverage. Together, Sphinx enables the development of PR review models that are not only fluent but also context-aware, technically precise, and practically deployable in real-world development workflows. The data will be released after review.", "AI": {"tldr": "Sphinx\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684PR\u5ba1\u67e5\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6570\u636e\u751f\u6210\u3001\u68c0\u67e5\u8868\u8bc4\u4f30\u548cCRPO\u8bad\u7ec3\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u5ba1\u67e5\u8d28\u91cf\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u89e3\u51b3PR\u5ba1\u67e5\u81ea\u52a8\u5316\u4e2d\u7684\u566a\u58f0\u76d1\u7763\u3001\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0d\u8db3\u548c\u8bc4\u4f30\u6307\u6807\u4e0d\u5b8c\u5584\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e09\u90e8\u5206\u6846\u67b6\uff1a\u7ed3\u6784\u5316\u6570\u636e\u751f\u6210\u7ba1\u9053\u3001\u57fa\u4e8e\u68c0\u67e5\u8868\u7684\u8bc4\u4f30\u57fa\u51c6\u3001CRPO\u8bad\u7ec3\u8303\u5f0f\u3002", "result": "\u5728\u5ba1\u67e5\u5b8c\u6574\u6027\u548c\u7cbe\u786e\u6027\u4e0a\u8fbe\u5230SOTA\uff0c\u68c0\u67e5\u8868\u8986\u76d6\u7387\u6bd4\u57fa\u7ebf\u9ad840%\u3002", "conclusion": "Sphinx\u4f7fPR\u5ba1\u67e5\u6a21\u578b\u66f4\u6d41\u7545\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u6280\u672f\u7cbe\u51c6\u4e14\u53ef\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2601.04750", "categories": ["cs.DC", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.04750", "abs": "https://arxiv.org/abs/2601.04750", "authors": ["Krishna Chaitanya Sunkara"], "title": "Cognitive Infrastructure: A Unified DCIM Framework for AI Data Centers", "comment": "71 pages, 10 figures, 5 tables, 9 chapters including cases study. Published independently under Creative Commons BY 4.0. Includes comprehensive technical diagrams, quantitative models, JSON schema specifications, and production deployment validation.This is comprehensive manuscript synthesizing original research and systems engineering practices in AI Scale data center infrastructure management", "summary": "This work presents DCIM 3.0, a unified framework integrating semantic reasoning, predictive analytics, autonomous orchestration, and unified connectivity for next-generation AI data center management. The framework addresses critical challenges in infrastructure automation, sustainability, and digital-twin design through knowledge graph-based intelligence, thermal modeling, and the Unified Device Connectivity Protocol (UDCP).Keywords-Data Center Infrastructure Management, DCIM, AI Data Centers, Knowledge Graphs, Digital Twin, Thermal Management, Infrastructure Automation, Sustainability, GPU Computing, Data Center", "AI": {"tldr": "DCIM 3.0 \u662f\u4e00\u4e2a\u6574\u5408\u8bed\u4e49\u63a8\u7406\u3001\u9884\u6d4b\u5206\u6790\u3001\u81ea\u4e3b\u7f16\u6392\u4e0e\u7edf\u4e00\u8fde\u63a5\u7684\u4e0b\u4e00\u4ee3AI\u6570\u636e\u4e2d\u5fc3\u7ba1\u7406\u6846\u67b6\u3002", "motivation": "\u89e3\u51b3\u6570\u636e\u4e2d\u5fc3\u5728\u57fa\u7840\u8bbe\u65bd\u81ea\u52a8\u5316\u3001\u53ef\u6301\u7eed\u6027\u53ca\u6570\u5b57\u5b6a\u751f\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u667a\u80fd\u6280\u672f\u3001\u70ed\u5efa\u6a21\u65b9\u6cd5\u4e0e\u7edf\u4e00\u8bbe\u5907\u8fde\u63a5\u534f\u8bae\uff08UDCP\uff09\u3002", "result": "\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u667a\u80fd\u4e14\u53ef\u6301\u7eed\u7684\u6570\u636e\u4e2d\u5fc3\u7ba1\u7406\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u65f6\u4ee3\u6570\u636e\u4e2d\u5fc3\u8fd0\u7ef4\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.04801", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04801", "abs": "https://arxiv.org/abs/2601.04801", "authors": ["Lei Xu", "Shanshan Wang", "Chenglong Xiao"], "title": "MPM-LLM4DSE: Reaching the Pareto Frontier in HLS with Multimodal Learning and LLM-Driven Exploration", "comment": null, "summary": "High-Level Synthesis (HLS) design space exploration (DSE) seeks Pareto-optimal designs within expansive pragma configuration spaces. To accelerate HLS DSE, graph neural networks (GNNs) are commonly employed as surrogates for HLS tools to predict quality of results (QoR) metrics, while multi-objective optimization algorithms expedite the exploration. However, GNN-based prediction methods may not fully capture the rich semantic features inherent in behavioral descriptions, and conventional multi-objective optimization algorithms often do not explicitly account for the domain-specific knowledge regarding how pragma directives influence QoR. To address these limitations, this paper proposes the MPM-LLM4DSE framework, which incorporates a multimodal prediction model (MPM) that simultaneously fuses features from behavioral descriptions and control and data flow graphs. Furthermore, the framework employs a large language model (LLM) as an optimizer, accompanied by a tailored prompt engineering methodology. This methodology incorporates pragma impact analysis on QoR to guide the LLM in generating high-quality configurations (LLM4DSE). Experimental results demonstrate that our multimodal predictive model significantly outperforms state-of-the-art work ProgSG by up to 10.25$\\times$. Furthermore, in DSE tasks, the proposed LLM4DSE achieves an average performance gain of 39.90\\% over prior methods, validating the effectiveness of our prompting methodology. Code and models are available at https://github.com/wslcccc/MPM-LLM4DSE.", "AI": {"tldr": "\u63d0\u51faMPM-LLM4DSE\u6846\u67b6\uff0c\u878d\u5408\u591a\u6a21\u6001\u9884\u6d4b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347HLS\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u6548\u7387\u3002", "motivation": "\u73b0\u6709GNN\u9884\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5145\u5206\u6355\u6349\u884c\u4e3a\u63cf\u8ff0\u8bed\u4e49\u7279\u5f81\uff0c\u4f20\u7edf\u591a\u76ee\u6807\u4f18\u5316\u7b97\u6cd5\u672a\u6709\u6548\u5229\u7528pragma\u5bf9QoR\u5f71\u54cd\u7684\u9886\u57df\u77e5\u8bc6\u3002", "method": "\u6784\u5efa\u591a\u6a21\u6001\u9884\u6d4b\u6a21\u578b\u878d\u5408\u884c\u4e3a\u63cf\u8ff0\u4e0e\u6570\u636e\u6d41\u56fe\u7279\u5f81\uff0c\u5e76\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u5b9a\u5236\u63d0\u793a\u5de5\u7a0b\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u9884\u6d4b\u6a21\u578b\u8f83ProgSG\u63d0\u5347\u8fbe10.25\u500d\uff0cDSE\u4efb\u52a1\u5e73\u5747\u6027\u80fd\u589e\u76ca39.90%\u3002", "conclusion": "MPM-LLM4DSE\u6846\u67b6\u5728HLS\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u8d8a\u6027\uff0c\u9a8c\u8bc1\u4e86\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.05016", "categories": ["cs.MA", "cs.AI", "cs.GR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.05016", "abs": "https://arxiv.org/abs/2601.05016", "authors": ["Jin Gao", "Saichandu Juluri"], "title": "From Idea to Co-Creation: A Planner-Actor-Critic Framework for Agent Augmented 3D Modeling", "comment": null, "summary": "We present a framework that extends the Actor-Critic architecture to creative 3D modeling through multi-agent self-reflection and human-in-the-loop supervision. While existing approaches rely on single-prompt agents that directly execute modeling commands via tools like Blender MCP, our approach introduces a Planner-Actor-Critic architecture. In this design, the Planner coordinates modeling steps, the Actor executes them, and the Critic provides iterative feedback, while human users act as supervisors and advisors throughout the process. Through systematic comparison between single-prompt modeling and our reflective multi-agent approach, we demonstrate improvements in geometric accuracy, aesthetic quality, and task completion rates across diverse 3D modeling scenarios. Our evaluation reveals that critic-guided reflection, combined with human supervisory input, reduces modeling errors and increases complexity and quality of the result compared to direct single-prompt execution. This work establishes that structured agent self-reflection, when augmented by human oversight and advisory guidance, produces higher-quality 3D models while maintaining efficient workflow integration through real-time Blender synchronization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u81ea\u7701\u4e0e\u4eba\u673a\u534f\u540c\u76d1\u7763\u76843D\u5efa\u6a21\u6846\u67b6\uff0c\u76f8\u8f83\u5355\u63d0\u793a\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6a21\u578b\u51e0\u4f55\u7cbe\u5ea6\u3001\u7f8e\u5b66\u8d28\u91cf\u4e0e\u4efb\u52a1\u5b8c\u6210\u7387\u3002", "motivation": "\u73b0\u6709\u5355\u63d0\u793a\u5efa\u6a21\u65b9\u6cd5\u7f3a\u4e4f\u8fed\u4ee3\u53cd\u9988\u4e0e\u4eba\u7c7b\u6307\u5bfc\uff0c\u5bfc\u81f4\u9519\u8bef\u7387\u9ad8\u3001\u8f93\u51fa\u8d28\u91cf\u53d7\u9650\u3002", "method": "\u6784\u5efaPlanner-Actor-Critic\u67b6\u6784\uff1aPlanner\u89c4\u5212\u6b65\u9aa4\uff0cActor\u6267\u884c\u64cd\u4f5c\uff0cCritic\u63d0\u4f9b\u53cd\u9988\uff0c\u4eba\u7c7b\u5168\u7a0b\u62c5\u4efb\u76d1\u7763\u4e0e\u987e\u95ee\u89d2\u8272\uff0c\u5e76\u901a\u8fc7Blender\u5b9e\u65f6\u540c\u6b65\u5b9e\u73b0\u9ad8\u6548\u5de5\u4f5c\u6d41\u96c6\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u79cd3D\u5efa\u6a21\u573a\u666f\u4e2d\u5747\u4f18\u4e8e\u5355\u63d0\u793a\u65b9\u6cd5\uff0c\u6709\u6548\u964d\u4f4e\u9519\u8bef\u3001\u63d0\u5347\u590d\u6742\u5ea6\u4e0e\u8f93\u51fa\u8d28\u91cf\u3002", "conclusion": "\u7ed3\u6784\u5316\u667a\u80fd\u4f53\u81ea\u7701\u7ed3\u5408\u4eba\u7c7b\u76d1\u7763\u53ef\u7a33\u5b9a\u751f\u6210\u9ad8\u8d28\u91cf3D\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u5de5\u4f5c\u6d41\u6574\u5408\u80fd\u529b\u3002"}}
{"id": "2601.04813", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04813", "abs": "https://arxiv.org/abs/2601.04813", "authors": ["Homayoun Maleki", "Nekane Sainz", "Jon Legarda"], "title": "Proof of Commitment: A Human-Centric Resource for Permissionless Consensus", "comment": null, "summary": "Permissionless consensus protocols require a scarce resource to regulate leader election and provide Sybil resistance. Existing paradigms such as Proof of Work and Proof of Stake instantiate this scarcity through parallelizable resources like computation or capital. Once acquired, these resources can be subdivided across many identities at negligible marginal cost, making linear Sybil cost fundamentally unattainable.\n  We introduce Proof of Commitment (PoCmt), a consensus primitive grounded in a non-parallelizable resource: real-time human engagement. Validators maintain a commitment state capturing cumulative human effort, protocol participation, and online availability. Engagement is enforced through a Human Challenge Oracle that issues identity-bound, time-sensitive challenges, limiting the number of challenges solvable within each human window.\n  Under this model, sustaining multiple active identities requires proportional human-time effort. We establish a cost-theoretic separation showing that protocols based on parallelizable resources admit zero marginal Sybil cost, whereas PoCmt enforces a strictly linear cost profile. Using a weighted-backbone analysis, we show that PoCmt achieves safety, liveness, and commitment-proportional fairness under partial synchrony.\n  Simulations complement the analysis by isolating human-time capacity as the sole adversarial bottleneck and validating the predicted commitment drift and fairness properties. These results position PoCmt as a new point in the consensus design space, grounding permissionless security in sustained human effort rather than computation or capital.", "AI": {"tldr": "\u63d0\u51faProof of Commitment\u5171\u8bc6\u673a\u5236\uff0c\u4ee5\u4eba\u7c7b\u5b9e\u65f6\u53c2\u4e0e\u4f5c\u4e3a\u6297\u5973\u5deb\u653b\u51fb\u7684\u7a00\u7f3a\u8d44\u6e90\uff0c\u5b9e\u73b0\u7ebf\u6027\u8fb9\u9645\u6210\u672c\u4e0e\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709\u5171\u8bc6\u673a\u5236\u4f9d\u8d56\u53ef\u5e76\u884c\u8d44\u6e90\uff0c\u5bfc\u81f4\u5973\u5deb\u653b\u51fb\u8fb9\u9645\u6210\u672c\u8d8b\u8fd1\u4e8e\u96f6\uff0c\u9700\u5bfb\u627e\u4e0d\u53ef\u5e76\u884c\u5316\u7684\u65b0\u8d44\u6e90\u57fa\u7840\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u4eba\u7c7b\u6311\u6218\u9884\u8a00\u673a\u7684\u8eab\u4efd\u7ed1\u5b9a\u3001\u65f6\u95f4\u654f\u611f\u6311\u6218\u673a\u5236\uff0c\u5f3a\u5236\u9a8c\u8bc1\u8005\u7d2f\u79ef\u771f\u5b9e\u4eba\u529b\u6295\u5165\uff0c\u5e76\u901a\u8fc7\u52a0\u6743\u9aa8\u5e72\u5206\u6790\u8bc1\u660e\u534f\u8bae\u5b89\u5168\u6027\u3002", "result": "\u7406\u8bba\u4e0e\u4eff\u771f\u8868\u660ePoCmt\u80fd\u5b9e\u73b0\u5b89\u5168\u3001\u6d3b\u6027\u4e0e\u6bd4\u4f8b\u516c\u5e73\u6027\uff0c\u4e14\u653b\u51fb\u8005\u552f\u4e00\u74f6\u9888\u4e3a\u4eba\u7c7b\u65f6\u95f4\u5bb9\u91cf\u3002", "conclusion": "PoCmt\u5f00\u521b\u4e86\u4ee5\u6301\u7eed\u4eba\u529b\u6295\u5165\u800c\u975e\u7b97\u529b\u6216\u8d44\u672c\u4e3a\u57fa\u7840\u7684\u65b0\u578b\u65e0\u8bb8\u53ef\u5171\u8bc6\u8303\u5f0f\u3002"}}
{"id": "2601.05047", "categories": ["cs.AR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05047", "abs": "https://arxiv.org/abs/2601.05047", "authors": ["Xiaoyu Ma", "David Patterson"], "title": "Challenges and Research Directions for Large Language Model Inference Hardware", "comment": "Accepted for publication by IEEE Computer, 2026", "summary": "Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup communication. While our focus is datacenter AI, we also review their applicability for mobile devices.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u5185\u5b58\u4e0e\u4e92\u8fde\u74f6\u9888\uff0c\u5e76\u63d0\u51fa\u56db\u9879\u67b6\u6784\u7814\u7a76\u65b9\u5411\u4ee5\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u56e0\u81ea\u56de\u5f52\u89e3\u7801\u9636\u6bb5\u4e0e\u8bad\u7ec3\u4e0d\u540c\uff0c\u9762\u4e34\u5185\u5b58\u548c\u4e92\u8fde\u74f6\u9888\uff0c\u800c\u975e\u8ba1\u7b97\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u9ad8\u5e26\u5bbd\u95ea\u5b58\u3001\u8fd1\u5185\u5b58\u5904\u7406\u30013D\u5806\u53e0\u53ca\u4f4e\u5ef6\u8fdf\u4e92\u8fde\u56db\u9879\u67b6\u6784\u4f18\u5316\u65b9\u6848\u3002", "result": "\u8fd9\u4e9b\u65b9\u6848\u6709\u671b\u663e\u8457\u63d0\u5347\u6570\u636e\u4e2d\u5fc3AI\u63a8\u7406\u6548\u7387\uff0c\u5e76\u90e8\u5206\u9002\u7528\u4e8e\u79fb\u52a8\u8bbe\u5907\u3002", "conclusion": "\u672a\u6765AI\u67b6\u6784\u5e94\u805a\u7126\u5185\u5b58\u4e0e\u901a\u4fe1\u4f18\u5316\uff0c\u800c\u975e\u5355\u7eaf\u63d0\u5347\u7b97\u529b\u3002"}}
{"id": "2601.04526", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04526", "abs": "https://arxiv.org/abs/2601.04526", "authors": ["Zhao Tian"], "title": "Advancing Language Models for Code-related Tasks", "comment": "Accepted by ICSE 2026 (DS)", "summary": "Recent advances in language models (LMs) have driven significant progress in various software engineering tasks. However, existing LMs still struggle with complex programming scenarios due to limitations in data quality, model architecture, and reasoning capability. This research systematically addresses these challenges through three complementary directions: (1) improving code data quality with a code difference-guided adversarial augmentation technique (CODA) and a code denoising technique (CodeDenoise); (2) enhancing model architecture via syntax-guided code LMs (LEAM and LEAM++); and (3) advancing model reasoning with a prompting technique (muFiX) and an agent-based technique (Specine). These techniques aim to promote the practical adoption of LMs in software development and further advance intelligent software engineering.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u3001\u67b6\u6784\u4f18\u5316\u548c\u63a8\u7406\u6539\u8fdb\u4e09\u65b9\u9762\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7f16\u7a0b\u573a\u666f\u4e2d\u53d7\u9650\u4e8e\u6570\u636e\u8d28\u91cf\u3001\u6a21\u578b\u67b6\u6784\u548c\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faCODA\u4e0eCodeDenoise\u63d0\u5347\u6570\u636e\u8d28\u91cf\uff0cLEAM\u7cfb\u5217\u4f18\u5316\u67b6\u6784\uff0cmuFiX\u4e0eSpecine\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u3002", "result": "\u6709\u6548\u63a8\u52a8\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b9e\u9645\u843d\u5730\uff0c\u4fc3\u8fdb\u667a\u80fd\u8f6f\u4ef6\u5de5\u7a0b\u53d1\u5c55\u3002", "conclusion": "\u7efc\u5408\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u7f16\u7a0b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4e0e\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.05109", "categories": ["cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.05109", "abs": "https://arxiv.org/abs/2601.05109", "authors": ["Marco Laju", "Donghyun Son", "Saurabh Agarwal", "Nitin Kedia", "Myungjin Lee", "Jayanth Srinivasa", "Aditya Akella"], "title": "Nalar: An agent serving framework", "comment": null, "summary": "LLM-driven agentic applications increasingly automate complex, multi-step tasks, but serving them efficiently remains challenging due to heterogeneous components, dynamic and model-driven control flow, long-running state, and unpredictable latencies. Nalar is a ground-up agent-serving framework that cleanly separates workflow specification from execution while providing the runtime visibility and control needed for robust performance. Nalar preserves full Python expressiveness, using lightweight auto-generated stubs that turn agent and tool invocations into futures carrying dependency and context metadata. A managed state layer decouples logical state from physical placement, enabling safe reuse, migration, and consistent retry behavior. A two-level control architecture combines global policy computation with local event-driven enforcement to support adaptive routing, scheduling, and resource management across evolving workflows. Together, these mechanisms allow Nalar to deliver scalable, efficient, and policy-driven serving of heterogeneous agentic applications without burdening developers with orchestration logic. Across three agentic workloads, Nalar cuts tail latency by 34--74\\%, achieves up to $2.9\\times$ speedups, sustains 80 RPS where baselines fail, and scales to 130K futures with sub-500 ms control overhead.", "AI": {"tldr": "Nalar \u662f\u4e00\u4e2a\u4e13\u4e3a\u9ad8\u6548\u670d\u52a1 LLM \u9a71\u52a8\u7684\u667a\u80fd\u4f53\u5e94\u7528\u800c\u8bbe\u8ba1\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u5de5\u4f5c\u6d41\u89c4\u8303\u4e0e\u6267\u884c\u3001\u7ba1\u7406\u72b6\u6001\u548c\u4e24\u7ea7\u63a7\u5236\u67b6\u6784\uff0c\u663e\u8457\u964d\u4f4e\u5c3e\u5ef6\u8fdf\u5e76\u63d0\u5347\u541e\u5410\u91cf\u3002", "motivation": "\u5f53\u524d LLM \u667a\u80fd\u4f53\u5e94\u7528\u56e0\u7ec4\u4ef6\u5f02\u6784\u3001\u63a7\u5236\u6d41\u52a8\u6001\u3001\u72b6\u6001\u6301\u4e45\u548c\u5ef6\u8fdf\u4e0d\u53ef\u9884\u6d4b\uff0c\u5bfc\u81f4\u670d\u52a1\u6548\u7387\u4f4e\u4e0b\uff0c\u4e9f\u9700\u4e13\u7528\u6846\u67b6\u4f18\u5316\u6027\u80fd\u3002", "method": "Nalar \u91c7\u7528\u8f7b\u91cf\u5b58\u6839\u751f\u6210\u672a\u6765\u5bf9\u8c61\u3001\u89e3\u8026\u903b\u8f91\u4e0e\u7269\u7406\u72b6\u6001\u3001\u4e24\u7ea7\u63a7\u5236\u67b6\u6784\uff08\u5168\u5c40\u7b56\u7565+\u672c\u5730\u4e8b\u4ef6\u9a71\u52a8\uff09\u5b9e\u73b0\u81ea\u9002\u5e94\u8c03\u5ea6\u4e0e\u8d44\u6e90\u7ba1\u7406\u3002", "result": "\u5728\u4e09\u4e2a\u667a\u80fd\u4f53\u8d1f\u8f7d\u4e2d\uff0cNalar \u5c3e\u5ef6\u8fdf\u964d\u4f4e 34\u201374%\uff0c\u901f\u5ea6\u63d0\u5347\u6700\u9ad8\u8fbe 2.9 \u500d\uff0c\u652f\u6301 80 RPS\uff08\u57fa\u7ebf\u5931\u8d25\uff09\uff0c\u53ef\u6269\u5c55\u81f3 13 \u4e07 future \u5bf9\u8c61\u4e14\u63a7\u5236\u5f00\u9500\u4f4e\u4e8e 500ms\u3002", "conclusion": "Nalar \u5728\u4e0d\u589e\u52a0\u5f00\u53d1\u8005\u8d1f\u62c5\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u5f02\u6784\u667a\u80fd\u4f53\u5e94\u7528\u7684\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u3001\u7b56\u7565\u9a71\u52a8\u7684\u670d\u52a1\u80fd\u529b\u3002"}}
{"id": "2601.04540", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04540", "abs": "https://arxiv.org/abs/2601.04540", "authors": ["Tanghaoran Zhang", "Xinjun Mao", "Shangwen Wang", "Yuxin Zhao", "Yao Lu", "Jin Zhang", "Zhang Zhang", "Kang Yang", "Yue Yu"], "title": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation", "comment": "13 pages, 7 figures, Accepted by ASE 2025", "summary": "Recent advancements in large language models (LLMs) have automated various software engineering tasks, with benchmarks emerging to evaluate their capabilities. However, for adaptation, a critical activity during code reuse, there is no benchmark to assess LLMs' performance, leaving their practical utility in this area unclear. To fill this gap, we propose AdaptEval, a benchmark designed to evaluate LLMs on code snippet adaptation. Unlike existing benchmarks, AdaptEval incorporates the following three distinctive features: First, Practical Context. Tasks in AdaptEval are derived from developers' practices, preserving rich contextual information from Stack Overflow and GitHub communities. Second, Multi-granularity Annotation. Each task is annotated with requirements at both task and adaptation levels, supporting the evaluation of LLMs across diverse adaptation scenarios. Third, Fine-grained Evaluation. AdaptEval includes a two-tier testing framework combining adaptation-level and function-level tests, which enables evaluating LLMs' performance across various individual adaptations. Based on AdaptEval, we conduct the first empirical study to evaluate six instruction-tuned LLMs and especially three reasoning LLMs on code snippet adaptation. Experimental results demonstrate that AdaptEval enables the assessment of LLMs' adaptation capabilities from various perspectives. It also provides critical insights into their current limitations, particularly their struggle to follow explicit instructions. We hope AdaptEval can facilitate further investigation and enhancement of LLMs' capabilities in code snippet adaptation, supporting their real-world applications.", "AI": {"tldr": "\u63d0\u51faAdaptEval\u57fa\u51c6\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7247\u6bb5\u9002\u914d\u4e2d\u7684\u8868\u73b0\uff0c\u586b\u8865\u73b0\u6709\u8bc4\u4f30\u7a7a\u767d\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u590d\u7528\u4e2d\u9002\u914d\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u5bfc\u81f4\u5176\u5b9e\u9645\u6548\u7528\u4e0d\u660e\u3002", "method": "\u6784\u5efa\u5305\u542b\u5b9e\u8df5\u4e0a\u4e0b\u6587\u3001\u591a\u7c92\u5ea6\u6807\u6ce8\u548c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u4e09\u7279\u5f81\u7684AdaptEval\u57fa\u51c6\uff0c\u5e76\u5bf9\u516d\u79cd\u6307\u4ee4\u8c03\u4f18\u53ca\u4e09\u79cd\u63a8\u7406\u578b\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAdaptEval\u53ef\u4ece\u591a\u89d2\u5ea6\u8bc4\u4f30\u6a21\u578b\u9002\u914d\u80fd\u529b\uff0c\u5e76\u63ed\u793a\u5176\u96be\u4ee5\u9075\u5faa\u660e\u786e\u6307\u4ee4\u7b49\u5c40\u9650\u3002", "conclusion": "AdaptEval\u6709\u52a9\u4e8e\u63a8\u52a8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u9002\u914d\u9886\u57df\u7684\u80fd\u529b\u63d0\u5347\u4e0e\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2601.04930", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.04930", "abs": "https://arxiv.org/abs/2601.04930", "authors": ["Antonella Del Pozzo", "Achille Desreumaux", "Mathieu Gestin", "Alexandre Rapetti", "Sara Tucci-Piergiovanni"], "title": "Asynchronous Secure Federated Learning with Byzantine aggregators", "comment": null, "summary": "Privacy-preserving federated averaging is a central approach for protecting client privacy in federated learning. In this paper, we study this problem in an asynchronous communications setting with malicious aggregators. We propose a new solution to provide federated averaging in this model while protecting the client's data privacy through secure aggregation and differential privacy. Our solution maintains the same performance as the state of the art across all metrics. The main contributions of this paper are threefold. First, unlike existing single- or multi-server solutions, we consider malicious aggregation servers that may manipulate the model to leak clients' data or halt computation. To tolerate this threat, we replicate the aggregators, allowing a fraction of them to be corrupted. Second, we propose a new privacy preservation protocol for protocols in asynchronous communication models with Byzantine aggregators. In this protocol, clients mask their values and add Gaussian noise to their models. In contrast with previous works, we use the replicated servers to unmask the models, while ensuring the liveness of training even if aggregators misbehave. Third, the asynchronous communication model introduces new challenges not present in existing approaches. In such a setting, faster clients may contribute more frequently, potentially reducing their privacy and biasing the training. To address this, we introduce an inclusion mechanism that ensures uniform client participation and balanced privacy budgets. Interestingly, the solution presented in this paper does not rely on agreement between aggregators. Thus, we circumvent the known impossibility of consensus in asynchronous settings where processes might crash. Additionally, this feature increases availability, as a consensus-based algorithm only progresses in periods of low latency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5f02\u6b65\u901a\u4fe1\u548c\u6076\u610f\u805a\u5408\u5668\u73af\u5883\u4e0b\u4fdd\u62a4\u5ba2\u6237\u7aef\u9690\u79c1\u7684\u8054\u90a6\u5e73\u5747\u65b0\u65b9\u6848\uff0c\u7ed3\u5408\u5b89\u5168\u805a\u5408\u4e0e\u5dee\u5206\u9690\u79c1\uff0c\u5728\u4e0d\u4f9d\u8d56\u805a\u5408\u5668\u5171\u8bc6\u7684\u524d\u63d0\u4e0b\u7ef4\u6301\u8bad\u7ec3\u6d3b\u6027\u4e0e\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6848\u96be\u4ee5\u5e94\u5bf9\u5f02\u6b65\u901a\u4fe1\u4e2d\u6076\u610f\u805a\u5408\u5668\u653b\u51fb\u53ca\u5ba2\u6237\u7aef\u53c2\u4e0e\u4e0d\u5747\u5bfc\u81f4\u7684\u9690\u79c1\u6cc4\u9732\u4e0e\u8bad\u7ec3\u504f\u5dee\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u590d\u5236\u805a\u5408\u5668\u5bb9\u5fcd\u90e8\u5206\u6076\u610f\u8282\u70b9\u3001\u5ba2\u6237\u7aef\u6dfb\u52a0\u9ad8\u65af\u566a\u58f0\u5e76\u63a9\u7801\u6a21\u578b\u3001\u5f15\u5165\u5305\u542b\u673a\u5236\u5747\u8861\u5ba2\u6237\u7aef\u53c2\u4e0e\u9891\u7387\uff0c\u907f\u514d\u4f9d\u8d56\u5171\u8bc6\u534f\u8bae\u3002", "result": "\u65b9\u6848\u5728\u5f02\u6b65\u62dc\u5360\u5ead\u73af\u5883\u4e0b\u4fdd\u6301\u4e0e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u5347\u9690\u79c1\u4fdd\u62a4\u5f3a\u5ea6\u4e0e\u7cfb\u7edf\u53ef\u7528\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5f02\u6b65\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9690\u79c1\u4e0e\u9c81\u68d2\u6027\u6311\u6218\uff0c\u65e0\u9700\u5171\u8bc6\u673a\u5236\u5373\u53ef\u4fdd\u969c\u8bad\u7ec3\u6301\u7eed\u8fdb\u884c\uff0c\u5177\u6709\u66f4\u9ad8\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.04556", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04556", "abs": "https://arxiv.org/abs/2601.04556", "authors": ["Bo Yu", "Lei Zhao"], "title": "4D-ARE: Bridging the Attribution Gap in LLM Agent Requirements Engineering", "comment": "39 pages, 11 tables", "summary": "We deployed an LLM agent with ReAct reasoning and full data access. It executed flawlessly, yet when asked \"Why is completion rate 80%?\", it returned metrics instead of causal explanation. The agent knew how to reason but we had not specified what to reason about. This reflects a gap: runtime reasoning frameworks (ReAct, Chain-of-Thought) have transformed LLM agents, but design-time specification--determining what domain knowledge agents need--remains under-explored. We propose 4D-ARE (4-Dimensional Attribution-Driven Agent Requirements Engineering), a preliminary methodology for specifying attribution-driven agents. The core insight: decision-makers seek attribution, not answers. Attribution concerns organize into four dimensions (Results -> Process -> Support -> Long-term), motivated by Pearl's causal hierarchy. The framework operationalizes through five layers producing artifacts that compile directly to system prompts. We demonstrate the methodology through an industrial pilot deployment in financial services. 4D-ARE addresses what agents should reason about, complementing runtime frameworks that address how. We hypothesize systematic specification amplifies the power of these foundational advances. This paper presents a methodological proposal with preliminary industrial validation; rigorous empirical evaluation is planned for future work.", "AI": {"tldr": "\u63d0\u51fa4D-ARE\u65b9\u6cd5\u8bba\uff0c\u7cfb\u7edf\u5316\u6307\u5b9aLLM\u667a\u80fd\u4f53\u5e94\u63a8\u7406\u7684\u5185\u5bb9\uff0c\u4ee5\u8865\u8db3\u73b0\u6709\u8fd0\u884c\u65f6\u63a8\u7406\u6846\u67b6\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524dLLM\u667a\u80fd\u4f53\u867d\u5177\u5907\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u8bbe\u8ba1\u9636\u6bb5\u5bf9\u2018\u5e94\u63a8\u7406\u4ec0\u4e48\u2019\u7684\u660e\u786e\u89c4\u8303\uff0c\u5bfc\u81f4\u8f93\u51fa\u504f\u79bb\u7528\u6237\u771f\u5b9e\u9700\u6c42\uff08\u5982\u5f52\u56e0\u89e3\u91ca\uff09\u3002", "method": "\u57fa\u4e8ePearl\u56e0\u679c\u5c42\u7ea7\u6784\u5efa\u56db\u7ef4\u5f52\u56e0\u6846\u67b6\uff08\u7ed3\u679c\u2192\u8fc7\u7a0b\u2192\u652f\u6301\u2192\u957f\u671f\uff09\uff0c\u901a\u8fc7\u4e94\u5c42\u7ed3\u6784\u751f\u6210\u53ef\u7f16\u8bd1\u4e3a\u7cfb\u7edf\u63d0\u793a\u7684\u5de5\u4ef6\uff0c\u6307\u5bfc\u667a\u80fd\u4f53\u805a\u7126\u5f52\u56e0\u63a8\u7406\u3002", "result": "\u5728\u91d1\u878d\u670d\u52a1\u4e1a\u8bd5\u70b9\u90e8\u7f72\u9a8c\u8bc1\u4e864D-ARE\u7684\u521d\u6b65\u53ef\u884c\u6027\uff0c\u80fd\u6709\u6548\u5f15\u5bfc\u667a\u80fd\u4f53\u8f93\u51fa\u7b26\u5408\u51b3\u7b56\u8005\u9700\u6c42\u7684\u5f52\u56e0\u5206\u6790\u800c\u975e\u5355\u7eaf\u6307\u6807\u6570\u636e\u3002", "conclusion": "\u7cfb\u7edf\u5316\u7684\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\u53ef\u653e\u5927\u73b0\u6709\u63a8\u7406\u6846\u67b6\u6548\u80fd\uff0c\u672a\u6765\u9700\u5f00\u5c55\u4e25\u8c28\u5b9e\u8bc1\u8bc4\u4f30\u4ee5\u5b8c\u5584\u8be5\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2601.04689", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04689", "abs": "https://arxiv.org/abs/2601.04689", "authors": ["Charaka Geethal Kapugama"], "title": "Extending Delta Debugging Minimization for Spectrum-Based Fault Localization", "comment": "Accepted to 2026 IEEE 16th Annual Computing and Communication Workshop and Conference (CCWC)", "summary": "This paper introduces DDMIN-LOC, a technique that combines Delta Debugging Minimization (DDMIN) with Spectrum-Based Fault Localization (SBFL). It can be applied to programs taking string inputs, even when only a single failure-inducing input is available. DDMIN is an algorithm that systematically explores the minimal failure-inducing input that exposes a bug, given an initial failing input. However, it does not provide information about the faulty statements responsible for the failure. DDMIN-LOC addresses this limitation by collecting the passing and failing inputs generated during the DDMIN process and computing suspiciousness scores for program statements and predicates using SBFL algorithms. These scores are then combined to rank statements according to their likelihood of being faulty. DDMIN-LOC requires only one failing input of the buggy program, although it can be applied only to programs that take string inputs. DDMIN-LOC was evaluated on 136 programs selected from the QuixBugs and Codeflaws benchmarks using the SBFL algorithms Tarantula, Ochiai, GenProg, Jaccard and DStar. Experimental results show that DDMIN-LOC performs best with Jaccard: in most subjects, fewer than 20% executable lines need to be examined to locate the faulty statements. Moreover, in most subjects, faulty statements are ranked within the top 3 positions in all the generated test suites derived from different failing inputs.", "AI": {"tldr": "DDMIN-LOC\u7ed3\u5408Delta Debugging\u4e0e\u9891\u8c31\u6545\u969c\u5b9a\u4f4d\uff0c\u4ec5\u9700\u4e00\u4e2a\u5931\u8d25\u8f93\u5165\u5373\u53ef\u9ad8\u6548\u5b9a\u4f4d\u5b57\u7b26\u4e32\u8f93\u5165\u7a0b\u5e8f\u4e2d\u7684\u7f3a\u9677\u8bed\u53e5\u3002", "motivation": "\u89e3\u51b3DDMIN\u65e0\u6cd5\u6307\u51fa\u5177\u4f53\u6545\u969c\u8bed\u53e5\u7684\u95ee\u9898\uff0c\u63d0\u5347\u8c03\u8bd5\u6548\u7387\u3002", "method": "\u5229\u7528DDMIN\u751f\u6210\u7684\u901a\u8fc7/\u5931\u8d25\u8f93\u5165\uff0c\u7ed3\u5408SBFL\u7b97\u6cd5\u8ba1\u7b97\u8bed\u53e5\u53ef\u7591\u5ea6\u5e76\u6392\u5e8f\u3002", "result": "\u5728136\u4e2a\u57fa\u51c6\u7a0b\u5e8f\u4e2d\uff0c\u4f7f\u7528Jaccard\u7b97\u6cd5\u65f6\u591a\u6570\u60c5\u51b5\u4e0b\u53ea\u9700\u68c0\u67e520%\u4ee5\u5185\u4ee3\u7801\u884c\uff0c\u4e14\u6545\u969c\u8bed\u53e5\u591a\u6392\u5728\u524d3\u4f4d\u3002", "conclusion": "DDMIN-LOC\u663e\u8457\u63d0\u5347\u4e86\u4ec5\u51ed\u5355\u4e00\u5931\u8d25\u8f93\u5165\u5b9a\u4f4d\u7a0b\u5e8f\u7f3a\u9677\u7684\u80fd\u529b\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5b57\u7b26\u4e32\u8f93\u5165\u573a\u666f\u3002"}}
{"id": "2601.04841", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04841", "abs": "https://arxiv.org/abs/2601.04841", "authors": ["Jefferson Seide Moll\u00e9ri", "Sami Hyrynsalmi", "Antti Hakkala", "Kai K. Kimppa", "Jouni Smed"], "title": "A Longitudinal Analysis of Gamification in Untappd: Ethical Reflections on a Social Drinking Application", "comment": null, "summary": "This paper presents a longitudinal ethical analysis of Untappd, a social drinking application that gamifies beer consumption through badges, streaks, and social sharing. Building on an exploratory study conducted in 2020, we revisit the platform in 2025 to examine how its gamification features and ethical framings have evolved. Drawing on traditional ethical theory and practical frameworks for Software Engineering, we analyze five categories of badges and their implications for user autonomy and well-being. Our findings show that, despite small adjustments and superficial disclaimers, many of the original ethical issues remain. We argue for continuous ethical reflection built embedded into software lifecycles to prevent the normalization of risky behaviors through design.", "AI": {"tldr": "\u672c\u6587\u7eb5\u5411\u5206\u6790\u4e86\u793e\u4ea4\u996e\u9152\u5e94\u7528Untappd\u7684\u4f26\u7406\u6f14\u53d8\uff0c\u6307\u51fa\u5176\u6e38\u620f\u5316\u8bbe\u8ba1\u4ecd\u5b58\u4f26\u7406\u95ee\u9898\uff0c\u547c\u5401\u5c06\u4f26\u7406\u53cd\u601d\u5d4c\u5165\u8f6f\u4ef6\u751f\u547d\u5468\u671f\u3002", "motivation": "\u63a2\u8ba8Untappd\u5e73\u53f0\u6e38\u620f\u5316\u529f\u80fd\u5982\u4f55\u5f71\u54cd\u7528\u6237\u81ea\u4e3b\u6027\u4e0e\u798f\u7949\uff0c\u5e76\u63a8\u52a8\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u6301\u7eed\u4f26\u7406\u53cd\u601d\u3002", "method": "\u57fa\u4e8e2020\u5e74\u521d\u6b65\u7814\u7a76\uff0c2025\u5e74\u91cd\u8bbf\u5e73\u53f0\uff0c\u7ed3\u5408\u4f20\u7edf\u4f26\u7406\u7406\u8bba\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u6846\u67b6\uff0c\u5206\u6790\u4e94\u7c7b\u5fbd\u7ae0\u8bbe\u8ba1\u3002", "result": "\u5c3d\u7ba1\u6709\u5c0f\u5e45\u8c03\u6574\u548c\u514d\u8d23\u58f0\u660e\uff0c\u539f\u59cb\u4f26\u7406\u95ee\u9898\u5927\u591a\u4ecd\u5b58\uff0c\u6e38\u620f\u5316\u8bbe\u8ba1\u4ecd\u53ef\u80fd\u52a9\u957f\u98ce\u9669\u884c\u4e3a\u3002", "conclusion": "\u5e94\u5c06\u8fde\u7eed\u4f26\u7406\u53cd\u601d\u673a\u5236\u5185\u5d4c\u4e8e\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\uff0c\u4ee5\u9632\u6b62\u901a\u8fc7\u8bbe\u8ba1\u4f7f\u9ad8\u98ce\u9669\u884c\u4e3a\u5e38\u6001\u5316\u3002"}}
{"id": "2601.04922", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.04922", "abs": "https://arxiv.org/abs/2601.04922", "authors": ["Th\u00e9o Boivin", "Joeffrey Legaux"], "title": "AVX / NEON Intrinsic Functions: When Should They Be Used?", "comment": null, "summary": "A cross-configuration benchmark is proposed to explore the capacities and limitations of AVX / NEON intrinsic functions in a generic context of development project, when a vectorisation strategy is required to optimise the code. The main aim is to guide developers to choose when using intrinsic functions, depending on the OS, architecture and/or available compiler. Intrinsic functions were observed highly efficient in conditional branching, with intrinsic version execution time reaching around 5% of plain code execution time. However, intrinsic functions were observed as unnecessary in many cases, as the compilers already well auto-vectorise the code.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u8de8\u914d\u7f6e\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30AVX/NEON\u5185\u8054\u51fd\u6570\u5728\u4e0d\u540c\u5f00\u53d1\u73af\u5883\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u6307\u5bfc\u5f00\u53d1\u8005\u4f55\u65f6\u5e94\u624b\u52a8\u4f7f\u7528\u5185\u8054\u51fd\u6570\u4f18\u5316\u4ee3\u7801\u3002", "motivation": "\u5e2e\u52a9\u5f00\u53d1\u8005\u6839\u636e\u64cd\u4f5c\u7cfb\u7edf\u3001\u67b6\u6784\u548c\u7f16\u8bd1\u5668\u9009\u62e9\u662f\u5426\u4f7f\u7528\u5185\u8054\u51fd\u6570\u8fdb\u884c\u5411\u91cf\u5316\u4f18\u5316\u3002", "method": "\u8bbe\u8ba1\u8de8\u914d\u7f6e\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u5185\u8054\u51fd\u6570\u4e0e\u666e\u901a\u4ee3\u7801\u53ca\u7f16\u8bd1\u5668\u81ea\u52a8\u5411\u91cf\u5316\u7684\u6267\u884c\u6548\u7387\u3002", "result": "\u5185\u8054\u51fd\u6570\u5728\u6761\u4ef6\u5206\u652f\u4e2d\u6548\u7387\u6781\u9ad8\uff08\u6267\u884c\u65f6\u95f4\u7ea6\u4e3a\u666e\u901a\u4ee3\u7801\u76845%\uff09\uff0c\u4f46\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u7f16\u8bd1\u5668\u5df2\u80fd\u826f\u597d\u81ea\u52a8\u5411\u91cf\u5316\uff0c\u65e0\u9700\u624b\u52a8\u4f18\u5316\u3002", "conclusion": "\u4ec5\u5728\u7279\u5b9a\u573a\u666f\uff08\u5982\u590d\u6742\u6761\u4ef6\u5206\u652f\uff09\u63a8\u8350\u4f7f\u7528\u5185\u8054\u51fd\u6570\uff0c\u5176\u4ed6\u60c5\u51b5\u4f9d\u8d56\u7f16\u8bd1\u5668\u81ea\u52a8\u4f18\u5316\u5373\u53ef\u3002"}}
