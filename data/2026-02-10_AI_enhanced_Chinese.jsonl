{"id": "2602.08389", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08389", "abs": "https://arxiv.org/abs/2602.08389", "authors": ["Yao-hua Franck Xu", "Tayeb Lemlouma", "Arnaud Braud", "Jean-Marie Bonnin"], "title": "Altruism and Fair Objective in Mixed-Motive Markov games", "comment": null, "summary": "Cooperation is fundamental for society's viability, as it enables the emergence of structure within heterogeneous groups that seek collective well-being. However, individuals are inclined to defect in order to benefit from the group's cooperation without contributing the associated costs, thus leading to unfair situations. In game theory, social dilemmas entail this dichotomy between individual interest and collective outcome. The most dominant approach to multi-agent cooperation is the utilitarian welfare which can produce efficient highly inequitable outcomes. This paper proposes a novel framework to foster fairer cooperation by replacing the standard utilitarian objective with Proportional Fairness. We introduce a fair altruistic utility for each agent, defined on the individual log-payoff space and derive the analytical conditions required to ensure cooperation in classic social dilemmas. We then extend this framework to sequential settings by defining a Fair Markov Game and deriving novel fair Actor-Critic algorithms to learn fair policies. Finally, we evaluate our method in various social dilemma environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6bd4\u4f8b\u516c\u5e73\u6846\u67b6\u53d6\u4ee3\u529f\u5229\u4e3b\u4e49\uff0c\u4ee5\u4fc3\u8fdb\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u516c\u5e73\u6027\uff0c\u901a\u8fc7\u65b0\u9020\u516c\u5e73\u5229\u4ed6\u6548\u7528\u51fd\u6570\u548c\u7b97\u6cd5\u5728\u987a\u5e8f\u73af\u5883\u4e2d\u8bc4\u4f30\u3002", "motivation": "\u52a8\u673a\u662f\u89e3\u51b3\u793e\u4f1a\u56f0\u5883\u4e2d\u4e2a\u4eba\u5229\u76ca\u4e0e\u96c6\u4f53\u798f\u7949\u7684\u51b2\u7a81\uff0c\u529f\u5229\u4e3b\u4e49\u65b9\u6cd5\u867d\u9ad8\u6548\u4f46\u53ef\u80fd\u52a0\u5267\u4e0d\u516c\u5e73\u3002", "method": "\u65b9\u6cd5\u662f\u5b9a\u4e49\u57fa\u4e8e\u4e2a\u4f53\u5bf9\u6570\u6536\u76ca\u6bd4\u4f8b\u7684\u516c\u5e73\u5229\u4ed6\u5b9e\u7528\u51fd\u6570\uff0c\u63a8\u5bfc\u5408\u4f5c\u6761\u4ef6\uff1b\u6269\u5c55\u81f3\u987a\u5e8f\u60c5\u5883\uff0c\u521b\u5efa\u516c\u5e73\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u5e76\u5f15\u5165\u516c\u5e73Actor-Critic\u7b97\u6cd5\u3002", "result": "\u7ed3\u679c\u5728\u591a\u79cd\u793e\u4f1a\u56f0\u5883\u73af\u5883\u4e2d\u8bc4\u4f30\uff0c\u663e\u793a\u6846\u67b6\u6709\u6548\u4fc3\u8fdb\u516c\u5e73\u5408\u4f5c\u3002", "conclusion": "\u7ed3\u8bba\u4e3a\u8be5\u6846\u67b6\u53ef\u66ff\u4ee3\u529f\u5229\u4e3b\u4e49\uff0c\u5b9e\u73b0\u66f4\u516c\u5e73\u7684\u5408\u4f5c\u8fc7\u7a0b\u3002"}}
{"id": "2602.08081", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.08081", "abs": "https://arxiv.org/abs/2602.08081", "authors": ["Brian Rojkov", "Shubham Ranjan", "Derek Wright", "Manoj Sachdev"], "title": "Investigating Energy Bounds of Analog Compute-in-Memory with Local Normalization", "comment": null, "summary": "Modern edge AI workloads demand maximum energy efficiency, motivating the pursuit of analog Compute-in-Memory (CIM) architectures. Simultaneously, the popularity of Large-Language-Models (LLMs) drives the adoption of low-bit floating-point formats which prioritize dynamic range. However, the conventional direct-accumulation CIM accommodates floating-points by normalizing them to a shared widened fixed-point scale. Consequently, hardware resolution is dictated by the input's dynamic range rather than its precision, and energy consumption is dominated by the ADC. We address this limitation by introducing local normalization for each input, weight, and multiply-accumulate (MAC) output via a Gain-Ranging MAC (GR-MAC). Normalization overhead is handled by low-power digital logic, enabling the computationally expensive MAC operation to remain in the energy-efficient low-precision analog regime. Energy modelling shows that the addition of a gain-ranging Stage to the MAC enables a 4-bit increase in input dynamic range without increased energy consumption at a 35 dB SQNR standard. Additionally, the ADC resolution requirement becomes invariant to input distribution assumptions, allowing construction of an upper bound with a 1.5-bit reduction compared to the conventional lower bound. These results establish a pathway towards unlocking favourable energy scaling trends of analog CIM for modern AI workloads.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u589e\u76ca\u8303\u56f4MAC\uff08GR-MAC\uff09\u67b6\u6784\uff0c\u901a\u8fc7\u5c40\u90e8\u5f52\u4e00\u5316\u89e3\u51b3\u6a21\u62df\u5b58\u50a8\u5668\u8ba1\u7b97\u4e2d\u6d6e\u70b9\u6570\u5904\u7406\u7684\u80fd\u6548\u95ee\u9898\uff0c\u63d0\u5347\u52a8\u6001\u8303\u56f4\u5e76\u964d\u4f4eADC\u9700\u6c42\u3002", "motivation": "\u73b0\u4ee3\u8fb9\u7f18AI\u5de5\u4f5c\u8d1f\u8f7d\u8ffd\u6c42\u6700\u9ad8\u80fd\u6548\uff0c\u63a8\u52a8\u6a21\u62df\u5b58\u50a8\u5668\u8ba1\u7b97\u67b6\u6784\u53d1\u5c55\uff1b\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6d41\u884c\u4fc3\u4f7f\u91c7\u7528\u4f4e\u4f4d\u6d6e\u70b9\u683c\u5f0f\u4f18\u5148\u52a8\u6001\u8303\u56f4\u3002\u4f20\u7edf\u76f4\u63a5\u7d2f\u79ef\u67b6\u6784\u901a\u8fc7\u6269\u5c55\u5b9a\u70b9\u5f52\u4e00\u5316\u5904\u7406\u6d6e\u70b9\u6570\uff0c\u5bfc\u81f4\u786c\u4ef6\u5206\u8fa8\u7387\u53d7\u52a8\u6001\u8303\u56f4\u5236\u7ea6\uff0c\u4e14ADC\u529f\u8017\u5360\u6bd4\u8fc7\u9ad8\u3002", "method": "\u5f15\u5165GR-MAC\u67b6\u6784\uff0c\u5bf9\u6bcf\u4e2a\u8f93\u5165\u3001\u6743\u91cd\u548c\u4e58\u6cd5\u7d2f\u52a0\u8f93\u51fa\u6267\u884c\u5c40\u90e8\u5f52\u4e00\u5316\uff0c\u7531\u4f4e\u529f\u8017\u6570\u5b57\u903b\u8f91\u5904\u7406\u5f00\u9500\uff0c\u4f7f\u8ba1\u7b97\u5bc6\u96c6\u578bMAC\u64cd\u4f5c\u4fdd\u6301\u5728\u9ad8\u6548\u7684\u6a21\u62df\u4f4e\u7cbe\u5ea6\u57df\u3002", "result": "\u80fd\u6e90\u5efa\u6a21\u8868\u660e\uff0c\u52a0\u5165\u589e\u76ca\u8303\u56f4\u9636\u6bb5\u572835 dB\u4fe1\u566a\u6bd4\u4e0b\uff0c\u5728\u4e0d\u589e\u52a0\u80fd\u8017\u60c5\u51b5\u4e0b\u5b9e\u73b04\u4f4d\u52a8\u6001\u8303\u56f4\u63d0\u5347\uff1bADC\u5206\u8fa8\u7387\u9700\u6c42\u5bf9\u8f93\u5165\u5206\u5e03\u4e0d\u53d8\u6027\uff0c\u4e0a\u754c\u6bd4\u4f20\u7edf\u4e0b\u9650\u51cf\u5c111.5\u4f4d\u3002", "conclusion": "\u8be5\u6210\u679c\u4e3a\u73b0\u4ee3AI\u5de5\u4f5c\u8d1f\u8f7d\u89e3\u9501\u6a21\u62df\u8ba1\u7b97\u7684\u9ad8\u6548\u80fd\u6548\u6269\u5c55\u8def\u5f84\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.07244", "categories": ["cs.NI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.07244", "abs": "https://arxiv.org/abs/2602.07244", "authors": ["John Pravin Arockiasamy", "Alexey Vinel"], "title": "Performance Evaluation of V2X Communication Using Large-Scale Traffic Data", "comment": null, "summary": "Vehicular communication (V2X) technologies are widely regarded as a cornerstone for cooperative and automated driving, yet their large-scale real-world deployment remains limited. As a result, understanding V2X performance under realistic, full-scale traffic conditions continues to be relevant. Most existing performance evaluations rely on synthetic traffic scenarios generated by simulators, which, while useful, may not fully capture the features of real-world traffic. In this paper, we present a large-scale, data-driven evaluation of V2X communication performance using real-world traffic datasets. Vehicle trajectories derived from the Highway Drone (HighD) and Intersection Drone (InD) datasets are converted into simulation-ready formats and coupled with a standardized V2X networking stack to enable message-level performance analysis for entire traffic populations comprising over hundred thousands vehicles across multiple locations. We evaluate key V2X performance indicators, including inter-generation gap, inter-packet gap, packet delivery ratio, and channel busy ratio, across both highway and urban intersection environments. Our results show that cooperative awareness services remain feasible at scale under realistic traffic conditions. In addition, the findings highlight how traffic density, mobility patterns, and communication range influence V2X performance and how synthetic traffic assumptions may overestimate channel congestion.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u771f\u5b9e\u4ea4\u901a\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u5927\u89c4\u6a21V2X\u901a\u4fe1\u6027\u80fd\u8bc4\u4f30\uff0c\u8bc1\u5b9e\u73b0\u5b9e\u4ea4\u901a\u6761\u4ef6\u4e0b\u534f\u4f5c\u611f\u77e5\u670d\u52a1\u53ef\u6269\u5c55\u8fd0\u884c\uff0c\u5e76\u63ed\u793a\u5408\u6210\u4ea4\u901a\u6a21\u62df\u53ef\u80fd\u9ad8\u4f30\u4fe1\u9053\u62e5\u5835\u3002", "motivation": "V2X\u6280\u672f\u867d\u88ab\u89c6\u4f5c\u81ea\u52a8\u9a7e\u9a76\u5173\u952e\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u6709\u9650\uff1b\u73b0\u6709\u8bc4\u4f30\u591a\u4f9d\u8d56\u6a21\u62df\u4ea4\u901a\u573a\u666f\uff0c\u53ef\u80fd\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u771f\u5b9e\u4ea4\u901a\u7279\u5f81\uff0c\u9700\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u8865\u5145\u7814\u7a76\u3002", "method": "\u5c06HighD\u548cInD\u65e0\u4eba\u673a\u91c7\u96c6\u7684\u771f\u5b9e\u8f66\u8f86\u8f68\u8ff9\u8f6c\u6362\u4e3a\u4eff\u771f\u683c\u5f0f\uff0c\u7ed3\u5408\u6807\u51c6\u5316V2X\u534f\u8bae\u6808\uff0c\u5bf9\u5341\u4f59\u4e07\u8f86\u8f66\u7684\u6d88\u606f\u7ea7\u6027\u80fd\u8fdb\u884c\u5206\u6790\uff0c\u8bc4\u4f30\u9ad8\u901f\u516c\u8def\u4e0e\u57ce\u5e02\u8def\u53e3\u7684\u6838\u5fc3\u6027\u80fd\u6307\u6807\u3002", "result": "\u534f\u4f5c\u611f\u77e5\u670d\u52a1\u5728\u771f\u5b9e\u4ea4\u901a\u573a\u666f\u4e2d\u4ecd\u5177\u53ef\u884c\u6027\uff1b\u4ea4\u901a\u5bc6\u5ea6\u3001\u79fb\u52a8\u6a21\u5f0f\u548c\u901a\u4fe1\u8303\u56f4\u663e\u8457\u5f71\u54cd\u6027\u80fd\uff1b\u5408\u6210\u4ea4\u901a\u6a21\u578b\u53ef\u80fd\u9ad8\u4f30\u4fe1\u9053\u7e41\u5fd9\u7387\u3002", " Jobsconclusion": "\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u7684\u8bc4\u4f30\u63ed\u793aV2X\u5b9e\u9645\u6027\u80fd\u4e0e\u6a21\u62df\u5dee\u5f02\uff0c\u9a8c\u8bc1\u4e86\u5927\u89c4\u6a21\u90e8\u7f72\u53ef\u884c\u6027\uff0c\u5e76\u5efa\u8bae\u4fee\u6b63\u73b0\u6709\u4eff\u771f\u4e2d\u5bf9\u4fe1\u9053\u62e5\u5835\u7684\u9884\u4f30\u504f\u5dee\u3002", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.07071", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07071", "abs": "https://arxiv.org/abs/2602.07071", "authors": ["S M Rakib UI Karim", "Wenyi Lu", "Sean Goggins"], "title": "Artificial Intelligence in Open Source Software Engineering: A Foundation for Sustainability", "comment": null, "summary": "Open-source software (OSS) is foundational to modern digital infrastructure, yet this context for group work continues to struggle to ensure sufficient contributions in many critical cases. This literature review explores how artificial intelligence (AI) is being leveraged to address critical challenges to OSS sustainability, including maintaining contributor engagement, securing funding, ensuring code quality and security, fostering healthy community dynamics, and preventing project abandonment. Synthesizing recent interdisciplinary research, the paper identifies key applications of AI in this domain, including automated bug triaging, system maintenance, contributor onboarding and mentorship, community health analytics, vulnerability detection, and task automation. The review also examines the limitations and ethical concerns that arise from applying AI in OSS contexts, including data availability, bias and fairness, transparency, risks of misuse, and the preservation of human-centered values in collaborative development. By framing AI not as a replacement but as a tool to augment human infrastructure, this study highlights both the promise and pitfalls of AI-driven interventions. It concludes by identifying critical research gaps and proposing future directions at the intersection of AI, sustainability, and OSS, aiming to support more resilient and equitable open-source ecosystems.", "AI": {"tldr": "\u8fd9\u7bc7\u6587\u732e\u7efc\u8ff0\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u5982\u4f55\u5e94\u7528\u4e8e\u5f00\u6e90\u8f6f\u4ef6\u53ef\u6301\u7eed\u6027\uff0c\u6db5\u76d6AI\u5728\u7ef4\u62a4\u8d21\u732e\u8005\u3001\u8d44\u91d1\u3001\u4ee3\u7801\u8d28\u91cf\u7b49\u65b9\u9762\u7684\u4f5c\u7528\u4e0e\u4f26\u7406\u6311\u6218\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u662f\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u7684\u6838\u5fc3\uff0c\u4f46\u9762\u4e34\u8d21\u732e\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u9700\u8981AI\u89e3\u51b3\u65b9\u6848\u4ee5\u63d0\u5347\u53ef\u6301\u7eed\u6027\u548c\u793e\u533a\u97e7\u6027\u3002", "method": "\u901a\u8fc7\u7efc\u5408\u8de8\u5b66\u79d1\u7814\u7a76\u7684\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790AI\u5982\u4f55\u5e94\u5bf9OSS\u6311\u6218\u3002", "result": "\u8bc6\u522bAI\u5e94\u7528\u5305\u62ec\u81ea\u52a8\u5316\u9519\u8bef\u5206\u6d41\u3001\u6f0f\u6d1e\u68c0\u6d4b\u7b49\u4f18\u52bf\uff0c\u4f46\u4e5f\u66b4\u9732\u6570\u636e\u53ef\u7528\u6027\u3001\u504f\u89c1\u548c\u4e0d\u900f\u660e\u7b49\u4f26\u7406\u5c40\u9650\u3002", "conclusion": "AI\u5e94\u4f5c\u4e3a\u4eba\u7c7b\u534f\u4f5c\u7684\u8f85\u52a9\u5de5\u5177\u800c\u975e\u66ff\u4ee3\uff1b\u7814\u7a76\u63ed\u793a\u5176\u6f5c\u529b\u4e0e\u98ce\u9669\uff0c\u63d0\u51fa\u672a\u6765\u65b9\u5411\u4ee5\u652f\u6301\u66f4\u516c\u5e73\u7684\u5f00\u6e90\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2602.07191", "categories": ["cs.OS", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.07191", "abs": "https://arxiv.org/abs/2602.07191", "authors": ["John Zhuoyang Ye", "Jiyuan Wang", "Yifan Qiao", "Jens Palsberg"], "title": "HALO: A Fine-Grained Resource Sharing Quantum Operating System", "comment": null, "summary": "As quantum computing enters the cloud era, thousands of users must share access to a small number of quantum processors. Users need to wait minutes to days to start their jobs, which only takes a few seconds for execution. Current quantum cloud platforms employ a fair-share scheduler, as there is no way to multiplex a quantum computer among multiple programs at the same time, leaving many qubits idle and significantly under-utilizing the hardware. This imbalance between high user demand and scarce quantum resources has become a key barrier to scalable and cost-effective quantum computing.\n  We present HALO, the first quantum operating system design that supports fine-grained resource-sharing. HALO introduces two complementary mechanisms. First, a hardware-aware qubit-sharing algorithm that places shared helper qubits on regions of the quantum computer that minimize routing overhead and avoid cross-talk noise between different users' processes. Second, a shot-adaptive scheduler that allocates execution windows according to each job's sampling requirements, improving throughput and reducing latency. Together, these mechanisms transform the way quantum hardware is scheduled and achieve more fine-grained parallelism.\n  We evaluate HALO on the IBM Torino quantum computer on helper qubit intense benchmarks. Compared to state-of-the-art systems such as HyperQ, HALO improves overall hardware utilization by up to 2.44x, increasing throughput by 4.44x, and maintains fidelity loss within 33%, demonstrating the practicality of resource-sharing in quantum computing.", "AI": {"tldr": "HALO \u662f\u9996\u4e2a\u91cf\u5b50\u64cd\u4f5c\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u8d44\u6e90\u5171\u4eab\uff0c\u901a\u8fc7\u786c\u4ef6\u611f\u77e5\u91cf\u5b50\u6bd4\u7279\u5171\u4eab\u548c\u81ea\u9002\u5e94\u8c03\u5ea6\uff0c\u63d0\u9ad8\u786c\u4ef6\u5229\u7528\u7387\u548c\u541e\u5410\u91cf\uff0c\u63a7\u5236\u4fdd\u771f\u5ea6\u635f\u5931\u3002", "motivation": "\u91cf\u5b50\u4e91\u8ba1\u7b97\u4e2d\uff0c\u5927\u91cf\u7528\u6237\u5171\u4eab\u6709\u9650\u5904\u7406\u5668\uff0c\u5f53\u524d\u516c\u5e73\u8c03\u5ea6\u5668\u4e32\u884c\u5904\u7406\u4f5c\u4e1a\u5bfc\u81f4\u786c\u4ef6\u5229\u7528\u7387\u4f4e\u4e0b\u548c\u957f\u6392\u961f\u65f6\u95f4\u3002", "method": "\u5f15\u5165\u786c\u4ef6\u611f\u77e5\u91cf\u5b50\u6bd4\u7279\u5171\u4eab\u7b97\u6cd5\uff0c\u4f18\u5316\u91cf\u5b50\u6bd4\u7279\u653e\u7f6e\u4ee5\u51cf\u5c11\u8def\u7531\u5f00\u9500\u548c\u566a\u58f0\uff0c\u5e76\u7ed3\u5408\u81ea\u9002\u5e94\u6267\u884c\u8c03\u5ea6\u5668\u636e\u91c7\u6837\u9700\u6c42\u5206\u914d\u7a97\u53e3\u3002", "result": "\u5728IBM Torino\u4e0a\u5b9e\u9a8c\u663e\u793a\uff0c\u786c\u4ef6\u5229\u7528\u7387\u63d0\u53472.44\u500d\uff0c\u541e\u5410\u91cf\u589e4.44\u500d\uff0c\u4fdd\u771f\u5ea6\u635f\u5931\u4f4e\u4e8e33%\u3002", "conclusion": "\u8d44\u6e90\u5171\u4eab\u673a\u5236\u5b9e\u7528\u53ef\u884c\uff0c\u5b9e\u73b0\u66f4\u7ec6\u7c92\u5ea6\u5e76\u884c\uff0c\u4fc3\u8fdb\u91cf\u5b50\u8ba1\u7b97\u7684\u53ef\u6269\u5c55\u6027\u548c\u6210\u672c\u6548\u76ca\u3002"}}
{"id": "2602.07306", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07306", "abs": "https://arxiv.org/abs/2602.07306", "authors": ["Chong Wang", "Nan Du", "Tom Gunter", "Tao Lei", "Kulin Seth", "Senyu Tong", "Jianyu Wang", "Guoli Yin", "Xiyou Zhou", "Kelvin Zou", "Ruoming Pang"], "title": "Parallel Track Transformers: Enabling Fast GPU Inference with Reduced Synchronization", "comment": null, "summary": "Efficient large-scale inference of transformer-based large language models (LLMs) remains a fundamental systems challenge, frequently requiring multi-GPU parallelism to meet stringent latency and throughput targets. Conventional tensor parallelism decomposes matrix operations across devices but introduces substantial inter-GPU synchronization, leading to communication bottlenecks and degraded scalability. We propose the Parallel Track (PT) Transformer, a novel architectural paradigm that restructures computation to minimize cross-device dependencies. PT achieves up to a 16x reduction in synchronization operations relative to standard tensor parallelism, while maintaining competitive model quality in our experiments. We integrate PT into two widely adopted LLM serving stacks-Tensor-RT-LLM and vLLM-and report consistent improvements in serving efficiency, including up to 15-30% reduced time to first token, 2-12% reduced time per output token, and up to 31.90% increased throughput in both settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u884c\u8f68\u8ff9\uff08PT\uff09\u53d8\u538b\u5668\u67b6\u6784\uff0c\u901a\u8fc7\u5728\u591a\u4e2aGPU\u4e0a\u51cf\u5c11\u540c\u6b65\u64cd\u4f5c\uff0c\u89e3\u51b3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e2d\u7684\u901a\u4fe1\u6548\u7387\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u5f20\u91cf\u5e76\u884c\u5728\u591aGPU\u63a8\u7406\u4e2d\u5f15\u5165\u5927\u91cf\u8bbe\u5907\u95f4\u540c\u6b65\uff0c\u9020\u6210\u901a\u4fe1\u74f6\u9888\u548c\u53ef\u6269\u5c55\u6027\u4e0b\u964d\uff0c\u9700\u8981\u4f18\u5316\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u5f00\u53d1PT\u53d8\u538b\u5668\u67b6\u6784\uff0c\u91cd\u6784\u8ba1\u7b97\u8fc7\u7a0b\u4ee5\u6700\u5c0f\u5316\u8de8\u8bbe\u5907\u4f9d\u8d56\uff0c\u96c6\u6210\u5230Tensor-RT-LLM\u548cvLLM\u7b49\u670d\u52a1\u7cfb\u7edf\u4e2d\u3002", "result": "\u76f8\u6bd4\u6807\u51c6\u5f20\u91cf\u5e76\u884c\uff0c\u540c\u6b65\u64cd\u4f5c\u51cf\u5c11\u6700\u9ad816\u500d\uff1b\u670d\u52a1\u6548\u7387\u663e\u8457\u63d0\u5347\uff0c\u9996\u6b21\u4ee4\u724c\u65f6\u95f4\u51cf\u5c1115-30%\uff0c\u8f93\u51fa\u4ee4\u724c\u65f6\u95f4\u7f29\u77ed2-12%\uff0c\u541e\u5410\u91cf\u589e\u52a031.90%\u3002", "conclusion": "PT\u67b6\u6784\u5728\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u63d0\u5347LLM\u670d\u52a1\u6548\u7387\u548c\u6027\u80fd\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2602.08529", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08529", "abs": "https://arxiv.org/abs/2602.08529", "authors": ["Ning Lin", "Haolun Li", "Mingshu Liu", "Chengyun Ruan", "Kaibo Huang", "Yukun Wei", "Zhongliang Yang", "Linna Zhou"], "title": "EvoCorps: An Evolutionary Multi-Agent Framework for Depolarizing Online Discourse", "comment": null, "summary": "Polarization in online discourse erodes social trust and accelerates misinformation, yet technical responses remain largely diagnostic and post-hoc. Current governance approaches suffer from inherent latency and static policies, struggling to counter coordinated adversarial amplification that evolves in real-time. We present EvoCorps, an evolutionary multi-agent framework for proactive depolarization. EvoCorps frames discourse governance as a dynamic social game and coordinates roles for monitoring, planning, grounded generation, and multi-identity diffusion. A retrieval-augmented collective cognition core provides factual grounding and action--outcome memory, while closed-loop evolutionary learning adapts strategies as the environment and attackers change. We implement EvoCorps on the MOSAIC social-AI simulation platform for controlled evaluation in a multi-source news stream with adversarial injection and amplification. Across emotional polarization, viewpoint extremity, and argumentative rationality, EvoCorps improves discourse outcomes over an adversarial baseline, pointing to a practical path from detection and post-hoc mitigation to in-process, closed-loop intervention. The code is available at https://github.com/ln2146/EvoCorps.", "AI": {"tldr": "EvoCorps\u662f\u7528\u4e8e\u4e3b\u52a8\u51cf\u5c11\u5728\u7ebf\u8ba8\u8bba\u6781\u5316\u7684\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u6a21\u62df\u52a8\u6001\u793e\u4f1a\u6e38\u620f\uff0c\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u5728\u7ebf\u6781\u5316\u4fb5\u8680\u793e\u4f1a\u4fe1\u4efb\u5e76\u52a0\u901f\u9519\u8bef\u4fe1\u606f\u4f20\u64ad\uff0c\u73b0\u6709\u6cbb\u7406\u65b9\u6cd5\u6ede\u540e\u3001\u9759\u6001\uff0c\u96be\u5e94\u5bf9\u5b9e\u65f6\u6f14\u5316\u7684\u534f\u8c03\u5bf9\u6297\u653e\u5927\u3002", "method": "\u6846\u67b6\u5c06\u6cbb\u7406\u6846\u5b9a\u4e3a\u52a8\u6001\u793e\u4f1a\u6e38\u620f\uff0c\u534f\u8c03\u89d2\u8272\u5982\u76d1\u63a7\u3001\u89c4\u5212\u3001\u4e8b\u5b9e\u751f\u6210\u548c\u591a\u8eab\u4efd\u6269\u6563\uff1b\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u96c6\u4f53\u8ba4\u77e5\u6838\u5fc3\u8fdb\u884c\u4e8b\u5b9e\u951a\u5b9a\u548c\u5b9e\u8df5\u5b66\u4e60\uff0c\u95ed\u73af\u8fdb\u5316\u81ea\u9002\u5e94\u7b56\u7565\u3002", "result": "\u5728MOSAIC\u5e73\u53f0\u6a21\u62df\u5bf9\u6297\u65b0\u95fb\u6d41\u4e2d\uff0cEvoCorps\u663e\u8457\u63d0\u5347\u60c5\u611f\u6781\u5316\u3001\u89c2\u70b9\u6781\u7aef\u6027\u548c\u8bba\u8bc1\u7406\u6027\u6307\u6807\uff0c\u4f18\u4e8e\u5bf9\u6297\u57fa\u7ebf\u3002", "conclusion": "\u8bc1\u5b9e\u4ece\u4e1a\u540e\u68c0\u6d4b\u8f6c\u5411\u95ed\u73af\u5e72\u9884\u7684\u5b9e\u7528\u8def\u5f84\uff0c\u4ee3\u7801\u5f00\u6e90\u63d0\u4f9b\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2602.08323", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.08323", "abs": "https://arxiv.org/abs/2602.08323", "authors": ["Yousuf Choudhary", "Tosiron Adegbija"], "title": "Antiferromagnetic Tunnel Junctions (AFMTJs) for In-Memory Computing: Modeling and Case Study", "comment": "Design, Automation and Test in Europe (DATE) 2026", "summary": "Antiferromagnetic Tunnel Junctions (AFMTJs) enable picosecond switching and femtojoule writes through ultrafast sublattice dynamics. We present the first end-to-end AFMTJ simulation framework integrating multi-sublattice Landau-Lifshitz-Gilbert (LLG) dynamics with circuit-level modeling. SPICE-based simulations show that AFMTJs achieve ~8x lower write latency and ~9x lower write energy than conventional MTJs. When integrated into an in-memory computing architecture, AFMTJs deliver 17.5x average speedup and nearly 20x energy savings versus a CPU baseline-significantly outperforming MTJ-based IMC. These results establish AFMTJs as a compelling primitive for scalable, low-power computing.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u53cd\u94c1\u78c1\u96a7\u9053\u7ed3\u53ef\u5b9e\u73b0\u76ae\u79d2\u7ea7\u5f00\u5173\u548c\u98de\u7126\u8033\u7ea7\u5199\u5165\u80fd\u8017\uff0c\u521b\u65b0\u6027\u7aef\u5230\u7aef\u4eff\u771f\u6846\u67b6\u6a21\u62df\u591a\u4e9a\u6676\u683c\u52a8\u529b\u5b66\uff0c\u6027\u80fd\u8fdc\u8d85\u4f20\u7edfMTJ\u548cCPU\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edf\u78c1\u6027\u96a7\u9053\u7ed3\uff08MTJ\uff09\u5b58\u5728\u901f\u5ea6\u548c\u80fd\u8017\u9650\u5236\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u65b0\u578b\u8d85\u4f4e\u529f\u8017\u5b58\u50a8\u5668\u6280\u672f\u4ee5\u6ee1\u8db3\u9ad8\u6027\u80fd\u8ba1\u7b97\u9700\u6c42\u3002", "method": "\u6784\u5efa\u9996\u4e2a\u96c6\u6210\u591a\u0440\u0438\u0458\u0435\u043b\u0443\u09b2\u0cbf\u0c97\u0cb3 Landau-Lifshitz-G\u6740\u5bb3\u52a8\u529b\u5b66\u4e0e\u7535\u8def\u7ea7\u6a21\u578b\u7684\u7aef\u5230\u7aef\u4eff\u771f\u6846\u67b6\uff0c\u91c7\u7528SPICE\u8fdb\u884c\u6027\u80fd\u6a21\u62df\u3002", "result": "AFMTJ\u6bd4\u4f20\u7edfMTJ\u5199\u5165\u5ef6\u8fdf\u964d\u4f4e8\u500d\u3001\u80fd\u8017\u964d\u4f4e9\u500d\uff1b\u5728\u5b58\u5185\u8ba1\u7b97\u4e2d\u76f8\u6bd4CPU\u5b9e\u73b017.5\u500d\u901f\u5ea6\u63d0\u5347\u548c\u8fd120\u500d\u80fd\u8017\u8282\u7701\uff0c\u663e\u8457\u4f18\u4e8eMTJ\u65b9\u6848\u3002", "conclusion": "AFMTJ\u88ab\u9a8c\u8bc1\u4e3a\u5177\u5907\u9ad8\u5ea6\u53ef\u6269\u5c55\u6027\u4e0e\u8d85\u4f4e\u80fd\u8017\u7684\u8ba1\u7b97\u57fa\u5143\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u5b58\u50a8\u6280\u672f\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2602.07396", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2602.07396", "abs": "https://arxiv.org/abs/2602.07396", "authors": ["Junjie Wu", "Tianrui Li", "Yi Zhang", "Ziyuan Yang"], "title": "Mirage: Transmitting a Video as a Perceptual Illusion for 50,000X Speedup", "comment": "14 pages", "summary": "The existing communication framework mainly aims at accurate reconstruction of source signals to ensure reliable transmission. However, this signal-level fidelity-oriented design often incurs high communication overhead and system complexity, particularly in video communication scenarios where mainstream frameworks rely on transmitting visual data itself, resulting in significant bandwidth consumption. To address this issue, we propose a visual data-free communication framework, Mirage, for extremely efficient video transmission while preserving semantic information. Mirage decomposes video content into two complementary components: temporal sequence information capturing motion dynamics and spatial appearance representations describing overall visual structure. Temporal information is preserved through video captioning, while key frames are encoded into compact semantic representations for spatial appearance. These representations are transmitted to the receiver, where videos are synthesized using generative video models. Since no raw visual data is transmitted, Mirage is inherently privacy-preserving. Mirage also supports personalized adaptation across deployment scenarios. The sender, network, and receiver can independently impose constraints on semantic representation, transmission, and generation, enabling flexible trade-offs between efficiency, privacy, control, and perceptual quality. Experimental results in video transmission demonstrate that Mirage achieves up to a 50000X data-level compression speedup over raw video transmission, with gains expected to scale with larger video content sizes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u89c6\u89c9\u6570\u636e\u7684\u901a\u4fe1\u6846\u67b6Mirage\uff0c\u7528\u4e8e\u9ad8\u6548\u89c6\u9891\u4f20\u8f93\uff0c\u901a\u8fc7\u8bed\u4e49\u8868\u793a\u66ff\u4ee3\u539f\u59cb\u6570\u636e\uff0c\u663e\u8457\u964d\u4f4e\u5e26\u5bbd\u6d88\u8017\u5e76\u4fdd\u62a4\u9690\u79c1\u3002", "motivation": "\u73b0\u6709\u6846\u67b6\u6ce8\u91cd\u4fe1\u53f7\u7ea7\u4fdd\u771f\u5ea6\u91cd\u6784\uff0c\u5bfc\u81f4\u9ad8\u901a\u4fe1\u5f00\u9500\u548c\u7cfb\u7edf\u590d\u6742\u6027\uff0c\u5c24\u5176\u5728\u89c6\u9891\u4f20\u8f93\u4e2d\u9020\u6210\u5de8\u5927\u5e26\u5bbd\u6d88\u8017\u3002", "method": "Mirage\u5c06\u89c6\u9891\u5206\u89e3\u4e3a\u65f6\u95f4\u5e8f\u5217\u4fe1\u606f\uff08\u6355\u6349\u52a8\u4f5c\u52a8\u6001\uff09\u548c\u7a7a\u95f4\u5916\u8c8c\u8868\u793a\uff08\u63cf\u8ff0\u89c6\u89c9\u7ed3\u6784\uff09\uff0c\u524d\u8005\u901a\u8fc7\u89c6\u9891\u63cf\u8ff0\u751f\u6210\u4fdd\u7559\uff0c\u540e\u8005\u7f16\u7801\u4e3a\u7d27\u51d1\u8bed\u4e49\u8868\u793a\uff1b\u4f20\u8f93\u8fd9\u4e9b\u8868\u793a\u540e\uff0c\u63a5\u6536\u7aef\u7528\u751f\u6210\u6a21\u578b\u5408\u6210\u89c6\u9891\uff0c\u5e76\u652f\u6301\u4e2a\u6027\u5316\u7ea6\u675f\u4ee5\u5b9e\u73b0\u7075\u6d3b\u6743\u8861\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cMirage\u76f8\u6bd4\u539f\u59cb\u89c6\u9891\u4f20\u8f93\u5b9e\u73b0\u9ad8\u8fbe50000\u500d\u6570\u636e\u7ea7\u538b\u7f29\u52a0\u901f\uff0c\u4e14\u89c4\u6a21\u8d8a\u5927\u589e\u76ca\u8d8a\u663e\u8457\u3002", "conclusion": "\u8fd9\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u4e14\u7075\u6d3b\u7684\u6846\u67b6\uff0c\u5141\u8bb8\u5728\u6548\u7387\u3001\u9690\u79c1\u3001\u63a7\u5236\u4e0e\u611f\u77e5\u8d28\u91cf\u95f4\u5e73\u8861\u3002"}}
{"id": "2602.08199", "categories": ["cs.OS", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.08199", "abs": "https://arxiv.org/abs/2602.08199", "authors": ["Cong Wang", "Yusheng Zheng"], "title": "Fork, Explore, Commit: OS Primitives for Agentic Exploration", "comment": null, "summary": "AI agents increasingly perform agentic exploration: pursuing multiple solution paths in parallel and committing only the successful one. Because each exploration path may modify files and spawn processes, agents require isolated environments with atomic commit and rollback semantics for both filesystem state and process state. We introduce the branch context, a new OS abstraction that provides: (1) copy-on-write state isolation with independent filesystem views and process groups, (2) a structured lifecycle of fork, explore, and commit/abort, (3) first-commit-wins resolution that automatically invalidates sibling branches, and (4) nestable contexts for hierarchical exploration. We realize branch contexts in Linux through two complementary components. First, BranchFS is a FUSE-based filesystem that gives each branch context an isolated copy-on-write workspace, with O(1) creation, atomic commit to the parent, and automatic sibling invalidation, all without root privileges. BranchFS is open sourced in https://github.com/multikernel/branchfs. Second, branch() is a proposed Linux syscall that spawns processes into branch contexts with reliable termination, kernel-enforced sibling isolation, and first-commit-wins coordination. Preliminary evaluation of BranchFS shows sub-350 us branch creation independent of base filesystem size, and modification-proportional commit overhead (under 1 ms for small changes).", "AI": {"motivation": "To provide isolated environments for AI agents' parallel explorations with atomic commit/rollback semantics.", "method": "Introduced branch contexts via BranchFS (FUSE-based filesystem for CoW isolation) and a proposed branch() syscall for process management.", "result": "BranchFS achieves <350 \u03bcs branch creation and <1 ms commit overhead for small modifications.", "conclusion": "Branch contexts enable reliable, efficient hierarchical agentic exploration while ensuring state consistency.", "tldr": "Summary generation failed"}}
{"id": "2602.08842", "categories": ["cs.AR", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.08842", "abs": "https://arxiv.org/abs/2602.08842", "authors": ["Jean-Pierre Busch", "Lukas Ostendorf", "Guido Linden", "Lennart Reiher", "Till Beemelmanns", "Bastian Lampe", "Timo Woopen", "Lutz Eckstein"], "title": "karl. -- A Research Vehicle for Automated and Connected Driving", "comment": "8 pages; Accepted to be published as part of the 37th Intelligent Vehicles Symposium (IV), Detroit, MI, United States, June 22-25, 2026", "summary": "As highly automated driving is transitioning from single-vehicle closed-access testing to commercial deployments of public ride-hailing in selected areas (e.g., Waymo), automated driving and connected cooperative intelligent transport systems (C-ITS) remain active fields of research. Even though simulation is omnipresent in the development and validation life cycle of automated and connected driving technology, the complex nature of public road traffic and software that masters it still requires real-world integration and testing with actual vehicles. Dedicated vehicles for research and development allow testing and validation of software and hardware components under real-world conditions early on. They also enable collecting and publishing real-world datasets that let others conduct research without vehicle access, and support early demonstration of futuristic use cases. In this paper, we present karl., our new research vehicle for automated and connected driving. Apart from major corporations, few institutions worldwide have access to their own L4-capable research vehicles, restricting their ability to carry out independent research. This paper aims to help bridge that gap by sharing the reasoning, design choices, and technical details that went into making karl. a flexible and powerful platform for research, engineering, and validation in the context of automated and connected driving. More impressions of karl. are available at https://karl.ac.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u540d\u4e3akarl\u7684\u65b0\u578b\u7814\u7a76\u8f66\u8f86\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u9a7e\u9a76\u548c\u8f66\u8054\u7f51\u6d4b\u8bd5\uff0c\u5f25\u8865\u673a\u6784\u7f3a\u4e4f\u81ea\u4e3bL4\u7ea7\u8f66\u8f86\u7684\u5dee\u8ddd\uff0c\u652f\u6301\u5171\u4eab\u6570\u636e\u96c6\u548c\u771f\u5b9e\u573a\u666f\u9a8c\u8bc1\u3002", "motivation": "\u89e3\u51b3\u5168\u7403\u673a\u6784\u56e0\u7f3a\u4e4f\u81ea\u5efaL4\u7ea7\u81ea\u52a8\u9a7e\u9a76\u7814\u7a76\u8f66\u8f86\u800c\u65e0\u6cd5\u5f00\u5c55\u72ec\u7acb\u7814\u7a76\u7684\u9650\u5236\uff0c\u4fc3\u8fdb\u534f\u4f5c\u4e0e\u7814\u7a76\u6c11\u4e3b\u5316\u3002", "method": "\u8bbe\u8ba1\u548c\u5f00\u53d1\u4e86karl\u7814\u7a76\u8f66\u8f86\uff0c\u8be6\u8ff0\u4e86\u63a8\u7406\u8fc7\u7a0b\u3001\u8bbe\u8ba1\u9009\u62e9\u548c\u6280\u672f\u7ec6\u8282\uff0c\u4f7f\u5176\u6210\u4e3a\u7075\u6d3b\u5e73\u53f0\u7528\u4e8e\u5de5\u7a0b\u9a8c\u8bc1\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u7075\u6d3b\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7814\u7a76\u7684\u8f66\u8f86\u5e73\u53f0\uff0c\u5e2e\u52a9\u6536\u96c6\u548c\u5171\u4eab\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u652f\u6301\u672a\u6765\u573a\u666f\u5c55\u793a\u3002", "conclusion": "\u8be5\u8f66\u8f86\u5e73\u53f0\u53ef\u63d0\u5347\u81ea\u52a8\u5316\u9a7e\u9a76\u7814\u7a76\u53ef\u53ca\u6027\uff0c\u4e3a\u7f3a\u5931\u8d44\u6e90\u7684\u673a\u6784\u63d0\u4f9b\u64cd\u4f5c\u6a21\u677f\uff0c\u63a8\u52a8\u6280\u672f\u53d1\u5c55\u548c\u793e\u533a\u534f\u4f5c\u3002"}}
{"id": "2602.07079", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07079", "abs": "https://arxiv.org/abs/2602.07079", "authors": ["Go Frendi Gunawan", "Mukhlis Amien"], "title": "Comprehensive Evaluation of Large Language Models on Software Engineering Tasks: A Multi-Task Benchmark", "comment": "10 pages, 7 figures. Under review. Code and data will be fully released", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in software engineering, yet comprehensive benchmarks covering diverse SE activities remain limited. We present a multi-task evaluation of 11 state-of-the-art LLMs across five representative software engineering tasks: bug fixing, feature development, code refactoring, technical copywriting, and research synthesis. Our automated verification framework measures both output quality and completion efficiency. Key findings reveal that (1) models achieving identical perfect scores exhibit 22x variation in completion time, 49x variation in tool efficiency, and 53x variation in estimated cost; (2) tool usage frequency shows no correlation with success (r = 0.077, p = 0.575) - one model used 917 tool calls while another solved the same task with 3 calls; (3) we identify two distinct inefficiency patterns: loop inefficiency and inference inefficiency; and (4) coding tasks achieve 100 percent success while research tasks present greater challenges (90.9 percent). We release all experimental data, verification scripts, and analysis code for full reproducibility.", "AI": {"tldr": "\u8bc4\u4f3011\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6f0f\u6d1e\u4fee\u590d\u3001\u7279\u6027\u5f00\u53d1\u7b49\u4e94\u9879\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u6548\u7387\u6210\u672c\u663e\u8457\u5dee\u5f02\u3001\u5de5\u5177\u4f7f\u7528\u4e0e\u6210\u529f\u65e0\u5173\u7b49\u5173\u952e\u53d1\u73b0\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7f3a\u4e4f\u5168\u9762\u8986\u76d6\u591a\u6837\u8f6f\u4ef6\u6d3b\u52a8\u57fa\u51c6\u6d4b\u8bd5\u7684\u73b0\u51b5\u63a8\u52a8\u4e86\u672c\u7814\u7a76\u3002", "method": "\u91c7\u7528\u81ea\u52a8\u5316\u9a8c\u8bc1\u6846\u67b6\u5bf911\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\u6267\u884c\u4e94\u9879\u4efb\u52a1\u8bc4\u4f30\uff0c\u6d4b\u91cf\u8f93\u51fa\u8d28\u91cf\u548c\u5b8c\u6210\u6548\u7387\u6548\u7387\u3002 progressed practical deployment.", "result": "\u6a21\u578b\u5f97\u5206\u76f8\u540c\u65f6\u53d1\u73b0\u5b8c\u6210\u65f6\u95f4\u5dee22\u500d\u3001\u5de5\u5177\u6548\u7387\u5dee49\u500d\u3001\u6210\u672c\u5dee53\u500d\uff1b\u5de5\u5177\u4f7f\u7528\u9891\u7387\u4e0e\u6210\u529f\u65e0\u5173\u8054\uff08r=0.077, p=0.575\uff09\uff1b\u8bc6\u522b\u51fa\u5faa\u73af\u4f4e\u6548\u548c\u63a8\u4f4e\u6548\u4e24\u79cd\u6a21\u5f0f\uff1b\u7f16\u7801\u4efb\u52a1\u6210\u529f\u7387100%\uff0c\u7814\u7a76\u4efb\u52a190.9%\u3002", "conclusion": "\u516c\u5e03\u6240\u6709\u6570\u636e\u4e0e\u4ee3\u7801\u652f\u6301\u53ef\u91cd\u590d\u6027\uff0c\u5f3a\u8c03\u6548\u7387\u6a21\u5f0f\u5206\u6790\u5bf9\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8f6f\u4ef6\u5de5\u7a0b\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.08800", "categories": ["cs.OS", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.08800", "abs": "https://arxiv.org/abs/2602.08800", "authors": ["Kaiyang Zhao", "Neha Gholkar", "Hasan Maruf", "Abhishek Dhanotia", "Johannes Weiner", "Gregory Price", "Ning Sun", "Bhavya Dwivedi", "Stuart Clark", "Dimitrios Skarlatos"], "title": "Equilibria: Fair Multi-Tenant CXL Memory Tiering At Scale", "comment": null, "summary": "Memory dominates datacenter system cost and power. Memory expansion via Compute Express Link (CXL) is an effective way to provide additional memory at lower cost and power, but its effective use requires software-level tiering for hyperscaler workloads. Existing tiering solutions, including current Linux support, face fundamental limitations in production deployments. First, they lack multi-tenancy support, failing to handle stacked homogeneous or heterogeneous workloads. Second, limited control-plane flexibility leads to fairness violations and performance variability. Finally, insufficient observability prevents operators from diagnosing performance pathologies at scale.\n  We present Equilibria, an OS framework enabling fair, multi-tenant CXL tiering at datacenter scale. Equilibria provides per-container controls for memory fair-share allocation and fine-grained observability of tiered-memory usage and operations. It further enforces flexible, user-specified fairness policies through regulated promotion and demotion, and mitigates noisy-neighbor interference by suppressing thrashing.\n  Evaluated in a large hyperscaler fleet using production workloads and benchmarks, Equilibria helps workloads meet service level objectives (SLOs) while avoiding performance interference. It improves performance over the state-of-the-art Linux solution, TPP, by up to 52% for production workloads and 1.7x for benchmarks. All Equilibria patches have been released to the Linux community.", "AI": {"tldr": "Equilibria\u662f\u4e00\u4e2a\u64cd\u4f5c\u7cfb\u7edf\u6846\u67b6\uff0c\u89e3\u51b3CXL\u5185\u5b58\u6269\u5c55\u4e2d\u7684\u8f6f\u4ef6\u5c42\u7ea7\u5316\u95ee\u9898\uff0c\u5728\u591a\u79df\u6237\u6570\u636e\u4e2d\u5fc3\u63d0\u4f9b\u516c\u5e73\u5185\u5b58\u5206\u914d\u548c\u9ad8\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5185\u5b58\u5c42\u7ea7\u5316\u65b9\u6848\uff08\u5982Linux TPP\uff09\u5728\u591a\u79df\u6237\u652f\u6301\u3001\u516c\u5e73\u63a7\u5236\u548c\u53ef\u89c2\u6d4b\u6027\u4e0a\u4e0d\u8db3\uff0c\u5bfc\u81f4\u6027\u80fd\u6ce2\u52a8\u548c\u5e72\u6270\u8bca\u65ad\u56f0\u96be\u3002", "method": "\u901a\u8fc7\u9010\u5bb9\u5668\u63a7\u5236\u5185\u5b58\u516c\u5e73\u5171\u4eab\u3001\u53ef\u89c2\u6d4b\u6027\u589e\u5f3a\u3001\u7528\u6237\u5b9a\u4e49\u516c\u5e73\u653f\u7b56\uff08\u89c4\u8303\u5347\u7ea7\u964d\u7ea7\uff09\u548c\u6291\u5236\u5de5\u4f5c\u632f\u8361\u566a\u97f3\uff08\u51cf\u5c11\u5e72\u6270\uff09\u6765\u5b9e\u73b0\u4f18\u5316\u3002mundhir", "result": "\u5728\u751f\u4ea7\u8d1f\u8f7d\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cEquilibria\u8f83\u5f53\u524dLinux\u65b9\u6848TPP\u6027\u80fd\u63d0\u5347\u8fbe52%\u548c1.7\u500d\uff0c\u6709\u6548\u6ee1\u8db3\u670d\u52a1\u6c34\u5e73\u76ee\u6807\u4e14\u65e0\u5e72\u6270\u3002\u6240\u6709\u8865\u4e01\u5df2\u5f00\u6e90\u8d21\u732e\u81f3Linux\u793e\u533a\u3002", "conclusion": "Equilibria\u89e3\u51b3\u4e86\u5185\u5b58\u5c42\u7ea7\u5316\u6838\u5fc3\u7f3a\u9677\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u4e2d\u5fc3\u7684\u53ef\u6269\u5c55\u6027\u3001\u516c\u5e73\u6027\u548c\u4ea4\u4e92\u6027\u6027\u80fd\u3002"}}
{"id": "2602.07850", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.07850", "abs": "https://arxiv.org/abs/2602.07850", "authors": ["Shanuja Sasi"], "title": "Privacy-Preserving Coding Schemes for Multi-Access Distributed Computing Models", "comment": null, "summary": "Distributed computing frameworks such as MapReduce have become essential for large-scale data processing by decomposing tasks across multiple nodes. The multi-access distributed computing (MADC) model further advances this paradigm by decoupling mapper and reducer roles: dedicated mapper nodes store data and compute intermediate values, while reducer nodes are connected to multiple mappers and aggregate results to compute final outputs. This separation reduces communication bottlenecks without requiring file replication. In this paper, we introduce privacy constraints into MADC and develop private coded schemes for two specific connectivity models. We construct new families of extended placement delivery arrays and derive corresponding coding schemes that guarantee privacy of each reducer's assigned function.", "AI": {"tldr": "\u672c\u6587\u5728\u5206\u5e03\u5f0f\u8ba1\u7b97\u6846\u67b6MADC\u4e2d\u5f15\u5165\u9690\u79c1\u7ea6\u675f\uff0c\u4e3a\u4e24\u79cd\u8fde\u63a5\u6a21\u578b\u5f00\u53d1\u79c1\u6709\u7f16\u7801\u65b9\u6848\uff0c\u786e\u4fdd\u51cf\u901f\u5668\u51fd\u6570\u9690\u79c1\u3002", "motivation": "\u52a8\u673a\u662f\u4fdd\u62a4\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u51cf\u901f\u5668\u529f\u80fd\u7684\u673a\u5bc6\u6027\uff0c\u907f\u514d\u51fd\u6570\u6cc4\u9732\u98ce\u9669\uff0c\u540c\u65f6\u51cf\u5c11\u901a\u4fe1\u74f6\u9888\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u6784\u5efa\u65b0\u578b\u6269\u5c55\u653e\u7f6e\u4ea4\u4ed8\u9635\u5217\u5bb6\u65cf\uff0c\u5e76\u63a8\u5bfc\u9690\u79c1\u4fdd\u8bc1\u7684\u7f16\u7801\u65b9\u6848\u3002", "result": "\u5b9e\u73b0\u4e86\u51cf\u901f\u5668\u51fd\u6570\u5728\u7279\u5b9a\u6a21\u578b\u4e0b\u7684\u9690\u79c1\u4fdd\u969c\uff0c\u63d0\u4f9b\u9ad8\u6548\u8ba1\u7b97\u3002", "conclusion": "\u7ed3\u8bba\u662f\u79c1\u6709\u7f16\u7801\u65b9\u6848\u6210\u529f\u63d0\u5347MADC\u7684\u9690\u79c1\u5b89\u5168\u6027\u3002"}}
{"id": "2602.08938", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08938", "abs": "https://arxiv.org/abs/2602.08938", "authors": ["Tuo Zhang", "Leonardo Stella"], "title": "Teaching an Old Dynamics New Tricks: Regularization-free Last-iterate Convergence in Zero-sum Games via BNN Dynamics", "comment": null, "summary": "Zero-sum games are a fundamental setting for adversarial training and decision-making in multi-agent learning (MAL). Existing methods often ensure convergence to (approximate) Nash equilibria by introducing a form of regularization. Yet, regularization requires additional hyperparameters, which must be carefully tuned--a challenging task when the payoff structure is known, and considerably harder when the structure is unknown or subject to change. Motivated by this problem, we repurpose a classical model in evolutionary game theory, i.e., the Brown-von Neumann-Nash (BNN) dynamics, by leveraging the intrinsic convergence of this dynamics in zero-sum games without regularization, and provide last-iterate convergence guarantees in noisy normal-form games (NFGs). Importantly, to make this approach more applicable, we develop a novel framework with theoretical guarantees that integrates the BNN dynamics in extensive-form games (EFGs) through counterfactual weighting. Furthermore, we implement an algorithm that instantiates our framework with neural function approximation, enabling scalable learning in both NFGs and EFGs. Empirical results show that our method quickly adapts to nonstationarities, outperforming the state-of-the-art regularization-based approach.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.07080", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07080", "abs": "https://arxiv.org/abs/2602.07080", "authors": ["Yicheng He", "Zheng Zhao", "Zhou Kaiyu", "Bryan Dai", "Jie Fu", "Yonghui Yang"], "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs", "comment": null, "summary": "Current paradigms for code verification rely heavily on external mechanisms-such as execution-based unit tests or auxiliary LLM judges-which are often labor-intensive or limited by the judging model's own capabilities. This raises a fundamental, yet unexplored question: Can an LLM's functional correctness be assessed purely from its internal computational structure? Our primary objective is to investigate whether the model's neural dynamics encode internally decodable signals that are predictive of logical validity during code generation. Inspired by mechanistic interpretability, we propose to treat code verification as a mechanistic diagnostic task, mapping the model's explicit algorithmic trajectory into line-level attribution graphs. By decomposing complex residual flows, we aim to identify the structural signatures that distinguish sound reasoning from logical failure within the model's internal circuits. Analysis across Python, C++, and Java confirms that intrinsic correctness signals are robust across diverse syntaxes. Topological features from these internal graphs predict correctness more reliably than surface heuristics and enable targeted causal interventions to fix erroneous logic. These findings establish internal introspection as a decodable property for verifying generated code. Our code is at https:// github.com/bruno686/CodeCircuit.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.08257", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.08257", "abs": "https://arxiv.org/abs/2602.08257", "authors": ["Antonis Psistakis", "Burak Ocalan", "Fabien Chaix", "Ramnatthan Alagappan", "Josep Torrellas"], "title": "HEAL: Online Incremental Recovery for Leaderless Distributed Systems Across Persistency Models", "comment": null, "summary": "Ensuring resilience in distributed systems has become an acute concern. In today's environment, it is crucial to develop light-weight mechanisms that recover a distributed system from faults quickly and with only a small impact on the live-system throughput. To address this need, this paper proposes a new low-overhead, general recovery scheme for modern non-transactional leaderless distributed systems. We call our scheme HEAL. On a node failure, HEAL performs an optimized online incremental recovery. This paper presents HEAL's algorithms for settings with Linearizable consistency and different memory persistency models. We implement HEAL on a 6-node Intel cluster. Our experiments running TAOBench workloads show that HEAL is very effective. HEAL recovers the cluster in 120 milliseconds on average, while reducing the throughput of the running workload by an average of 8.7%. In contrast, a conventional recovery scheme for leaderless systems needs 360 seconds to recover, reducing the throughput of the system by 16.2%. Finally, compared to an incremental recovery scheme for a state-of-the-art leader-based system, HEAL reduces the average recovery latency by 20.7x and the throughput degradation by 62.4%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a HEAL \u7684\u9ad8\u6548\u4f4e\u5f00\u9500\u6062\u590d\u673a\u5236\uff0c\u7528\u4e8e\u73b0\u4ee3\u65e0\u9886\u5bfc\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u4ee5\u4f18\u5316\u6545\u969c\u65f6\u7684\u5728\u7ebf\u589e\u91cf\u6062\u590d\u3002", "motivation": "\u4e3a\u5e94\u5bf9\u5206\u5e03\u5f0f\u7cfb\u7edf\u5728\u6545\u969c\u65f6\u9700\u5b9e\u73b0\u5feb\u901f\u6062\u590d\u5e76\u6700\u5c0f\u5316\u541e\u5410\u91cf\u5f71\u54cd\u7684\u9700\u6c42\uff0c\u5c24\u5176\u662f\u5728\u73b0\u4ee3\u73af\u5883\u4e2d\u786e\u4fdd\u97e7\u6027\u5c24\u4e3a\u91cd\u8981\u3002", "method": "\u63d0\u51fa HEAL \u65b9\u6848\uff0c\u5305\u62ec\u9488\u5bf9\u7ebf\u6027\u4e00\u81f4\u6027\u548c\u591a\u79cd\u5185\u5b58\u6301\u4e45\u6027\u6a21\u578b\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u5728\u7ebf\u589e\u91cf\u6062\u590d\u6765\u5904\u7406\u8282\u70b9\u6545\u969c\u3002", "_ONEOF": "\u8bf4\u660e\u8be5\u65b9\u6cd5\u91c7\u7528\u4e86\u7279\u5b9a\u7b97\u6cd5\u5e76\u901a\u8fc7\u96c6\u7fa4\u5b9e\u65bd\u3002", "result": "\u5b9e\u9a8c\u57fa\u4e8e6\u8282\u70b9Intel\u96c6\u7fa4\u8fd0\u884cTAOBench\u5de5\u4f5c\u8d1f\u8f7d\uff1aHEAL\u5e73\u5747\u6062\u590d\u65f6\u95f4\u4e3a120\u6beb\u79d2\uff0c\u541e\u5410\u91cf\u4e0b\u964d\u4ec58.7%\uff0c\u901f\u5ea6\u6bd4\u4f20\u7edf\u65b9\u6848\u5feb\uff08360\u79d2\u6062\u590d/16.2%\u4e0b\u964d\uff09\uff0c\u4e14\u5ef6\u8fdf\u51cf\u5c1120.7\u500d\uff0c\u541e\u5410\u52a3\u5316\u964d\u4f4e62.4%\u3002", "conclusion": "HEAL\u9a8c\u8bc1\u4e3a\u975e\u5e38\u6709\u6548\uff0c\u663e\u8457\u63d0\u5347\u6062\u590d\u6548\u7387\u548c\u7cfb\u7edf\u97e7\u6027\u3002\u5728\u5206\u5e03\u5f0f weak-consistency-like \u7cfb\u7edf\u4e2d\u5e94\u7528\u6f5c\u529b\u5927"}}
{"id": "2602.08965", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08965", "abs": "https://arxiv.org/abs/2602.08965", "authors": ["John Gardiner", "Orlando Romero", "Brendan Tivnan", "Nicol\u00f2 Dal Fabbro", "George J. Pappas"], "title": "Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning", "comment": null, "summary": "The inability to communicate poses a major challenge to coordination in multi-agent reinforcement learning (MARL). Prior work has explored correlating local policies via shared randomness, sometimes in the form of a correlation device, as a mechanism to assist in decentralized decision-making. In contrast, this work introduces the first framework for training MARL agents to exploit shared quantum entanglement as a coordination resource, which permits a larger class of communication-free correlated policies than shared randomness alone. This is motivated by well-known results in quantum physics which posit that, for certain single-round cooperative games with no communication, shared quantum entanglement enables strategies that outperform those that only use shared randomness. In such cases, we say that there is quantum advantage. Our framework is based on a novel differentiable policy parameterization that enables optimization over quantum measurements, together with a novel policy architecture that decomposes joint policies into a quantum coordinator and decentralized local actors. To illustrate the effectiveness of our proposed method, we first show that we can learn, purely from experience, strategies that attain quantum advantage in single-round games that are treated as black box oracles. We then demonstrate how our machinery can learn policies with quantum advantage in an illustrative multi-agent sequential decision-making problem formulated as a decentralized partially observable Markov decision process (Dec-POMDP).", "AI": {"tldr": "\u9996\u6b21\u63d0\u51fa\u5229\u7528\u5171\u4eab\u91cf\u5b50\u7ea0\u7f20\u7684MARL\u6846\u67b6\uff0c\u7a81\u7834\u7ecf\u5178\u5171\u4eab\u968f\u673a\u6027\u7684\u534f\u8c03\u5c40\u9650\uff0c\u5b9e\u73b0\u65e0\u901a\u4fe1\u4e0b\u7684\u91cf\u5b50\u4f18\u52bf\u534f\u4f5c\u7b56\u7565\u3002", "motivation": "\u91cf\u5b50\u7269\u7406\u7814\u7a76\u8868\u660e\u7ea0\u7f20\u80fd\u5728\u65e0\u901a\u4fe1\u534f\u4f5c\u4efb\u52a1\u4e2d\u8d85\u8d8a\u7ecf\u5178\u968f\u673a\u6027\uff0c\u4e3aMARL\u534f\u8c03\u96be\u9898\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u8bbe\u8ba1\u53ef\u5fae\u5206\u7b56\u7565\u53c2\u6570\u5316\u4f18\u5316\u91cf\u5b50\u6d4b\u91cf\uff0c\u91c7\u7528\u91cf\u5b50\u534f\u8c03\u5668+\u5206\u6563\u6267\u884c\u8005\u7684\u67b6\u6784\u5206\u89e3\u8054\u5408\u7b56\u7565\u3002", "result": "\u5728\u5355\u8f6e\u9ed1\u76d2\u6e38\u620f\u4e0e\u5e8f\u5217\u5316Dec-POMDP\u4e2d\u9a8c\u8bc1\uff1a\u7eaf\u7ecf\u9a8c\u5b66\u4e60\u80fd\u5b9e\u73b0\u8d85\u8d8a\u7ecf\u5178\u65b9\u6cd5\u7684\u91cf\u5b50\u4f18\u52bf\u7b56\u7565\u3002", "conclusion": "\u8be5\u6846\u67b6\u6269\u5c55\u4e86\u65e0\u901a\u4fe1\u534f\u8c03\u7b56\u7565\u7684\u8fb9\u754c\uff0c\u4e3a\u590d\u6742MARL\u95ee\u9898\u5f00\u8f9f\u91cf\u5b50\u589e\u5f3a\u65b0\u8def\u5f84\u3002"}}
{"id": "2602.07083", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07083", "abs": "https://arxiv.org/abs/2602.07083", "authors": ["Yongqing Jiang", "Jianze Wang", "Zhiqi Shen", "Zhenghong Lin", "Jiayuan Wang", "Yijian Yang", "Kaoshan Dai", "Haoran Luo"], "title": "Rethinking Scientific Modeling: Toward Physically Consistent and Simulation-Executable Programmatic Generation", "comment": null, "summary": "Structural modeling is a fundamental component of computational engineering science, in which even minor physical inconsistencies or specification violations may invalidate downstream simulations. The potential of large language models (LLMs) for automatic generation of modeling code has been demonstrated. However, non-executable or physically inconsistent outputs remain prevalent under stringent engineering constraints. A framework for physics-consistent automatic building modeling is therefore proposed, integrating domain knowledge construction, constraint-oriented model alignment, and verification-driven evaluation. CivilInstruct is introduced as a domain-specific dataset that formalizes structural engineering knowledge and constraint reasoning to enable simulation-ready model generation. A two-stage fine-tuning strategy is further employed to enforce constraint satisfaction and application programming interface compliance, substantially reducing hallucinated and non-conforming outputs. MBEval is presented as a verification-driven benchmark that evaluates executability and structural dynamics consistency through closed-loop validation. Experimental results show consistent improvements over baselines across rigorous verification metrics. Our code is available at https://github.com/Jovanqing/AutoBM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7269\u7406\u5b66\u4e00\u81f4\u7684\u81ea\u52a8\u5efa\u7b51\u5efa\u6a21\u6846\u67b6\uff0c\u7ed3\u5408 CivilInstruct \u6570\u636e\u96c6\u548c\u4e24\u9636\u6bb5\u5fae\u8c03\u7b56\u7565\uff0c\u6709\u6548\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9 boyut\u8f93\u51fa\uff0c\u5e76\u901a\u8fc7 MBEval \u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u5176\u6027\u80fd\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u7ed3\u6784\u5efa\u6a21\u4e2d\u7684\u5fae\u5c0f\u7269\u7406\u4e0d\u4e00\u81f4\u4f1a\u5f71\u54cd\u4e0b\u6e38\u6a21\u62df\uff1b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e25\u683c\u5de5\u7a0b\u7ea6\u675f\u4e0b\u751f\u6210\u7684\u4ee3\u7801\u5e38\u4e0d\u53ef\u6267\u884c\u6216\u8fdd\u53cd\u7269\u7406\u89c4\u5219\uff0c\u4e9f\u9700\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u9886\u57df\u77e5\u8bc6\u6784\u5efa\uff08\u5982 CivilInstruct \u6570\u636e\u96c6\uff09\u3001\u7ea6\u675f\u5bfc\u5411\u7684\u6a21\u578b\u5bf9\u9f50\u53ca\u9a8c\u8bc1\u9a71\u52a8\u7684\u8bc4\u4f30\uff08MBEval\u57fa\u51c6\uff09\uff0c\u4f7f\u7528\u4e24\u9636\u6bb5\u5fae\u8c03\u7b56\u7565\u5f3a\u5316\u7ea6\u675f\u6ee1\u8db3\u548cAPI\u5408\u89c4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5404\u9879\u4e25\u8c28\u9a8c\u8bc1\u6307\u6807\u4e0a\uff0c\u6846\u67b6\u8f83\u57fa\u7ebf\u6a21\u578b\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u975e\u4e00\u81f4\u8f93\u51fa\u5927\u5e45\u51cf\u5c11\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u7269\u7406\u5b66\u4e00\u81f4\u7684\u6a21\u578b\u751f\u6210\uff0c\u4e3a\u81ea\u52a8\u5efa\u7b51\u5efa\u6a21\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u53ef\u9a8c\u8bc1\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.08271", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.08271", "abs": "https://arxiv.org/abs/2602.08271", "authors": ["Antonis Psistakis", "Burak Ocalan", "Chloe Alverti", "Fabien Chaix", "Ramnatthan Alagappan", "Josep Torrellas"], "title": "Towards CXL Resilience to CPU Failures", "comment": null, "summary": "Compute Express Link (CXL) 3.0 and beyond allows the compute nodes of a cluster to share data with hardware cache coherence and at the granularity of a cache line. This enables shared-memory semantics for distributed computing, but introduces new resilience challenges: a node failure leads to the loss of the dirty data in its caches, corrupting application state. Unfortunately, the CXL specification does not consider processor failures. Moreover, when a component fails, the specification tries to isolate it and continue application execution; there is no attempt to bring the application to a consistent state. To address these limitations, this paper extends the CXL specification to be resilient to node failures, and to correctly recover the application after node failures. We call the system ReCXL. To handle the failure of nodes, ReCXL augments the coherence transaction of a write with messages that propagate the update to a small set of other nodes (i.e., Replicas). Replicas save the update in a hardware Logging Unit. Such replication ensures resilience to node failures. Then, at regular intervals, the Logging Units dump the updates to memory. Recovery involves using the logs in the Logging Units to bring the directory and memory to a correct state. Our evaluation shows that ReCXL enables fault-tolerant execution with only a 30% slowdown over the same platform with no fault-tolerance support.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ReCXL\u7cfb\u7edf\uff0c\u6269\u5c55CXL\u534f\u8bae\u4ee5\u89e3\u51b3\u8282\u70b9\u6545\u969c\u4e0b\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u5f39\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u590d\u5236\u5199\u5165\u548c\u65e5\u5fd7\u8bb0\u5f55\u5b9e\u73b0\u6545\u969c\u6062\u590d\u3002", "motivation": "CXL 3.0\u53ca\u4ee5\u4e0a\u652f\u6301\u57fa\u4e8e\u786c\u4ef6\u7f13\u5b58\u4e00\u81f4\u6027\u7684\u5171\u4eab\u5185\u5b58\uff0c\u4f46\u672a\u5904\u7406\u8282\u70b9\u6545\u969c\uff1b\u6545\u969c\u53ef\u80fd\u5bfc\u81f4\u810f\u6570\u636e\u4e22\u5931\u5e76\u7834\u574f\u5e94\u7528\u72b6\u6001\uff0c\u4e14\u6307\u5b9a\u89c4\u8303\u65e0\u4e00\u81f4\u6027\u6062\u590d\u673a\u5236\u3002", "method": "ReCXL\u5728\u5199\u5165\u4e8b\u52a1\u4e2d\u6dfb\u52a0\u6d88\u606f\uff0c\u5c06\u66f4\u65b0\u590d\u5236\u5230\u526f\u672c\u8282\u70b9\uff0c\u5b58\u50a8\u5728\u786c\u4ef6\u65e5\u5fd7\u5355\u5143\uff1b\u5b9a\u671f\u5c06\u65e5\u5fd7\u8f6c\u50a8\u5230\u5185\u5b58\uff1b\u6062\u590d\u65f6\u5229\u7528\u65e5\u5fd7\u4fee\u590d\u76ee\u5f55\u548c\u5185\u5b58\u72b6\u6001\u3002", "result": "ReCXL\u7cfb\u7edf\u652f\u6301\u6545\u969c\u5bb9\u5fcd\u6267\u884c\uff0c\u4e0e\u65e0\u5bb9\u9519\u5e73\u53f0\u76f8\u6bd4\u6027\u80fd\u4ec5\u4e0b\u964d30%\u3002", "conclusion": "ReCXL\u6709\u6548\u589e\u5f3a\u4e86CXL\u5f39\u6027\uff0c\u4e3a\u5206\u5e03\u5f0f\u8ba1\u7b97\u63d0\u4f9b\u6210\u672c\u6548\u76ca\u9ad8\u7684\u6545\u969c\u6062\u590d\u65b9\u6848\u3002"}}
{"id": "2602.07086", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07086", "abs": "https://arxiv.org/abs/2602.07086", "authors": ["Michael Marketsm\u00fcller", "Simon Martin", "Tim Schlippe"], "title": "Evaluating Retrieval-Augmented Generation Variants for Natural Language-Based SQL and API Call Generation", "comment": "preprint of conference submission", "summary": "Enterprise systems increasingly require natural language interfaces that can translate user requests into structured operations such as SQL queries and REST API calls. While large language models (LLMs) show promise for code generation [Chen et al., 2021; Huynh and Lin, 2025], their effectiveness in domain-specific enterprise contexts remains underexplored, particularly when both retrieval and modification tasks must be handled jointly. This paper presents a comprehensive evaluation of three retrieval-augmented generation (RAG) variants [Lewis et al., 2021] -- standard RAG, Self-RAG [Asai et al., 2024], and CoRAG [Wang et al., 2025] -- across SQL query generation, REST API call generation, and a combined task requiring dynamic task classification. Using SAP Transactional Banking as a realistic enterprise use case, we construct a novel test dataset covering both modalities and evaluate 18 experimental configurations under database-only, API-only, and hybrid documentation contexts. Results demonstrate that RAG is essential: Without retrieval, exact match accuracy is 0% across all tasks, whereas retrieval yields substantial gains in execution accuracy (up to 79.30%) and component match accuracy (up to 78.86%). Critically, CoRAG proves most robust in hybrid documentation settings, achieving statistically significant improvements in the combined task (10.29% exact match vs. 7.45% for standard RAG), driven primarily by superior SQL generation performance (15.32% vs. 11.56%). Our findings establish retrieval-policy design as a key determinant of production-grade natural language interfaces, showing that iterative query decomposition outperforms both top-k retrieval and binary relevance filtering under documentation heterogeneity.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e09\u79cd\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u53d8\u4f53\u5728\u4f01\u4e1a\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u4e2d\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u68c0\u7d22\u5bf9\u63d0\u5347\u51c6\u786e\u7387\u81f3\u5173\u91cd\u8981\uff0cCoRAG\u5728\u6df7\u5408\u6587\u6863\u73af\u5883\u4e0b\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u4f01\u4e1a\u7cfb\u7edf\u9700\u8981\u9ad8\u6548\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u8054\u5408\u5904\u7406\u68c0\u7d22\u548c\u4fee\u6539\u4efb\u52a1\u7684\u6548\u679c\u5c1a\u5f85\u63a2\u7d22\uff0c\u5c24\u5176\u5728\u590d\u6742\u64cd\u4f5c\u573a\u666f\u4e2d\u3002", "method": "\u8bc4\u4f30\u6807\u51c6RAG\u3001Self-RAG\u548cCoRAG\u5728SQL\u67e5\u8be2\u751f\u6210\u3001REST API\u8c03\u7528\u548c\u6df7\u5408\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff1b\u4f7f\u7528SAP Transactional Banking\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5728\u6570\u636e\u5e93\u4ec5\u3001API\u4ec5\u548c\u6df7\u5408\u6587\u6863\u4e0a\u4e0b\u6587\u96c6\u8bd518\u79cd\u914d\u7f6e\u3002", "result": "\u65e0\u68c0\u7d22\u65f6\u51c6\u786e\u7387\u4e3a0%\uff0c\u68c0\u7d22\u4f7f\u6267\u884c\u51c6\u786e\u7387\u63d0\u5347\u8fbe79.30%\uff1bCoRAG\u5728\u6df7\u5408\u6587\u6863\u4e2dSQL\u751f\u6210\u6027\u80fd\u6700\u4f18\uff0815.32%\uff09\uff0c\u6df7\u5408\u4efb\u52a1\u51c6\u786e\u738710.29%\uff0c\u4f18\u4e8e\u6807\u51c6RAG\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u68c0\u7d22\u7b56\u7565\u8bbe\u8ba1\u662f\u5173\u952e\u751f\u4ea7\u56e0\u7d20\uff0c\u5728\u6587\u6863\u5f02\u6784\u73af\u5883\u4e0b\uff0c\u8fed\u4ee3\u67e5\u8be2\u5206\u89e3\u4f18\u4e8eTop-K\u68c0\u7d22\u548c\u4e8c\u8fdb\u5236\u76f8\u5173\u6027\u8fc7\u6ee4\u3002"}}
{"id": "2602.08747", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2602.08747", "abs": "https://arxiv.org/abs/2602.08747", "authors": ["Zhixin Zhao", "Yitao Hu", "Simin Chen", "Mingfang Ji", "Wei Yang", "Yuhao Zhang", "Laiping Zhao", "Wenxin Li", "Xiulong Liu", "Wenyu Qu", "Hao Wang"], "title": "PARD: Enhancing Goodput for Inference Pipeline via Proactive Request Dropping", "comment": "Accepted by EuroSys'26", "summary": "Modern deep neural network (DNN) applications integrate multiple DNN models into inference pipelines with stringent latency requirements for customized tasks. To mitigate extensive request timeouts caused by accumulation, systems for inference pipelines commonly drop a subset of requests so the remaining ones can satisfy latency constraints. Since it is commonly believed that request dropping adversely affects goodput, existing systems only drop requests when they have to, which we call reactive dropping. However, this reactive policy can not maintain high goodput, as it neither makes timely dropping decisions nor identifies the proper set of requests to drop, leading to issues of dropping requests too late or dropping the wrong set of requests.\n  We propose that the inference system should proactively drop certain requests in advance to enhance the goodput across the entire workload. To achieve this, we design an inference system PARD. It enhances goodput with timely and precise dropping decisions by integrating a proactive dropping method that decides when to drop requests using runtime information of the inference pipeline, and an adaptive request priority mechanism that selects which specific requests to drop based on remaining latency budgets and workload intensity. Evaluation on a cluster of 64 GPUs over real-world workloads shows that PARD achieves $16\\%$-$176\\%$ higher goodput than the state of the art while reducing the drop rate and wasted computation resources by $1.6\\times$-$17\\times$ and $1.5\\times$-$62\\times$ respectively.", "AI": {"tldr": "\u63d0\u51fa\u4e3b\u52a8\u8bf7\u6c42\u4e22\u5f03\u7cfb\u7edfPARD\uff0c\u901a\u8fc7\u9884\u5224\u5f0f\u4e22\u5f03\u7b56\u7565\u63d0\u5347DNN\u63a8\u7406\u7ba1\u9053\u541e\u5410\u6548\u80fd", "motivation": "\u73b0\u6709\u88ab\u52a8\u4e22\u5f03\u673a\u5236\u56e0\u5ef6\u8fdf\u51b3\u7b56\u548c\u9519\u8bef\u9009\u62e9\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u8bf7\u6c42\u7d2f\u79ef\uff0c\u635f\u5bb3\u7cfb\u7edf\u6709\u6548\u541e\u5410\u91cf", "method": "\u7ed3\u5408\u8fd0\u884c\u65f6\u4fe1\u606f\u7684\u4e3b\u52a8\u4e22\u5f03\u65f6\u673a\u51b3\u7b56 + \u57fa\u4e8e\u5269\u4f59\u5ef6\u8fdf\u9884\u7b97\u548c\u5de5\u4f5c\u8d1f\u8f7d\u5f3a\u5ea6\u7684\u81ea\u9002\u5e94\u8bf7\u6c42\u4f18\u5148\u7ea7\u9009\u62e9\u673a\u5236", "result": "64 GPU\u96c6\u7fa4\u5b9e\u6d4b\u663e\u793a\uff1a\u6709\u6548\u541e\u5410\u91cf\u63d0\u534716%-176%\uff0c\u4e22\u5305\u7387\u964d\u4f4e1.6-17\u500d\uff0c\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u51cf\u5c111.5-62\u500d", "conclusion": "\u4e3b\u52a8\u4e22\u5f03\u7b56\u7565\u901a\u8fc7\u7cbe\u51c6\u9884\u5224\u663e\u8457\u4f18\u5316\u7cfb\u7edf\u541e\u5410\u6548\u80fd\u4e0e\u8d44\u6e90\u5229\u7528\u7387"}}
{"id": "2602.07947", "categories": ["cs.NI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.07947", "abs": "https://arxiv.org/abs/2602.07947", "authors": ["Kai Tian", "Chuan Lin", "Guangjie Han", "Chen An", "Qian Zhu", "Shengzhao Zhu", "Zhenyu Wang"], "title": "DHEA-MECD: An Embodied Intelligence-Powered DRL Algorithm for AUV Tracking in Underwater Environments with High-Dimensional Features", "comment": null, "summary": "In recent years, autonomous underwater vehicle (AUV) systems have demonstrated significant potential in complex marine exploration. However, effective AUV-based tracking remains challenging in realistic underwater environments characterized by high-dimensional features, including coupled kinematic states, spatial constraints, time-varying environmental disturbances, etc. To address these challenges, this paper proposes a hierarchical embodied-intelligence (EI) architecture for underwater multi-target tracking with AUVs in complex underwater environments. Built upon this architecture, we introduce the Double-Head Encoder-Attention-based Multi-Expert Collaborative Decision (DHEA-MECD), a novel Deep Reinforcement Learning (DRL) algorithm designed to support efficient and robust multi-target tracking. Specifically, in DHEA-MECD, a Double-Head Encoder-Attention-based information extraction framework is designed to semantically decompose raw sensory observations and explicitly model complex dependencies among heterogeneous features, including spatial configurations, kinematic states, structural constraints, and stochastic perturbations. On this basis, a motion-stage-aware multi-expert collaborative decision mechanism with Top-k expert selection strategy is introduced to support stage-adaptive decision-making. Furthermore, we propose the DHEA-MECD-based underwater multitarget tracking algorithm to enable AUV smart, stable, and anti-interference multi-target tracking. Extensive experimental results demonstrate that the proposed approach achieves superior tracking success rates, faster convergence, and improved motion optimality compared with mainstream DRL-based methods, particularly in complex and disturbance-rich marine environments.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u5177\u8eab\u667a\u80fd\u67b6\u6784\u548cDHEA-MECD\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u89e3\u51b3\u81ea\u4e3b\u6c34\u4e0b\u822a\u884c\u5668\u5728\u590d\u6742\u6d77\u6d0b\u73af\u5883\u4e2d\u591a\u76ee\u6807\u8ddf\u8e2a\u7684\u9c81\u68d2\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u5b9e\u6c34\u4e0b\u73af\u5883\u5b58\u5728\u9ad8\u7ef4\u7279\u5f81\u8026\u5408\u3001\u7a7a\u95f4\u7ea6\u675f\u548c\u65f6\u53d8\u5e72\u6270\u7b49\u6311\u6218\uff0c\u5bfc\u81f4AUV\u591a\u76ee\u6807\u8ddf\u8e2a\u6548\u7387\u4e0d\u8db3\u3002", "method": "\u8bbe\u8ba1\u53cc\u5934\u7f16\u7801\u5668\u6ce8\u610f\u529b\u6846\u67b6\u5206\u89e3\u611f\u77e5\u6570\u636e\u5e76\u5efa\u6a21\u5f02\u6784\u7279\u5f81\u4f9d\u8d56\uff1b\u5f15\u5165\u8fd0\u52a8\u9636\u6bb5\u611f\u77e5\u7684\u591a\u4e13\u5bb6\u51b3\u7b56\u673a\u5236\u4e0eTop-k\u4e13\u5bb6\u9009\u62e9\u7b56\u7565\u5b9e\u73b0\u81ea\u9002\u5e94\u51b3\u7b56\u3002", "result": "\u76f8\u6bd4\u4e3b\u6d41DRL\u65b9\u6cd5\uff0c\u5728\u5e72\u6270\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6210\u529f\u7387\u3001\u66f4\u5feb\u6536\u655b\u548c\u66f4\u4f18\u8fd0\u52a8\u8f68\u8ff9\u3002", "conclusion": "DHEA-MECD\u7b97\u6cd5\u6709\u6548\u63d0\u5347\u4e86AUV\u5728\u6270\u52a8\u73af\u5883\u4e0b\u591a\u76ee\u6807\u8ddf\u8e2a\u7684\u667a\u80fd\u5316\u3001\u7a33\u5b9a\u6027\u548c\u6297\u5e72\u6270\u80fd\u529b\u3002"}}
{"id": "2602.07147", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07147", "abs": "https://arxiv.org/abs/2602.07147", "authors": ["Marco De Luca", "Michele Perlotto", "Anna Rita Fasolino", "Porfirio Tramontana"], "title": "Architectural Anti-Patterns in Student-Developed Microservice Architectures: An Exploratory Study", "comment": null, "summary": "Teaching microservice architectures is challenging due to distributed complexity and the gap between academia and industry. Understanding the quality issues students introduce in MSAs is essential to improve education. This study analyzes student-developed microservices using an established anti-pattern taxonomy and derives lessons learned with actionable teaching recommendations. We conducted a longitudinal, project-based course (2023-2025) involving 216 Master's students (67 teams) who designed and deployed a realistic, containerized MSA for a gamified testing platform. The final systems revealed 23 out of 58 known MSA anti-patterns, spanning five categories. Security issues were most frequent, highlighting weaknesses in authentication, authorization, and data protection. Team Organization and Service Interaction problems followed, reflecting limited DevOps experience and difficulties in inter-service coordination. Fewer issues appeared in Intra-service Design and Inter-service Decomposition, suggesting students generally defined service boundaries well. Overall, students prioritized feature delivery over robustness and operational discipline. To address this, we recommend enforcing minimal standards (API contracts, gateways), providing labs on resilient communication, integrating security-by-design practices, and offering CI-CD templates. The paper contributes a realistic, full-scale educational experience and a replicable model for teaching industry-aligned microservice architecture.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u5b66\u751f\u5728\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u5f15\u5165\u7684\u8d28\u91cf\u95ee\u9898\uff0c\u63a2\u7a76\u53cd\u6a21\u5f0f\u5e76\u63d0\u4f9b\u6559\u80b2\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u6559\u5b66\u5fae\u670d\u52a1\u67b6\u6784\u56e0\u5206\u5e03\u5f0f\u590d\u6742\u6027\u548c\u5b66\u672f\u754c\u5de5\u4e1a\u754c\u5dee\u8ddd\u800c\u5177\u6311\u6218\u6027\uff0c\u8bc6\u522b\u5b66\u751f\u9519\u8bef\u4ee5\u63d0\u5347\u6559\u5b66\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002", "method": "2023-2025\u5e74\u7eb5\u5411\u8bfe\u7a0b\u4e2d\uff0c216\u540d\u7855\u58eb\u751f\u5206\u4e3a67\u7ec4\u8bbe\u8ba1\u5e76\u90e8\u7f72\u5bb9\u5668\u5316\u5fae\u670d\u52a1\u7cfb\u7edf\uff0c\u91c7\u7528\u65e2\u6709\u7684\u53cd\u6a21\u5f0f\u5206\u7c7b\u6cd5\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7cfb\u7edf\u66b4\u973258\u79cd\u53cd\u6a21\u5f0f\u4e2d\u768423\u79cd\uff0c\u6d89\u53ca\u4e94\u7c7b\uff1a\u5b89\u5168\u95ee\u9898\uff08\u5982\u8ba4\u8bc1\u6388\u6743\u4e0d\u8db3\uff09\u6700\u4e3a\u5e38\u89c1\uff0c\u56e2\u961f\u7ec4\u7ec7\u548c\u670d\u52a1\u4ea4\u4e92\u95ee\u9898\u6b21\u4e4b\uff0c\u5185\u90e8\u8bbe\u8ba1\u548c\u5206\u89e3\u95ee\u9898\u8f83\u5c11\u3002", "conclusion": "\u5b66\u751f\u91cd\u529f\u80fd\u4ea4\u4ed8\u8f7b\u7a33\u5065\u8fd0\u884c\uff0c\u5efa\u8bae\u5f3a\u5236\u57fa\u7840\u6807\u51c6\u3001\u52a0\u5f3a\u5f39\u6027\u901a\u4fe1\u5b9e\u9a8c\u3001\u6574\u5408\u5b89\u5168\u8bbe\u8ba1\u6d41\u7a0b\u5e76\u63d0\u4f9bCI-CD\u6a21\u677f\uff0c\u8d21\u732e\u4e86\u53ef\u590d\u5236\u7684\u5de5\u4e1a\u5bf9\u9f50\u6559\u5b66\u6a21\u578b\u3002"}}
{"id": "2602.07195", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07195", "abs": "https://arxiv.org/abs/2602.07195", "authors": ["Bihui Jin", "Kaiyuan Wang", "Pengyu Nie"], "title": "Automated Modernization of Machine Learning Engineering Notebooks for Reproducibility", "comment": null, "summary": "Interactive computational notebooks (e.g., Jupyter notebooks) are widely used in machine learning engineering (MLE) to program and share end-to-end pipelines, from data preparation to model training and evaluation. However, environment erosion-the rapid evolution of hardware and software ecosystems for machine learning-has rendered many published MLE notebooks non-reproducible in contemporary environments, hindering code reuse and scientific progress. To quantify this gap, we study 12,720 notebooks mined from 79 popular Kaggle competitions: only 35.4% remain reproducible today. Crucially, we find that environment backporting, i.e., downgrading dependencies to match the submission time, does not improve reproducibility but rather introduces additional failure modes.\n  To address environment erosion, we design and implement MLEModernizer, an LLM-driven agentic framework that treats the contemporary environment as a fixed constraint and modernizes notebook code to restore reproducibility. MLEModernizer iteratively executes notebooks, collects execution feedback, and applies targeted fixes in three types: error-repair, runtime-reduction, and score-calibration. Evaluated on 7,402 notebooks that are non-reproducible under the baseline environment, MLEModernizer makes 5,492 (74.2%) reproducible. MLEModernizer enables practitioners to validate, reuse, and maintain MLE artifacts as the hardware and software ecosystems continue to evolve.", "AI": {"tldr": "\u7814\u7a76\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u7b14\u8bb0\u672c\u7684\u73af\u5883\u4fb5\u8680\u95ee\u9898\uff0c\u63d0\u51faLLM\u9a71\u52a8\u7684MLEModernizer\u6846\u67b6\uff0c\u6210\u529f\u4fee\u590d74.2%\u4e0d\u53ef\u590d\u73b0\u7684\u7b14\u8bb0\u672c\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7b14\u8bb0\u672c\u56e0\u8f6f\u786c\u4ef6\u73af\u5883\u5feb\u901f\u8fed\u4ee3\uff08\u73af\u5883\u4fb5\u8680\uff09\u5bfc\u81f4\u5927\u91cf\u5386\u53f2\u4ee3\u7801\u65e0\u6cd5\u590d\u73b0\uff0c\u963b\u788d\u79d1\u5b66\u590d\u7528\uff08\u4ec535.4%Kaggle\u7b14\u8bb0\u672c\u53ef\u8fd0\u884c\uff09\uff0c\u4e14\u4f20\u7edf\u4f9d\u8d56\u964d\u7ea7\u65b9\u6848\u65e0\u6548\u3002", "method": "\u8bbe\u8ba1MLEModernizer\u6846\u67b6\uff1a\u4ee5\u5f53\u4ee3\u73af\u5883\u4e3a\u7ea6\u675f\uff0c\u901a\u8fc7\u8fed\u4ee3\u6267\u884c-\u53cd\u9988\u5faa\u73af\u5b9e\u73b0\u4e09\u7c7b\u4ee3\u7801\u4fee\u590d\uff08\u9519\u8bef\u4fee\u590d/\u8fd0\u884c\u65f6\u4f18\u5316/\u5206\u6570\u6821\u6b63\uff09\uff0c\u91c7\u7528LLM\u667a\u80fd\u4f53\u9a71\u52a8\u73b0\u4ee3\u5316\u6539\u9020\u3002", "result": "\u57287,402\u4e2a\u57fa\u7ebf\u73af\u5883\u4e0b\u4e0d\u53ef\u590d\u73b0\u7684\u7b14\u8bb0\u672c\u4e2d\uff0c\u6210\u529f\u4fee\u590d5,492\u4e2a\uff0874.2%\uff09\uff0c\u663e\u8457\u63d0\u5347\u590d meticulously \u73b0\u7387\uff1b\u76f8\u8f83\u4e4b\u4e0b\u4f9d\u8d56\u964d\u7ea7\u65b9\u6848sit>\u5b66\u53cd\u6548\u679c\u3002", "conclusion": "MLEModernizer\u53ef\u6709\u6548\u5e94\u5bf9\u73af\u5883\u4fb5\u8680\uff0c\u4e3a\u6301\u7eed\u6f14\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u751f\u6001\u63d0\u4f9b\u53ef\u9760\u7684\u4ee3\u7801\u7ef4\u62a4\u4e0e\u590d\u7528\u65b9\u6848\u3002"}}
{"id": "2602.07412", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07412", "abs": "https://arxiv.org/abs/2602.07412", "authors": ["Raula Gaikovina Kula", "Christoph Treude", "Xing Hu", "Sebastian Baltes", "Earl T. Barr", "Kelly Blincoe", "Fabio Calefato", "Junjie Chen", "Marc Cheong", "Youmei Fan", "Daniel M. German", "Marco Gerosa", "Jin L. C. Guo", "Shinpei Hayashi", "Robert Hirschfeld", "Reid Holmes", "Yintong Huo", "Takashi Kobayashi", "Michele Lanza", "Zhongxin Liu", "Olivier Nourry", "Nicole Novielli", "Denys Poshyvanyk", "Shinobu Saito", "Kazumasa Shimari", "Igor Steinmacher", "Mairieli Wessel", "Markus Wagner", "Annie Vella", "Laurie Williams", "Xin Xia"], "title": "Forecasting Developer Environments with GenAI: A Research Perspective", "comment": "IDE Workshop", "summary": "Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222, a four-day intensive research meeting. Four themes emerged as areas of interest for researchers and practitioners.", "AI": {"tldr": "\u4e13\u5bb6\u4f1a\u8bae\u63a2\u8ba8\u751f\u6210\u5f0f anglais \u5bf9 IDE \u4ea4\u4e92\u6a21\u5f0f\u7684\u5f71\u54cd\u548c\u6f5c\u5728\u53d8\u9769\u3002", "motivation": "\u7814\u7a76\u751f\u6210\u5f0f AI \u63d0\u5347\u4ee3\u7801\u62bd\u8c61\u5c42\u7ea7\u540e\uff0c\u63a2\u8ba8\u5176\u6539\u53d8 IDE \u4eba\u673a\u4ea4\u4e92\u7684\u6311\u6218\u6e7f\u5ea6 \u673a\u9047\u3002", "method": "\u53ec\u96c6 33 \u4f4d SE/AI/HCI \u9886\u57df\u4e13\u5bb6\uff0c\u4e3e\u884c\u4e3a\u671f\u56db\u5929\u7684\u5b66\u672f\u7814\u8ba8\u4f1a\u3002", "result": "\u4f1a\u8bae\u786e\u7acb\u4e86\u7814\u53d1\u4eba\u5458\u9996\u8981\u5173\u6ce8\u7684\u56db\u4e2a\u6838\u5fc3\u521b\u65b0\u65b9\u5411\u3002", "conclusion": "\u751f\u6210\u5f0f AI \u5c06\u6df1\u523b\u91cd\u5851 IDE \u4ea4\u4e92\u8303\u5f0f\uff0c\u56db\u5927\u4e3b\u9898\u4e3a\u5173\u952e\u7814\u7a76\u8def\u5f84\u3002"}}
{"id": "2602.07561", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07561", "abs": "https://arxiv.org/abs/2602.07561", "authors": ["Quanjun Zhang", "Ye Shang", "Haichuan Hu", "Chunrong Fang", "Zhenyu Chen", "Liang Xiao"], "title": "ComPass: Contrastive Learning for Automated Patch Correctness Assessment in Program Repair", "comment": "30 pages, 3 figures", "summary": "Automated program repair (APR) attempts to reduce manual debugging efforts and plays a vital role in software maintenance. Despite remarkable progress, APR is still limited in generating overfitting patches, i.e., patches passing available test suites but incorrect. This issue, known as patch overfitting, has become a key concern in the APR community, with numerous approaches proposed to address it. Very recent work proposes a pre-trained language model (PLM)-based automated patch correctness assessment (APCA) approach, indicating the potential of such PLMs in reasoning about patch correctness. Despite being promising, it is still far from perfect due to various limitations, such as the training paradigm and training dataset. In this paper, we present ComPass, a PLM-based APCA approach that leverages contrastive learning and data augmentation to address the technical limitations of prior work. Our work is inspired by the opportunity to integrate contrastive learning with recent PLMs in the field of patch correctness assessment, where large-scale labeled patches are difficult to obtain. ComPass utilizes code transformation rules to generate semantic-preserving code snippets for both unlabeled pre-training corpus and labeled fine-tuning patches. ComPass then pre-trains PLMs with contrastive learning, which captures code features with the same semantics but different structures. ComPass finally integrates representation embeddings of patch code snippets and fine-tunes PLMs with a binary classifier jointly to assess patch code correctness. Experimental results on 2274 real-world patches from Defects4J demonstrate that ComPass achieves an accuracy of 88.35%, significantly outperforming state-of-the-art baseline APPT.", "AI": {"tldr": "\u63d0\u51faComPass\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u6539\u8fdb\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u8865\u4e01\u6b63\u786e\u6027\u8bc4\u4f30\u4e2d\u7684\u8868\u73b0\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u4e2d\u666e\u904d\u5b58\u5728\u8865\u4e01\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5373\u8865\u4e01\u901a\u8fc7\u6d4b\u8bd5\u4f46\u4e0d\u6b63\u786e\u3002\u73b0\u6709\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u65b9\u6cd5\u56e0\u8bad\u7ec3\u8303\u5f0f\u548c\u6570\u636e\u9650\u5236\u6548\u679c\u4e0d\u4f73\u3002", "method": "ComPass Levels\uff1a1)\u5229\u7528\u4ee3\u7801\u8f6c\u6362\u89c4\u5219\u751f\u6210\u8bed\u4e49\u4fdd\u7559\u7684\u4ee3\u7801\u7247\u6bb5\u4f5c\u4e3a\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u8bed\u6599\uff1b2)\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u9884\u8bad\u7ec3PLM\u6355\u83b7\u76f8\u540c\u8bed\u4e49\u4e0d\u540c\u7ed3\u6784\u7684\u7279\u5f81\uff1b3)\u7ed3\u5408\u8868\u5f81\u5d4c\u5165\u548c\u4e8c\u5143\u5206\u7c7b\u5668\u5fae\u8c03\u6a21\u578b\u8bc4\u4f30\u8865\u4e01\u6b63\u786e\u6027\u3002", "result": "\u5728Defects4J\u76842274\u4e2a\u771f\u5b9e\u8865\u4e01\u4e0a\u8fbe\u523088.35%\u51c6\u786e\u7387\uff0c\u663e\u8457\u8d85\u8fc7APPT\u7b49\u6700\u5148\u8fdb\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u8865\u4e01\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u4e3a\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2602.07569", "categories": ["cs.SE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.07569", "abs": "https://arxiv.org/abs/2602.07569", "authors": ["Eduardo C. Peixoto", "Hector Oliveira", "Geber L. Ramalho", "Cesar Fran\u00e7a"], "title": "Clarifying Core Dimensions in Digital Maturity Models: An Integrative Approach", "comment": "34 pages, 8 figures, 10 tables, 2 appendices", "summary": "Digital Transformation (DT) initiatives frequently face high failure rates, and while Digital Maturity Models (DMMs) offer potential solutions, they have notable shortcomings. Specifically, there is significant disparity in the dimensions considered relevant, a lack of clarity in their definitions, and uncertainty regarding their components. This study aims to provide a clearer understanding of DMMs by proposing integrative definitions of the most frequently used dimensions. Using a Systematic Mapping approach, including automatic search and snowballing techniques, we analyzed 76 DMMs to answer two Research Questions: (RQ1) What are the most frequent dimensions in DMMs? and (RQ2) How are these dimensions described, including their components? We reconcile varying interpretations of the ten most frequent dimensions -- Organization, Strategy, Technology, Culture, Process, Operations, People, Management, Customer, and Data -- and propose integrative definitions for each. Compared to previous analyses, this study provides a broader and more recent perspective on Digital Maturity Models.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u5206\u679076\u4e2a\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\uff0c\u63d0\u51fa\u5341\u5927\u7ef4\u5ea6\u7684\u6574\u5408\u5b9a\u4e49\u4ee5\u89e3\u51b3\u7ef4\u5ea6\u5b9a\u4e49\u6a21\u7cca\u95ee\u9898\u3002", "motivation": "\u6570\u5b57\u8f6c\u578b\u5931\u8d25\u7387\u9ad8\uff0c\u73b0\u6709\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\u5b58\u5728\u7ef4\u5ea6\u5b9a\u4e49\u4e0d\u6e05\u6670\u3001\u7ef4\u5ea6\u4e0d\u4e00\u81f4\u548c\u7ec4\u4ef6\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u9700\u7cfb\u7edf\u5316\u6574\u5408\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6620\u5c04\u6cd5\uff0c\u7ed3\u5408\u81ea\u52a8\u68c0\u7d22\u4e0e\u6eda\u96ea\u7403\u6280\u672f\uff0c\u5206\u679076\u4e2a\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\uff0c\u805a\u7126\u9ad8\u9891\u7ef4\u5ea6\u7684\u8bc6\u522b\u4e0e\u5b9a\u4e49\u3002", "result": "\u786e\u5b9a\u5341\u5927\u9ad8\u9891\u7ef4\u5ea6\uff08\u7ec4\u7ec7\u3001\u6218\u7565\u3001\u6280\u672f\u3001\u6587\u5316\u3001\u6d41\u7a0b\u3001\u8fd0\u8425\u3001\u4eba\u5458\u3001\u7ba1\u7406\u3001\u5ba2\u6237\u3001\u6570\u636e\uff09\uff0c\u5e76\u4e3a\u5176\u63d0\u51fa\u7edf\u4e00\u7684\u6574\u5408\u5b9a\u4e49\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u6bd4\u65e2\u5f80\u7814\u7a76\u66f4\u5168\u9762\u3001\u66f4\u65b0\u7684\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\u89c6\u89d2\uff0c\u89e3\u51b3\u4e86\u7ef4\u5ea6\u5b9a\u4e49\u788e\u7247\u5316\u95ee\u9898\u3002"}}
{"id": "2602.07589", "categories": ["cs.SE", "cs.CY", "cs.ET", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.07589", "abs": "https://arxiv.org/abs/2602.07589", "authors": ["Andriy Miranskyy"], "title": "A Course on the Introduction to Quantum Software Engineering: Experience Report", "comment": null, "summary": "Quantum computing is increasingly practiced through programming, yet most educational offerings emphasize algorithmic or framework-level use rather than software engineering concerns such as testing, abstraction, tooling, and lifecycle management.\n  This paper reports on the design and first offering of a cross-listed undergraduate--graduate course that frames quantum computing through a software engineering lens, focusing on early-stage competence relevant to software engineering practice. The course integrates foundational quantum concepts with software engineering perspectives, emphasizing executable artifacts, empirical reasoning, and trade-offs arising from probabilistic behaviour, noise, and evolving toolchains. Evidence is drawn from instructor observations, student feedback, surveys, and analysis of student work.\n  Despite minimal prior exposure to quantum computing, students were able to engage productively with quantum software engineering topics once a foundational understanding of quantum information and quantum algorithms, expressed through executable artifacts, was established. This experience report contributes a modular course design, a scalable assessment model for mixed academic levels, and transferable lessons for software engineering educators developing quantum computing curricula.", "AI": {"tldr": "\u8bba\u6587\u62a5\u544a\u4e00\u95e8\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u548c\u8f6f\u4ef6\u5de5\u7a0b\u7684\u8de8\u5e74\u7ea7\u8bfe\u7a0b\u8bbe\u8ba1\u4e0e\u9996\u6b21\u6559\u5b66\uff0c\u5b66\u751f\u638c\u63e1\u57fa\u7840\u77e5\u8bc6\u540e\u80fd\u6709\u6548\u5b66\u4e60\u5de5\u7a0b\u5b9e\u8df5\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u6559\u80b2\u591a\u4fa7\u91cd\u7b97\u6cd5\u6216\u6846\u67b6\u5c42\u9762\uff0c\u5ffd\u7565\u8f6f\u4ef6\u5de5\u7a0b\u8981\u7d20\u5982\u6d4b\u8bd5\u3001\u62bd\u8c61\u5316\u3001\u5de5\u5177\u5316\u548c\u751f\u547d\u5468\u671f\u7ba1\u7406\u3002\u8bfe\u7a0b\u65e8\u5728\u57f9\u517b\u65e9\u671f\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u65bd\u672c\u79d1-\u7814\u7a76\u751f\u8de8\u5e74\u7ea7\u8bfe\u7a0b\uff0c\u6574\u5408\u91cf\u5b50\u6982\u5ff5\u4e0e\u5de5\u7a0b\u89c6\u89d2\uff0c\u901a\u8fc7\u6559\u5e08\u89c2\u5bdf\u3001\u5b66\u751f\u53cd\u9988\u3001\u8c03\u67e5\u548c\u5b66\u751f\u4f5c\u4e1a\u5206\u6790\u6536\u96c6\u8bc1\u636e\u3002", "result": "\u5b66\u751f\u5728\u5177\u5907\u91cf\u5b50\u4fe1\u606f\u4e0e\u7b97\u6cd5\u57fa\u7840\u540e\uff0c\u5c3d\u7ba1\u91cf\u5b50\u7ecf\u9a8c\u6709\u9650\uff0c\u4ecd\u80fd\u9ad8\u6548\u53c2\u4e0e\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u4e3b\u9898\uff0c\u91cd\u89c6\u53ef\u6267\u884c\u6784\u4ef6\u548c\u89e3\u51b3\u91cf\u5b50\u566a\u58f0\u7b49\u6311\u6218\u3002", "conclusion": "\u8d21\u732e\u6a21\u5757\u5316\u8bfe\u7a0b\u8bbe\u8ba1\u3001\u9002\u7528\u4e8e\u6df7\u5408\u5b66\u672f\u6c34\u5e73\u7684\u8bc4\u4f30\u6a21\u5f0f\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u8005\u5f00\u53d1\u91cf\u5b50\u8ba1\u7b97\u8bfe\u7a0b\u63d0\u4f9b\u53ef\u8f6c\u79fb\u7ecf\u9a8c\u6559\u8bad\u3002"}}
{"id": "2602.07609", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07609", "abs": "https://arxiv.org/abs/2602.07609", "authors": ["Ruoyu Su", "Alexander Bakhtin", "Noman Ahmad", "Matteo Esposito", "Valentina Lenarduzzi", "Davide Taibi"], "title": "Evaluating Large Language Models for Detecting Architectural Decision Violations", "comment": null, "summary": "Architectural Decision Records (ADRs) play a central role in maintaining software architecture quality, yet many decision violations go unnoticed because projects lack both systematic documentation and automated detection mechanisms. Recent advances in Large Language Models (LLMs) open up new possibilities for automating architectural reasoning at scale. We investigated how effectively LLMs can identify decision violations in open-source systems by examining their agreement, accuracy, and inherent limitations. Our study analyzed 980 ADRs across 109 GitHub repositories using a multi-model pipeline in which one LLM primary screens potential decision violations, and three additional LLMs independently validate the reasoning. We assessed agreement, accuracy, precision, and recall, and complemented the quantitative findings with expert evaluation. The models achieved substantial agreement and strong accuracy for explicit, code-inferable decisions. Accuracy falls short for implicit or deployment-oriented decisions that depend on deployment configuration or organizational knowledge. Therefore, LLMs can meaningfully support validation of architectural decision compliance; however, they are not yet replacing human expertise for decisions not focused on code.", "AI": {"tldr": "\u7814\u7a76\u63a2\u7d22\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u68c0\u6d4b\u8f6f\u4ef6\u67b6\u6784\u51b3\u7b56\u8fdd\u89c4\uff0c\u53d1\u73b0\u5176\u5bf9\u663e\u6027\u4ee3\u7801\u51b3\u7b56\u6709\u6548\u4f46\u5bf9\u9690\u6027\u914d\u7f6e\u51b3\u7b56\u6709\u5c40\u9650", "motivation": "\u89e3\u51b3\u8f6f\u4ef6\u9879\u76ee\u4e2d\u67b6\u6784\u51b3\u7b56\u8fdd\u89c4\u96be\u68c0\u6d4b\u7684\u95ee\u9898\uff0c\u56e0\u7f3a\u4e4f\u7cfb\u7edf\u6587\u6863\u548c\u81ea\u52a8\u673a\u5236", "method": "\u901a\u8fc7\u591a\u6a21\u578b\u6d41\u6c34\u7ebf\u5206\u6790109\u4e2aGitHub\u4ed3\u5e93\u7684980\u4efd\u51b3\u7b56\u8bb0\u5f55\uff1a\u4e3b\u6a21\u578b\u7b5b\u9009\u8fdd\u89c4\uff0c\u4e09\u4e2a\u884d\u751f\u6a21\u578b\u72ec\u7acb\u9a8c\u8bc1\uff0c\u7ed3\u5408\u5b9a\u91cf\u6307\u6807\u4e0e\u4e13\u5bb6\u8bc4\u4f30", "result": "\u6a21\u578b\u5bf9\u4ee3\u7801\u53ef\u63a8\u5bfc\u7684\u663e\u6027\u51b3\u7b56\u51c6\u786e\u7387\u9ad8\uff08\u663e\u8457\u4e00\u81f4\uff09\uff0c\u4f46\u4f9d\u8d56\u914d\u7f6e/\u7ec4\u7ec7\u77e5\u8bc6\u7684\u9690\u6027\u548c\u90e8\u7f72\u5bfc\u5411\u51b3\u7b56\u51c6\u786e\u7387\u4f4e", "conclusion": "LLMs\u53ef\u8f85\u52a9\u67b6\u6784\u5408\u89c4\u9a8c\u8bc1\uff0c\u4f46\u65e0\u6cd5\u66ff\u4ee3\u4eba\u7c7b\u5728\u975e\u4ee3\u7801\u51b3\u7b56\u4e2d\u7684\u4e13\u4e1a\u5224\u65ad"}}
{"id": "2602.08242", "categories": ["cs.SE", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.08242", "abs": "https://arxiv.org/abs/2602.08242", "authors": ["Ali Hassaan Mughal", "Muhammad Bilal"], "title": "Software Testing at the Network Layer: Automated HTTP API Quality Assessment and Security Analysis of Production Web Applications", "comment": "18 pages, 5 figures, 3 tables. Code and data: https://github.com/amughalbscs16/network-layer-quality-testing", "summary": "Modern web applications rely heavily on client-side API calls to fetch data, render content, and communicate with backend services. However, the quality of these network interactions (redundant requests, missing cache headers, oversized payloads, and excessive third-party dependencies) is rarely tested in a systematic way. Moreover, many of these quality deficiencies carry security implications: missing cache headers enable cache poisoning, excessive third-party dependencies expand the supply-chain attack surface, and error responses risk leaking server internals. In this study, we present an automated software testing framework that captures and analyzes the complete HTTP traffic of 18 production websites spanning 11 categories (e-commerce, news, government, developer tools, travel, and more). Using automated browser instrumentation via Playwright, we record 108 HAR (HTTP Archive) files across 3 independent runs per page, then apply 8 heuristic-based anti-pattern detectors to produce a composite quality score (0-100) for each site. Our results reveal a wide quality spectrum: minimalist server-rendered sites achieve perfect scores of 100, while content-heavy commercial sites score as low as 56.8. We identify redundant API calls and missing cache headers as the two most pervasive anti-patterns, each affecting 67% of sites, while third-party overhead exceeds 20% on 72% of sites. One utility site makes 2,684 requests per page load, which is 447x more than the most minimal site. To protect site reputations, all identities are anonymized using category-based pseudonyms. We provide all analysis scripts, anonymized results, and reproducibility instructions as an open artifact. This work establishes an empirical baseline for HTTP API call quality across the modern web and offers a reproducible testing framework that researchers and practitioners can apply to their own applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u52a8\u5316\u6d4b\u8bd5\u6846\u67b6\u8bc4\u4f30Web\u5e94\u7528\u7684\u5ba2\u6237\u7aefAPI\u8c03\u7528\u8d28\u91cf\uff0c\u901a\u8fc7\u5206\u679018\u4e2a\u751f\u4ea7\u7f51\u7ad9\u7684HTTP\u6d41\u91cf\uff0c\u63ed\u793a\u5197\u4f59\u8bf7\u6c42\u3001\u7f13\u5b58\u7f3a\u5931\u7b49\u666e\u904d\u7f3a\u9677\uff0c\u5e76\u5efa\u7acb\u8de8\u884c\u4e1a\u7684\u8d28\u91cf\u57fa\u51c6\u3002", "motivation": "\u73b0\u4ee3Web\u5e94\u7528\u4f9d\u8d56\u5ba2\u6237\u7aefAPI\u8c03\u7528\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u8d28\u91cf\u6d4b\u8bd5\uff0c\u5197\u4f59\u8bf7\u6c42\u3001\u7f13\u5b58\u5934\u7f3a\u5931\u53ca\u7b2c\u4e09\u65b9\u4f9d\u8d56\u8fc7\u591a\u7b49\u6f0f\u6d1e\u53ef\u80fd\u5f15\u53d1\u7f13\u5b58\u6c61\u67d3\u3001\u4f9b\u5e94\u94fe\u653b\u51fb\u548c\u6570\u636e\u6cc4\u9732\u7b49\u5b89\u5168\u9690\u60a3\u3002", "method": "\u91c7\u7528Playwright\u81ea\u52a8\u5316\u6d4f\u89c8\u5668\u8bb0\u5f55108\u4efdHAR\u6587\u4ef6\uff08\u6bcf\u7f51\u7ad93\u6b21\u8fd0\u884c\uff09\uff0c\u8bbe\u8ba18\u79cd\u542f\u53d1\u5f0f\u53cd\u6a21\u5f0f\u68c0\u6d4b\u5668\u751f\u62100-100\u5206\u8d28\u91cf\u8bc4\u5206\uff0c\u8986\u76d611\u7c7b18\u4e2a\u533f\u540d\u751f\u4ea7\u7ad9\u70b9\u3002", "result": "\u8d28\u91cf\u5206\u5dee\u663e\u8457\uff1a\u6781\u7b80\u7ad9\u70b9\u6ee1\u5206100\u5206\uff0c\u5546\u4e1a\u7ad9\u70b9 Microbiolo56.8\u5206\u300267%\u7ad9\u70b9\u5b58\u5728\u5197\u4f59API\u8c03\u7528\u548c\u7f13\u5b58\u5934\u7f3a\u5931\uff0c72%\u7ad9\u70b9\u7b2c\u4e09\u65b9\u5f00\u9500\u8d8520%\uff0c\u5355\u7ad9\u70b9\u5cf0\u5024\u8bf7\u6c42\u8fbe2684\u6b21\uff08\u662f\u6700\u4f4e\u7ad9\u70b9\u7684447\u500d\uff09\u3002", "conclusion": "\u7814\u7a76\u5efa\u7acb\u4e86HTTP API\u8d28\u91cf\u7684\u73b0\u4ee3\u57fa\u7ebf\u6846\u67b6\uff0c\u63d0\u51fa\u53ef\u590d\u73b0\u7684\u5f00\u6e90\u6d4b\u8bd5\u65b9\u6848\uff08\u542b\u811a\u672c\u4e0e\u533f\u540d\u6570\u636e\u96c6\uff09\uff0c\u4e3a\u5f00\u53d1\u4eba\u5458\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u7cfb\u7edf\u6027\u8d28\u91cf\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2602.07672", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL", "cs.SC"], "pdf": "https://arxiv.org/pdf/2602.07672", "abs": "https://arxiv.org/abs/2602.07672", "authors": ["Babak Rahmani"], "title": "Debugging code world models", "comment": "8 pages, 4 figures, under review in conference", "summary": "Code World Models (CWMs) are language models trained to simulate program execution by predicting explicit runtime state after every executed command. This execution-based world modeling enables internal verification within the model, offering an alternative to natural language chain-of-thought reasoning. However, the sources of errors and the nature of CWMs' limitations remain poorly understood. We study CWMs from two complementary perspectives: local semantic execution and long-horizon state tracking. On real-code benchmarks, we identify two dominant failure regimes. First, dense runtime state reveals produce token-intensive execution traces, leading to token-budget exhaustion on programs with long execution histories. Second, failures disproportionately concentrate in string-valued state, which we attribute to limitations of subword tokenization rather than program structure. To study long-horizon behavior, we use a controlled permutation-tracking benchmark that isolates state propagation under action execution. We show that long-horizon degradation is driven primarily by incorrect action generation: when actions are replaced with ground-truth commands, a Transformer-based CWM propagates state accurately over long horizons, despite known limitations of Transformers in long-horizon state tracking. These findings suggest directions for more efficient supervision and state representations in CWMs that are better aligned with program execution and data types.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4ee3\u7801\u4e16\u754c\u6a21\u578b(CWMs)\uff1a\u901a\u8fc7\u9884\u6d4b\u6307\u4ee4\u6267\u884c\u540e\u7684\u8fd0\u884c\u65f6\u72b6\u6001\u6765\u6a21\u62df\u7a0b\u5e8f\u8fd0\u884c\uff0c\u66ff\u4ee3\u81ea\u7136\u8bed\u8a00\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\uff0c\u4f46\u5b58\u5728\u672a\u77e5\u5c40\u9650\u3002\u7814\u7a76\u63ed\u793a\u4e24\u79cd\u4e3b\u8981\u9519\u8bef\u673a\u5236\u548c\u5c40\u9650\u6027\u6839\u6e90\uff0c\u63d0\u51fa\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "\u7406\u89e3CWMs\u7684\u8bef\u5dee\u6765\u6e90\u548c\u5c40\u9650\u6027\u672c\u8d28\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u65b9\u9762\u76ee\u524d\u7814\u7a76\u4e0d\u8db3\uff0c\u9700\u8981\u63a2\u7a76\u5bfc\u81f4\u5931\u8d25\u7684\u5185\u90e8\u673a\u5236\u3002", "method": "\u4f7f\u7528\u4e24\u79cd\u65b9\u6cd5\uff1a\u4e00\u662f\u771f\u5b9e\u4ee3\u7801\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5206\u6790\u5c40\u90e8\u8bed\u4e49\u6267\u884c\u4e2d\u7684\u9519\u8bef\u6a21\u5f0f\uff1b\u4e8c\u662f\u90fd\u5177\u6709\u53ef\u63a7\u6392\u5217\u8ddf\u8e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9694\u79bb\u52a8\u4f5c\u6267\u884c\u4e0b\u7684\u72b6\u6001\u4f20\u64ad\uff0c\u7814\u7a76\u957f\u5e8f\u5217\u884c\u4e3a\u3002\u5b9e\u9a8c\u4e2d\u6d4b\u8bd5\u4e86\u57fa\u4e8eTransformer\u7684CWM\u6a21\u578b\u3002", "result": "\u4e3b\u8981\u53d1\u73b0\uff1a\u7b2c\u4e00\uff0c\u5fd9\u53e8\u5bc6\u96c6\u8fd0\u884c\u65f6\u72b6\u6001\u751f\u6210\u9ad8token\u6d88\u8017\u7684\u6267\u884c\u8e2a\u8ff9\uff0c\u5bfc\u81f4\u957f\u5386\u53f2\u7a0b\u5e8f\u56e0token\u9884\u7b97\u8017\u5c3d\u800c\u5931\u8d25\uff1b\u7b2c\u4e8c\uff0c\u9519\u8bef\u591a\u96c6\u4e2d\u4e8e\u5b57\u7b26\u4e32\u503c\u72b6\u6001\uff0c\u5f52\u56e0\u4e8e\u5b50\u8bcd\u5206\u8bcd\u800c\u975e\u7a0b\u5e8f\u7ed3\u6784\u9650\u5236\u3002\u5728\u957f\u5e8f\u5217\u8ddf\u8e2a\u4e2d\uff0c\u9000\u5316\u4e3b\u8981\u7531\u52a8\u4f5c\u751f\u6210\u9519\u8bef\u9a71\u52a8\uff1a\u5f53\u52a8\u4f5c\u66ff\u6362\u4e3a\u771f\u5b9e\u547d\u4ee4\u65f6\uff0cCWM\u80fd\u957f\u671f\u51c6\u786e\u4f20\u64ad\u72b6\u6001\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5e94\u4f18\u5316\u76d1\u7763\u6548\u7387\u548c\u72b6\u6001\u8868\u793a\u673a\u5236\uff0c\u4f7f\u5176\u66f4\u597d\u5730\u5bf9\u9f50\u7a0b\u5e8f\u6267\u884c\u548c\u6570\u636e\u7c7b\u578b\u8bbe\u8ba1\uff0c\u4ece\u800c\u63d0\u5347CWMs\u7684\u6027\u80fd\u3002"}}
{"id": "2602.07698", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07698", "abs": "https://arxiv.org/abs/2602.07698", "authors": ["Adam Sorrenti", "Andriy Miranskyy"], "title": "On Sequence-to-Sequence Models for Automated Log Parsing", "comment": null, "summary": "Log parsing is a critical standard operating procedure in software systems, enabling monitoring, anomaly detection, and failure diagnosis. However, automated log parsing remains challenging due to heterogeneous log formats, distribution shifts between training and deployment data, and the brittleness of rule-based approaches. This study aims to systematically evaluate how sequence modelling architecture, representation choice, sequence length, and training data availability influence automated log parsing performance and computational cost. We conduct a controlled empirical study comparing four sequence modelling architectures: Transformer, Mamba state-space, monodirectional LSTM, and bidirectional LSTM models. In total, 396 models are trained across multiple dataset configurations and evaluated using relative Levenshtein edit distance with statistical significance testing. Transformer achieves the lowest mean relative edit distance (0.111), followed by Mamba (0.145), mono-LSTM (0.186), and bi-LSTM (0.265), where lower values are better. Mamba provides competitive accuracy with substantially lower computational cost. Character-level tokenization generally improves performance, sequence length has negligible practical impact on Transformer accuracy, and both Mamba and Transformer demonstrate stronger sample efficiency than recurrent models. Overall, Transformers reduce parsing error by 23.4%, while Mamba is a strong alternative under data or compute constraints. These results also clarify the roles of representation choice, sequence length, and sample efficiency, providing practical guidance for researchers and practitioners.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5e8f\u5217\u5efa\u6a21\u67b6\u6784\u7b49\u56e0\u7d20\u5bf9\u81ea\u52a8\u5316\u65e5\u5fd7\u89e3\u6790\u6027\u80fd\u4e0e\u8ba1\u7b97\u6210\u672c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0Transformer\u6700\u4f18\uff0cMamba\u5728\u8ba1\u7b97\u53d7\u9650\u65f6\u662f\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u81ea\u52a8\u5316\u65e5\u5fd7\u89e3\u6790\u9762\u4e34\u65e5\u5fd7\u683c\u5f0f\u5f02\u6784\u3001\u8bad\u7ec3\u4e0e\u90e8\u7f72\u6570\u636e\u5206\u5e03\u504f\u79fb\u53ca\u89c4\u5219\u65b9\u6cd5\u8106\u5f31\u6027\u7b49\u6311\u6218\uff0c\u9700\u91cf\u5316\u8bc4\u4f30\u6a21\u578b\u67b6\u6784\u7b49\u5173\u952e\u56e0\u7d20\u7684\u5f71\u54cd\u3002", "method": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u914d\u7f6e\u4e0b\u8bad\u7ec3\u5e76\u6bd4\u8f83Transformer\u3001Mamba\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u3001\u5355\u5411LSTM\u548c\u53cc\u5411LSTM\u5171396\u4e2a\u6a21\u578b\uff0c\u4f7f\u7528\u76f8\u5bf9Levenshtein\u7f16\u8f91\u8ddd\u79bb\u7ed3\u5408\u7edf\u8ba1\u663e\u8457\u6027\u68c0\u9a8c\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "Transformer\u76f8\u5bf9\u7f16\u8f91\u8ddd\u79bb\u6700\u4f4e\uff080.111\uff09\uff0cMamba\u7d27\u968f\u5176\u540e\uff080.145\uff09\u4e14\u8ba1\u7b97\u6210\u672c\u663e\u8457\u8f83\u4f4e\uff1b\u5b57\u7b26\u7ea7\u5206\u8bcd\u63d0\u5347\u6027\u80fd\uff0c\u5e8f\u5217\u957f\u5ea6\u5bf9Transformer\u5f71\u54cd\u5fae\u5c0f\uff0cMamba\u548cTransformer\u6837\u672c\u6548\u7387\u4f18\u4e8e\u5faa\u73af\u6a21\u578b\u3002", "conclusion": "Transformers\u964d\u4f4e\u89e3\u6790\u9519\u8bef\u738723.4%\uff0cMamba\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u573a\u666f\uff1b\u7814\u7a76\u660e\u786e\u4e86\u8868\u5f81\u9009\u62e9\u3001\u5e8f\u5217\u957f\u5ea6\u53ca\u6837\u672c\u6548\u7387\u7684\u4f5c\u7528\uff0c\u4e3a\u65e5\u5fd7\u89e3\u6790\u5b9e\u8df5\u63d0\u4f9b\u5177\u4f53\u6307\u5bfc\u3002"}}
{"id": "2602.07783", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07783", "abs": "https://arxiv.org/abs/2602.07783", "authors": ["Zejun Zhang", "Yixin Gan", "Zhenchang Xing", "Tian Zhang", "Yi Li", "Xiwei Xu", "Qinghua Lu", "Liming Zhu"], "title": "Still Manual? Automated Linter Configuration via DSL-Based LLM Compilation of Coding Standards", "comment": "Accepted By FSE2026", "summary": "Coding standards are essential for maintaining consistent and high-quality code across teams and projects. Linters help developers enforce these standards by detecting code violations. However, manual linter configuration is complex and expertise-intensive, and the diversity and evolution of programming languages, coding standards, and linters lead to repetitive and maintenance-intensive configuration work. To reduce manual effort, we propose LintCFG, a domain-specific language (DSL)-driven, LLM-based compilation approach to automate linter configuration generation for coding standards, independent of programming languages, coding standards, and linters. Inspired by compiler design, we first design a DSL to express coding rules in a tool-agnostic, structured, readable, and precise manner. Then, we build linter configurations into DSL configuration instructions. For a given natural language coding standard, the compilation process parses it into DSL coding standards, matches them with the DSL configuration instructions to set configuration names, option names and values, verifies consistency between the standards and configurations, and finally generates linter-specific configurations. Experiments with Checkstyle for Java coding standard show that our approach achieves over 90% precision and recall in DSL representation, with accuracy, precision, recall, and F1-scores close to 70% (with some exceeding 70%) in fine-grained linter configuration generation. Notably, our approach outperforms baselines by over 100% in precision. A user study further shows that our approach improves developers' efficiency in configuring linters for coding standards. Finally, we demonstrate the generality of the approach by generating ESLint configurations for JavaScript coding standards, showcasing its broad applicability across other programming languages, coding standards, and linters.", "AI": {"tldr": "LintCFG automates linter configuration using a DSL and LLM-based compilation, improving efficiency and accuracy across programming languages.", "motivation": "Manual linter configuration is complex and maintenance-intensive due to evolving Char coding standards, languages, and tools, requiring expert input.", "method": "Design a DSL for structured rule expression, then compile natural language standards into DSL, match with config instructions, verify consistency, and generate linter-specific configurations.", "result": "Experiments showed >90% precision/recal in DSL representation, ~70% accuracy in config generation, >100% precision improvement over baselines; user studies confirmed efficiency gains; applicability demonstrated for Java and JavaScript.", "conclusion": "The approach enhances developer efficiency and maintains high slightly accuracy, scalable to diverse programming languages and linters."}}
{"id": "2602.07821", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07821", "abs": "https://arxiv.org/abs/2602.07821", "authors": ["Shinobu Saito"], "title": "Software Space Analytics: Towards Visualization and Statistics of Internal Software Execution", "comment": null, "summary": "In software maintenance work, software architects and programmers need to identify modules that require modification or deletion. Whilst user requests and bug reports are utilised for this purpose, evaluating the execution status of modules within the software is also crucial. This paper, therefore, applies spatial statistics to assess internal software execution data. First, we define a software space dataset, viewing the software's internal structure as a space based on module call relationships. Then, using spatial statistics, we conduct the visualization of spatial clusters and the statistical testing using spatial measures. Finally, we consider the usefulness of spatial statistics in the software engineering domain and future challenges.", "AI": {"tldr": "\u672c\u6587\u5e94\u7528\u7a7a\u95f4\u7edf\u8ba1\u65b9\u6cd5\u8bc4\u4f30\u8f6f\u4ef6\u5185\u90e8\u6267\u884c\u6570\u636e\uff0c\u5e2e\u52a9\u8bc6\u522b\u9700\u4fee\u6539\u6216\u5220\u9664\u7684\u6a21\u5757\u3002", "motivation": "\u8f6f\u4ef6\u7ef4\u62a4\u4e2d\u9700\u8bc6\u522b\u5e94\u4fee\u6539\u7684\u6a21\u5757\uff0c\u73b0\u6709\u65b9\u6cd5\uff08\u5982\u7528\u6237\u8bf7\u6c42\u548c\u9519\u8bef\u62a5\u544a\uff09\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8bc4\u4f30\u6a21\u5757\u6267\u884c\u72b6\u6001\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "method": "\u5b9a\u4e49\u8f6f\u4ef6\u7a7a\u95f4\u6570\u636e\u96c6\uff0c\u4ee5\u6a21\u5757\u8c03\u7528\u5173\u7cfb\u4e3a\u57fa\u7840\u6784\u5efa\u7a7a\u95f4\u7ed3\u6784\uff1b\u4f7f\u7528\u7a7a\u95f4\u7edf\u8ba1\u8fdb\u884c\u805a\u7c7b\u53ef\u89c6\u5316\u53ca\u7edf\u8ba1\u68c0\u9a8c\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u7a7a\u95f4\u805a\u7c7b\u53ef\u89c6\u5316\u548c\u7edf\u8ba1\u6d4b\u8bd5\uff0c\u63a2\u8ba8\u4e86\u7a7a\u95f4\u7edf\u8ba1\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u53ca\u6311\u6218\u3002", "conclusion": "\u7a7a\u95f4\u7edf\u8ba1\u4e3a\u8f6f\u4ef6\u6a21\u5757\u5206\u6790\u63d0\u4f9b\u65b0\u89c6\u89d2\uff0c\u4f46\u5e94\u7528\u9700\u514b\u670d berada\u5c11\u6311\u6218\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2602.07871", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07871", "abs": "https://arxiv.org/abs/2602.07871", "authors": ["Xiang Li", "Siyu Lu", "Sarro Federica", "Claire Le Goues", "He Ye"], "title": "HerAgent: Rethinking the Automated Environment Deployment via Hierarchical Test Pyramid", "comment": null, "summary": "Automated software environment setup is a prerequisite for testing, debugging, and reproducing failures, yet remains challenging in practice due to complex dependencies, heterogeneous build systems, and incomplete documentation. Recent work leverages large language models to automate this process, but typically evaluates success using weak signals such as dependency installation or partial test execution, which do not ensure that a project can actually run. In this paper, we argue that environment setup success should be evaluated through executable evidence rather than a single binary signal. We introduce the Environment Maturity Hierarchy, which defines three success levels based on progressively stronger execution requirements, culminating in successful execution of a project's main entry point. Guided by this hierarchy, we propose HerAgent, an automated environment setup approach that incrementally constructs executable environments through execution-based validation and repair. We evaluate HerAgent on four public benchmarks, where it outperforms all related work, achieving up to 79.6\\% improvement due to its holistic understanding of project structure and dependencies. On complex C/C++ projects, HerAgent surpasses prior approaches by 66.7\\%. In addition, HerAgent uniquely resolves 11-30 environment instances across the benchmarks that no prior method can configure.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u81ea\u52a8\u5316\u8f6f\u4ef6BFMS\u73af\u5883\u8bbe\u7f6e\u7684\u8bc4\u4f30\u77ed\u677f\uff0c\u63d0\u51fa\u57fa\u4e8e\u6267\u884c\u9a8c\u8bc1\u7684\u6210\u719f\u5ea6\u5c42\u6b21\u7ed3\u6784\u548cHerAgent\u6539\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5f31\u4fe1\u53f7\u5982\u4f9d\u8d56\u5b89\u88c5\u4f5c\u4e3a\u8bc4\u4f30\u6807\u51c6\uff0c\u65e0\u6cd5\u786e\u4fdd\u9879\u76ee\u5b9e\u9645\u53ef\u8fd0\u884c\uff0cBFMS\u4e9f\u9700\u66f4\u5f3a\u6267\u884c\u8bc1\u636e\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u9996\u6b21\u5b9a\u4e49\u73af\u5883\u6210\u719f\u5ea6\u5c42\u6b21\u7ed3\u6784\uff0c\u5206\u4e09\u9636\u6bb5\u63d0\u5347\u6267\u884c\u8981\u6c42\uff0c\u5e76\u5f00\u53d1HerAgent\u65b9\u6cd5\u589e\u91cf\u6784\u5efa\u73af\u5883\u548c\u4fee\u590d\u9519\u8bef\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBFMSHerAgent\u6027\u80fd\u63d0\u5347\u6700\u9ad879.6%\uff0c\u5c24\u5176\u662fC/C++\u9879\u76ee\u8d85\u8d8a66.7%\uff0c\u4e14\u72ec\u5bb6\u89e3\u51b311-30\u4e2a\u6848\u4f8b\u3002", "conclusion": "BFMS\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u73af\u5883\u8bbe\u7f6e\u6210\u529f\u7387\uff0c\u8bc1\u660e\u6267\u884c\u9a71\u52a8\u8bc4\u4f30\u7684\u4f18\u52bf\uff0c\u5e76\u4e3a\u590d\u6742\u9879\u76ee\u81ea\u52a8\u5316\u63d0\u4f9b\u65b0\u8303\u5f0f\u3002"}}
{"id": "2602.07882", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07882", "abs": "https://arxiv.org/abs/2602.07882", "authors": ["Chen Xie", "Yuling Shi", "Xiaodong Gu", "Beijun Shen"], "title": "Rethinking Code Complexity Through the Lens of Large Language Models", "comment": null, "summary": "Code complexity metrics such as cyclomatic complexity have long been used to assess software quality and maintainability. With the rapid advancement of large language models (LLMs) on code understanding and generation tasks, an important yet underexplored question arises: do these traditional complexity metrics meaningfully characterize the difficulty LLMs experience when processing code? In this work, we empirically demonstrate that, after controlling for code length, classical metrics exhibit no consistent correlation with LLM performance, revealing a fundamental mismatch with model-perceived difficulty. To address this gap, we propose LM-CC, a novel code complexity metric designed from the perspective of LLMs. The core premise of LM-CC is that LLM-perceived difficulty is driven by the nonlinearity of program semantics. Accordingly, we decompose programs into semantic units based on entropy, organize these units into a compositional hierarchy, and quantify complexity as a principled aggregation of compositional level and branching-induced divergence, capturing cumulative model uncertainty during code processing. Our extensive experiments show that LM-CC not only correlates more strongly with LLM performance than traditional metrics but also that lowering it directly enhances task performance.", "AI": {"tldr": "\u50b3\u7d71\u4ee3\u78bc\u8907\u96dc\u5ea6\u6307\u6a19\uff08\u5982\u74b0\u72c0\u8907\u96dc\u5ea6\uff09\u8207LLM\u8655\u7406\u56f0\u96e3\u5ea6\u4e0d\u76f8\u95dc\uff0c\u7814\u7a76\u63d0\u51fa\u57fa\u65bc\u8a9e\u7fa9\u975e\u7dda\u6027\u7684\u65b0\u6307\u6a19LM-CC\uff0c\u5be6\u9a57\u8b49\u660e\u5176\u6709\u66f4\u5f37\u76f8\u95dc\u6027\u4e14\u964d\u4f4e\u53ef\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73fe\u6709\u8907\u96dc\u5ea6\u6307\u6a19\u7121\u6cd5\u53cd\u6620LLM\u611f\u77e5\u4ee3\u78bc\u56f0\u96e3\u7a0b\u5ea6\uff0c\u9700\u586b\u88dc\u6b64\u7f3a\u53e3\u4e26\u63d0\u4f9b\u9069\u7528\u65bcAI\u6a21\u578b\u7684\u65b0\u8a55\u4f30\u65b9\u6cd5\u3002", "method": "\u5f9eLLM\u8996\u89d2\u51fa\u767c\uff0c\u57fa\u65bc\u71b5\u5206\u89e3\u4ee3\u78bc\u70ba\u8a9e\u7fa9\u55ae\u4f4d\uff0c\u5c64\u6b21\u5316\u805a\u5408\u7d50\u69cb\u8207\u5206\u652f\u4e0d\u78ba\u5b9a\u6027\uff0c\u8a2d\u8a08LM-CC\u91cf\u5316\u8907\u96dc\u5ea6\u3002", "result": "LM-CC\u76f8\u6bd4\u50b3\u7d71\u6307\u6a19\u66f4\u5f37\u76f8\u95dc\u65bcLLM\u4efb\u52d9\u8868\u73fe\uff1b\u5be6\u9a57\u986f\u793a\u964d\u4f4eLM-CC\u76f4\u63a5\u63d0\u5347\u6a21\u578b\u6548\u679c\u3002", "conclusion": "LM-CC\u80fd\u66f4\u6e96\u78ba\u6355\u6349LLM\u8655\u7406\u4ee3\u78bc\u7684\u56f0\u96e3\uff0c\u70ba\u63d0\u5347\u6a21\u578b\u6027\u80fd\u53ca\u4ee3\u78bc\u7dad\u8b77\u63d0\u4f9b\u65b0\u5de5\u5177\u3002"}}
{"id": "2602.07893", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07893", "abs": "https://arxiv.org/abs/2602.07893", "authors": ["Zhiyuan Chen", "Soham Sanjay Deo", "Poorna Chander Reddy Puttaparthi", "Vanessa Nava-Camal", "Yiming Tang", "Xueling Zhang", "Weiyi Shang"], "title": "Is Your Private Information Logged? An Empirical Study on Android App Logs", "comment": null, "summary": "With the rapid growth of mobile apps, users' concerns about their privacy have become increasingly prominent. Android app logs serve as crucial computer resources, aiding developers in debugging and monitoring the status of Android apps, while also containing a wealth of software system information. Previous studies have acknowledged privacy leaks in software logs and Android apps as significant issues without providing a comprehensive view of the privacy leaks in Android app logs. In this study, we build a comprehensive dataset of Android app logs and conduct an empirical study to analyze the status and severity of privacy leaks in Android app logs. Our study comprises three aspects: (1) Understanding real-world developers' concerns regarding privacy issues related to software logs; (2) Studying privacy leaks in the Android app logs; (3) Investigating the characteristics of privacy-leaking Android app logs and analyzing the reasons behind them. Our study reveals five different categories of concerns from real-world developers regarding privacy issues related to software logs and the prevalence of privacy leaks in Android app logs, with the majority stemming from developers' unawareness of such leaks. Additionally, our study provides developers with suggestions to safeguard their privacy from being logged.", "AI": {"tldr": "\u672c\u6458\u8981\u7814\u7a76\u5b89\u5353\u5e94\u7528\u65e5\u5fd7\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u63ed\u793a\u5f00\u53d1\u8005\u5173\u5207\u3001\u6cc4\u9732\u72b6\u51b5\u53ca\u6210\u56e0\uff0c\u5e76\u63d0\u51fa\u9632\u62a4\u5efa\u8bae\u3002", "motivationavigator": "\u968f\u7740\u79fb\u52a8\u5e94\u7528\u5feb\u901f\u589e\u957f\uff0c\u7528\u6237\u9690\u79c1\u62c5\u5fe7\u52a0\u5267\uff1b\u5b89\u5353\u65e5\u5fd7\u4f5c\u4e3a\u5173\u952e\u8d44\u6e90\u542b\u654f\u611f\u4fe1\u606f\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5168\u9762\u8ba4\u8bc6\u9690\u79c1\u6cc4\u9732\u73b0\u72b6\u3002", "method": "\u6784\u5efa\u5b89\u5353\u5e94\u7528\u65e5\u5fd7\u6570\u636e\u96c6\uff0c\u5b9e\u8bc1\u7814\u7a76\u4e09\u65b9\u9762\uff1a\u5f00\u53d1\u8005\u5bf9\u65e5\u5fd7\u9690\u79c1\u7684\u5173\u5207\u3001 queen\u6cc4\u9732\u5b9e\u4f8b\u5206\u6790\u548c\u6cc4\u9732\u7279\u6027\u4e0e\u539f\u56e0\u63a2\u7a76\u3002", "result": "\u53d1\u73b0\u5f00\u53d1\u8005\u6709\u4e94\u7c7b\u9690\u79c1\u5173\u5207\uff1a\u6cc4\u9732\u666e\u904d\u56e0\u5f00\u53d1\u8005\u4e0d\u77e5\u60c5\uff1b\u57fa\u4e8e\u5206\u6790\u63d0\u4f9b\u9632\u6cc4\u9732\u5b9e\u64cd\u5efa\u8bae\u3002", "conclusion": "\u9690\u79c1\u6cc4\u9732\u4e25\u91cd\u6e90\u4e8e\u5f00\u53d1\u8005\u610f\u8bc6\u4e0d\u8db3\uff0c\u9700\u52a0\u5f3a\u5b89\u5168\u6559\u80b2\u5e76\u63d0\u4f9b\u9632\u62a4\u5de5\u5177\u4ee5\u4f18\u5316\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "Motivation analysis unavailable"}}
{"id": "2602.08004", "categories": ["cs.SE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.08004", "abs": "https://arxiv.org/abs/2602.08004", "authors": ["George Ling", "Shanshan Zhong", "Richard Huang"], "title": "Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality", "comment": null, "summary": "Agent skills extend large language model (LLM) agents with reusable, program-like modules that define triggering conditions, procedural logic, and tool interactions. As these skills proliferate in public marketplaces, it is unclear what types are available, how users adopt them, and what risks they pose. To answer these questions, we conduct a large-scale, data-driven analysis of 40,285 publicly listed skills from a major marketplace. Our results show that skill publication tends to occur in short bursts that track shifts in community attention. We also find that skill content is highly concentrated in software engineering workflows, while information retrieval and content creation account for a substantial share of adoption. Beyond content trends, we uncover a pronounced supply-demand imbalance across categories, and we show that most skills remain within typical prompt budgets despite a heavy-tailed length distribution. Finally, we observe strong ecosystem homogeneity, with widespread intent-level redundancy, and we identify non-trivial safety risks, including skills that enable state-changing or system-level actions. Overall, our findings provide a quantitative snapshot of agent skills as an emerging infrastructure layer for agents and inform future work on skill reuse, standardization, and safety-aware design.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e8640,285\u4e2a\u516c\u5f00LLM\u667a\u80fd\u4f53\u6280\u80fd\u7684\u5e02\u573a\u6570\u636e\uff0c\u63ed\u793a\u4e86\u6280\u80fd\u53d1\u5e03\u96c6\u4e2d\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u3001\u5b58\u5728\u4f9b\u9700\u5931\u8861\u4e0e\u5b89\u5168\u98ce\u9669\uff0c\u4e3a\u751f\u6001\u6807\u51c6\u5316\u63d0\u4f9b\u4f9d\u636e\u3002", "motivation": "\u63a2\u7a76\u516c\u5f00\u5e02\u573aLLM\u6280\u80fd\u7684\u7c7b\u578b\u5206\u5e03\u3001\u7528\u6237\u91c7\u7528\u6a21\u5f0f\u53ca\u6f5c\u5728\u98ce\u9669", "method": "\u5bf9\u4e3b\u6d41\u5e02\u573a40,285\u4e2a\u516c\u5f00\u6280\u80fd\u8fdb\u884c\u5927\u89c4\u6a21\u6570\u636e\u5206\u6790", "result": "\u6280\u80fd\u53d1\u5e03\u5448\u77ed\u671f\u7206\u53d1\u5f0f\u589e\u957f\uff0c\u9ad8\u5ea6\u96c6\u4e2d\u4e8e\u8f6f\u4ef6\u5de5\u7a0b/\u4fe1\u606f\u68c0\u7d22\uff1b\u591a\u6570\u6280\u80fd\u957f\u5ea6\u5408\u89c4\u4f46\u4ecd\u5b58\u5c3e\u90e8\u98ce\u9669\uff1b\u8bc6\u522b\u51fa\u610f\u56fe\u91cd\u590d\u6027\u9ad8\u53ca\u72b6\u6001\u7be1\u6539\u7b49\u5b89\u5168\u9690\u60a3", "conclusion": "\u91cf\u5316\u63ed\u793a\u4e86\u6280\u80fd\u751f\u6001\u7684\u540c\u8d28\u5316\u4e0e\u5b89\u5168\u98ce\u9669\uff0c\u4e3a\u6280\u80fd\u590d\u7528\u6807\u51c6\u5316\u548c\u5b89\u5168\u8bbe\u8ba1\u63d0\u4f9b\u51b3\u7b56\u4f9d\u636e"}}
{"id": "2602.08015", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08015", "abs": "https://arxiv.org/abs/2602.08015", "authors": ["Patricia G. F. Matsubara", "Tayana Conte"], "title": "Bridging the Gap: Adapting Evidence to Decision Frameworks to support the link between Software Engineering academia and industry", "comment": "Accepted for publication in ICSE 2026 - Future of Software Engineering", "summary": "Over twenty years ago, the Software Engineering (SE) research community have been involved with Evidence-Based Software Engineering (EBSE). EBSE aims to inform industrial practice with the best evidence from rigorous research, preferably from systematic literature reviews (SLRs). Since then, SE researchers have conducted many SLRs, perfected their SLR procedures, proposed alternative ways of presenting their results (such as Evidence Briefings), and profusely discussed how to conduct research that impacts practice. Nevertheless, there is still a feeling that SLRs' results are not reaching practitioners. Something is missing. In this vision paper, we introduce Evidence to Decision (EtD) frameworks from the health sciences, which propose gathering experts in panels to assess the existing best evidence about the impact of an intervention in all relevant outcomes and make structured recommendations based on them. The insight we can leverage from EtD frameworks is not their structure per se but all the relevant criteria for making recommendations to practitioners from SLRs. Furthermore, we provide a worked example based on an SE SLR. We also discuss the challenges the SE research and practice community may face when adopting EtD frameworks, highlighting the need for more comprehensive criteria in our recommendations to industry practitioners.", "AI": {"tldr": "\u6458\u8981\uff1a\u672c\u6587\u63a2\u8ba8\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff08SLR\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u4e2d\u5f71\u54cd\u6709\u9650\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u5f15\u5165\u5065\u5eb7\u79d1\u5b66\u7684\u8bc1\u636e\u81f3\u51b3\u7b56\uff08EtD\uff09\u6846\u67b6\uff0c\u4ee5\u6539\u5584\u8bc1\u636e\u9a71\u52a8\u5b9e\u8df5\u3002", "motivation": "\u52a8\u673a\uff1a\u5c3d\u7ba1\u8bc1\u636e\u9a71\u52a8\u8f6f\u4ef6\u5de5\u7a0b\uff08EBSE\uff09\u53d1\u5c55\u903e20\u5e74\uff0c\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\uff08SLR\uff09\u7684\u7ed3\u679c\u4ecd\u96be\u4ee5\u6709\u6548\u4f20\u8fbe\u7ed9\u884c\u4e1a\u4ece\u4e1a\u8005\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u7684\u63a8\u8350\u673a\u5236\u6765\u5f25\u5408\u7814\u7a76\u4e0e\u5b9e\u8df5\u7684\u5dee\u8ddd\u3002", "method": "\u65b9\u6cd5\uff1a\u501f\u9274\u5065\u5eb7\u79d1\u5b66\u9886\u57df\u7684EtD\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u5bb6\u5c0f\u7ec4\u8bc4\u4f30\u7814\u7a76\u8bc1\u636e\u3001\u7ed3\u6784\u5316\u63a8\u8350\u6807\u51c6\uff0c\u5e76\u4ee5\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684SLR\u6848\u4f8b\u8fdb\u884c\u5e94\u7528\u6f14\u793a\uff0c\u5206\u6790\u6f5c\u5728\u6311\u6218\u3002", "result": "\u7ed3\u679c\uff1aEtD\u6846\u67b6\u53ef\u63d0\u4f9b\u66f4\u5168\u9762\u6807\u51c6\u6307\u5bfc\u5b9e\u8df5\u63a8\u8350\uff0c\u63d0\u5347SLR\u5f71\u54cd\u529b\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u9762\u4e34\u4e13\u5bb6\u5171\u8bc6\u96be\u3001\u6807\u51c6\u6574\u5408\u7b49\u6311\u6218\uff0c\u9700\u8fdb\u4e00\u6b65\u5b8c\u5584\u6807\u51c6\u4f53\u7cfb\u3002", "conclusion": "\u7ed3\u8bba\uff1aEtD\u6846\u67b6\u6709\u671b\u589e\u5f3a\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u5b9e\u8df5\u5f71\u54cd\uff0c\u4fc3\u8fdb\u884c\u4e1a\u91c7\u7eb3\uff0c\u4f46\u5fc5\u987b\u89e3\u51b3\u6267\u884c\u969c\u788d\u5e76\u5f00\u53d1\u66f4\u5177\u5305\u5bb9\u6027\u7684\u63a8\u8350\u51c6\u5219\u3002"}}
{"id": "2602.08084", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08084", "abs": "https://arxiv.org/abs/2602.08084", "authors": ["Mark Looi", "Marc Szepan"], "title": "Outsourcing in Global Software Development: Effects of Temporal Location and Methodologies", "comment": "Published in International Journal of Business and Social Science International Journal of Business and Social Science, Vol. 12, No. 3; March 2021, DOI: 10.30845/ijbss.v12n3p3", "summary": "Developing software globally using outsourced resources has become a common practice, with project teams often distributed in different time zones. In this study, we focus on customers that contract software development to vendors in temporally nearshore or far offshore locations. We conducted a survey to determine the effect of temporal distance on overall success, costs, project management effort, schedule, quality, communication problems, and other outcomes of interest to managers. In the survey of 80 customers and interviews with 6 of them, we also investigated the effect of software development methodology on the same outcomes. The results show that nearshore development is advantageous for overall success, quality, reduced PM effort, maintaining schedule, higher quality, and engendering fewer communication problems. Development methodology appears to only influence higher costs. We assess our findings in the context of prior GSE research and provide practical advice for customers of outsourced global software development, chief of which is to favor nearshore for communication-intensive or Agile projects.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u65f6\u95f4\u8ddd\u79bb\u5bf9\u5168\u7403\u8f6f\u4ef6\u5916\u5305\u9879\u76ee\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8fd1\u5cb8\u5916\u5305\u5728\u6574\u4f53\u6210\u529f\u3001\u8d28\u91cf\u3001\u7ba1\u7406\u6548\u7387\u548c\u6c9f\u901a\u65b9\u9762\u4f18\u4e8e\u8fdc\u5cb8\u5916\u5305\uff0c\u5f00\u53d1\u65b9\u6cd5\u4ec5\u589e\u52a0\u6210\u672c\u3002", "motivation": "\u5168\u7403\u8f6f\u4ef6\u5f00\u53d1\u4e2d\uff0c\u5916\u5305\u56e2\u961f\u5206\u5e03\u4e8e\u4e0d\u540c\u65f6\u533a\u3002\u5ba2\u6237\u5e38\u5916\u5305\u7ed9\u65f6\u95f4\u8ddd\u79bb\u8fd1\uff08ui\u00e7\u00e3o\u8fd1\u5cb8\uff09\u6216\u8fdc\uff08\u8fdc\u5cb8\uff09\u7684\u5382\u5546\uff0c\u9700\u4e86\u89e3\u65f6\u95f4\u8ddd\u79bb\u548c\u65b9\u6cd5\u8bba\u5bf9\u9879\u76ee\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u8c03\u67e580\u540d\u5ba2\u6237\u5e76\u8fdb\u884c\u6df1\u5ea6\u8bbf\u8c08\u5176\u4e2d6\u4eba\uff0c\u8bc4\u4f30\u65f6\u95f4\u8ddd\u79bb\u548c\u8f6f\u4ef6\u5f00\u53d1\u65b9\u6cd5\u5bf9\u6210\u529f\u3001\u6210\u672c\u3001\u7ba1\u7406\u52aa\u529b\u3001\u8fdb\u5ea6\u7b49\u53d8\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u8fd1\u5cb8\u5f00\u53d1\u5bf9\u6574\u4f53\u6210\u529f\u3001\u8d28\u91cf\u63d0\u5347\u3001\u51cf\u5c11\u7ba1\u7406\u52aa\u529b\u3001\u6309\u65f6\u5b8c\u6210\u548c\u964d\u4f4e\u6c9f\u901a\u95ee\u9898\u6709\u4f18\u52bf\uff1b\u5f00\u53d1\u65b9\u6cd5\u4ec5\u5bfc\u81f4\u66f4\u9ad8\u6210\u672c\u3002", "conclusion": "\u5728\u4ee5\u5f80\u7814\u7a76\u57fa\u7840\u4e0a\uff0c\u5efa\u8bae\u5ba2\u6237\u4f18\u5148\u9009\u62e9\u8fd1\u5cb8\u5916\u5305\uff0c\u5c24\u5176\u9488\u5bf9\u6c9f\u901a\u5bc6\u96c6\u6216\u654f\u6377\u9879\u76ee\uff0c\u4ee5\u63d0\u9ad8 favorable\u6548\u679c\u3002"}}
{"id": "2602.08133", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08133", "abs": "https://arxiv.org/abs/2602.08133", "authors": ["Mojtaba Mostafavi Ghahfarokhi", "Hamed Jahantigh", "Alireza Asadi", "Abbas Heydarnoori"], "title": "Integrating Code Metrics into Automated Documentation Generation for Computational Notebooks", "comment": null, "summary": "Effective code documentation is essential for collaboration, comprehension, and long-term software maintainability, yet developers often neglect it due to its repetitive nature. Automated documentation generation has evolved from heuristic and rule-based methods to neural network-based and large language model (LLM)-based approaches. However, existing methods often overlook structural and quantitative characteristics of code that influence readability and comprehension. Prior research suggests that code metrics capture information relevant to program understanding. Building on these insights, this paper investigates the role of source code metrics as auxiliary signals for automated documentation generation, focusing on computational notebooks, a popular medium among data scientists that integrates code, narrative, and results but suffers from inconsistent documentation. We propose a two-stage approach. First, the CodeSearchNet dataset construction process was refined to create a specialized dataset from over 17 million code and markdown cells. After structural and semantic filtering, approximately 36,734 high-quality (code, markdown) pairs were extracted. Second, two modeling paradigms, a lightweight CNN-RNN architecture and a few-shot GPT-3.5 architecture, were evaluated with and without metric information. Results show that incorporating code metrics improves the accuracy and contextual relevance of generated documentation, yielding gains of 6% in BLEU-1 and 3% in ROUGE-L F1 for CNN-RNN-based architecture, and 9% in BERTScore F1 for LLM-based architecture. These findings demonstrate that integrating code metrics provides valuable structural context, enhancing automated documentation generation across diverse model families.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5229\u7528\u4ee3\u7801\u5ea6\u91cf\u4f5c\u4e3a\u8f85\u52a9\u4fe1\u53f7\u63d0\u5347\u81ea\u52a8\u5316\u6587\u6863\u751f\u6210\u6548\u679c\uff0c\u7279\u522b\u9488\u5bf9\u8ba1\u7b97\u7b14\u8bb0\u672c\u73af\u5883\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u6587\u6863\u751f\u6210\u65b9\u6cd5\u5e38\u5ffd\u89c6\u4ee3\u7801\u7ed3\u6784\u4e0e\u91cf\u5316\u7279\u5f81\u5bf9\u53ef\u8bfb\u6027\u7684\u5f71\u54cd\uff0c\u4e14\u8ba1\u7b97\u7b14\u8bb0\u672c\u5b58\u5728\u6587\u6863\u4e0d\u89c4\u8303\u95ee\u9898\u3002\u4ee3\u7801\u5ea6\u91cf\uff08\u5982\u590d\u6742\u5ea6\u6307\u6807\uff09\u53ef\u80fd\u8574\u542b\u7406\u89e3\u4ee3\u7801\u7684\u5173\u952e\u4fe1\u606f\uff0c\u9700\u63a2\u7d22\u5176\u5bf9\u6587\u6863\u751f\u6210\u7684\u8865\u5145\u4ef7\u503c\u3002", "method": "1) \u91cd\u6784CodeSearchNet\u6570\u636e\u96c6\u6784\u5efa\u6d41\u7a0b\uff0c\u4ece1700\u4eba\u306e\u4e07\u4ee3\u7801/\u6807\u8bb0\u5355\u5143\u4e2d\u7ecf\u7ed3\u6784/\u8bed\u4e49\u7b5b\u9009\uff0c\u63d0\u53d636,734\u7ec4\u9ad8\u8d28\u91cf(\u4ee3\u7801,\u6587\u6863)\u5bf9\uff1b2) \u5728\u8f7b\u91cf\u7ea7CNN-RNN\u4e0e\u5c11\u6837\u672cGPT-3.5\u67b6\u6784\u4e0a\u5bf9\u6bd4\u5f15\u5165\u4ee3\u7801\u5ea6\u91cf\u524d\u540e\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u52a0\u5165\u4ee3\u7801\u5ea6\u91cf\u540e\uff1aCNN-RNN\u6a21\u578b\u7684BLEU-1\u63d0\u53476%\uff0cROUGE-L F1\u63d0\u53473%\uff1bGPT-3.5\u7684BERTScore F1\u63d0\u53479%\uff0c\u751f\u6210\u6587\u6863\u7684\u51c6\u786e\u6027\u53ca\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u5747\u663e\u8457\u589e\u5f3a\u3002", "conclusion": "\u4ee3\u7801\u5ea6\u91cf\u4e3a\u6587\u6863\u751f\u6210\u63d0\u4f9b\u5173\u952e\u7ed3\u6784\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u80fd\u8de8\u6a21\u578b\u63d0\u5347\u81ea\u52a8\u5316\u6587\u6863\u8d28\u91cf\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u6837\u5316\u67b6\u6784\u4e2d\u7684\u901a\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.08166", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08166", "abs": "https://arxiv.org/abs/2602.08166", "authors": ["Oscar Manglaras", "Alex Farkas", "Thomas Woolford", "Christoph Treude", "Markus Wagner"], "title": "Distributed Architecture Reconstruction of Polyglot and Multi-Repository Microservice Projects", "comment": null, "summary": "Microservice architectures encourage the use of small, independently developed services; however, this can lead to increased architectural complexity. Accurate documentation is crucial, but is challenging to maintain due to the rapid, independent evolution of services. While static architecture reconstruction provides a way to maintain up-to-date documentation, existing approaches suffer from technology limitations, mono-repo constraints, or high implementation barriers. This paper presents a novel framework for static architecture reconstruction that supports technology-specific analysis modules, called \\emph{extractors}, and supports \\emph{distributed architecture reconstruction} in multi-repo environments. We describe the core design concepts and algorithms that govern how extractors are executed, how data is passed between them, and how their outputs are unified. Furthermore, the framework is interoperable with existing static analysis tools and algorithms, allowing them to be invoked from or embedded within extractors.", "AI": {"tldr": "\u63d0\u51fa\u65b0\u578b\u9759\u6001\u67b6\u6784\u91cd\u6784\u6846\u67b6\uff0c\u89e3\u51b3\u5fae\u670d\u52a1\u6587\u6863\u66f4\u65b0\u96be\u9898", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u5bfc\u81f4\u590d\u6742\u5ea6\u589e\u52a0\uff0c\u73b0\u6709\u9759\u6001\u91cd\u6784\u65b9\u6cd5\u5b58\u5728\u6280\u672f\u5c40\u9650\u3001\u5355\u4ed3\u5e93\u4f9d\u8d56\u548c\u5b9e\u65bd\u95e8\u69db\u9ad8\u7684\u95ee\u9898", "method": "\u8bbe\u8ba1\u652f\u6301\u591a\u4ed3\u5e93\u5206\u5e03\u5f0f\u67b6\u6784\u91cd\u6784\u6846\u67b6\uff0c\u901a\u8fc7\u6280\u672f\u4e13\u7528\u63d0\u53d6\u5668\u6a21\u5757\u5b9e\u73b0\u8de8\u5de5\u5177\u4e92\u64cd\u4f5c\uff0c\u6838\u5fc3\u7b97\u6cd5\u5904\u7406\u63d0\u53d6\u5668\u8c03\u5ea6\u4e0e\u6570\u636e\u6574\u5408", "result": "\u6846\u67b6\u7a81\u7834\u6280\u672f\u9650\u5236\u4e0e\u4ed3\u5e93\u7ea6\u675f\uff0c\u53ef\u96c6\u6210\u73b0\u6709\u9759\u6001\u5206\u6790\u5de5\u5177\u5b9e\u73b0\u6301\u7eed\u6587\u6863\u66f4\u65b0", "conclusion": "\u8be5\u65b9\u6848\u4e3a\u5feb\u901f\u6f14\u8fdb\u7684\u5fae\u670d\u52a1\u7cfb\u7edf\u63d0\u4f9b\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u5b9e\u65f6\u67b6\u6784\u6587\u6863\u7ef4\u62a4\u80fd\u529b"}}
{"id": "2602.08181", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08181", "abs": "https://arxiv.org/abs/2602.08181", "authors": ["Oscar Manglaras", "Alex Farkas", "Thomas Woolford", "Christoph Treude", "Markus Wagner"], "title": "ModARO: A Modular Approach to Architecture Reconstruction of Distributed Microservice Codebases", "comment": null, "summary": "Microservice architectures promote small, independently developed services, but increase overall architectural complexity. It is crucial that developers understand the architecture and how changes to a service affect the overall system, but rapid and independent development of services increases the risk of architectural drift and discourages the creation and maintenance of documentation. Automatic architecture reconstruction can help avoid these issues, but it is difficult to reuse reconstruction code across multiple projects, as all use different combinations of technologies and project-specific conventions. Reconstruction of architecture-level details is further complicated by the tendency to split microservices into separate repositories, preventing a full view of the system from any one codebase. In this paper, we present and evaluate ModARO, an approach to microservice architecture reconstruction that allows writing modular reconstruction code ('extractors') for any technologies and reusing them across different projects, independent of the surrounding technology stack or whether or not the services are split into multiple codebases. We demonstrate the effectiveness of our approach by configuring ModARO to reconstruct 10 open source projects, and we validate the usefulness and usability of ModARO against a state-of-the-art baseline in a user study with 8 industry practitioners. Using this approach, developers can assemble or create extractors tailored to their technology stacks and distribute architecture reconstruction across repositories, enabling integration into repository CI/CD pipelines.", "AI": {"tldr": "ModARO\u662f\u4e00\u79cd\u5fae\u670d\u52a1\u67b6\u6784\u91cd\u6784\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u63d0\u53d6\u5668\u652f\u6301\u8de8\u4e0d\u540c\u6280\u672f\u5806\u6808\u548c\u4ed3\u5e93\u7684\u91cd\u7528\uff0c\u907f\u514d\u4e86\u67b6\u6784\u6f02\u79fb\u548c\u6587\u6863\u7ef4\u62a4\u96be\u9898\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u589e\u52a0\u4e86\u7cfb\u7edf\u590d\u6742\u6027\uff0c\u53d8\u66f4\u6613\u5bfc\u81f4\u67b6\u6784\u6f02\u79fb\u4e14\u6587\u6863\u7ef4\u62a4\u56f0\u96be\uff1b\u73b0\u6709\u81ea\u52a8\u91cd\u6784\u5de5\u5177\u96be\u4ee5\u590d\u7528\uff0c\u9700\u89e3\u51b3\u8de8\u9879\u76ee\u548c\u788e\u7247\u5316\u4ed3\u5e93\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1ModARO\u65b9\u6cd5\uff0c\u7f16\u5199\u53ef\u5b9a\u5236\u7684\u6a21\u5757\u5316\u67b6\u6784\u63d0\u53d6\u5668\uff1b\u8bc4\u4f30\u5305\u62ec\u91cd\u678410\u4e2a\u5f00\u6e90\u9879\u76ee\u548c\u4f7f\u75288\u540d\u4ece\u4e1a\u8005\u7684\u7528\u6237\u7814\u7a76\u5bf9\u6bd4\u57fa\u7ebf\u5de5\u5177\u3002", "result": "\u6210\u529f\u91cd\u6784\u6240\u6709\u9879\u76ee\uff0c\u7528\u6237\u7814\u7a76\u8868\u660eModARO\u5728\u5b9e\u7528\u6027\u548c\u53ef\u7528\u6027\u4e0a\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5f00\u53d1\u8005\u53ef\u9ad8\u6548\u5b9a\u5236\u63d0\u53d6\u5668\u3002", "conclusion": "ModARO\u652f\u6301\u7075\u6d3b\u96c6\u6210\u5230CI/CD\u7ba1\u9053\uff0c\u63d0\u5347\u67b6\u6784\u7406\u89e3\u548c\u7ba1\u7406\u6548\u7387\uff0c\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u5fae\u670d\u52a1\u73af\u5883\u3002"}}
{"id": "2602.08192", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08192", "abs": "https://arxiv.org/abs/2602.08192", "authors": ["Mirko Perkusich", "Danyllo Albuquerque", "Allysson Allex Ara\u00fajo", "Matheus Paix\u00e3o", "Rohit Gheyi", "Marcos Kalinowski", "Angelo Perkusich"], "title": "Adoption of Large Language Models in Scrum Management: Insights from Brazilian Practitioners", "comment": "Accepted for publication at the 27th International Conference on Agile Software Development (XP 2026)", "summary": "Scrum is widely adopted in software project management due to its adaptability and collaborative nature. The recent emergence of Large Language Models (LLMs) has created new opportunities to support knowledge-intensive Scrum practices. However, existing research has largely focused on technical activities such as coding and testing, with limited evidence on the use of LLMs in management-related Scrum activities. In this study, we investigate the use of LLMs in Scrum management activities through a survey of 70 Brazilian professionals. Among them, 49 actively use Scrum, and 33 reported using LLM-based assistants in their Scrum practices. The results indicate a high level of proficiency and frequent use of LLMs, with 85% of respondents reporting intermediate or advanced proficiency and 52% using them daily. LLM use concentrates on exploring Scrum practices, with artifacts and events receiving targeted yet uneven support, whereas broader management tasks appear to be adopted more cautiously. The main benefits include increased productivity (78%) and reduced manual effort (75%). However, several critical risks remain, as respondents report 'almost correct' outputs (81%), confidentiality concerns (63%), and hallucinations during use (59%). This work provides one of the first empirical characterizations of LLM use in Scrum management, identifying current practices, quantifying benefits and risks, and outlining directions for responsible adoption and integration in Agile environments.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e570\u540d\u5df4\u897f\u4ece\u4e1a\u8005\u5728Scrum\u7ba1\u7406\u4e2d\u5e94\u7528LLMs\u7684\u73b0\u72b6\uff0c\u7ed3\u679c\u663e\u793a\u8f83\u9ad8\u4f7f\u7528\u9891\u7387\u548c\u719f\u7ec3\u5ea6\uff0c\u4f46\u5b58\u5728\u8f93\u51fa\u51c6\u786e\u6027\u3001\u9690\u79c1\u548c\u5e7b\u89c9\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8LLMs\u5728\u7f16\u7801\u6d4b\u8bd5\u7b49\u6280\u672f\u6d3b\u52a8\u4e2d\u7684\u5e94\u7528\uff0c\u800c\u7ba1\u7406\u76f8\u5173\u7684Scrum\u6d3b\u52a8\u7814\u7a76\u7f3a\u4e4f\u5b9e\u8bc1\uff0c\u9700\u586b\u8865\u6b64\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u95ee\u5377\u8c03\u67e5\u6cd5\uff0c\u8c03\u781470\u540d\u5df4\u897f\u4e13\u4e1a\u4eba\u58eb\uff08\u5176\u4e2d49\u540d\u4f7f\u7528Scrum\uff0c33\u540d\u5728Scrum\u4e2d\u5e94\u7528LLM\u52a9\u624b\uff09\u3002", "result": "85%\u7528\u6237\u8fbe\u4e2d\u9ad8\u7ea7\u719f\u7ec3\u5ea6\uff0c52%\u6bcf\u65e5\u4f7f\u7528\uff1bLLM\u4e3b\u8981\u7528\u4e8eScrum\u5de5\u4ef6\u548c\u4e8b\u4ef6\uff08\u751f\u4ea7\u529b\u63d0\u534778%\uff0c\u4eba\u5de5\u8d1f\u62c5\u51cf\u5c1175%\uff09\uff0c\u4f46\u98ce\u9669\u7a81\u51fa\uff1a81%\u906d\u9047'\u8fd1\u4e4e\u6b63\u786e'\u8f93\u51fa\uff0c63%\u62c5\u5fe7\u4fdd\u5bc6\u6027\uff0c59%\u51fa\u73b0\u5e7b\u89c9\u3002", "conclusion": "\u9996\u6b21\u5b9e\u8bc1\u523b\u753bLLMs\u5728Scrum\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\u573a\u666f\uff0c\u91cf\u5316\u6536\u76ca\u4e0e\u98ce\u9669\uff0c\u4e3a\u654f\u6377\u73af\u5883\u4e0b\u8d1f\u8d23\u4efb\u96c6\u6210\u63d0\u51fa\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2602.08263", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08263", "abs": "https://arxiv.org/abs/2602.08263", "authors": ["Taohong Zhu", "Lucas C. Cordeiro", "Mustafa A. Mustafa", "Youcheng Sun"], "title": "Specification Vibing for Automated Program Repair", "comment": null, "summary": "Large language model (LLM)-driven automated program repair (APR) has advanced rapidly, but most methods remain code-centric: they directly rewrite source code and thereby risk hallucinated, behaviorally inconsistent fixes. This limitation suggests the need for an alternative repair paradigm that relies on a representation more accessible to LLMs than raw code, enabling more accurate understanding, analysis, and alignment during repair. To address this gap, we propose VibeRepair, a specification-centric APR technique that treats repair as behavior-specification repair rather than ad-hoc code editing. VibeRepair first translates buggy code into a structured behavior specification that captures the program's intended runtime behavior, then infers and repairs specification misalignments, and finally synthesizes code strictly guided by the corrected behavior specification. An on-demand reasoning component enriches hard cases with program analysis and historical bug-fix evidence while controlling cost. Across Defects4J and real-world benchmarks and multiple LLMs, VibeRepair demonstrates consistently strong repair effectiveness with a significantly smaller patch space. On Defects4J v1.2, VibeRepair correctly repairs 174 bugs, exceeding the strongest state-of-the-art baseline by 28 bugs, which corresponds to a 19% improvement. On Defects4J v2.0, it repairs 178 bugs, outperforming prior approaches by 33 bugs, representing a 23% improvement. Evaluations on real-world benchmarks collected after the training period of selected LLMs further confirm its effectiveness and generalizability. By centering repair on explicit behavioral intent, VibeRepair reframes APR for the era of \"vibe\" coding: make the behavior sing, and the code will follow.", "AI": {"tldr": "VibeRepair\uff1a\u901a\u8fc7\u5c06\u4fee\u590d\u7126\u70b9\u4ece\u4ee3\u7801\u8f6c\u5411\u884c\u4e3a\u89c4\u8303\uff0c\u663e\u8457\u63d0\u5347LLM\u9a71\u52a8\u7a0b\u5e8f\u4fee\u590d\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\u76f4\u63a5\u4fee\u6539\u4ee3\u7801\uff0c\u6613\u4ea7\u751f\u5e7b\u89c9\u4fee\u590d\u4e0e\u884c\u4e3a\u4e0d\u4e00\u81f4\uff0c\u9700\u8f6c\u5411\u66f4\u9002\u5408LLM\u7406\u89e3\u7684\u4e2d\u95f4\u8868\u793a\u5f62\u5f0f\u3002", "method": "\u5c06\u9519\u8bef\u4ee3\u7801\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u884c\u4e3a\u89c4\u8303\uff0c\u4fee\u590d\u89c4\u8303\u504f\u5dee\u540e\u6309\u89c4\u8303\u5408\u6210\u4ee3\u7801\uff1b\u96be\u4f8b\u4e2d\u91c7\u7528\u6309\u9700\u7a0b\u5e8f\u5206\u6790\u4e0e\u5386\u53f2\u4fee\u590d\u8bc1\u636e\u589e\u5f3a\u767d\u8336\u63a8\u7406\u3002", "result": "Defects4J v1.2\u4fee\u590d174\u4e2a\u9519\u8bef\uff08\u8d85\u8d8aSOTA 28\u4e2a\uff0c\u63d0\u534719%\uff09\uff1bv2.0\u4fee\u590d178\u4e2a\u9519\u8bef\uff08\u8d85\u8d8a33\u4e2a\uff0c\u63d0\u534723%\uff09\uff1b\u771f\u5b9e\u573a\u666f\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u6cdb\u5316\u6027\u3002", "conclusion": "\u4ee5\u660e\u786e\u884c\u4e3a\u610f\u56fe\u4e3a\u6838\u5fc3\u7684\u89c4\u8303\u4fee\u590d\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7cbe\u5ea6\u4e0e\u66f4\u5c0fbein\u8865\u4e01\u7a7a\u95f4\u7684\u7a0b\u5e8f\u4fee\u590d\u3002"}}
{"id": "2602.08765", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08765", "abs": "https://arxiv.org/abs/2602.08765", "authors": ["Micah Villmow"], "title": "Taming Scylla: Understanding the multi-headed agentic daemon of the coding seas", "comment": "32 Pages, 7 Figures", "summary": "LLM-based tools are automating more software development tasks at a rapid pace, but there is no rigorous way to evaluate how different architectural choices -- prompts, skills, tools, multi-agent setups -- materially affect both capability and cost. This paper introduces Scylla, an evaluation framework for benchmarking agentic coding tools through structured ablation studies that uses seven testing tiers (T0-T6) progressively adding complexity to isolate what directly influences results and how. The key metric is Cost-of-Pass (CoP): the expected dollar cost to get one correct solution, which directly quantifies the trade-off between complexity and efficiency. The framework is model-agnostic, designed to work with any CLI tool; this paper demonstrates it with Claude Sonnet 4.5, using multiple LLM judges (Opus 4.5, Sonnet 4.5, Haiku 4.5) from the same vendor for evaluation consensus, where judges score results using direct tests, human-designed LLM-evaluated rubrics, and qualitative assessment. The result is a reproducible framework that quantifies trade-offs between agent complexity and actual outcomes, suggesting that architectural complexity does not always improve quality.", "AI": {"tldr": "\u63d0\u51faScylla\u6846\u67b6\uff0c\u901a\u8fc7\u4e03\u7ea7\u6d4b\u8bd5\u4e0eCoP\u6307\u6807\u91cf\u5316\u667a\u80fd\u4f53\u67b6\u6784\u590d\u6742\u6027\u5bf9\u7f16\u7801\u5de5\u5177\u80fd\u529b\u4e0e\u6210\u672c\u7684\u5f71\u54cd", "motivation": "\u5f53\u524dLLM\u5de5\u5177\u7814\u53d1\u7f3a\u4e4f\u8bc4\u4f30\u4e0d\u540c\u67b6\u6784\u9009\u62e9\uff08\u63d0\u793a/\u6280\u80fd/\u5de5\u5177/\u591a\u667a\u80fd\u4f53\uff09\u5bf9\u80fd\u529b\u4e0e\u6210\u672c\u5f71\u54cd\u7684\u4e25\u8c28\u65b9\u6cd5", "method": "\u91c7\u7528\u5206\u7ea7\u6d4b\u8bd5\u67b6\u6784\uff08T0-T6\uff09\u8fdb\u884c\u6d88\u878d\u7814\u7a76\uff0c\u4ee5\u6210\u672c\u901a\u8fc7\u7387\uff08CoP\uff09\u4e3a\u6838\u5fc3\u6307\u6807\uff1b\u6846\u67b6\u6a21\u578b\u65e0\u5173\uff0c\u4f7f\u7528Claude Sonnet 4.5\u6f14\u793a\uff0c\u5e76\u7531\u591aLLM\u8bc4\u5ba1\uff08Opus/Sonnet/Haiku 4.5\uff09\u901a\u8fc7\u6d4b\u8bd5/\u91cf\u89c4/\u5b9a\u6027\u8bc4\u4f30\u8fbe\u6210\u5171\u8bc6", "result": "\u6784\u5efa\u4e86\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8bc1\u660e\u67b6\u6784\u590d\u6742\u6027\u4e0e\u4ea7\u51fa\u8d28\u91cf\u672a\u5448\u73b0\u5fc5\u7136\u6b63\u76f8\u5173", "conclusion": "Scylla\u6709\u6548\u91cf\u5316\u4e86\u590d\u6742\u6027\u4e0e\u6548\u7387\u7684\u5e73\u8861\u5173\u7cfb\uff0c\u4e3a\u667a\u80fd\u7f16\u7801\u5de5\u5177\u7684\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6570\u636e\u5316\u51b3\u7b56\u4f9d\u636e"}}
{"id": "2602.08866", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08866", "abs": "https://arxiv.org/abs/2602.08866", "authors": ["Bang Xie", "Senjian Zhang", "Zhiyuan Peng", "Wei Chen", "Chenhao Ying", "Yuan Luo"], "title": "ArkEval: Benchmarking and Evaluating Automated CodeRepair for ArkTS", "comment": null, "summary": "Large language models have transformed code generation, enabling unprecedented automation in software development. As mobile ecosystems evolve, HarmonyOS has emerged as a critical platform requiring robust development tools. Software development for the HarmonyOS ecosystem relies heavily on ArkTS, a statically typed extension of TypeScript. Despite its growing importance, the ecosystem lacks robust tools for automated code repair, primarily due to the absence of a high-quality benchmark for evaluation. To address this gap, we present ArkEval, a unified framework for ArkTS automated repair workflow evaluation and benchmark construction. It provides the first comprehensive benchmark specifically designed for ArkTS automated program repair. We constructed this benchmark by mining issues from a large-scale official Huawei repository containing over 400 independent ArkTS applications. Through a rigorous multi-stage filtering process, we curated 502 reproducible issues. To ensure testability, we employed a novel LLM-based test generation and voting mechanism involving Claude and other models. Furthermore, we standardized problem statements to facilitate fair evaluation. Finally, we evaluated four state-of-the-art Large Language Models (LLMs) on our benchmark using a retrieval-augmented repair workflow. Our results highlight the current capabilities and limitations of LLMs in repairing ArkTS code, paving the way for future research in this low-resource language domain.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faArkEval\u6846\u67b6\uff0c\u9996\u4e2a\u9488\u5bf9ArkTS\u81ea\u52a8\u5316\u4fee\u590d\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u901a\u8fc7\u6316\u6398\u534e\u4e3a\u4ed3\u5e93\u6784\u5efa502\u4e2a\u53ef\u590d\u73b0\u95ee\u9898\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4fee\u590d\u80fd\u529b\u4e0e\u5c40\u9650\u3002", "motivation": "\u9e3f\u8499\u751f\u6001\u7cfb\u7edf\u7f3a\u4e4fArkTS\u8bed\u8a00\u7684\u81ea\u52a8\u5316\u4ee3\u7801\u4fee\u590d\u5de5\u5177\uff0c\u4e3b\u8981\u7531\u4e8e\u9ad8\u8d28\u91cf\u8bc4\u4f30\u57fa\u51c6\u7f3a\u5931\uff0c\u963b\u788d\u4e86\u5f00\u53d1\u5de5\u5177\u8fdb\u5c55\u3002", "method": "\u4ece\u534e\u4e3a\u5b98\u65b9\u5927\u578b\u4ed3\u5e93400\u591a\u4e2a\u72ec\u7acbArkTS\u5e94\u7528\u4e2d\u6316\u6398\u95ee\u9898\uff0c\u7ecf\u591a\u9636\u6bb5\u7b5b\u9009\u83b7\u5f97502\u4e2a\u53ef\u590d\u73b0\u6837\u672c\uff1b\u5229\u7528Claude\u7b49LLM\u8fdb\u884c\u65b0\u9896\u6d4b\u8bd5\u751f\u6210\u4e0e\u6295\u7968\u673a\u5236\u786e\u4fdd\u6d4b\u8bd5\u6027\uff1b\u6807\u51c6\u5316\u95ee\u9898\u63cf\u8ff0\uff1b\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u4fee\u590d\u6d41\u7a0b\u8bc4\u4f30\u56db\u79cd\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4fee\u590dArkTS\u4ee3\u7801\u65f6\u63ed\u793a\u4e86\u5f53\u524d\u80fd\u529b\u548c\u5c40\u9650\u6027\uff0c\u5982\u4fee\u590d\u6210\u529f\u7387\u7684\u5dee\u8ddd\u3002", "conclusion": "\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00ArkTS\u7684\u672a\u6765\u7814\u7a76\u94fa\u5e73\u9053\u8def\uff0c\u63a8\u52a8\u81ea\u52a8\u5316\u4fee\u590d\u5de5\u5177\u53d1\u5c55\u3002"}}
{"id": "2602.08887", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08887", "abs": "https://arxiv.org/abs/2602.08887", "authors": ["Adam Trendowicz", "Daniel Seifert", "Andreas Jedlitschka", "Marcus Ciolkowski", "Anton Strahilov"], "title": "DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories", "comment": null, "summary": "Generative artificial intelligence (GAI), specifically large language models (LLMs), are increasingly used in software engineering, mainly for coding tasks. However, requirements engineering - particularly requirements validation - has seen limited application of GAI. The current focus of using GAI for requirements is on eliciting, transforming, and classifying requirements, not on quality assessment. We propose and evaluate the LLM-based (GPT-4o) approach \"DeepQuali\", for assessing and improving requirements quality in agile software development. We applied it to projects in two small companies, where we compared LLM-based quality assessments with expert judgments. Experts also participated in walkthroughs of the solution, provided feedback, and rated their acceptance of the approach. Experts largely agreed with the LLM's quality assessments, especially regarding overall ratings and explanations. However, they did not always agree with the other experts on detailed ratings, suggesting that expertise and experience may influence judgments. Experts recognized the usefulness of the approach but criticized the lack of integration into their workflow. LLMs show potential in supporting software engineers with the quality assessment and improvement of requirements. The explicit use of quality models and explanatory feedback increases acceptance.", "AI": {"tldr": "\u751f\u6210\u4eba\u5de5\u667a\u80fd\u5728\u9700\u6c42\u5de5\u7a0b\u9a8c\u8bc1\u4e2d\u5e94\u7528\u6709\u9650\uff1b\u672c\u7814\u7a76\u63d0\u51faDeepQuali\u65b9\u6cd5\uff0c\u57fa\u4e8eLLM\u8bc4\u4f30\u654f\u6377\u5f00\u53d1\u9700\u6c42\u8d28\u91cf\uff0c\u4e13\u5bb6\u8ba4\u53ef\u5176\u6574\u4f53\u8bc4\u4f30\u7ed3\u679c\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u4eba\u5de5\u667a\u80fd\u805a\u7126\u9700\u6c42\u83b7\u53d6\u4e0e\u5206\u7c7b\uff0c\u7f3a\u4e4f\u8d28\u91cf\u8bc4\u4f30\u7814\u7a76\uff1bDeepQuali\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u5347\u9700\u6c42\u9a8c\u8bc1\u6548\u7387\u3002", "method": "\u5728\u4e24\u4e2a\u5c0f\u578b\u516c\u53f8\u9879\u76ee\u4e2d\u90e8\u7f72DeepQuali\uff08\u4f7f\u7528GPT-4o\uff09\uff0c\u6bd4\u8f83LLM\u8d28\u91cf\u8bc4\u4f30\u4e0e\u4e13\u5bb6\u5224\u65ad\uff0c\u5305\u62ec\u4e13\u5bb6\u6f14\u7ec3\u548c\u63a5\u53d7\u5ea6\u8bc4\u5206\u3002", "result": "\u4e13\u5bb6\u9ad8\u5ea6\u8ba4\u53efLLM\u7684\u6574\u4f53\u8bc4\u4f30\u53ca\u89e3\u91ca\uff0c\u4f46\u4e13\u5bb6\u95f4\u8be6\u7ec6\u8bc4\u7ea7\u5b58\u5728\u5206\u6b67\uff1b\u53d7\u8bbf\u8005\u8ba4\u540c\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u4f46\u6279\u8bc4\u5de5\u4f5c\u6d41\u7a0b\u96c6\u6210\u56f0\u96be\u3002", "conclusion": "LLM\u5728\u9700\u6c42\u8d28\u91cf\u8bc4\u4f30\u5177\u6709\u6f5c\u529b\uff1b\u660e\u786e\u8d28\u91cf\u6a21\u578b\u548c\u89e3\u91ca\u53cd\u9988\u53ef\u63d0\u9ad8\u63a5\u53d7\u5ea6\uff0c\u4f46\u9700\u4f18\u5316\u96c6\u6210\u3002"}}
{"id": "2602.08915", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08915", "abs": "https://arxiv.org/abs/2602.08915", "authors": ["Giovanni Pinna", "Jingzhi Gong", "David Williams", "Federica Sarro"], "title": "Comparing AI Coding Agents: A Task-Stratified Analysis of Pull Request Acceptance", "comment": "Accepted by MSR'26 Mining Challenge Track", "summary": "The rapid adoption of AI-powered coding assistants is transforming software development practices, yet systematic comparisons of their effectiveness across different task types and over time remain limited. This paper presents an empirical study comparing five popular agents (OpenAI Codex, GitHub Copilot, Devin, Cursor, and Claude Code), analyzing 7,156 pull requests (PRs) from the AIDev dataset. Temporal trend analysis reveals heterogeneous evolution patterns: Devin exhibits the only consistent positive trend in acceptance rate (+0.77% per week over 32 weeks), whereas other agents remain largely stable. Our analysis suggests that the PR task type is a dominant factor influencing acceptance rates: documentation tasks achieve 82.1% acceptance compared to 66.1% for new features - a 16 percentage point gap that exceeds typical inter-agent variance for most tasks. OpenAI Codex achieves consistently high acceptance rates across all nine task categories (59.6%-88.6%), with stratified Chi-square tests confirming statistically significant advantages over other agents in several task categories. However, no single agent performs best across all task types: Claude Code leads in documentation (92.3%) and features (72.6%), while Cursor excels in fix tasks (80.4%).", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e94\u79cdAI\u7f16\u7a0b\u52a9\u624b\u7684\u5b9e\u6548\uff1aDevin\u63a5\u53d7\u7387\u6301\u7eed\u4e0a\u5347\uff0c\u4efb\u52a1\u7c7b\u578b\u4e3b\u5bfc\u63a5\u53d7\u7387\u5dee\u5f02\uff0c\u5982\u6587\u6863\u4efb\u52a1\u6bd4\u65b0\u7279\u5f81\u9ad816%\uff1bOpenAI\u7efc\u5408\u8868\u73b0\u4f18\uff0c\u4f46\u5404\u52a9\u624b\u64c5\u957f\u7684\u4efb\u52a1\u5404\u5f02\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9AI\u7f16\u7a0b\u52a9\u624b\u5728\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u548c\u5386\u53f2\u53d8\u8fc1\u4e2d\u6709\u6548\u6027\u7684\u7cfb\u7edf\u6bd4\u8f83\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u5e76\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "method": "\u5206\u6790AIDev\u6570\u636e\u96c6\u76847,156\u4e2a\u62c9\u53d6\u8bf7\u6c42\uff08PRs\uff09\uff0c\u4f7f\u7528\u65f6\u95f4\u8d8b\u52bf\u5206\u6790\u548c\u5206\u5c42\u5361\u65b9\u68c0\u9a8c\u8bc4\u4ef7\u4e94\u79cd\u52a9\u624b\uff08OpenAI Codex\u3001\u5b9e\u4f53Copilot\u3001Devin\u3001Cursor\u3001Claude Code\uff09\u7684\u6548\u80fd\u3002", "result": "Devin\u63a5\u53d7\u738732\u5468\u5185\u6bcf\u5468\u589e\u957f0.77%\uff0c\u5176\u4ed6\u52a9\u624b\u8868\u73b0\u7a33\u5b9a\uff1b\u6587\u6863\u4efb\u52a1\u63a5\u53d7\u738782.1%\u8fdc\u8d85\u65b0\u7279\u5f81\u768466.1%\uff1bOpenAI\u5728\u4e5d\u7c7b\u4efb\u52a1\u4e2d\u5747\u9886\u5148\uff0859.6%-88.6%\uff09\uff0c\u4f46Claude\u5728\u6587\u6863\uff0892.3%\uff09\u548c\u529f\u80fd\u4efb\u52a1\uff0872.6%\uff09\u6700\u4f18\uff0cCursor\u5219\u5728\u4fee\u590d\u4efb\u52a1\u8868\u73b0\u6700\u4f73\uff0880.4%\uff09\u3002", "conclusion": "\u4efb\u52a1\u7c7b\u578b\u662f\u5f71\u54cdAI\u52a9\u624b\u63a5\u53d7\u7387\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4e14\u6ca1\u6709\u5355\u4e00\u52a9\u624b\u5728\u6240\u6709\u4efb\u52a1uiten\u8868\u73b0\u6700\u4f73\uff0c\u5f3a\u8c03\u672a\u6765\u9700\u4fa7\u91cd\u4efb\u52a1\u7279\u5f02\u6027\u4f18\u5316\u3002"}}
