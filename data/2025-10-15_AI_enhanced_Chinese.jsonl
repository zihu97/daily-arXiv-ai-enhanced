{"id": "2510.10225", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.10225", "abs": "https://arxiv.org/abs/2510.10225", "authors": ["Jialin Sun", "Yuchen Hu", "Dean You", "Yushu Du", "Hui Wang", "Xinwei Fang", "Weiwei Shan", "Nan Guan", "Zhe Jiang"], "title": "ISAAC: Intelligent, Scalable, Agile, and Accelerated CPU Verification via LLM-aided FPGA Parallelism", "comment": null, "summary": "Functional verification is a critical bottleneck in integrated circuit\ndevelopment, with CPU verification being especially time-intensive and\nlabour-consuming. Industrial practice relies on differential testing for CPU\nverification, yet faces bottlenecks at nearly each stage of the framework\npipeline: front-end stimulus generation lacks micro-architectural awareness,\nyielding low-quality and redundant tests that impede coverage closure and miss\ncorner cases. Meanwhile, back-end simulation infrastructure, even with FPGA\nacceleration, often stalls on long-running tests and offers limited visibility,\ndelaying feedback and prolonging the debugging cycle. Here, we present ISAAC, a\nfull-stack, Large Language Model (LLM)-aided CPU verification framework with\nFPGA parallelism, from bug categorisation and stimulus generation to simulation\ninfrastructure. To do so, we presented a multi-agent stimulus engine in ISAAC's\nfront-end, infused with micro-architectural knowledge and historical bug\npatterns, generating highly targeted tests that rapidly achieve coverage goals\nand capture elusive corner cases. In ISAAC's back-end, we introduce a\nlightweight forward-snapshot mechanism and a decoupled co-simulation\narchitecture between the Instruction Set Simulator (ISS) and the Design Under\nTest (DUT), enabling a single ISS to drive multiple DUTs in parallel. By\neliminating long-tail test bottlenecks and exploiting FPGA parallelism, the\nsimulation throughput is significantly improved. As a demonstration, we used\nISAAC to verify a mature CPU that has undergone multiple successful tape-outs.\nResults show up to 17,536x speed-up over software RTL simulation, while\ndetecting several previously unknown bugs, two of which are reported in this\npaper.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ISAAC\uff0c\u4e00\u4e2a\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0eFPGA\u5e76\u884c\u52a0\u901f\u7684\u5168\u6808CPU\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u5177\u5907\u5fae\u67b6\u6784\u77e5\u8bc6\u7684\u591a\u667a\u80fd\u4f53\u6fc0\u52b1\u751f\u6210\u5f15\u64ce\u548c\u8f7b\u91cf\u7ea7\u5feb\u7167\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u9a8c\u8bc1\u6548\u7387\u4e0e\u8986\u76d6\u7387\uff0c\u5728\u5b9e\u9645CPU\u9a8c\u8bc1\u4e2d\u5b9e\u73b0\u4e86\u6700\u9ad817,536\u500d\u7684\u4eff\u771f\u52a0\u901f\uff0c\u5e76\u53d1\u73b0\u4e86\u591a\u4e2a\u672a\u77e5\u7f3a\u9677\u3002", "motivation": "CPU\u529f\u80fd\u9a8c\u8bc1\u5728\u5de5\u4e1a\u5b9e\u8df5\u4e2d\u9ad8\u5ea6\u4f9d\u8d56\u5dee\u5206\u6d4b\u8bd5\uff0c\u4f46\u73b0\u6709\u6d41\u7a0b\u5728\u6fc0\u52b1\u751f\u6210\u548c\u4eff\u771f\u57fa\u7840\u8bbe\u65bd\u4e24\u65b9\u9762\u5747\u5b58\u5728\u74f6\u9888\uff1a\u524d\u7aef\u7f3a\u4e4f\u5fae\u67b6\u6784\u611f\u77e5\uff0c\u751f\u6210\u4f4e\u8d28\u91cf\u5197\u4f59\u6d4b\u8bd5\uff1b\u540e\u7aef\u5373\u4f7f\u4f7f\u7528FPGA\u52a0\u901f\uff0c\u4ecd\u53d7\u9650\u4e8e\u957f\u8fd0\u884c\u6d4b\u8bd5\u548c\u8c03\u8bd5\u53cd\u9988\u5ef6\u8fdf\u3002", "method": "ISAAC\u6846\u67b6\u5728\u524d\u7aef\u91c7\u7528\u878d\u5408\u5fae\u67b6\u6784\u77e5\u8bc6\u4e0e\u5386\u53f2\u7f3a\u9677\u6a21\u5f0f\u7684\u591a\u667a\u80fd\u4f53\u6fc0\u52b1\u5f15\u64ce\uff0c\u751f\u6210\u9ad8\u9488\u5bf9\u6027\u6d4b\u8bd5\uff1b\u540e\u7aef\u5f15\u5165\u8f7b\u91cf\u7ea7\u524d\u5411\u5feb\u7167\u673a\u5236\u4e0eISS/DUT\u89e3\u8026\u7684\u534f\u540c\u4eff\u771f\u67b6\u6784\uff0c\u652f\u6301\u5355\u4e2aISS\u9a71\u52a8\u591a\u4e2aDUT\u5e76\u884c\u6267\u884c\uff0c\u5e76\u5229\u7528FPGA\u5e76\u884c\u6027\u63d0\u5347\u541e\u5410\u91cf\u3002", "result": "\u5728\u5df2\u591a\u6b21\u6210\u529f\u6d41\u7247\u7684\u6210\u719fCPU\u4e0a\u9a8c\u8bc1ISAAC\uff0c\u7ed3\u679c\u663e\u793a\u76f8\u6bd4\u8f6f\u4ef6RTL\u4eff\u771f\u6700\u9ad8\u52a0\u901f17,536\u500d\uff0c\u5e76\u53d1\u73b0\u591a\u4e2a\u6b64\u524d\u672a\u77e5\u7684bug\uff0c\u5176\u4e2d\u4e24\u4e2a\u5728\u6587\u4e2d\u62a5\u544a\u3002", "conclusion": "ISAAC\u901a\u8fc7LLM\u9a71\u52a8\u7684\u667a\u80fd\u6fc0\u52b1\u751f\u6210\u4e0e\u9ad8\u6548\u5e76\u884c\u4eff\u771f\u67b6\u6784\uff0c\u6709\u6548\u7a81\u7834\u4e86\u4f20\u7edfCPU\u9a8c\u8bc1\u4e2d\u7684\u5173\u952e\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u9a8c\u8bc1\u901f\u5ea6\u3001\u8986\u76d6\u7387\u4e0e\u7f3a\u9677\u68c0\u51fa\u80fd\u529b\uff0c\u4e3a\u5de5\u4e1a\u7ea7CPU\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2510.10623", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.10623", "abs": "https://arxiv.org/abs/2510.10623", "authors": ["Ahmed J. Abdelmaksoud", "Cristian Sestito", "Shiwei Wang", "Themis Prodromakis"], "title": "ADiP: Adaptive Precision Systolic Array for Matrix Multiplication Acceleration", "comment": null, "summary": "Transformers are at the core of modern AI nowadays. They rely heavily on\nmatrix multiplication and require efficient acceleration due to their\nsubstantial memory and computational requirements. Quantization plays a vital\nrole in reducing memory usage, and can be exploited for computations by\ndesigning reconfigurable architectures that enhance matrix multiplication by\ndynamically adjusting the precision. This paper proposes ADiP, a novel\nadaptive-precision systolic array architecture designed for efficient matrix\nmultiplication acceleration.The proposed architecture consists of NxN\nadaptive-precision processing elements (PEs) and shared accumulators. ADiP\nsupports multiple computation modes, including symmetric single-matrix\nmultiplication as well as asymmetric multi-matrix multiplication with a shared\ninput matrix, thereby improving data-reuse and PE utilization. In addition,\nADiP maximizes the computational density by adapting to different precisions,\nsuch as 8bitx8bit, 8bitx4bit, and 8bitx2bit. Analytical models are developed\nfor ADiP architecture, including latency and throughput for versatile\narchitecture configurations. A comprehensive hardware design space exploration\nis demonstrated using 22nm commercial technology, achieving up to a 4x higher\ncomputational throughput. Furthermore, ADiP is evaluated on different\ntransformer workloads from GPT-2 Medium, BERT Large, and BitNet-1.58B models,\ndelivering latency improvement up to 53.6%, and energy improvement up to 24.4%\nfor BitNet-1.58B MHA workloads. At a 64x64 size with 4096 PEs, ADiP achieves a\npeak throughput of 8.192 TOPS, 16.384 TOPS, and 32.768 TOPS for 8bitx8bit,\n8bitx4bit, and 8bitx2bit operations, respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aADiP\u7684\u81ea\u9002\u5e94\u7cbe\u5ea6\u8109\u52a8\u9635\u5217\u67b6\u6784\uff0c\u7528\u4e8e\u9ad8\u6548\u52a0\u901fTransformer\u6a21\u578b\u4e2d\u7684\u77e9\u9635\u4e58\u6cd5\u3002\u8be5\u67b6\u6784\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8ba1\u7b97\u7cbe\u5ea6\uff08\u59828bit\u00d78bit\u30018bit\u00d74bit\u30018bit\u00d72bit\uff09\u63d0\u5347\u8ba1\u7b97\u5bc6\u5ea6\u548c\u80fd\u6548\uff0c\u572822nm\u5de5\u827a\u4e0b\u5b9e\u73b0\u6700\u9ad84\u500d\u541e\u5410\u91cf\u63d0\u5347\uff0c\u5e76\u5728GPT-2\u3001BERT\u548cBitNet\u7b49\u6a21\u578b\u4e0a\u9a8c\u8bc1\u4e86\u5176\u5728\u5ef6\u8fdf\u548c\u80fd\u8017\u65b9\u9762\u7684\u663e\u8457\u4f18\u52bf\u3002", "motivation": "Transformer\u6a21\u578b\u4f9d\u8d56\u5927\u91cf\u77e9\u9635\u4e58\u6cd5\uff0c\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u5de8\u5927\uff0c\u4e9f\u9700\u9ad8\u6548\u786c\u4ef6\u52a0\u901f\u3002\u91cf\u5316\u53ef\u964d\u4f4e\u5185\u5b58\u5360\u7528\uff0c\u82e5\u7ed3\u5408\u53ef\u91cd\u6784\u67b6\u6784\u52a8\u6001\u8c03\u6574\u7cbe\u5ea6\uff0c\u5219\u53ef\u8fdb\u4e00\u6b65\u4f18\u5316\u77e9\u9635\u4e58\u6cd5\u6548\u7387\u3002", "method": "\u63d0\u51faADiP\u67b6\u6784\uff0c\u5305\u542bN\u00d7N\u4e2a\u81ea\u9002\u5e94\u7cbe\u5ea6\u5904\u7406\u5355\u5143\uff08PE\uff09\u548c\u5171\u4eab\u7d2f\u52a0\u5668\uff0c\u652f\u6301\u5bf9\u79f0\u5355\u77e9\u9635\u4e0e\u975e\u5bf9\u79f0\u591a\u77e9\u9635\u4e58\u6cd5\u6a21\u5f0f\uff0c\u63d0\u5347\u6570\u636e\u590d\u7528\u4e0ePE\u5229\u7528\u7387\uff1b\u5efa\u7acb\u5ef6\u8fdf\u4e0e\u541e\u5410\u91cf\u5206\u6790\u6a21\u578b\uff0c\u5e76\u572822nm\u5de5\u827a\u4e0b\u8fdb\u884c\u786c\u4ef6\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u3002", "result": "\u572864\u00d764\u89c4\u6a21\uff084096\u4e2aPE\uff09\u4e0b\uff0cADiP\u57288bit\u00d78bit\u30018bit\u00d74bit\u548c8bit\u00d72bit\u8fd0\u7b97\u4e2d\u5206\u522b\u8fbe\u52308.192\u300116.384\u548c32.768 TOPS\u7684\u5cf0\u503c\u541e\u5410\u91cf\uff1b\u5728BitNet-1.58B\u7684MHA\u4efb\u52a1\u4e2d\uff0c\u5ef6\u8fdf\u964d\u4f4e53.6%\uff0c\u80fd\u8017\u964d\u4f4e24.4%\uff0c\u6574\u4f53\u541e\u5410\u91cf\u6700\u9ad8\u63d0\u53474\u500d\u3002", "conclusion": "ADiP\u901a\u8fc7\u81ea\u9002\u5e94\u7cbe\u5ea6\u8bbe\u8ba1\u663e\u8457\u63d0\u5347\u4e86\u77e9\u9635\u4e58\u6cd5\u7684\u8ba1\u7b97\u6548\u7387\u4e0e\u80fd\u6548\uff0c\u4e3aTransformer\u6a21\u578b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u786c\u4ef6\u52a0\u901f\u65b9\u6848\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.10676", "categories": ["cs.AR", "cs.CL", "cs.RO", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.10676", "abs": "https://arxiv.org/abs/2510.10676", "authors": ["Mukul Lokhande", "Tanushree Dewangan", "Mohd Sharik Mansoori", "Tejas Chaudhari", "Akarsh J.", "Damayanti Lokhande", "Adam Teman", "Santosh Kumar Vishvakarma"], "title": "Bhasha-Rupantarika: Algorithm-Hardware Co-design approach for Multilingual Neural Machine Translation", "comment": null, "summary": "This paper introduces Bhasha-Rupantarika, a light and efficient multilingual\ntranslation system tailored through algorithm-hardware codesign for\nresource-limited settings. The method investigates model deployment at\nsub-octet precision levels (FP8, INT8, INT4, and FP4), with experimental\nresults indicating a 4.1x reduction in model size (FP4) and a 4.2x speedup in\ninference speed, which correlates with an increased throughput of 66 tokens/s\n(improvement by 4.8x). This underscores the importance of ultra-low precision\nquantization for real-time deployment in IoT devices using FPGA accelerators,\nachieving performance on par with expectations. Our evaluation covers\nbidirectional translation between Indian and international languages,\nshowcasing its adaptability in low-resource linguistic contexts. The FPGA\ndeployment demonstrated a 1.96x reduction in LUTs and a 1.65x decrease in FFs,\nresulting in a 2.2x enhancement in throughput compared to OPU and a 4.6x\nenhancement compared to HPTA. Overall, the evaluation provides a viable\nsolution based on quantisation-aware translation along with hardware efficiency\nsuitable for deployable multilingual AI systems. The entire codes\n[https://github.com/mukullokhande99/Bhasha-Rupantarika/] and dataset for\nreproducibility are publicly available, facilitating rapid integration and\nfurther development by researchers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Bhasha-Rupantarika\uff0c\u4e00\u79cd\u901a\u8fc7\u7b97\u6cd5\u4e0e\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u5b9e\u73b0\u7684\u8f7b\u91cf\u9ad8\u6548\u591a\u8bed\u8a00\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u4e13\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4f18\u5316\u3002\u901a\u8fc7\u5728FP8\u3001INT8\u3001INT4\u548cFP4\u7b49\u4e9a\u5b57\u8282\u7cbe\u5ea6\u4e0b\u90e8\u7f72\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u6a21\u578b\u4f53\u79ef\u7f29\u5c0f4.1\u500d\u3001\u63a8\u7406\u901f\u5ea6\u63d0\u53474.2\u500d\uff08\u541e\u5410\u8fbe66 tokens/s\uff09\uff0c\u5e76\u5728FPGA\u4e0a\u663e\u8457\u964d\u4f4e\u8d44\u6e90\u5360\u7528\uff0c\u9002\u7528\u4e8e\u7269\u8054\u7f51\u8bbe\u5907\u7684\u5b9e\u65f6\u591a\u8bed\u8a00\u7ffb\u8bd1\u3002", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\uff08\u5982\u7269\u8054\u7f51\u8bbe\u5907\uff09\uff0c\u90e8\u7f72\u9ad8\u6548\u3001\u4f4e\u5ef6\u8fdf\u7684\u591a\u8bed\u8a00\u7ffb\u8bd1\u7cfb\u7edf\u9762\u4e34\u8ba1\u7b97\u8d44\u6e90\u548c\u80fd\u8017\u9650\u5236\u3002\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u517c\u987e\u6a21\u578b\u6027\u80fd\u4e0e\u786c\u4ef6\u6548\u7387\uff0c\u56e0\u6b64\u4e9f\u9700\u4e00\u79cd\u7ed3\u5408\u8d85\u4f4e\u7cbe\u5ea6\u91cf\u5316\u4e0e\u786c\u4ef6\u534f\u540c\u4f18\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u63a2\u7d22\u5728FP8\u3001INT8\u3001INT4\u548cFP4\u7b49\u4e9a\u5b57\u8282\u7cbe\u5ea6\u4e0b\u8fdb\u884c\u6a21\u578b\u91cf\u5316\uff0c\u5e76\u5728FPGA\u52a0\u901f\u5668\u4e0a\u90e8\u7f72\u591a\u8bed\u8a00\u7ffb\u8bd1\u6a21\u578b\u3002\u7cfb\u7edf\u652f\u6301\u5370\u5ea6\u8bed\u8a00\u4e0e\u56fd\u9645\u8bed\u8a00\u4e4b\u95f4\u7684\u53cc\u5411\u7ffb\u8bd1\uff0c\u5e76\u901a\u8fc7\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u786e\u4fdd\u7ffb\u8bd1\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cFP4\u91cf\u5316\u4f7f\u6a21\u578b\u4f53\u79ef\u51cf\u5c114.1\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53474.2\u500d\uff08\u541e\u5410\u91cf\u8fbe66 tokens/s\uff0c\u63d0\u53474.8\u500d\uff09\u3002FPGA\u90e8\u7f72\u76f8\u6bd4OPU\u548cHPTA\u5206\u522b\u5b9e\u73b02.2\u500d\u548c4.6\u500d\u7684\u541e\u5410\u63d0\u5347\uff0c\u540c\u65f6LUTs\u51cf\u5c111.96\u500d\u3001FFs\u51cf\u5c111.65\u500d\uff0c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u9ad8\u6548\u6027\u4e0e\u5b9e\u7528\u6027\u3002", "conclusion": "Bhasha-Rupantarika\u901a\u8fc7\u8d85\u4f4e\u7cbe\u5ea6\u91cf\u5316\u4e0eFPGA\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u7684\u591a\u8bed\u8a00AI\u7ffb\u8bd1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u517c\u5177\u6a21\u578b\u538b\u7f29\u3001\u63a8\u7406\u52a0\u901f\u4e0e\u786c\u4ef6\u8d44\u6e90\u4f18\u5316\u4f18\u52bf\uff0c\u4ee3\u7801\u4e0e\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2510.10872", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2510.10872", "abs": "https://arxiv.org/abs/2510.10872", "authors": ["Sumukh Pinge", "Ashkan Moradifirouzabadi", "Keming Fan", "Prasanna Venkatesan Ravindran", "Tanvir H. Pantha", "Po-Kai Hsu", "Zheyu Li", "Weihong Xu", "Zihan Xia", "Flavio Ponzina", "Winston Chern", "Taeyoung Song", "Priyankka Ravikumar", "Mengkun Tian", "Lance Fernandes", "Huy Tran", "Hari Jayasankar", "Hang Chen", "Chinsung Park", "Amrit Garlapati", "Kijoon Kim", "Jongho Woo", "Suhwan Lim", "Kwangsoo Kim", "Wanki Kim", "Daewon Ha", "Duygu Kuzum", "Shimeng Yu", "Sourav Dutta", "Asif Khan", "Tajana Rosing", "Mingu Kang"], "title": "FeNOMS: Enhancing Open Modification Spectral Library Search with In-Storage Processing on Ferroelectric NAND (FeNAND) Flash", "comment": null, "summary": "The rapid expansion of mass spectrometry (MS) data, now exceeding hundreds of\nterabytes, poses significant challenges for efficient, large-scale library\nsearch - a critical component for drug discovery. Traditional processors\nstruggle to handle this data volume efficiently, making in-storage computing\n(ISP) a promising alternative. This work introduces an ISP architecture\nleveraging a 3D Ferroelectric NAND (FeNAND) structure, providing significantly\nhigher density, faster speeds, and lower voltage requirements compared to\ntraditional NAND flash. Despite its superior density, the NAND structure has\nnot been widely utilized in ISP applications due to limited throughput\nassociated with row-by-row reads from serially connected cells. To overcome\nthese limitations, we integrate hyperdimensional computing (HDC), a\nbrain-inspired paradigm that enables highly parallel processing with simple\noperations and strong error tolerance. By combining HDC with the proposed\ndual-bound approximate matching (D-BAM) distance metric, tailored to the FeNAND\nstructure, we parallelize vector computations to enable efficient MS spectral\nlibrary search, achieving 43x speedup and 21x higher energy efficiency over\nstate-of-the-art 3D NAND methods, while maintaining comparable accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e3D\u94c1\u7535NAND\uff08FeNAND\uff09\u7684\u5b58\u5185\u8ba1\u7b97\u67b6\u6784\uff0c\u7ed3\u5408\u8d85\u7ef4\u8ba1\u7b97\uff08HDC\uff09\u4e0e\u53cc\u8fb9\u754c\u8fd1\u4f3c\u5339\u914d\uff08D-BAM\uff09\u8ddd\u79bb\u5ea6\u91cf\uff0c\u663e\u8457\u52a0\u901f\u8d28\u8c31\u6570\u636e\u7684\u8c31\u5e93\u641c\u7d22\uff0c\u76f8\u6bd4\u73b0\u67093D NAND\u65b9\u6cd5\u5b9e\u73b043\u500d\u52a0\u901f\u548c21\u500d\u80fd\u6548\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u8d28\u8c31\uff08MS\uff09\u6570\u636e\u89c4\u6a21\u8fc5\u901f\u589e\u957f\uff08\u8d85\u6570\u767eTB\uff09\uff0c\u4f20\u7edf\u5904\u7406\u5668\u96be\u4ee5\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u8c31\u5e93\u641c\u7d22\u4efb\u52a1\uff0c\u800c\u73b0\u6709\u5b58\u5185\u8ba1\u7b97\uff08ISP\uff09\u65b9\u6848\u53d7\u9650\u4e8eNAND\u95ea\u5b58\u4e32\u884c\u8bfb\u53d6\u5bfc\u81f4\u7684\u541e\u5410\u91cf\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e3D FeNAND\u7ed3\u6784\u7684ISP\u67b6\u6784\uff0c\u5229\u7528\u5176\u9ad8\u5bc6\u5ea6\u3001\u9ad8\u901f\u5ea6\u548c\u4f4e\u7535\u538b\u4f18\u52bf\uff0c\u5e76\u5f15\u5165\u8d85\u7ef4\u8ba1\u7b97\uff08HDC\uff09\u5b9e\u73b0\u9ad8\u5ea6\u5e76\u884c\u5316\u5904\u7406\uff0c\u540c\u65f6\u8bbe\u8ba1\u9002\u914dFeNAND\u7ed3\u6784\u7684\u53cc\u8fb9\u754c\u8fd1\u4f3c\u5339\u914d\uff08D-BAM\uff09\u8ddd\u79bb\u5ea6\u91cf\uff0c\u4ee5\u5e76\u884c\u5316\u5411\u91cf\u8ba1\u7b97\u3002", "result": "\u5728\u8d28\u8c31\u8c31\u5e93\u641c\u7d22\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u76843D NAND\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e8643\u500d\u7684\u901f\u5ea6\u63d0\u5347\u548c21\u500d\u7684\u80fd\u6548\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u7ed3\u5408FeNAND\u3001HDC\u548cD-BAM\u7684\u5b58\u5185\u8ba1\u7b97\u67b6\u6784\u80fd\u6709\u6548\u5e94\u5bf9\u5927\u89c4\u6a21\u8d28\u8c31\u6570\u636e\u641c\u7d22\u7684\u6548\u7387\u4e0e\u80fd\u8017\u6311\u6218\uff0c\u4e3a\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u9ad8\u6027\u80fd\u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u65b0\u8def\u5f84\u3002"}}
{"id": "2510.10747", "categories": ["cs.DC", "cs.OS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.10747", "abs": "https://arxiv.org/abs/2510.10747", "authors": ["Chirag Shetty", "Sarthak Chakraborty", "Hubertus Franke", "Larisa Shwartz", "Chandra Narayanaswami", "Indranil Gupta", "Saurabh Jha"], "title": "CPU-Limits kill Performance: Time to rethink Resource Control", "comment": "Vision Paper accepted to SoCC 2025", "summary": "Research in compute resource management for cloud-native applications is\ndominated by the problem of setting optimal CPU limits -- a fundamental OS\nmechanism that strictly restricts a container's CPU usage to its specified\nCPU-limits . Rightsizing and autoscaling works have innovated on\nallocation/scaling policies assuming the ubiquity and necessity of CPU-limits .\nWe question this. Practical experiences of cloud users indicate that CPU-limits\nharms application performance and costs more than it helps. These observations\nare in contradiction to the conventional wisdom presented in both academic\nresearch and industry best practices. We argue that this indiscriminate\nadoption of CPU-limits is driven by erroneous beliefs that CPU-limits is\nessential for operational and safety purposes. We provide empirical evidence\nmaking a case for eschewing CPU-limits completely from latency-sensitive\napplications. This prompts a fundamental rethinking of auto-scaling and billing\nparadigms and opens new research avenues. Finally, we highlight specific\nscenarios where CPU-limits can be beneficial if used in a well-reasoned way\n(e.g. background jobs).", "AI": {"tldr": "\u8be5\u8bba\u6587\u8d28\u7591\u5728\u4e91\u539f\u751f\u5e94\u7528\u4e2d\u666e\u904d\u4f7f\u7528CPU\u9650\u5236\uff08CPU-limits\uff09\u7684\u505a\u6cd5\uff0c\u6307\u51fa\u5176\u5bf9\u5ef6\u8fdf\u654f\u611f\u578b\u5e94\u7528\u7684\u6027\u80fd\u548c\u6210\u672c\u6709\u8d1f\u9762\u5f71\u54cd\uff0c\u5e76\u4e3b\u5f20\u5b8c\u5168\u6452\u5f03\u6b64\u7c7b\u9650\u5236\uff0c\u4ece\u800c\u63a8\u52a8\u81ea\u52a8\u6269\u7f29\u5bb9\u548c\u8ba1\u8d39\u8303\u5f0f\u7684\u6839\u672c\u6027\u91cd\u6784\u3002", "motivation": "\u5f53\u524d\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u666e\u904d\u8ba4\u4e3aCPU\u9650\u5236\u5bf9\u4e8e\u5bb9\u5668\u8d44\u6e90\u7ba1\u7406\u548c\u7cfb\u7edf\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5b9e\u9645\u4e91\u7528\u6237\u7ecf\u9a8c\u8868\u660e\uff0cCPU\u9650\u5236\u5e38\u5e38\u635f\u5bb3\u5e94\u7528\u6027\u80fd\u5e76\u589e\u52a0\u6210\u672c\uff0c\u8fd9\u4e0e\u4f20\u7edf\u8ba4\u77e5\u76f8\u77db\u76fe\u3002", "method": "\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u548c\u5bf9\u5b9e\u9645\u4e91\u7528\u6237\u7ecf\u9a8c\u7684\u89c2\u5bdf\uff0c\u8bc4\u4f30CPU\u9650\u5236\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u7684\u5f71\u54cd\uff0c\u5e76\u5bf9\u6bd4\u5176\u5728\u5ef6\u8fdf\u654f\u611f\u578b\u5e94\u7528\u4e0e\u540e\u53f0\u4efb\u52a1\u4e2d\u7684\u9002\u7528\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5bf9\u4e8e\u5ef6\u8fdf\u654f\u611f\u578b\u5e94\u7528\uff0cCPU\u9650\u5236\u5f0a\u5927\u4e8e\u5229\uff1b\u4f46\u5728\u7279\u5b9a\u573a\u666f\uff08\u5982\u540e\u53f0\u4efb\u52a1\uff09\u4e2d\uff0c\u82e5\u5408\u7406\u4f7f\u7528\uff0c\u4ecd\u53ef\u5e26\u6765\u76ca\u5904\u3002", "conclusion": "\u5e94\u91cd\u65b0\u5ba1\u89c6CPU\u9650\u5236\u7684\u5fc5\u8981\u6027\uff0c\u5c24\u5176\u5728\u5ef6\u8fdf\u654f\u611f\u578b\u5e94\u7528\u4e2d\u5e94\u8003\u8651\u5b8c\u5168\u5f03\u7528\uff0c\u540c\u65f6\u63a8\u52a8\u81ea\u52a8\u6269\u7f29\u5bb9\u4e0e\u8ba1\u8d39\u673a\u5236\u7684\u9769\u65b0\u3002"}}
{"id": "2510.09847", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.09847", "abs": "https://arxiv.org/abs/2510.09847", "authors": ["Said Muhammad", "Lahlou Laaziz", "Nadjia Kara", "Phat Tan Nguyen", "Timothy Murphy"], "title": "THEAS: Efficient Power Management in Multi-Core CPUs via Cache-Aware Resource Scheduling", "comment": "Accepted and presented at the 13th IEEE International Conference on\n  Intelligent Mobile Computing 2025 (IMC), CISOSE 2025 in Tucson, Arizona, USA.\n  This is the author's accepted manuscript (AAM). The final published version\n  will appear in the IEEE conference proceedings", "summary": "The dynamic adaptation of resource levels enables the system to enhance\nenergy efficiency while maintaining the necessary computational resources,\nparticularly in scenarios where workloads fluctuate significantly over time.\nThe proposed approach can play a crucial role in heterogeneous systems where\nworkload characteristics are not uniformly distributed, such as non-pinning\ntasks. The deployed THEAS algorithm in this research work ensures a balance\nbetween performance and power consumption, making it suitable for a wide range\nof real-time applications. A comparative analysis of the proposed THEAS\nalgorithm with well-known scheduling techniques such as Completely Fair\nScheduler (CFS), Energy-Aware Scheduling (EAS), Heterogeneous Scheduling\n(HeteroSched), and Utility-Based Scheduling is presented in Table III. Each\nscheme is compared based on adaptability, core selection criteria, performance\nscaling, cache awareness, overhead, and real-time suitability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTHEAS\u7684\u52a8\u6001\u8d44\u6e90\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5728\u5f02\u6784\u7cfb\u7edf\u4e2d\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u8d44\u6e90\u6c34\u5e73\uff0c\u5728\u4fdd\u969c\u6027\u80fd\u7684\u540c\u65f6\u63d0\u5347\u80fd\u6548\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u8d1f\u8f7d\u6ce2\u52a8\u5927\u3001\u4efb\u52a1\u975e\u7ed1\u5b9a\u7684\u5b9e\u65f6\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u5728\u8d1f\u8f7d\u968f\u65f6\u95f4\u663e\u8457\u6ce2\u52a8\u7684\u5f02\u6784\u7cfb\u7edf\u4e2d\uff0c\u4f20\u7edf\u8c03\u5ea6\u7b56\u7565\u96be\u4ee5\u517c\u987e\u6027\u80fd\u4e0e\u80fd\u6548\uff0c\u5c24\u5176\u5bf9\u4e8e\u975e\u7ed1\u5b9a\u4efb\u52a1\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u52a8\u6001\u9002\u5e94\u8d1f\u8f7d\u53d8\u5316\u7684\u8c03\u5ea6\u673a\u5236\u3002", "method": "\u63d0\u51fa\u5e76\u90e8\u7f72THEAS\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u8ba1\u7b97\u8d44\u6e90\u6c34\u5e73\uff0c\u5b9e\u73b0\u6027\u80fd\u4e0e\u529f\u8017\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u5e76\u5728\u6838\u5fc3\u9009\u62e9\u3001\u6027\u80fd\u6269\u5c55\u3001\u7f13\u5b58\u611f\u77e5\u7b49\u65b9\u9762\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u901a\u8fc7\u4e0eCFS\u3001EAS\u3001HeteroSched\u548c\u57fa\u4e8e\u6548\u7528\u7684\u8c03\u5ea6\u7b49\u7ecf\u5178\u7b97\u6cd5\u5bf9\u6bd4\uff0cTHEAS\u5728\u9002\u5e94\u6027\u3001\u6838\u5fc3\u9009\u62e9\u3001\u6027\u80fd\u6269\u5c55\u3001\u7f13\u5b58\u611f\u77e5\u3001\u5f00\u9500\u548c\u5b9e\u65f6\u9002\u7528\u6027\u7b49\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "THEAS\u7b97\u6cd5\u5728\u5f02\u6784\u7cfb\u7edf\u4e2d\u6709\u6548\u517c\u987e\u4e86\u5b9e\u65f6\u6027\u80fd\u4e0e\u80fd\u6548\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u5b9e\u9645\u5e94\u7528\u573a\u666f\uff0c\u5c55\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u8c03\u5ea6\u7b56\u7565\u7684\u7efc\u5408\u80fd\u529b\u3002"}}
{"id": "2510.09688", "categories": ["cs.MA", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.09688", "abs": "https://arxiv.org/abs/2510.09688", "authors": ["R. W. S. Pessoa", "M. H. N\u00e6ss", "J. C. Bijos", "C. M. Rebello", "D. Colombo", "L. Schnitman", "I. B. R. Nogueira"], "title": "A Hybrid Agent-Based and System Dynamics Framework for Modelling Project Execution and Technology Maturity in Early-Stage R&D", "comment": null, "summary": "This paper presents a hybrid approach to predict the evolution of\ntechnological maturity in R and D projects, using the oil and gas sector as an\nexample. Integrating System Dynamics (SD) and Agent Based Modelling (ABM)\nallows the proposed multi level framework to capture uncertainties in work\neffort, team size, and project duration, which influence technological\nprogress. While AB SD hybrid models are established in other fields, their use\nin R and D remains limited. The model combines system level feedback structures\ngoverning work phases, rework cycles, and duration with decentralised agents\nsuch as team members, tasks, and controllers, whose interactions generate\nemergent project dynamics. A base case scenario analysed early stage innovation\nprojects with 15 parallel tasks over 156 weeks. A comparative sequential\nscenario showed an 88 percent reduction in rework duration. A second scenario\nassessed mixed parallel sequential task structures with varying team sizes. In\nparallel configurations, increasing team size reduced project duration and\nimproved task completion, with optimal results for teams of four to five\nmembers. These findings align with empirical evidence showing that moderate\nteam expansion enhances coordination efficiency without excessive communication\noverhead. However, larger teams may decrease performance due to communication\ncomplexity and management delays. Overall, the model outputs and framework\nalign with expert understanding, supporting their validity as quantitative\ntools for analysing resource allocation, scheduling efficiency, and technology\nmaturity progression.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u7cfb\u7edf\u52a8\u529b\u5b66\uff08SD\uff09\u4e0e\u57fa\u4e8e\u667a\u80fd\u4f53\u5efa\u6a21\uff08ABM\uff09\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u7814\u53d1\u9879\u76ee\u4e2d\u6280\u672f\u6210\u719f\u5ea6\u7684\u6f14\u8fdb\uff0c\u4ee5\u6cb9\u6c14\u884c\u4e1a\u4e3a\u4f8b\uff0c\u901a\u8fc7\u591a\u5c42\u7ea7\u6846\u67b6\u6355\u6349\u5de5\u4f5c\u91cf\u3001\u56e2\u961f\u89c4\u6a21\u548c\u9879\u76ee\u5468\u671f\u7b49\u4e0d\u786e\u5b9a\u6027\u56e0\u7d20\u5bf9\u6280\u672f\u8fdb\u5c55\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e2dABM\u4e0eSD\u6df7\u5408\u6a21\u578b\u5728\u5176\u4ed6\u9886\u57df\u5df2\u6709\u5e94\u7528\uff0c\u4f46\u5728\u7814\u53d1\uff08R&D\uff09\u9886\u57df\u4ecd\u8f83\u5c11\uff0c\u56e0\u6b64\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u6784\u5efa\u80fd\u66f4\u771f\u5b9e\u53cd\u6620\u7814\u53d1\u9879\u76ee\u52a8\u6001\u7684\u6a21\u578b\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u878d\u5408\u7cfb\u7edf\u5c42\u9762\u53cd\u9988\u7ed3\u6784\uff08\u5982\u5de5\u4f5c\u9636\u6bb5\u3001\u8fd4\u5de5\u5faa\u73af\u3001\u5468\u671f\uff09\u4e0e\u53bb\u4e2d\u5fc3\u5316\u667a\u80fd\u4f53\uff08\u5982\u56e2\u961f\u6210\u5458\u3001\u4efb\u52a1\u3001\u63a7\u5236\u5668\uff09\u7684\u591a\u5c42\u7ea7\u6df7\u5408\u6a21\u578b\uff0c\u901a\u8fc7\u4e0d\u540c\u4efb\u52a1\u7ed3\u6784\uff08\u5e76\u884c/\u4e32\u884c\uff09\u548c\u56e2\u961f\u89c4\u6a21\u7684\u60c5\u666f\u6a21\u62df\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5728\u5e76\u884c\u4efb\u52a1\u7ed3\u6784\u4e2d\uff0c\u56e2\u961f\u89c4\u6a21\u589e\u81f34\u20135\u4eba\u65f6\u9879\u76ee\u5468\u671f\u6700\u77ed\u3001\u4efb\u52a1\u5b8c\u6210\u6548\u7387\u6700\u9ad8\uff1b\u66f4\u5927\u56e2\u961f\u5219\u56e0\u6c9f\u901a\u590d\u6742\u6027\u548c\u7ba1\u7406\u5ef6\u8fdf\u5bfc\u81f4\u7ee9\u6548\u4e0b\u964d\u3002\u76f8\u6bd4\u7eaf\u4e32\u884c\u60c5\u666f\uff0c\u5e76\u884c\u7ed3\u6784\u53ef\u51cf\u5c1188%\u7684\u8fd4\u5de5\u65f6\u95f4\u3002", "conclusion": "\u8be5\u6df7\u5408\u6a21\u578b\u4e0e\u4e13\u5bb6\u8ba4\u77e5\u4e00\u81f4\uff0c\u9a8c\u8bc1\u4e86\u5176\u4f5c\u4e3a\u5206\u6790\u8d44\u6e90\u5206\u914d\u3001\u8c03\u5ea6\u6548\u7387\u548c\u6280\u672f\u6210\u719f\u5ea6\u6f14\u8fdb\u7684\u5b9a\u91cf\u5de5\u5177\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.09721", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.09721", "abs": "https://arxiv.org/abs/2510.09721", "authors": ["Jiale Guo", "Suizhi Huang", "Mei Li", "Dong Huang", "Xingsheng Chen", "Regina Zhang", "Zhijiang Guo", "Han Yu", "Siu-Ming Yiu", "Christian Jensen", "Pietro Lio", "Kwok-Yan Lam"], "title": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "comment": "21 pages", "summary": "The integration of LLMs into software engineering has catalyzed a paradigm\nshift from traditional rule-based systems to sophisticated agentic systems\ncapable of autonomous problem-solving. Despite this transformation, the field\nlacks a comprehensive understanding of how benchmarks and solutions\ninterconnect, hindering systematic progress and evaluation. This survey\npresents the first holistic analysis of LLM-empowered software engineering,\nbridging the critical gap between evaluation and solution approaches. We\nanalyze 150+ recent papers and organize them into a comprehensive taxonomy\nspanning two major dimensions: (1) Solutions, categorized into prompt-based,\nfine-tuning-based, and agent-based paradigms, and (2) Benchmarks, covering code\ngeneration, translation, repair, and other tasks. Our analysis reveals how the\nfield has evolved from simple prompt engineering to complex agentic systems\nincorporating planning and decomposition, reasoning and self-refinement, memory\nmechanisms, and tool augmentation. We present a unified pipeline that\nillustrates the complete workflow from task specification to final\ndeliverables, demonstrating how different solution paradigms address varying\ncomplexity levels across software engineering tasks. Unlike existing surveys\nthat focus on isolated aspects, we provide full-spectrum coverage connecting\n50+ benchmarks with their corresponding solution strategies, enabling\nresearchers to identify optimal approaches for specific evaluation criteria.\nFurthermore, we identify critical research gaps and propose actionable future\ndirections, including multi-agent collaboration frameworks, self-evolving code\ngeneration systems, and integration of formal verification with LLM-based\nmethods. This survey serves as a foundational resource for researchers and\npractitioners seeking to understand, evaluate, and advance LLM-empowered\nsoftware engineering systems.", "AI": {"tldr": "\u672c\u6587\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u9996\u6b21\u5168\u9762\u7efc\u8ff0\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u6db5\u76d6150\u591a\u7bc7\u8bba\u6587\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u4ece\u89e3\u51b3\u65b9\u6848\uff08\u63d0\u793a\u3001\u5fae\u8c03\u3001\u667a\u80fd\u4f53\uff09\u548c\u57fa\u51c6\u4efb\u52a1\uff08\u4ee3\u7801\u751f\u6210\u3001\u7ffb\u8bd1\u3001\u4fee\u590d\u7b49\uff09\u4e24\u4e2a\u7ef4\u5ea6\u7cfb\u7edf\u68b3\u7406\u4e86\u8be5\u9886\u57df\u7684\u53d1\u5c55\uff0c\u5e76\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u5de5\u4f5c\u6d41\u6846\u67b6\u4e0e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5f53\u524dLLM\u9a71\u52a8\u7684\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7f3a\u4e4f\u5bf9\u57fa\u51c6\u4efb\u52a1\u4e0e\u89e3\u51b3\u65b9\u6848\u4e4b\u95f4\u5173\u8054\u7684\u7cfb\u7edf\u6027\u7406\u89e3\uff0c\u963b\u788d\u4e86\u8be5\u9886\u57df\u7684\u8bc4\u4f30\u4e0e\u8fdb\u6b65\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e86150\u4f59\u7bc7\u8fd1\u671f\u8bba\u6587\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u4e8c\u7ef4\u5206\u7c7b\u4f53\u7cfb\uff1a\u4e00\u662f\u6309\u89e3\u51b3\u65b9\u6848\u5206\u4e3a\u63d0\u793a\u5de5\u7a0b\u3001\u5fae\u8c03\u548c\u667a\u80fd\u4f53\u8303\u5f0f\uff1b\u4e8c\u662f\u6309\u57fa\u51c6\u4efb\u52a1\u6db5\u76d6\u4ee3\u7801\u751f\u6210\u3001\u7ffb\u8bd1\u3001\u4fee\u590d\u7b49\u3002\u540c\u65f6\u63d0\u51fa\u7edf\u4e00\u5de5\u4f5c\u6d41\u7ba1\u9053\uff0c\u8fde\u63a550\u591a\u4e2a\u57fa\u51c6\u4e0e\u5176\u5bf9\u5e94\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u8be5\u9886\u57df\u4ece\u7b80\u5355\u63d0\u793a\u5de5\u7a0b\u5411\u590d\u6742\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6f14\u8fdb\u8d8b\u52bf\uff0c\u5305\u62ec\u89c4\u5212\u4e0e\u5206\u89e3\u3001\u63a8\u7406\u4e0e\u81ea\u4f18\u5316\u3001\u8bb0\u5fc6\u673a\u5236\u548c\u5de5\u5177\u589e\u5f3a\u7b49\u5173\u952e\u6280\u672f\uff0c\u5e76\u7cfb\u7edf\u5173\u8054\u4e86\u5404\u7c7b\u57fa\u51c6\u4e0e\u9002\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u672c\u7efc\u8ff0\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u7406\u89e3\u3001\u8bc4\u4f30\u548c\u63a8\u8fdbLLM\u8d4b\u80fd\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\u7684\u5168\u9762\u8d44\u6e90\uff0c\u5e76\u6307\u51fa\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u3001\u81ea\u8fdb\u5316\u4ee3\u7801\u751f\u6210\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\u878d\u5408\u7b49\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2510.11192", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11192", "abs": "https://arxiv.org/abs/2510.11192", "authors": ["Jo\u00e3o Paulo Cardoso de Lima", "Marc Dietrich", "Jeronimo Castrillon", "Asif Ali Khan"], "title": "Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs", "comment": "8 pages, to appear in IEEE Cross-disciplinary Conference on\n  Memory-Centric Computing (CCMCC)", "summary": "Structured sparsity enables deploying large language models (LLMs) on\nresource-constrained systems. Approaches like dense-to-sparse fine-tuning are\nparticularly compelling, achieving remarkable structured sparsity by reducing\nthe model size by over 6.7x, while still maintaining acceptable accuracy.\nDespite this reduction, LLM inference, especially the decode stage being\ninherently memory-bound, is extremely expensive on conventional Von-Neumann\narchitectures. Compute-in-memory (CIM) architectures mitigate this by\nperforming computations directly in memory, and when paired with sparse LLMs,\nenable storing and computing the entire model in memory, eliminating the data\nmovement on the off-chip bus and improving efficiency. Nonetheless, naively\nmapping sparse matrices onto CIM arrays leads to poor array utilization and\ndiminished computational efficiency. In this paper, we present an automated\nframework with novel mapping and scheduling strategies to accelerate sparse LLM\ninference on CIM accelerators. By exploiting block-diagonal sparsity, our\napproach improves CIM array utilization by over 50%, achieving more than 4x\nreduction in both memory footprint and the number of required floating-point\noperations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u6620\u5c04\u4e0e\u8c03\u5ea6\u7b56\u7565\uff0c\u5728\u5b58\u5185\u8ba1\u7b97\uff08CIM\uff09\u52a0\u901f\u5668\u4e0a\u9ad8\u6548\u52a0\u901f\u7a00\u758f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347CIM\u9635\u5217\u5229\u7528\u7387\u5e76\u51cf\u5c11\u5185\u5b58\u5360\u7528\u4e0e\u8ba1\u7b97\u91cf\u3002", "motivation": "\u5c3d\u7ba1\u7ed3\u6784\u5316\u7a00\u758f\u53ef\u5927\u5e45\u538b\u7f29LLM\u6a21\u578b\u89c4\u6a21\uff0c\u4f46\u5176\u63a8\u7406\uff08\u5c24\u5176\u662f\u89e3\u7801\u9636\u6bb5\uff09\u5728\u4f20\u7edf\u51af\u00b7\u8bfa\u4f9d\u66fc\u67b6\u6784\u4e0a\u4ecd\u53d7\u5185\u5b58\u5e26\u5bbd\u9650\u5236\uff1b\u800c\u5c06\u7a00\u758f\u6a21\u578b\u76f4\u63a5\u6620\u5c04\u5230\u5b58\u5185\u8ba1\u7b97\uff08CIM\uff09\u67b6\u6784\u65f6\uff0c\u53c8\u56e0\u6620\u5c04\u6548\u7387\u4f4e\u4e0b\u5bfc\u81f4\u9635\u5217\u5229\u7528\u7387\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u9488\u5bf9\u5757\u5bf9\u89d2\u7a00\u758f\u7ed3\u6784\u7684\u65b0\u578b\u6620\u5c04\u4e0e\u8c03\u5ea6\u7b56\u7565\uff0c\u4f18\u5316\u7a00\u758fLLM\u5728CIM\u52a0\u901f\u5668\u4e0a\u7684\u90e8\u7f72\u3002", "result": "\u8be5\u65b9\u6cd5\u5c06CIM\u9635\u5217\u5229\u7528\u7387\u63d0\u5347\u8d85\u8fc750%\uff0c\u540c\u65f6\u5b9e\u73b0\u5185\u5b58\u5360\u7528\u548c\u6d6e\u70b9\u8fd0\u7b97\u6b21\u6570\u5747\u51cf\u5c114\u500d\u4ee5\u4e0a\u3002", "conclusion": "\u901a\u8fc7\u9ad8\u6548\u5229\u7528\u7ed3\u6784\u5316\u7a00\u758f\u6027\uff0c\u6240\u63d0\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86CIM\u67b6\u6784\u4e0a\u7a00\u758fLLM\u63a8\u7406\u7684\u6548\u7387\u4e0e\u8d44\u6e90\u5229\u7528\u7387\uff0c\u4e3a\u5728\u8d44\u6e90\u53d7\u9650\u7cfb\u7edf\u4e0a\u90e8\u7f72\u5927\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.09983", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.09983", "abs": "https://arxiv.org/abs/2510.09983", "authors": ["Ethan Thompson", "Ali Sadeghi Jahromi", "AbdelRahman Abdou"], "title": "Fine-grained CDN Delegation", "comment": "13 pages, 2 figures", "summary": "The use of Content Delivery Networks (CDNs) has significantly increased over\nthe past decade, with approximately 55 million websites currently relying on\nCDN services. Emerging solutions, such as Delegated Credentials (RFC 9345),\nlack fine-grained definitions of many critical aspects of delegation, such as\nthe length of delegation chains, revocation mechanism, permitted operations,\nand a well-defined scope for said delegation. We present Delegation\nCertificates (DeCerts), which modify X.509 certificate standard and add new\nextensions to enable fine-grained CDN delegation. DeCerts allow domain owners\nto specify delegated and non-delegated subdomains, and control the depth of\ndelegation extended by CDNs, which provides flexibility in delegation\nmanagement. But more importantly, DeCerts are built on a new principle which\nprovides full autonomy to domain owners-domain owners can issue DeCerts fully\nindependent of Certificate Authorities (CAs), and thus have greater flexibility\nin policy control, including revocation methods. Such level of flexibility\nwould be hard to match if CAs where to issue such certificates. Revoking a\nDeCert revokes delegation. We discuss multiple revocation mechanisms for a\nDeCerts balancing security, performance, and delegator control. We modify\nFirefox to support DeCert (i.e., proper validation) as a proof-of-concept, and\ntest it to demonstrate the feasibility, compatibility of DeCerts with browsers\nand TLS/HTTPS protocols. DeCerts enhance the security, scalability, and\nmanageability of CDN delegation, offering a practical solution for Internet\nservices.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDelegation Certificates\uff08DeCerts\uff09\u7684\u65b0\u673a\u5236\uff0c\u901a\u8fc7\u6269\u5c55X.509\u8bc1\u4e66\u6807\u51c6\uff0c\u4f7f\u57df\u540d\u6240\u6709\u8005\u80fd\u591f\u7ec6\u7c92\u5ea6\u5730\u63a7\u5236CDN\u7684\u59d4\u6d3e\u6743\u9650\uff0c\u5305\u62ec\u6307\u5b9a\u53ef\u59d4\u6d3e/\u4e0d\u53ef\u59d4\u6d3e\u7684\u5b50\u57df\u540d\u3001\u63a7\u5236\u59d4\u6d3e\u6df1\u5ea6\uff0c\u5e76\u5b9e\u73b0\u65e0\u9700\u4f9d\u8d56\u8bc1\u4e66\u9881\u53d1\u673a\u6784\uff08CA\uff09\u7684\u81ea\u4e3b\u7b7e\u53d1\u4e0e\u7075\u6d3b\u540a\u9500\u673a\u5236\uff0c\u4ece\u800c\u63d0\u5347CDN\u59d4\u6d3e\u7684\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u4e0e\u53ef\u7ba1\u7406\u6027\u3002", "motivation": "\u73b0\u6709CDN\u59d4\u6d3e\u65b9\u6848\uff08\u5982RFC 9345\u4e2d\u7684Delegated Credentials\uff09\u7f3a\u4e4f\u5bf9\u59d4\u6d3e\u94fe\u957f\u5ea6\u3001\u540a\u9500\u673a\u5236\u3001\u5141\u8bb8\u64cd\u4f5c\u53ca\u59d4\u6d3e\u8303\u56f4\u7b49\u5173\u952e\u65b9\u9762\u7684\u7ec6\u7c92\u5ea6\u5b9a\u4e49\uff0c\u9650\u5236\u4e86\u57df\u540d\u6240\u6709\u8005\u5bf9\u59d4\u6d3e\u7b56\u7565\u7684\u63a7\u5236\u80fd\u529b\u3002", "method": "\u63d0\u51faDeCerts\u673a\u5236\uff0c\u4fee\u6539X.509\u8bc1\u4e66\u6807\u51c6\u5e76\u5f15\u5165\u65b0\u6269\u5c55\u5b57\u6bb5\uff0c\u4f7f\u57df\u540d\u6240\u6709\u8005\u53ef\u81ea\u4e3b\u7b7e\u53d1\u59d4\u6d3e\u8bc1\u4e66\uff0c\u660e\u786e\u63a7\u5236\u5b50\u57df\u540d\u59d4\u6d3e\u8303\u56f4\u4e0e\u6df1\u5ea6\uff0c\u5e76\u8bbe\u8ba1\u591a\u79cd\u517c\u987e\u5b89\u5168\u6027\u3001\u6027\u80fd\u548c\u63a7\u5236\u6743\u7684\u540a\u9500\u673a\u5236\uff1b\u540c\u65f6\u5728Firefox\u6d4f\u89c8\u5668\u4e2d\u5b9e\u73b0\u9a8c\u8bc1\u903b\u8f91\u4f5c\u4e3a\u6982\u5ff5\u9a8c\u8bc1\u3002", "result": "\u6210\u529f\u5728Firefox\u4e2d\u5b9e\u73b0DeCerts\u652f\u6301\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u6d4f\u89c8\u5668\u548cTLS/HTTPS\u534f\u8bae\u4e2d\u7684\u53ef\u884c\u6027\u4e0e\u517c\u5bb9\u6027\uff0c\u8bc1\u660eDeCerts\u80fd\u6709\u6548\u63d0\u5347CDN\u59d4\u6d3e\u7684\u7075\u6d3b\u6027\u3001\u5b89\u5168\u6027\u548c\u53ef\u7ba1\u7406\u6027\u3002", "conclusion": "DeCerts\u4e3aCDN\u59d4\u6d3e\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u3001\u5b89\u5168\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u8d4b\u4e88\u57df\u540d\u6240\u6709\u8005\u5b8c\u5168\u81ea\u4e3b\u6743\uff0c\u663e\u8457\u4f18\u4e8e\u4f9d\u8d56CA\u7684\u4f20\u7edf\u59d4\u6d3e\u673a\u5236\u3002"}}
{"id": "2510.09724", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.09724", "abs": "https://arxiv.org/abs/2510.09724", "authors": ["Qiaosheng Chen", "Yang Liu", "Lei Li", "Kai Chen", "Qipeng Guo", "Gong Cheng", "Fei Yuan"], "title": "InteractScience: Programmatic and Visually-Grounded Evaluation of Interactive Scientific Demonstration Code Generation", "comment": "27 pages, 17 figures", "summary": "Large Language Models (LLMs) are increasingly capable of generating complete\napplications from natural language instructions, creating new opportunities in\nscience and education. In these domains, interactive scientific demonstrations\nare particularly valuable for explaining concepts, supporting new teaching\nmethods, and presenting research findings. Generating such demonstrations\nrequires models to combine accurate scientific knowledge with the ability to\nimplement interactive front-end code that behaves correctly and responds to\nuser actions. This capability goes beyond the scope of existing benchmarks,\nwhich typically evaluate either knowledge question answering without grounding\nin code or static web code generation without scientific interactivity. To\nevaluate this integrated ability, we design a hybrid framework that combines\nprogrammatic functional testing to rigorously verify interaction logic with\nvisually-grounded qualitative testing to assess rendered outputs against\nreference snapshots. Building on this framework, we present InteractScience, a\nbenchmark consisting of a substantial set of carefully designed questions\nacross five scientific domains, each paired with unit tests, reference\nsnapshots, and checklists. We evaluate 30 leading open- and closed-source LLMs\nand report results that highlight ongoing weaknesses in integrating domain\nknowledge with interactive front-end coding. Our work positions InteractScience\nas the first benchmark to automatically measure this combined capability with\nrealistic interactive operations, providing a foundation for advancing reliable\nand educationally useful scientific demonstration code generation. All code and\ndata are publicly available at https://github.com/open-compass/InteractScience.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86InteractScience\uff0c\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u9886\u57df\u4e2d\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u4e0e\u4ea4\u4e92\u5f0f\u524d\u7aef\u4ee3\u7801\u751f\u6210\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u901a\u8fc7\u7a0b\u5e8f\u5316\u529f\u80fd\u6d4b\u8bd5\u4e0e\u89c6\u89c9\u5b9a\u6027\u8bc4\u4f30\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u6846\u67b6\u8fdb\u884c\u8bc4\u6d4b\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u4ea4\u4e92\u5f0f\u6f14\u793a\u751f\u6210\u65b9\u9762\u7684\u80fd\u529b\uff0c\u56e0\u5176\u901a\u5e38\u4ec5\u5173\u6ce8\u77e5\u8bc6\u95ee\u7b54\u6216\u9759\u6001\u7f51\u9875\u4ee3\u7801\u751f\u6210\uff0c\u7f3a\u4e4f\u5bf9\u79d1\u5b66\u77e5\u8bc6\u4e0e\u4ea4\u4e92\u903b\u8f91\u7ed3\u5408\u7684\u7efc\u5408\u8bc4\u4f30\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6df7\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u7ed3\u5408\u7a0b\u5e8f\u5316\u529f\u80fd\u6d4b\u8bd5\uff08\u9a8c\u8bc1\u4ea4\u4e92\u903b\u8f91\uff09\u548c\u57fa\u4e8e\u89c6\u89c9\u7684\u5b9a\u6027\u6d4b\u8bd5\uff08\u6bd4\u5bf9\u6e32\u67d3\u8f93\u51fa\u4e0e\u53c2\u8003\u5feb\u7167\uff09\uff0c\u5e76\u6784\u5efa\u4e86\u5305\u542b\u4e94\u4e2a\u79d1\u5b66\u9886\u57df\u3001\u914d\u6709\u5355\u5143\u6d4b\u8bd5\u3001\u53c2\u8003\u5feb\u7167\u548c\u68c0\u67e5\u6e05\u5355\u7684InteractScience\u57fa\u51c6\u3002", "result": "\u5bf930\u4e2a\u4e3b\u6d41\u5f00\u6e90\u548c\u95ed\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5b83\u4eec\u5728\u6574\u5408\u79d1\u5b66\u77e5\u8bc6\u4e0e\u4ea4\u4e92\u5f0f\u524d\u7aef\u7f16\u7801\u65b9\u9762\u4ecd\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002", "conclusion": "InteractScience\u662f\u9996\u4e2a\u80fd\u81ea\u52a8\u8bc4\u4f30\u6a21\u578b\u5728\u771f\u5b9e\u4ea4\u4e92\u64cd\u4f5c\u4e2d\u878d\u5408\u79d1\u5b66\u77e5\u8bc6\u4e0e\u524d\u7aef\u4ea4\u4e92\u4ee3\u7801\u751f\u6210\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u4e3a\u63d0\u5347\u53ef\u9760\u4e14\u5177\u6559\u80b2\u4ef7\u503c\u7684\u79d1\u5b66\u6f14\u793a\u751f\u6210\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.10040", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.10040", "abs": "https://arxiv.org/abs/2510.10040", "authors": ["Shafi Ullah Khan", "Michel Kulhandjian", "Debashri Roy"], "title": "Pushing the Boundaries in CBRS Band: Robust Radar Detection within High 5G Interference", "comment": null, "summary": "Spectrum sharing is a critical strategy for meeting escalating user demands\nvia commercial wireless services, yet its effective regulation and\ntechnological enablement, particularly concerning coexistence with incumbent\nsystems, remain significant challenges. Federal organizations have established\nregulatory frameworks to manage shared commercial use alongside\nmission-critical operations, such as military communications. This paper\ninvestigates the potential of machine learning (ML)-based approaches to enhance\nspectrum sharing capabilities within the Citizens Broadband Radio Service\n(CBRS) band, specifically focusing on the coexistence of commercial signals\n(e.g., 5G) and military radar systems. We demonstrate that ML techniques can\npotentially extend the Federal Communications Commission (FCC)-recommended\nsignal-to-interference-plus-noise ratio (SINR) boundaries by improving radar\ndetection and waveform identification in high-interference environments.\nThrough rigorous evaluation using both synthetic and real-world signals, our\nfindings indicate that proposed ML models, utilizing In-phase/Quadrature (IQ)\ndata and spectrograms, can achieve the FCC-recommended $99\\%$ radar detection\naccuracy even when subjected to high interference from 5G signals upto -5dB\nSINR, exceeding the required limits of $20$ SINR. Our experimental studies\ndistinguish this work from the state-of-the-art by significantly extending the\nSINR limit for $99\\%$ radar detection accuracy from approximately $12$ dB down\nto $-5$ dB. Subsequent to detection, we further apply ML to analyze and\nidentify radar waveforms. The proposed models also demonstrate the capability\nto classify six distinct radar waveform types with $93\\%$ accuracy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u5728CBRS\u9891\u6bb5\u4e2d\u63d0\u5347\u9891\u8c31\u5171\u4eab\u80fd\u529b\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u57285G\u5546\u4e1a\u4fe1\u53f7\u4e0e\u519b\u7528\u96f7\u8fbe\u7cfb\u7edf\u5171\u5b58\u7684\u573a\u666f\u4e0b\u3002\u901a\u8fc7\u4f7f\u7528IQ\u6570\u636e\u548c\u9891\u8c31\u56fe\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u9ad8\u5e72\u6270\u73af\u5883\u4e0b\uff08SINR\u4f4e\u81f3-5 dB\uff09\u4ecd\u80fd\u8fbe\u5230FCC\u63a8\u8350\u768499%\u96f7\u8fbe\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u5e76\u80fd\u4ee593%\u7684\u51c6\u786e\u7387\u8bc6\u522b\u516d\u79cd\u96f7\u8fbe\u6ce2\u5f62\u7c7b\u578b\u3002", "motivation": "\u968f\u7740\u5546\u4e1a\u65e0\u7ebf\u670d\u52a1\u7528\u6237\u9700\u6c42\u7684\u4e0d\u65ad\u589e\u957f\uff0c\u9891\u8c31\u5171\u4eab\u6210\u4e3a\u5173\u952e\u7b56\u7565\uff0c\u4f46\u5176\u6709\u6548\u76d1\u7ba1\u548c\u6280\u672f\u5b9e\u73b0\uff0c\u5c24\u5176\u662f\u5728\u4e0e\u73b0\u6709\u7cfb\u7edf\uff08\u5982\u519b\u7528\u96f7\u8fbe\uff09\u5171\u5b58\u65b9\u9762\uff0c\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u63d0\u5347\u5728\u9ad8\u5e72\u6270\u73af\u5883\u4e0b\u7684\u96f7\u8fbe\u68c0\u6d4b\u4e0e\u6ce2\u5f62\u8bc6\u522b\u80fd\u529b\uff0c\u4ee5\u652f\u6301\u66f4\u9ad8\u6548\u7684\u9891\u8c31\u5171\u4eab\u3002", "method": "\u91c7\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528I/Q\u6570\u636e\u548c\u9891\u8c31\u56fe\u4f5c\u4e3a\u8f93\u5165\uff0c\u6784\u5efa\u6a21\u578b\u4ee5\u5b9e\u73b0\u96f7\u8fbe\u4fe1\u53f7\u68c0\u6d4b\u548c\u6ce2\u5f62\u5206\u7c7b\u3002\u901a\u8fc7\u5408\u6210\u4fe1\u53f7\u548c\u771f\u5b9e\u4fe1\u53f7\u5bf9\u6a21\u578b\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\uff0c\u6d4b\u8bd5\u5176\u5728\u4e0d\u540cSINR\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u6240\u63d0ML\u6a21\u578b\u5728SINR\u4f4e\u81f3-5 dB\u7684\u9ad8\u5e72\u6270\u73af\u5883\u4e0b\u4ecd\u80fd\u5b9e\u73b099%\u7684\u96f7\u8fbe\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff08\u6b64\u524d\u7ea6\u4e3a12 dB\uff09\uff1b\u540c\u65f6\uff0c\u6a21\u578b\u80fd\u4ee593%\u7684\u51c6\u786e\u7387\u5bf9\u516d\u79cd\u96f7\u8fbe\u6ce2\u5f62\u8fdb\u884c\u5206\u7c7b\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u53ef\u663e\u8457\u6269\u5c55\u9891\u8c31\u5171\u4eab\u4e2d\u96f7\u8fbe\u68c0\u6d4b\u7684SINR\u8fb9\u754c\uff0c\u63d0\u5347\u57285G\u7b49\u5f3a\u5e72\u6270\u73af\u5883\u4e0b\u7684\u5171\u5b58\u80fd\u529b\uff0c\u4e3aCBRS\u7b49\u9891\u8c31\u5171\u4eab\u673a\u5236\u63d0\u4f9b\u6709\u6548\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2510.10325", "categories": ["cs.MA", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.10325", "abs": "https://arxiv.org/abs/2510.10325", "authors": ["Walid Abdela"], "title": "KG-MAS: Knowledge Graph-Enhanced Multi-Agent Infrastructure for coupling physical and digital robotic environments", "comment": null, "summary": "The seamless integration of physical and digital environments in\nCyber-Physical Systems(CPS), particularly within Industry 4.0, presents\nsignificant challenges stemming from system heterogeneity and complexity.\nTraditional approaches often rely on rigid, data-centric solutions like\nco-simulation frameworks or brittle point-to-point middleware bridges, which\nlack the semantic richness and flexibility required for intelligent, autonomous\ncoordination. This report introduces the Knowledge Graph-Enhanced Multi-Agent\nInfrastructure(KG-MAS), as resolution in addressing such limitations. KG-MAS\nleverages a centralized Knowledge Graph (KG) as a dynamic, shared world model,\nproviding a common semantic foundation for a Multi-Agent System(MAS).\nAutonomous agents, representing both physical and digital components, query\nthis KG for decision-making and update it with real-time state information. The\ninfrastructure features a model-driven architecture which facilitates the\nautomatic generation of agents from semantic descriptions, thereby simplifying\nsystem extension and maintenance. By abstracting away underlying communication\nprotocols and providing a unified, intelligent coordination mechanism, KG-MAS\noffers a robust, scalable, and flexible solution for coupling heterogeneous\nphysical and digital robotic environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aKG-MAS\u7684\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u591a\u667a\u80fd\u4f53\u57fa\u7840\u8bbe\u65bd\uff0c\u901a\u8fc7\u5c06\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u5171\u4eab\u8bed\u4e49\u4e16\u754c\u6a21\u578b\uff0c\u5b9e\u73b0\u5f02\u6784\u7269\u7406\u4e0e\u6570\u5b57\u73af\u5883\u5728\u5de5\u4e1a4.0\u4e2d\u7684\u667a\u80fd\u534f\u540c\u3002", "motivation": "\u73b0\u6709\u9762\u5411\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\uff08CPS\uff09\u7684\u65b9\u6cd5\uff08\u5982\u5171\u4eff\u771f\u6846\u67b6\u6216\u70b9\u5bf9\u70b9\u4e2d\u95f4\u4ef6\uff09\u7f3a\u4e4f\u8bed\u4e49\u8868\u8fbe\u80fd\u529b\u548c\u7075\u6d3b\u6027\uff0c\u96be\u4ee5\u652f\u6301\u667a\u80fd\u3001\u81ea\u4e3b\u7684\u534f\u540c\uff0c\u5c24\u5176\u5728\u5de5\u4e1a4.0\u4e2d\u9762\u5bf9\u7cfb\u7edf\u5f02\u6784\u6027\u548c\u590d\u6742\u6027\u65f6\u8868\u73b0\u4e0d\u8db3\u3002", "method": "KG-MAS\u67b6\u6784\u5229\u7528\u4e00\u4e2a\u4e2d\u5fc3\u5316\u7684\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u52a8\u6001\u5171\u4eab\u4e16\u754c\u6a21\u578b\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u7edf\u4e00\u8bed\u4e49\u57fa\u7840\uff1b\u667a\u80fd\u4f53\u57fa\u4e8e\u8be5\u56fe\u8c31\u8fdb\u884c\u67e5\u8be2\u4e0e\u72b6\u6001\u66f4\u65b0\uff0c\u5e76\u901a\u8fc7\u6a21\u578b\u9a71\u52a8\u65b9\u5f0f\u4ece\u8bed\u4e49\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u667a\u80fd\u4f53\u3002", "result": "\u8be5\u67b6\u6784\u5b9e\u73b0\u4e86\u5bf9\u5e95\u5c42\u901a\u4fe1\u534f\u8bae\u7684\u62bd\u8c61\uff0c\u63d0\u4f9b\u4e86\u7edf\u4e00\u3001\u667a\u80fd\u7684\u534f\u8c03\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u5728\u5f02\u6784\u7269\u7406\u4e0e\u6570\u5b57\u673a\u5668\u4eba\u73af\u5883\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u4e0e\u7075\u6d3b\u6027\u3002", "conclusion": "KG-MAS\u4e3a\u5de5\u4e1a4.0\u4e2d\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u7684\u8bed\u4e49\u5316\u3001\u667a\u80fd\u5316\u96c6\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u7ef4\u62a4\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10044", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.10044", "abs": "https://arxiv.org/abs/2510.10044", "authors": ["Rahul Vanukuri", "Shafi Ullah Khan", "Talip Tolga Sar\u0131", "Gokhan Secinti", "Diego Pati\u00f1o", "Debashri Roy"], "title": "Waves of Imagination: Unconditional Spectrogram Generation using Diffusion Architectures", "comment": null, "summary": "The growing demand for effective spectrum management and interference\nmitigation in shared bands, such as the Citizens Broadband Radio Service\n(CBRS), requires robust radar detection algorithms to protect the military\ntransmission from interference due to commercial wireless transmission. These\nalgorithms, in turn, depend on large, diverse, and carefully labeled\nspectrogram datasets. However, collecting and annotating real-world radio\nfrequency (RF) spectrogram data remains a significant challenge, as radar\nsignals are rare, and their occurrences are infrequent. This challenge makes\nthe creation of balanced datasets difficult, limiting the performance and\ngeneralizability of AI models in this domain.\n  To address this critical issue, we propose a diffusion-based generative model\nfor synthesizing realistic and diverse spectrograms of five distinct categories\nthat integrate LTE, 5G, and radar signals within the CBRS band. We conduct a\nstructural and statistical fidelity analysis of the generated spectrograms\nusing widely accepted evaluation metrics Structural Similarity Index Measure\n(SSIM) and Peak Signal-to-Noise Ratio (PSNR), to quantify their divergence from\nthe training data. Furthermore, we demonstrate that pre-training on the\ngenerated spectrograms significantly improves training efficiency on a\nreal-world radar detection task by enabling $51.5\\%$ faster convergence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u5408\u6210\u5305\u542bLTE\u30015G\u548c\u96f7\u8fbe\u4fe1\u53f7\u7684CBRS\u9891\u6bb5\u9891\u8c31\u56fe\uff0c\u4ee5\u89e3\u51b3\u771f\u5b9e\u96f7\u8fbe\u6570\u636e\u7a00\u7f3a\u5bfc\u81f4\u7684\u6570\u636e\u96c6\u4e0d\u5e73\u8861\u95ee\u9898\uff1b\u751f\u6210\u6570\u636e\u5728\u7ed3\u6784\u548c\u7edf\u8ba1\u7279\u6027\u4e0a\u4e0e\u771f\u5b9e\u6570\u636e\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u5e76\u80fd\u663e\u8457\u63d0\u5347\u96f7\u8fbe\u68c0\u6d4b\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u3002", "motivation": "\u5728CBRS\u7b49\u5171\u4eab\u9891\u6bb5\u4e2d\uff0c\u4e3a\u4fdd\u62a4\u519b\u7528\u901a\u4fe1\u514d\u53d7\u5546\u7528\u65e0\u7ebf\u4fe1\u53f7\u5e72\u6270\uff0c\u9700\u4f9d\u8d56\u5927\u91cf\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u4e14\u6807\u6ce8\u826f\u597d\u7684\u9891\u8c31\u56fe\u6570\u636e\u8bad\u7ec3\u96f7\u8fbe\u68c0\u6d4b\u7b97\u6cd5\uff0c\u4f46\u771f\u5b9e\u96f7\u8fbe\u4fe1\u53f7\u7a00\u5c11\u4e14\u51fa\u73b0\u9891\u7387\u4f4e\uff0c\u5bfc\u81f4\u96be\u4ee5\u6784\u5efa\u5e73\u8861\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86AI\u6a21\u578b\u7684\u6027\u80fd\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u6a21\u578b\uff0c\u5408\u6210CBRS\u9891\u6bb5\u5185\u5305\u542bLTE\u30015G\u548c\u96f7\u8fbe\u4fe1\u53f7\u7684\u4e94\u7c7b\u903c\u771f\u4e14\u591a\u6837\u7684\u9891\u8c31\u56fe\uff1b\u4f7f\u7528SSIM\u548cPSNR\u7b49\u6307\u6807\u5bf9\u751f\u6210\u9891\u8c31\u56fe\u8fdb\u884c\u7ed3\u6784\u4e0e\u7edf\u8ba1\u4fdd\u771f\u5ea6\u5206\u6790\uff0c\u5e76\u5728\u771f\u5b9e\u96f7\u8fbe\u68c0\u6d4b\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u5176\u9884\u8bad\u7ec3\u6548\u679c\u3002", "result": "\u751f\u6210\u7684\u9891\u8c31\u56fe\u5728SSIM\u548cPSNR\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u4e0e\u8bad\u7ec3\u6570\u636e\u9ad8\u5ea6\u76f8\u4f3c\u6027\uff1b\u5728\u771f\u5b9e\u96f7\u8fbe\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u4f7f\u7528\u751f\u6210\u6570\u636e\u9884\u8bad\u7ec3\u53ef\u4f7f\u6a21\u578b\u6536\u655b\u901f\u5ea6\u63d0\u534751.5%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6269\u6563\u751f\u6210\u6a21\u578b\u80fd\u6709\u6548\u7f13\u89e3\u771f\u5b9e\u96f7\u8fbe\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u5347\u9891\u8c31\u56fe\u6570\u636e\u96c6\u7684\u591a\u6837\u6027\u4e0e\u5e73\u8861\u6027\uff0c\u5e76\u663e\u8457\u589e\u5f3a\u96f7\u8fbe\u68c0\u6d4b\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u4e0e\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.10166", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.10166", "abs": "https://arxiv.org/abs/2510.10166", "authors": ["Suhrid Gupta", "Muhammed Tawfiqul Islam", "Rajkumar Buyya"], "title": "Proactive and Reactive Autoscaling Techniques for Edge Computing", "comment": null, "summary": "Edge computing allows for the decentralization of computing resources. This\ndecentralization is achieved through implementing microservice architectures,\nwhich require low latencies to meet stringent service level agreements (SLA)\nsuch as performance, reliability, and availability metrics. While cloud\ncomputing offers the large data storage and computation resources necessary to\nhandle peak demands, a hybrid cloud and edge environment is required to ensure\nSLA compliance. Several auto-scaling algorithms have been proposed to try to\nachieve these compliance challenges, but they suffer from performance issues\nand configuration complexity. This chapter provides a brief overview of edge\ncomputing architecture, its uses, benefits, and challenges for resource\nscaling. We then introduce Service Level Agreements, and existing research on\ndevising algorithms used in edge computing environments to meet these\nagreements, along with their benefits and drawbacks.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u8fb9\u7f18\u8ba1\u7b97\u67b6\u6784\u53ca\u5176\u5728\u6ee1\u8db3\u670d\u52a1\u7b49\u7ea7\u534f\u8bae\uff08SLA\uff09\u65b9\u9762\u7684\u8d44\u6e90\u6269\u5c55\u6311\u6218\uff0c\u4ecb\u7ecd\u4e86\u73b0\u6709\u81ea\u52a8\u6269\u5c55\u7b97\u6cd5\u7684\u4f18\u7f3a\u70b9\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u9700\u901a\u8fc7\u5fae\u670d\u52a1\u67b6\u6784\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u4ee5\u6ee1\u8db3SLA\u8981\u6c42\uff0c\u4f46\u73b0\u6709\u81ea\u52a8\u6269\u5c55\u7b97\u6cd5\u5b58\u5728\u6027\u80fd\u95ee\u9898\u548c\u914d\u7f6e\u590d\u6742\u6027\uff0c\u56e0\u6b64\u9700\u7cfb\u7edf\u68b3\u7406\u76f8\u5173\u7814\u7a76\u3002", "method": "\u5bf9\u8fb9\u7f18\u8ba1\u7b97\u67b6\u6784\u3001SLA\u5b9a\u4e49\u53ca\u73b0\u6709\u8fb9\u7f18\u73af\u5883\u4e2d\u7528\u4e8e\u6ee1\u8db3SLA\u7684\u81ea\u52a8\u6269\u5c55\u7b97\u6cd5\u8fdb\u884c\u7efc\u8ff0\u4e0e\u5206\u6790\u3002", "result": "\u603b\u7ed3\u4e86\u5f53\u524d\u8fb9\u7f18\u8ba1\u7b97\u4e2d\u8d44\u6e90\u6269\u5c55\u7b97\u6cd5\u7684\u4f18\u52bf\u4e0e\u4e0d\u8db3\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002", "conclusion": "\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u66f4\u9ad8\u6548\u3001\u6613\u914d\u7f6e\u7684\u81ea\u52a8\u6269\u5c55\u673a\u5236\uff0c\u4ee5\u5728\u6df7\u5408\u4e91\u8fb9\u73af\u5883\u4e2d\u6709\u6548\u4fdd\u969cSLA\u5408\u89c4\u3002"}}
{"id": "2510.09938", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.09938", "abs": "https://arxiv.org/abs/2510.09938", "authors": ["Youshuai Tan", "Zishuo Ding", "Jinfu Chen", "Weiyi Shang"], "title": "OFP-Repair: Repairing Floating-point Errors via Original-Precision Arithmetic", "comment": null, "summary": "Errors in floating-point programs can lead to severe consequences,\nparticularly in critical domains such as military, aerospace, and financial\nsystems, making their repair a crucial research problem. In practice, some\nerrors can be fixed using original-precision arithmetic, while others require\nhigh-precision computation. Developers often avoid addressing the latter due to\nexcessive computational resources required. However, they sometimes struggle to\ndistinguish between these two types of errors, and existing repair tools fail\nto assist in this differentiation. Most current repair tools rely on\nhigh-precision implementations, which are time-consuming to develop and demand\nspecialized expertise. Although a few tools do not require high-precision\nprograms, they can only fix a limited subset of errors or produce suboptimal\nresults.\n  To address these challenges, we propose a novel method, named OFP-Repair.On\nACESO's dataset, our patches achieve improvements of three, seven, three, and\neight orders of magnitude across four accuracy metrics. In real-world cases,\nour method successfully detects all five original-precision-repairable errors\nand fixes three, whereas ACESO only repairs one. Notably, these results are\nbased on verified data and do not fully capture the potential of OFP-Repair. To\nfurther validate our method, we deploy it on a decade-old open bug report from\nGNU Scientific Library (GSL), successfully repairing five out of 15 bugs. The\ndevelopers have expressed interest in our method and are considering\nintegrating our tool into their development workflow. We are currently working\non applying our patches to GSL. The results are highly encouraging,\ndemonstrating the practical applicability of our technique.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOFP-Repair\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u4fee\u590d\u6d6e\u70b9\u7a0b\u5e8f\u4e2d\u7684\u9519\u8bef\uff0c\u80fd\u591f\u6709\u6548\u533a\u5206\u5e76\u4fee\u590d\u4ec5\u9700\u539f\u59cb\u7cbe\u5ea6\u5373\u53ef\u4fee\u590d\u7684\u9519\u8bef\uff0c\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u9ad8\u7cbe\u5ea6\u8ba1\u7b97\u5f00\u9500\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u5e76\u5728\u771f\u5b9e\u6848\u4f8b\uff08\u5982GNU Scientific Library\u7684\u957f\u671f\u672a\u4fee\u590dbug\uff09\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u7684\u5b9e\u7528\u6027\u548c\u4fee\u590d\u80fd\u529b\u3002", "motivation": "\u6d6e\u70b9\u7a0b\u5e8f\u4e2d\u7684\u9519\u8bef\u5728\u519b\u4e8b\u3001\u822a\u5929\u548c\u91d1\u878d\u7b49\u5173\u952e\u9886\u57df\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u540e\u679c\u3002\u73b0\u6709\u4fee\u590d\u5de5\u5177\u8981\u4e48\u4f9d\u8d56\u8017\u65f6\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u7684\u9ad8\u7cbe\u5ea6\u5b9e\u73b0\uff0c\u8981\u4e48\u53ea\u80fd\u4fee\u590d\u6709\u9650\u7c7b\u578b\u7684\u9519\u8bef\uff0c\u4e14\u5f00\u53d1\u8005\u96be\u4ee5\u5224\u65ad\u54ea\u4e9b\u9519\u8bef\u53ef\u7528\u539f\u59cb\u7cbe\u5ea6\u4fee\u590d\u3002\u56e0\u6b64\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u81ea\u52a8\u533a\u5206\u5e76\u9ad8\u6548\u4fee\u590d\u8fd9\u4e24\u7c7b\u9519\u8bef\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faOFP-Repair\u65b9\u6cd5\uff0c\u65e0\u9700\u4f9d\u8d56\u9ad8\u7cbe\u5ea6\u7a0b\u5e8f\u5b9e\u73b0\uff0c\u901a\u8fc7\u5206\u6790\u5224\u65ad\u9519\u8bef\u662f\u5426\u53ef\u7528\u539f\u59cb\u7cbe\u5ea6\u4fee\u590d\uff0c\u5e76\u751f\u6210\u76f8\u5e94\u8865\u4e01\u3002", "result": "\u5728ACESO\u6570\u636e\u96c6\u4e0a\uff0cOFP-Repair\u5728\u56db\u4e2a\u7cbe\u5ea6\u6307\u6807\u4e0a\u5206\u522b\u63d0\u5347\u4e863\u30017\u30013\u548c8\u4e2a\u6570\u91cf\u7ea7\uff1b\u5728\u771f\u5b9e\u6848\u4f8b\u4e2d\u6210\u529f\u68c0\u6d4b\u51fa\u5168\u90e85\u4e2a\u53ef\u539f\u59cb\u7cbe\u5ea6\u4fee\u590d\u7684\u9519\u8bef\u5e76\u4fee\u590d\u5176\u4e2d3\u4e2a\uff08ACESO\u4ec5\u4fee\u590d1\u4e2a\uff09\uff1b\u5728GNU Scientific Library\u768415\u4e2a\u957f\u671fbug\u4e2d\u6210\u529f\u4fee\u590d5\u4e2a\uff0c\u83b7\u5f97\u5f00\u53d1\u8005\u8ba4\u53ef\u3002", "conclusion": "OFP-Repair\u5728\u6d6e\u70b9\u7a0b\u5e8f\u9519\u8bef\u4fee\u590d\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u6709\u6548\u51cf\u5c11\u5bf9\u9ad8\u7cbe\u5ea6\u8ba1\u7b97\u7684\u4f9d\u8d56\uff0c\u63d0\u5347\u4fee\u590d\u6548\u7387\u4e0e\u9002\u7528\u6027\uff0c\u5177\u5907\u826f\u597d\u7684\u5de5\u7a0b\u843d\u5730\u524d\u666f\u3002"}}
{"id": "2510.10302", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.10302", "abs": "https://arxiv.org/abs/2510.10302", "authors": ["Liangkun Chen", "Zijian Wen", "Tian Wu", "Xiaoxi Zhang", "Chuan Wu"], "title": "SP-MoE: Speculative Decoding and Prefetching for Accelerating MoE-based Model Inference", "comment": null, "summary": "The Mixture-of-Experts (MoE) architecture has been widely adopted in large\nlanguage models (LLMs) to reduce computation cost through model sparsity.\nEmploying speculative decoding (SD) can further accelerate MoE inference by\ndrafting multiple tokens per step and verifying them in parallel. However,\ncombining MoE with SD inflates GPU memory and aggravates CPU-GPU bandwidth\ncontention during multi-token verification. Existing MoE offloading systems are\nSD-agnostic and do not address this bottleneck. We present SP-MoE, the first\nSD-aware expert-offloading and compute-communication pipelining framework.\nSP-MoE introduces: (1) speculative expert prefetching that exploits structural\ncorrespondence between the draft and target models to prefetch likely experts\nahead of verification; (2) a cutoff-layer policy that bounds per-layer prefetch\ndepth based on empirical profiles and an analytical latency model, guaranteeing\njust-in-time availability without overfetch; and (3) a pipelined runtime with\nasynchronous prefetch threads and batched I/O to hide loading latency.\nExtensive experiments demonstrate that SP-MoE achieves a 1.07-3.5 times TPOT\nspeedup over state-of-the-art methods across diverse datasets, environments,\nand MoE-based models.", "AI": {"tldr": "SP-MoE \u662f\u9996\u4e2a\u9762\u5411\u63a8\u6d4b\u89e3\u7801\uff08SD\uff09\u7684\u4e13\u5bb6\u5378\u8f7d\u4e0e\u8ba1\u7b97\u901a\u4fe1\u6d41\u6c34\u7ebf\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u6d4b\u6027\u4e13\u5bb6\u9884\u53d6\u3001\u622a\u65ad\u5c42\u7b56\u7565\u548c\u6d41\u6c34\u7ebf\u8fd0\u884c\u65f6\uff0c\u663e\u8457\u52a0\u901f MoE \u6a21\u578b\u63a8\u7406\u3002", "motivation": "\u5c06 Mixture-of-Experts\uff08MoE\uff09\u4e0e\u63a8\u6d4b\u89e3\u7801\uff08SD\uff09\u7ed3\u5408\u867d\u80fd\u63d0\u5347\u63a8\u7406\u901f\u5ea6\uff0c\u4f46\u4f1a\u52a0\u5267 GPU \u5185\u5b58\u538b\u529b\u548c CPU-GPU \u5e26\u5bbd\u7ade\u4e89\uff0c\u800c\u73b0\u6709 MoE \u5378\u8f7d\u7cfb\u7edf\u672a\u8003\u8651 SD \u7279\u6027\uff0c\u65e0\u6cd5\u89e3\u51b3\u8be5\u74f6\u9888\u3002", "method": "SP-MoE \u63d0\u51fa\u4e09\u9879\u5173\u952e\u6280\u672f\uff1a(1) \u5229\u7528\u8349\u7a3f\u6a21\u578b\u4e0e\u76ee\u6807\u6a21\u578b\u7ed3\u6784\u5bf9\u5e94\u5173\u7cfb\u8fdb\u884c\u63a8\u6d4b\u6027\u4e13\u5bb6\u9884\u53d6\uff1b(2) \u57fa\u4e8e\u5b9e\u8bc1\u5206\u6790\u548c\u5ef6\u8fdf\u6a21\u578b\u8bbe\u5b9a\u6bcf\u5c42\u9884\u53d6\u6df1\u5ea6\u4e0a\u9650\u7684\u622a\u65ad\u5c42\u7b56\u7565\uff1b(3) \u91c7\u7528\u5f02\u6b65\u9884\u53d6\u7ebf\u7a0b\u4e0e\u6279\u5904\u7406 I/O \u7684\u6d41\u6c34\u7ebf\u8fd0\u884c\u65f6\u4ee5\u9690\u85cf\u52a0\u8f7d\u5ef6\u8fdf\u3002", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u3001\u73af\u5883\u548c MoE \u6a21\u578b\u4e0a\uff0cSP-MoE \u76f8\u6bd4\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\u5b9e\u73b0\u4e86 1.07 \u81f3 3.5 \u500d\u7684\u6bcf\u8f93\u51fa token \u65f6\u95f4\uff08TPOT\uff09\u52a0\u901f\u3002", "conclusion": "SP-MoE \u6709\u6548\u89e3\u51b3\u4e86 MoE \u4e0e\u63a8\u6d4b\u89e3\u7801\u7ed3\u5408\u65f6\u7684\u5185\u5b58\u4e0e\u5e26\u5bbd\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\uff0c\u4e3a\u9ad8\u6548 MoE \u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2510.09968", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.09968", "abs": "https://arxiv.org/abs/2510.09968", "authors": ["Stefan Pasch"], "title": "Operationalizing AI: Empirical Evidence on MLOps Practices, User Satisfaction, and Organizational Context", "comment": null, "summary": "Organizational efforts to utilize and operationalize artificial intelligence\n(AI) are often accompanied by substantial challenges, including scalability,\nmaintenance, and coordination across teams. In response, the concept of Machine\nLearning Operations (MLOps) has emerged as a set of best practices that\nintegrate software engineering principles with the unique demands of managing\nthe ML lifecycle. Yet, empirical evidence on whether and how these practices\nsupport users in developing and operationalizing AI applications remains\nlimited. To address this gap, this study analyzes over 8,000 user reviews of AI\ndevelopment platforms from G2.com. Using zero-shot classification, we measure\nreview sentiment toward nine established MLOps practices, including continuous\nintegration and delivery (CI/CD), workflow orchestration, reproducibility,\nversioning, collaboration, and monitoring. Seven of the nine practices show a\nsignificant positive relationship with user satisfaction, suggesting that\neffective MLOps implementation contributes tangible value to AI development.\nHowever, organizational context also matters: reviewers from small firms\ndiscuss certain MLOps practices less frequently, suggesting that organizational\ncontext influences the prevalence and salience of MLOps, though firm size does\nnot moderate the MLOps-satisfaction link. This indicates that once applied,\nMLOps practices are perceived as universally beneficial across organizational\nsettings.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u67908000\u591a\u6761AI\u5f00\u53d1\u5e73\u53f0\u7528\u6237\u8bc4\u8bba\uff0c\u53d1\u73b0\u5927\u591a\u6570MLOps\u5b9e\u8df5\u4e0e\u7528\u6237\u6ee1\u610f\u5ea6\u663e\u8457\u6b63\u76f8\u5173\uff0c\u4e14\u5176\u76ca\u5904\u666e\u904d\u9002\u7528\u4e8e\u4e0d\u540c\u89c4\u6a21\u7684\u7ec4\u7ec7\u3002", "motivation": "\u5c3d\u7ba1MLOps\u88ab\u63d0\u51fa\u4f5c\u4e3a\u5e94\u5bf9AI\u5f00\u53d1\u4e0e\u8fd0\u7ef4\u6311\u6218\u7684\u6700\u4f73\u5b9e\u8df5\uff0c\u4f46\u7f3a\u4e4f\u5b9e\u8bc1\u8bc1\u636e\u8bc1\u660e\u8fd9\u4e9b\u5b9e\u8df5\u662f\u5426\u4ee5\u53ca\u5982\u4f55\u652f\u6301\u7528\u6237\u5f00\u53d1\u548c\u90e8\u7f72AI\u5e94\u7528\u3002", "method": "\u7814\u7a76\u4eceG2.com\u6536\u96c6\u4e868000\u591a\u6761\u7528\u6237\u8bc4\u8bba\uff0c\u91c7\u7528\u96f6\u6837\u672c\u5206\u7c7b\u65b9\u6cd5\u8bc4\u4f30\u7528\u6237\u5bf9\u4e5d\u9879MLOps\u5b9e\u8df5\u7684\u60c5\u611f\u503e\u5411\uff0c\u5e76\u5206\u6790\u7ec4\u7ec7\u89c4\u6a21\u5bf9\u5b9e\u8df5\u4f7f\u7528\u9891\u7387\u53ca\u6ee1\u610f\u5ea6\u5f71\u54cd\u3002", "result": "\u4e5d\u9879MLOps\u5b9e\u8df5\u4e2d\uff0c\u6709\u4e03\u9879\u4e0e\u7528\u6237\u6ee1\u610f\u5ea6\u663e\u8457\u6b63\u76f8\u5173\uff1b\u5c0f\u578b\u4f01\u4e1a\u7528\u6237\u63d0\u53ca\u67d0\u4e9b\u5b9e\u8df5\u7684\u9891\u7387\u8f83\u4f4e\uff0c\u4f46\u7ec4\u7ec7\u89c4\u6a21\u5e76\u4e0d\u8c03\u8282MLOps\u4e0e\u6ee1\u610f\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "conclusion": "MLOps\u5b9e\u8df5\u4e00\u65e6\u5b9e\u65bd\uff0c\u65e0\u8bba\u7ec4\u7ec7\u89c4\u6a21\u5982\u4f55\uff0c\u5747\u88ab\u7528\u6237\u89c6\u4e3a\u5177\u6709\u666e\u904d\u4ef7\u503c\uff0c\u80fd\u6709\u6548\u63d0\u5347AI\u5f00\u53d1\u4e0e\u8fd0\u8425\u4f53\u9a8c\u3002"}}
{"id": "2510.10380", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10380", "abs": "https://arxiv.org/abs/2510.10380", "authors": ["Shouxu Lin", "Zimeng Pan", "Yuhang Yao", "Haeyoung Noh", "Pei Zhang", "Carlee Joe-Wong"], "title": "FLAMMABLE: A Multi-Model Federated Learning Framework with Multi-Model Engagement and Adaptive Batch Sizes", "comment": null, "summary": "Multi-Model Federated Learning (MMFL) is an emerging direction in Federated\nLearning (FL) where multiple models are trained in parallel, generally on\nvarious datasets. Optimizing the models' accuracies and training times in the\nMMFL setting requires adapting to data and system heterogeneity across clients\nas in single-model FL; these challenges are amplified in the MMFL setting due\nto additional heterogeneity across models. Neither existing solutions nor\nna\\\"ive extensions of single-model FL frameworks efficiently address these\nchallenges. To bridge this gap, we propose FLAMMABLE, a comprehensive MMFL\ntraining framework. FLAMMABLE optimizes model training by intelligently\nadapting client batch sizes while engaging them to train multiple carefully\nchosen models, depending on their system capabilities, in each training round.\nTo evaluate FLAMMABLE, we develop the first benchmark platform for the MMFL\nsetting, which may enable future reproducible MMFL research. Extensive\nevaluations on multiple datasets and models show that FLAMMABLE boosts the MMFL\ntime-to-accuracy performance by 1.1$\\sim$10.0$\\times$ while improving the final\nmodel accuracy by 1.3$\\sim$5.4\\% compared to several known baselines.", "AI": {"tldr": "FLAMMABLE \u662f\u4e00\u4e2a\u9762\u5411\u591a\u6a21\u578b\u8054\u90a6\u5b66\u4e60\uff08MMFL\uff09\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u8c03\u6574\u5ba2\u6237\u7aef\u6279\u5904\u7406\u5927\u5c0f\u5e76\u6839\u636e\u5176\u7cfb\u7edf\u80fd\u529b\u5206\u914d\u591a\u4e2a\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u901f\u5ea6\u548c\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u591a\u6a21\u578b\u8054\u90a6\u5b66\u4e60\uff08MMFL\uff09\u9762\u4e34\u6570\u636e\u3001\u7cfb\u7edf\u548c\u6a21\u578b\u95f4\u7684\u591a\u91cd\u5f02\u6784\u6027\u6311\u6218\uff0c\u73b0\u6709\u5355\u6a21\u578b\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u53ca\u5176\u7b80\u5355\u6269\u5c55\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\uff0c\u4e9f\u9700\u4e13\u95e8\u4f18\u5316\u7684\u8bad\u7ec3\u6846\u67b6\u3002", "method": "\u63d0\u51fa FLAMMABLE \u6846\u67b6\uff0c\u5728\u6bcf\u8f6e\u8bad\u7ec3\u4e2d\u6839\u636e\u5ba2\u6237\u7aef\u7684\u7cfb\u7edf\u80fd\u529b\u52a8\u6001\u8c03\u6574\u6279\u5904\u7406\u5927\u5c0f\uff0c\u5e76\u667a\u80fd\u9009\u62e9\u591a\u4e2a\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\uff1b\u540c\u65f6\u6784\u5efa\u9996\u4e2a MMFL \u57fa\u51c6\u5e73\u53f0\u4ee5\u652f\u6301\u53ef\u590d\u73b0\u7814\u7a76\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cFLAMMABLE \u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5c06\u65f6\u95f4-\u7cbe\u5ea6\u6027\u80fd\u63d0\u5347 1.1\uff5e10.0 \u500d\uff0c\u6700\u7ec8\u6a21\u578b\u7cbe\u5ea6\u63d0\u9ad8 1.3\uff5e5.4%\u3002", "conclusion": "FLAMMABLE \u6709\u6548\u89e3\u51b3\u4e86 MMFL \u4e2d\u7684\u5f02\u6784\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u4e0e\u6a21\u578b\u51c6\u786e\u6027\uff0c\u4e3a\u672a\u6765 MMFL \u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u6846\u67b6\u548c\u57fa\u51c6\u5e73\u53f0\u3002"}}
{"id": "2510.10943", "categories": ["cs.MA", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.10943", "abs": "https://arxiv.org/abs/2510.10943", "authors": ["Thi-Nhung Nguyen", "Linhao Luo", "Thuy-Trang Vu", "Dinh Phung"], "title": "The Social Cost of Intelligence: Emergence, Propagation, and Amplification of Stereotypical Bias in Multi-Agent Systems", "comment": "15 pages, 19 figures, Preprint. Under review", "summary": "Bias in large language models (LLMs) remains a persistent challenge,\nmanifesting in stereotyping and unfair treatment across social groups. While\nprior research has primarily focused on individual models, the rise of\nmulti-agent systems (MAS), where multiple LLMs collaborate and communicate,\nintroduces new and largely unexplored dynamics in bias emergence and\npropagation. In this work, we present a comprehensive study of stereotypical\nbias in MAS, examining how internal specialization, underlying LLMs and\ninter-agent communication protocols influence bias robustness, propagation, and\namplification. We simulate social contexts where agents represent different\nsocial groups and evaluate system behavior under various interaction and\nadversarial scenarios. Experiments on three bias benchmarks reveal that MAS are\ngenerally less robust than single-agent systems, with bias often emerging early\nthrough in-group favoritism. However, cooperative and debate-based\ncommunication can mitigate bias amplification, while more robust underlying\nLLMs improve overall system stability. Our findings highlight critical factors\nshaping fairness and resilience in multi-agent LLM systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u4e2d\u523b\u677f\u504f\u89c1\u7684\u4ea7\u751f\u4e0e\u4f20\u64ad\u673a\u5236\uff0c\u53d1\u73b0MAS\u901a\u5e38\u6bd4\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u66f4\u6613\u53d7\u504f\u89c1\u5f71\u54cd\uff0c\u4f46\u901a\u8fc7\u5408\u4f5c\u4e0e\u8fa9\u8bba\u5f0f\u901a\u4fe1\u4ee5\u53ca\u66f4\u7a33\u5065\u7684\u57fa\u7840\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u7f13\u89e3\u504f\u89c1\u653e\u5927\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u4e8e\u5355\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u504f\u89c1\u95ee\u9898\uff0c\u800c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u591a\u4e2a\u6a21\u578b\u534f\u4f5c\u53ef\u80fd\u5e26\u6765\u65b0\u7684\u504f\u89c1\u52a8\u6001\uff0c\u4e9f\u9700\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u4ee3\u8868\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\u7684\u667a\u80fd\u4f53\uff0c\u5728\u591a\u79cd\u4ea4\u4e92\u4e0e\u5bf9\u6297\u573a\u666f\u4e0b\uff0c\u8bc4\u4f30\u5185\u90e8\u4e13\u4e1a\u5316\u3001\u57fa\u7840LLM\u548c\u901a\u4fe1\u534f\u8bae\u5bf9\u504f\u89c1\u7a33\u5065\u6027\u3001\u4f20\u64ad\u4e0e\u653e\u5927\u6548\u5e94\u7684\u5f71\u54cd\uff0c\u5e76\u5728\u4e09\u4e2a\u504f\u89c1\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "MAS\u901a\u5e38\u6bd4\u5355\u667a\u80fd\u4f53\u7cfb\u7edf\u66f4\u4e0d\u7a33\u5065\uff0c\u504f\u89c1\u5e38\u56e0\u5185\u7fa4\u4f53\u504f\u597d\u65e9\u671f\u51fa\u73b0\uff1b\u4f46\u5408\u4f5c\u4e0e\u8fa9\u8bba\u5f0f\u901a\u4fe1\u80fd\u51cf\u8f7b\u504f\u89c1\u653e\u5927\uff0c\u66f4\u7a33\u5065\u7684\u5e95\u5c42LLM\u53ef\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u7a33\u5b9a\u6027\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u4e2d\u7684\u516c\u5e73\u6027\u4e0e\u9c81\u68d2\u6027\u53d7\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\uff0c\u5305\u62ec\u901a\u4fe1\u65b9\u5f0f\u548c\u57fa\u7840\u6a21\u578b\u8d28\u91cf\uff0c\u9700\u5728\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u4e88\u4ee5\u91cd\u89c6\u3002"}}
{"id": "2510.10010", "categories": ["cs.SE", "cs.AI", "68N01, 68T05, 68T07", "D.2.5; D.2.7; I.2.2; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.10010", "abs": "https://arxiv.org/abs/2510.10010", "authors": ["Matheus J. T. Vargas"], "title": "SLEAN: Simple Lightweight Ensemble Analysis Network for Multi-Provider LLM Coordination: Design, Implementation, and Vibe Coding Bug Investigation Case Study", "comment": "14 pages, 4 figures, 6 tables, link to code repo", "summary": "We present SLEAN (Simple Lightweight Ensemble Analysis Network), a\ndeterministic framework for coordinating multiple LLM providers through\ntext-based prompt orchestration. Unlike complex multi-agent systems requiring\nspecialized infrastructure, SLEAN operates as a simple prompt bridge between\nLLMs using .txt templates, requiring no deep technical knowledge for\ndeployment. The three-phase protocol formed by independent analysis,\ncross-critique, and arbitration, filters harmful AI-generated code suggestions\nbefore production deployment, addressing how AI-assisted debugging increasingly\nproduces modifications that introduce unnecessary complexity, break existing\nfunctionality, or address problems. Evaluating 15 software bugs, we analyzed 69\nAI-generated fix propositions. SLEAN's filtering accepted 22 fixes (31.9%, 95%\nCI 20.9-42.9%) while rejecting 47 that would have been harmful if applied\nverbatim. The arbitration process reduced code change surface by 83-90%\nrelative to raw AI outputs, enforcing minimal causal edits over scope-expanding\nmodifications. Minimal Type 2 inputs proved more efficient than detailed Type 1\ninputs, requiring 2.85 versus 3.56 propositions per accepted fix (35.1% versus\n28.1% acceptance, about a 20% efficiency gain). Agreement between AI systems\nshowed weak correlation with fix quality: high convergence (at least 80%)\noccurred in 4 of 15 cases and improved acceptance by only 2.4% points;\narbitration appeared only at exactly 10% convergence in 2 of 15 cases, although\nlow convergence alone did not necessitate arbitration. The file-driven,\nprovider-agnostic architecture enables deployment without specialized coding\nexpertise, making it applicable to security auditing, code review, document\nverification, and other domains requiring reliable multi-provider synthesis\nwith end-to-end auditability.", "AI": {"tldr": "SLEAN \u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u57fa\u4e8e\u6587\u672c\u63d0\u793a\u6a21\u677f\u7684\u786e\u5b9a\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u534f\u8bae\uff08\u72ec\u7acb\u5206\u6790\u3001\u4ea4\u53c9\u6279\u8bc4\u3001\u4ef2\u88c1\uff09\u534f\u8c03\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7684\u4ee3\u7801\u4fee\u590d\u5efa\u8bae\uff0c\u6709\u6548\u8fc7\u6ee4\u6709\u5bb3\u4fee\u6539\uff0c\u63d0\u5347\u4fee\u590d\u8d28\u91cf\u548c\u90e8\u7f72\u5b89\u5168\u6027\u3002", "motivation": "\u5f53\u524d AI \u8f85\u52a9\u8c03\u8bd5\u5e38\u751f\u6210\u5f15\u5165\u4e0d\u5fc5\u8981\u590d\u6742\u6027\u3001\u7834\u574f\u73b0\u6709\u529f\u80fd\u6216\u504f\u79bb\u95ee\u9898\u672c\u8d28\u7684\u4ee3\u7801\u4fee\u6539\uff0c\u4e9f\u9700\u4e00\u79cd\u7b80\u5355\u3001\u53ef\u5ba1\u8ba1\u4e14\u65e0\u9700\u590d\u6742\u57fa\u7840\u8bbe\u65bd\u7684\u65b9\u6cd5\u6765\u534f\u8c03\u591a\u4e2a LLM \u63d0\u4f9b\u5546\uff0c\u4ee5\u8fc7\u6ee4\u6709\u5bb3\u5efa\u8bae\u5e76\u4fdd\u7559\u9ad8\u8d28\u91cf\u4fee\u590d\u3002", "method": "SLEAN \u91c7\u7528\u57fa\u4e8e .txt \u6a21\u677f\u7684\u63d0\u793a\u7f16\u6392\u673a\u5236\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\uff1a\u5404 LLM \u72ec\u7acb\u5206\u6790\u3001\u76f8\u4e92\u4ea4\u53c9\u6279\u8bc4\u3001\u6700\u7ec8\u4ef2\u88c1\uff0c\u7b5b\u9009\u51fa\u6700\u5c0f\u56e0\u679c\u6539\u52a8\u7684\u4fee\u590d\u65b9\u6848\uff1b\u8be5\u6846\u67b6\u65e0\u9700\u6df1\u5ea6\u6280\u672f\u77e5\u8bc6\uff0c\u652f\u6301\u591a\u63d0\u4f9b\u5546\u4e14\u6587\u4ef6\u9a71\u52a8\u3002", "result": "\u5728 15 \u4e2a\u8f6f\u4ef6\u7f3a\u9677\u4e0a\u8bc4\u4f30 69 \u4e2a AI \u4fee\u590d\u5efa\u8bae\uff0cSLEAN \u63a5\u53d7 22 \u4e2a\uff0831.9%\uff09\uff0c\u62d2\u7edd 47 \u4e2a\u6709\u5bb3\u5efa\u8bae\uff1b\u4ef2\u88c1\u4f7f\u4ee3\u7801\u53d8\u66f4\u8303\u56f4\u51cf\u5c11 83\u201390%\uff1b\u4f7f\u7528\u7b80\u6d01\u8f93\u5165\uff08Type 2\uff09\u6bd4\u8be6\u7ec6\u8f93\u5165\uff08Type 1\uff09\u6548\u7387\u9ad8\u7ea6 20%\uff1bAI \u95f4\u9ad8\u4e00\u81f4\u6027\u4e0e\u4fee\u590d\u8d28\u91cf\u5f31\u76f8\u5173\u3002", "conclusion": "SLEAN \u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u3001\u53ef\u5ba1\u8ba1\u3001\u65e0\u9700\u4e13\u4e1a\u7f16\u7801\u77e5\u8bc6\u7684\u591a LLM \u534f\u540c\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u4ee3\u7801\u5ba1\u67e5\u3001\u5b89\u5168\u5ba1\u8ba1\u7b49\u9700\u53ef\u9760\u591a\u6e90\u5408\u6210\u7684\u573a\u666f\uff0c\u6709\u6548\u63d0\u5347 AI \u751f\u6210\u5185\u5bb9\u7684\u5b89\u5168\u6027\u4e0e\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.10620", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10620", "abs": "https://arxiv.org/abs/2510.10620", "authors": ["Chenyu Jiang", "Zhenkun Cai", "Ye Tian", "Zhen Jia", "Yida Wang", "Chuan Wu"], "title": "DCP: Addressing Input Dynamism In Long-Context Training via Dynamic Context Parallelism", "comment": "16 pages, 22 figures", "summary": "Context parallelism has emerged as a key technique to support long-context\ntraining, a growing trend in generative AI for modern large models. However,\nexisting context parallel methods rely on static parallelization configurations\nthat overlook the dynamic nature of training data, specifically, the\nvariability in sequence lengths and token relationships (i.e., attention\npatterns) across samples. As a result, these methods often suffer from\nunnecessary communication overhead and imbalanced computation. In this paper,\nwe present DCP, a dynamic context parallel training framework that introduces\nfine-grained blockwise partitioning of both data and computation. By enabling\nflexible mapping of data and computation blocks to devices, DCP can adapt to\nvarying sequence characteristics, effectively reducing communication and\nimproving memory and computation balance. Micro-benchmarks demonstrate that DCP\naccelerates attention by 1.19x~2.45x under causal masks and 2.15x~3.77x under\nsparse attention patterns. Additionally, we observe up to 0.94x~1.16x\nend-to-end training speed-up for causal masks, and 1.00x~1.46x for sparse\nmasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DCP\uff0c\u4e00\u79cd\u52a8\u6001\u4e0a\u4e0b\u6587\u5e76\u884c\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u5206\u5757\u7b56\u7565\u81ea\u9002\u5e94\u5904\u7406\u4e0d\u540c\u5e8f\u5217\u957f\u5ea6\u548c\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u4ece\u800c\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u5e76\u63d0\u5347\u8ba1\u7b97\u4e0e\u5185\u5b58\u5747\u8861\u6027\u3002", "motivation": "\u73b0\u6709\u4e0a\u4e0b\u6587\u5e76\u884c\u65b9\u6cd5\u91c7\u7528\u9759\u6001\u5e76\u884c\u914d\u7f6e\uff0c\u65e0\u6cd5\u9002\u5e94\u8bad\u7ec3\u6570\u636e\u4e2d\u5e8f\u5217\u957f\u5ea6\u548c\u6ce8\u610f\u529b\u6a21\u5f0f\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5bfc\u81f4\u901a\u4fe1\u5f00\u9500\u5927\u548c\u8ba1\u7b97\u8d1f\u8f7d\u4e0d\u5747\u8861\u3002", "method": "\u63d0\u51faDCP\u6846\u67b6\uff0c\u5bf9\u6570\u636e\u548c\u8ba1\u7b97\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u5757\u7ea7\u5212\u5206\uff0c\u5e76\u7075\u6d3b\u5730\u5c06\u8fd9\u4e9b\u5757\u6620\u5c04\u5230\u8bbe\u5907\u4e0a\uff0c\u4ee5\u9002\u5e94\u4e0d\u540c\u6837\u672c\u7684\u5e8f\u5217\u7279\u6027\u3002", "result": "\u5fae\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u5728\u56e0\u679c\u63a9\u7801\u4e0b\u6ce8\u610f\u529b\u8ba1\u7b97\u52a0\u901f1.19x~2.45x\uff0c\u5728\u7a00\u758f\u6ce8\u610f\u529b\u6a21\u5f0f\u4e0b\u52a0\u901f2.15x~3.77x\uff1b\u7aef\u5230\u7aef\u8bad\u7ec3\u901f\u5ea6\u5728\u56e0\u679c\u63a9\u7801\u4e0b\u63d0\u53470.94x~1.16x\uff0c\u5728\u7a00\u758f\u63a9\u7801\u4e0b\u63d0\u53471.00x~1.46x\u3002", "conclusion": "DCP\u901a\u8fc7\u52a8\u6001\u9002\u914d\u5e8f\u5217\u7279\u5f81\u663e\u8457\u63d0\u5347\u4e86\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u7684\u6548\u7387\u548c\u8d44\u6e90\u5229\u7528\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u9759\u6001\u4e0a\u4e0b\u6587\u5e76\u884c\u65b9\u6cd5\u3002"}}
{"id": "2510.11004", "categories": ["cs.MA", "cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.11004", "abs": "https://arxiv.org/abs/2510.11004", "authors": ["Haoran Liang", "Yufa Zhou", "Mohammad Talebi Kalaleh", "Qipei Mei"], "title": "Automating Structural Engineering Workflows with Large Language Model Agents", "comment": "Code: https://github.com/DelosLiang/masse", "summary": "We introduce $\\textbf{MASSE}$, the first Multi-Agent System for Structural\nEngineering, effectively integrating large language model (LLM)-based agents\nwith real-world engineering workflows. Structural engineering is a fundamental\nyet traditionally stagnant domain, with core workflows remaining largely\nunchanged for decades despite its substantial economic impact and global market\nsize. Recent advancements in LLMs have significantly enhanced their ability to\nperform complex reasoning, long-horizon planning, and precise tool utilization\n-- capabilities well aligned with structural engineering tasks such as\ninterpreting design codes, executing load calculations, and verifying\nstructural capacities. We present a proof-of-concept showing that most\nreal-world structural engineering workflows can be fully automated through a\ntraining-free LLM-based multi-agent system. MASSE enables immediate deployment\nin professional environments, and our comprehensive validation on real-world\ncase studies demonstrates that it can reduce expert workload from approximately\ntwo hours to mere minutes, while enhancing both reliability and accuracy in\npractical engineering scenarios.", "AI": {"tldr": "MASSE \u662f\u9996\u4e2a\u9762\u5411\u7ed3\u6784\u5de5\u7a0b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5229\u7528\u65e0\u9700\u8bad\u7ec3\u7684 LLM \u667a\u80fd\u4f53\u5b9e\u73b0\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\uff0c\u663e\u8457\u63d0\u5347\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "motivation": "\u7ed3\u6784\u5de5\u7a0b\u9886\u57df\u957f\u671f\u7f3a\u4e4f\u521b\u65b0\uff0c\u6838\u5fc3\u5de5\u4f5c\u6d41\u7a0b\u6570\u5341\u5e74\u672a\u53d8\uff0c\u5c3d\u7ba1\u5176\u5177\u6709\u5de8\u5927\u7684\u7ecf\u6d4e\u5f71\u54cd\uff1b\u800c\u8fd1\u671f LLM \u5728\u590d\u6742\u63a8\u7406\u3001\u957f\u671f\u89c4\u5212\u548c\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u7684\u80fd\u529b\u8fdb\u6b65\uff0c\u4f7f\u5176\u975e\u5e38\u9002\u5408\u7528\u4e8e\u7ed3\u6784\u5de5\u7a0b\u4efb\u52a1\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf MASSE\uff0c\u5c06\u5176\u96c6\u6210\u5230\u771f\u5b9e\u4e16\u754c\u7684\u7ed3\u6784\u5de5\u7a0b\u5de5\u4f5c\u6d41\u7a0b\u4e2d\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u6267\u884c\u8bbe\u8ba1\u89c4\u8303\u89e3\u8bfb\u3001\u8377\u8f7d\u8ba1\u7b97\u548c\u7ed3\u6784\u627f\u8f7d\u529b\u9a8c\u8bc1\u7b49\u4efb\u52a1\u3002", "result": "\u5728\u771f\u5b9e\u6848\u4f8b\u4e2d\u7684\u5168\u9762\u9a8c\u8bc1\u8868\u660e\uff0cMASSE \u80fd\u5c06\u4e13\u5bb6\u5de5\u4f5c\u91cf\u4ece\u7ea6\u4e24\u5c0f\u65f6\u51cf\u5c11\u5230\u51e0\u5206\u949f\uff0c\u540c\u65f6\u63d0\u9ad8\u5b9e\u9645\u5de5\u7a0b\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\u4e0e\u51c6\u786e\u6027\u3002", "conclusion": "MASSE \u8bc1\u660e\u4e86 LLM \u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ef\u6709\u6548\u81ea\u52a8\u5316\u7ed3\u6784\u5de5\u7a0b\u5de5\u4f5c\u6d41\uff0c\u5177\u5907\u5373\u63d2\u5373\u7528\u7684\u4e13\u4e1a\u90e8\u7f72\u80fd\u529b\uff0c\u4e3a\u4f20\u7edf\u5de5\u7a0b\u9886\u57df\u5e26\u6765\u663e\u8457\u6548\u7387\u4e0e\u8d28\u91cf\u63d0\u5347\u3002"}}
{"id": "2510.10066", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.10066", "abs": "https://arxiv.org/abs/2510.10066", "authors": ["Shan Jiang", "Chenguang Zhu", "Sarfraz Khurshid"], "title": "OBsmith: Testing JavaScript Obfuscator using LLM-powered sketching", "comment": null, "summary": "JavaScript obfuscators are widely deployed to protect intellectual property\nand resist reverse engineering, yet their correctness has been largely\noverlooked compared to performance and resilience. Existing evaluations\ntypically measure resistance to deobfuscation, leaving the critical question of\nwhether obfuscators preserve program semantics unanswered. Incorrect\ntransformations can silently alter functionality, compromise reliability, and\nerode security-undermining the very purpose of obfuscation. To address this\ngap, we present OBsmith, a novel framework to systematically test JavaScript\nobfuscators using large language models (LLMs). OBsmith leverages LLMs to\ngenerate program sketches abstract templates capturing diverse language\nconstructs, idioms, and corner cases-which are instantiated into executable\nprograms and subjected to obfuscation under different configurations. Besides\nLLM-powered sketching, OBsmith also employs a second source: automatic\nextraction of sketches from real programs. This extraction path enables more\nfocused testing of project specific features and lets developers inject domain\nknowledge into the resulting test cases. OBsmith uncovers 11 previously unknown\ncorrectness bugs. Under an equal program budget, five general purpose\nstate-of-the-art JavaScript fuzzers (FuzzJIT, Jsfunfuzz, Superion, DIE,\nFuzzilli) failed to detect these issues, highlighting OBsmith's complementary\nfocus on obfuscation induced misbehavior. An ablation shows that all components\nexcept our generic MRs contribute to at least one bug class; the negative MR\nresult suggests the need for obfuscator-specific metamorphic relations. Our\nresults also seed discussion on how to balance obfuscation presets and\nperformance cost. We envision OBsmith as an important step towards automated\ntesting and quality assurance of obfuscators and other semantic-preserving\ntoolchains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86OBsmith\uff0c\u4e00\u4e2a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u771f\u5b9e\u7a0b\u5e8f\u63d0\u53d6\u6280\u672f\uff0c\u7cfb\u7edf\u6027\u6d4b\u8bd5JavaScript\u6df7\u6dc6\u5668\u8bed\u4e49\u6b63\u786e\u6027\u7684\u65b0\u6846\u67b6\uff0c\u5e76\u53d1\u73b0\u4e8611\u4e2a\u6b64\u524d\u672a\u77e5\u7684\u6b63\u786e\u6027\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709JavaScript\u6df7\u6dc6\u5668\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u6297\u53cd\u6df7\u6dc6\u80fd\u529b\uff0c\u5ffd\u89c6\u4e86\u6df7\u6dc6\u662f\u5426\u4fdd\u6301\u7a0b\u5e8f\u8bed\u4e49\u6b63\u786e\u6027\uff1b\u9519\u8bef\u7684\u6df7\u6dc6\u53ef\u80fd\u7834\u574f\u529f\u80fd\u3001\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\uff0c\u56e0\u6b64\u4e9f\u9700\u7cfb\u7edf\u6027\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "OBsmith\u7ed3\u5408LLM\u751f\u6210\u6db5\u76d6\u591a\u6837\u8bed\u8a00\u7279\u6027\u548c\u8fb9\u754c\u60c5\u51b5\u7684\u7a0b\u5e8f\u6a21\u677f\uff08sketches\uff09\uff0c\u5e76\u4ece\u771f\u5b9e\u9879\u76ee\u4e2d\u81ea\u52a8\u63d0\u53d6\u6a21\u677f\uff0c\u5b9e\u4f8b\u5316\u540e\u5728\u4e0d\u540c\u6df7\u6dc6\u914d\u7f6e\u4e0b\u6267\u884c\uff0c\u901a\u8fc7\u8bed\u4e49\u4e00\u81f4\u6027\u68c0\u67e5\u53d1\u73b0\u9519\u8bef\u3002", "result": "OBsmith\u53d1\u73b0\u4e8611\u4e2a\u65b0\u6b63\u786e\u6027\u6f0f\u6d1e\uff0c\u800c\u4e94\u79cd\u4e3b\u6d41JavaScript\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u5728\u76f8\u540c\u6d4b\u8bd5\u9884\u7b97\u4e0b\u5747\u672a\u80fd\u53d1\u73b0\u8fd9\u4e9b\u95ee\u9898\uff1b\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u5404\u7ec4\u4ef6\u5bf9\u4e0d\u540c\u6f0f\u6d1e\u7c7b\u522b\u5747\u6709\u8d21\u732e\u3002", "conclusion": "OBsmith\u4e3a\u6df7\u6dc6\u5668\u53ca\u5176\u4ed6\u8bed\u4e49\u4fdd\u6301\u578b\u5de5\u5177\u94fe\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u4e0e\u8d28\u91cf\u4fdd\u969c\u624b\u6bb5\uff0c\u5f3a\u8c03\u9700\u5f00\u53d1\u9488\u5bf9\u6df7\u6dc6\u5668\u7684\u7279\u5b9a\u8715\u53d8\u5173\u7cfb\uff0c\u5e76\u5f15\u53d1\u5bf9\u6df7\u6dc6\u9884\u8bbe\u4e0e\u6027\u80fd\u4ee3\u4ef7\u5e73\u8861\u7684\u8ba8\u8bba\u3002"}}
{"id": "2510.11043", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.11043", "abs": "https://arxiv.org/abs/2510.11043", "authors": ["Yuemeng Xu", "Haoran Chen", "Jiarui Guo", "Mingwei Cui", "Qiuheng Yin", "Cheng Dong", "Daxiang Kang", "Xian Wu", "Chenmin Sun", "Peng He", "Yang Gao", "Lirong Lai", "Kai Wang", "Hongyu Wu", "Tong Yang", "Xiyun Xu"], "title": "Zephyrus: Scaling Gateways Beyond the Petabit-Era with DPU-Augmented Hierarchical Co-Offloading", "comment": null, "summary": "Operating at petabit-scale, ByteDance's cloud gateways are deployed at\ncritical aggregation points to orchestrate a wide array of business traffic.\nHowever, this massive scale imposes significant resource pressure on our\nprevious-generation cloud gateways, rendering them unsustainable in the face of\never-growing cloud-network traffic. As the DPU market rapidly expands, we see a\npromising path to meet our escalating business traffic demands by integrating\nDPUs with our established Tofino-based gateways. DPUs augment these gateways\nwith substantially larger table capacities and richer programmability without\ncompromising previously low-latency and high-throughput forwarding. Despite\ncompelling advantages, the practical integration of DPUs into cloud gateways\nremains unexplored, primarily due to underlying challenges. In this paper, we\npresent Zephyrus, a production-scale gateway built upon a unified P4 pipeline\nspanning high-performance Tofino and feature-rich DPUs, which successfully\novercomes these challenges. We further introduce a hierarchical co-offloading\narchitecture (HLCO) to orchestrate traffic flow within this heterogeneous\ngateway, achieving > 99% hardware offloading while retaining software fallback\npaths for complex operations. Zephyrus outperforms LuoShen (NSDI '24) with 33%\nhigher throughput and our evaluation further indicates 21% lower power\nconsumption and 14% lower hardware cost. Against FPGA-based systems, Albatross\n(SIGCOMM '25), it doubles the throughput at a substantially lower Total Cost of\nOwnership (TCO), showcasing its superior performance-per-dollar. Beyond these\nperformance gains, we also share key lessons from several years of developing\nand operating Zephyrus at production scale. We believe these insights provide\nvaluable references for researchers and practitioners designing performant\ncloud gateways.", "AI": {"tldr": "ByteDance\u63d0\u51faZephyrus\uff0c\u4e00\u79cd\u7ed3\u5408Tofino\u4e0eDPU\u7684\u9ad8\u6027\u80fd\u4e91\u7f51\u5173\u7cfb\u7edf\uff0c\u901a\u8fc7\u7edf\u4e00P4\u6d41\u6c34\u7ebf\u548c\u5206\u5c42\u534f\u540c\u5378\u8f7d\u67b6\u6784\uff08HLCO\uff09\uff0c\u5b9e\u73b0\u9ad8\u541e\u5410\u3001\u4f4e\u529f\u8017\u3001\u4f4e\u6210\u672c\uff0c\u5e76\u5df2\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u90e8\u7f72\u3002", "motivation": "\u9762\u5bf9\u4e0d\u65ad\u589e\u957f\u7684\u4e91\u7f51\u6d41\u91cf\uff0c\u4e0a\u4e00\u4ee3\u4e91\u7f51\u5173\u5728\u8d44\u6e90\u538b\u529b\u4e0b\u96be\u4ee5\u4e3a\u7ee7\uff0c\u4e9f\u9700\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u9ad8\u541e\u5410\uff0c\u53c8\u5177\u5907\u66f4\u5927\u8868\u5bb9\u91cf\u548c\u66f4\u5f3a\u53ef\u7f16\u7a0b\u6027\u7684\u65b0\u67b6\u6784\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u7edf\u4e00P4\u6d41\u6c34\u7ebf\u7684\u5f02\u6784\u7f51\u5173Zephyrus\uff0c\u6574\u5408Tofino\u4ea4\u6362\u82af\u7247\u4e0eDPU\uff0c\u5e76\u8bbe\u8ba1\u5206\u5c42\u534f\u540c\u5378\u8f7d\u67b6\u6784\uff08HLCO\uff09\u4ee5\u9ad8\u6548\u8c03\u5ea6\u6d41\u91cf\uff0c\u5b9e\u73b0\u786c\u4ef6\u9ad8\u6bd4\u4f8b\u5378\u8f7d\u4e0e\u8f6f\u4ef6\u56de\u9000\u8def\u5f84\u7684\u7ed3\u5408\u3002", "result": "Zephyrus\u76f8\u6bd4LuoShen\uff08NSDI '24\uff09\u541e\u5410\u91cf\u63d0\u534733%\uff0c\u529f\u8017\u964d\u4f4e21%\uff0c\u786c\u4ef6\u6210\u672c\u964d\u4f4e14%\uff1b\u76f8\u6bd4FPGA\u65b9\u6848Albatross\uff08SIGCOMM '25\uff09\uff0c\u541e\u5410\u7ffb\u500d\u4e14\u603b\u4f53\u62e5\u6709\u6210\u672c\uff08TCO\uff09\u663e\u8457\u66f4\u4f4e\u3002", "conclusion": "Zephyrus\u9a8c\u8bc1\u4e86DPU\u4e0eTofino\u878d\u5408\u67b6\u6784\u5728\u5927\u89c4\u6a21\u4e91\u7f51\u5173\u4e2d\u7684\u53ef\u884c\u6027\u4e0e\u4f18\u8d8a\u6027\uff0c\u5176\u8bbe\u8ba1\u7ecf\u9a8c\u4e3a\u672a\u6765\u9ad8\u6027\u80fd\u4e91\u7f51\u5173\u7814\u53d1\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2510.11108", "categories": ["cs.MA", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.11108", "abs": "https://arxiv.org/abs/2510.11108", "authors": ["Xinfeng Li", "Dong Huang", "Jie Li", "Hongyi Cai", "Zhenhong Zhou", "Wei Dong", "XiaoFeng Wang", "Yang Liu"], "title": "A Vision for Access Control in LLM-based Agent Systems", "comment": "10 pages, 1 figure", "summary": "The autonomy and contextual complexity of LLM-based agents render traditional\naccess control (AC) mechanisms insufficient. Static, rule-based systems\ndesigned for predictable environments are fundamentally ill-equipped to manage\nthe dynamic information flows inherent in agentic interactions. This position\npaper argues for a paradigm shift from binary access control to a more\nsophisticated model of information governance, positing that the core challenge\nis not merely about permission, but about governing the flow of information. We\nintroduce Agent Access Control (AAC), a novel framework that reframes AC as a\ndynamic, context-aware process of information flow governance. AAC operates on\ntwo core modules: (1) multi-dimensional contextual evaluation, which assesses\nnot just identity but also relationships, scenarios, and norms; and (2)\nadaptive response formulation, which moves beyond simple allow/deny decisions\nto shape information through redaction, summarization, and paraphrasing. This\nvision, powered by a dedicated AC reasoning engine, aims to bridge the gap\nbetween human-like nuanced judgment and scalable Al safety, proposing a new\nconceptual lens for future research in trustworthy agent design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u667a\u80fd\u4f53\u8bbf\u95ee\u63a7\u5236\u201d\uff08AAC\uff09\u7684\u65b0\u6846\u67b6\uff0c\u5c06\u4f20\u7edf\u9759\u6001\u7684\u8bbf\u95ee\u63a7\u5236\u673a\u5236\u8f6c\u53d8\u4e3a\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4fe1\u606f\u6d41\u6cbb\u7406\u6a21\u578b\uff0c\u4ee5\u5e94\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5728\u590d\u6742\u73af\u5883\u4e2d\u52a8\u6001\u4ea4\u4e92\u6240\u5e26\u6765\u7684\u5b89\u5168\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u9759\u6001\u8bbf\u95ee\u63a7\u5236\u673a\u5236\u65e0\u6cd5\u5e94\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5728\u52a8\u6001\u3001\u590d\u6742\u4e0a\u4e0b\u6587\u4e2d\u4ea7\u751f\u7684\u4fe1\u606f\u6d41\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u7ec6\u3001\u7075\u6d3b\u7684\u4fe1\u606f\u6cbb\u7406\u65b9\u6cd5\u3002", "method": "\u63d0\u51faAgent Access Control\uff08AAC\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a\uff081\uff09\u591a\u7ef4\u4e0a\u4e0b\u6587\u8bc4\u4f30\uff0c\u7efc\u5408\u8003\u91cf\u8eab\u4efd\u3001\u5173\u7cfb\u3001\u573a\u666f\u4e0e\u89c4\u8303\uff1b\uff082\uff09\u81ea\u9002\u5e94\u54cd\u5e94\u751f\u6210\uff0c\u901a\u8fc7\u5220\u51cf\u3001\u6458\u8981\u548c\u6539\u5199\u7b49\u65b9\u5f0f\u52a8\u6001\u8c03\u6574\u4fe1\u606f\u8f93\u51fa\uff0c\u800c\u975e\u7b80\u5355\u5141\u8bb8\u6216\u62d2\u7edd\u3002", "result": "\u8be5\u6846\u67b6\u901a\u8fc7\u4e13\u7528\u7684\u8bbf\u95ee\u63a7\u5236\u63a8\u7406\u5f15\u64ce\uff0c\u5b9e\u73b0\u4e86\u7c7b\u4eba\u7ea7\u522b\u7684\u7ec6\u7c92\u5ea6\u5224\u65ad\u4e0e\u53ef\u6269\u5c55\u7684AI\u5b89\u5168\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u4e3a\u53ef\u4fe1\u667a\u80fd\u4f53\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "conclusion": "\u672a\u6765\u53ef\u4fe1\u667a\u80fd\u4f53\u7684\u5b89\u5168\u673a\u5236\u5e94\u4ece\u4e8c\u5143\u8bbf\u95ee\u63a7\u5236\u8f6c\u5411\u52a8\u6001\u4fe1\u606f\u6d41\u6cbb\u7406\uff0cAAC\u4e3a\u6b64\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2510.10081", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.10081", "abs": "https://arxiv.org/abs/2510.10081", "authors": ["Youshuai Tan", "Zhanwei Zhang", "Zishuo Ding", "Lianyu Zheng", "Jinfu Chen", "Weiyi Shang"], "title": "A Mathematics-Guided Approach to Floating-Point Error Detection", "comment": null, "summary": "Floating-point program errors can lead to severe consequences, particularly\nin critical domains such as military applications. Only a small subset of\ninputs may induce substantial floating-point errors, prompting researchers to\ndevelop methods for identifying these error-inducing inputs. Although existing\napproaches have achieved some success, they still suffer from two major\nlimitations: (1) High computational cost: The evaluation of error magnitude for\ncandidate inputs relies on high-precision programs, which are prohibitively\ntime-consuming. (2) Limited long-range convergence capability: Current methods\nexhibit inefficiency in search, making the process akin to finding a needle in\na haystack.\n  To address these two limitations, we propose a novel method, named MGDE, to\ndetect error-inducing inputs based on mathematical guidance. By employing the\nNewton-Raphson method, which exhibits quadratic convergence properties, we\nachieve highly effective and efficient results. Since the goal of identifying\nerror-inducing inputs is to uncover the underlying bugs, we use the number of\nbugs detected in floating-point programs as the primary evaluation metric in\nour experiments. As FPCC represents the most effective state-of-the-art\napproach to date, we use it as the baseline for comparison. The dataset of FPCC\nconsists of 88 single-input floating-point programs. FPCC is able to detect 48\nbugs across 29 programs, whereas our method successfully identifies 89 bugs\nacross 44 programs. Moreover, FPCC takes 6.4096 times as long as our proposed\nmethod. We also deploy our method to multi-input programs, identifying a total\nof nine bugs with an average detection time of 0.6443 seconds per program. In\ncontrast, FPCC fails to detect any bugs while requiring an average computation\ntime of 100 seconds per program.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMGDE\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u725b\u987f-\u62c9\u5f17\u68ee\u6cd5\u7684\u6570\u5b66\u5f15\u5bfc\u673a\u5236\uff0c\u9ad8\u6548\u68c0\u6d4b\u6d6e\u70b9\u7a0b\u5e8f\u4e2d\u7684\u9519\u8bef\u8f93\u5165\u3002\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5FPCC\uff0cMGDE\u5728\u5355\u8f93\u5165\u7a0b\u5e8f\u4e2d\u53d1\u73b0\u66f4\u591a\u9519\u8bef\uff0889 vs. 48\uff09\uff0c\u8017\u65f6\u66f4\u5c11\uff08\u4ec5\u4e3aFPCC\u7684\u7ea61/6.4\uff09\uff0c\u5e76\u5728\u591a\u8f93\u5165\u7a0b\u5e8f\u4e2d\u6210\u529f\u68c0\u6d4b\u51faFPCC\u65e0\u6cd5\u53d1\u73b0\u7684\u9519\u8bef\u3002", "motivation": "\u73b0\u6709\u6d6e\u70b9\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u957f\u8ddd\u79bb\u6536\u655b\u80fd\u529b\u5f31\u4e24\u5927\u5c40\u9650\uff0c\u96be\u4ee5\u9ad8\u6548\u8bc6\u522b\u5f15\u53d1\u4e25\u91cd\u6d6e\u70b9\u8bef\u5dee\u7684\u8f93\u5165\u3002", "method": "\u63d0\u51faMGDE\u65b9\u6cd5\uff0c\u57fa\u4e8e\u725b\u987f-\u62c9\u5f17\u68ee\u6cd5\u7684\u4e8c\u6b21\u6536\u655b\u7279\u6027\uff0c\u901a\u8fc7\u6570\u5b66\u5f15\u5bfc\u9ad8\u6548\u641c\u7d22\u9519\u8bef\u8bf1\u5bfc\u8f93\u5165\u3002", "result": "\u572888\u4e2a\u5355\u8f93\u5165\u7a0b\u5e8f\u4e2d\uff0cMGDE\u68c0\u6d4b\u523089\u4e2a\u9519\u8bef\uff08\u8986\u76d644\u4e2a\u7a0b\u5e8f\uff09\uff0c\u800cFPCC\u4ec5\u68c0\u6d4b\u523048\u4e2a\uff08\u8986\u76d629\u4e2a\u7a0b\u5e8f\uff09\uff1bMGDE\u8fd0\u884c\u65f6\u95f4\u4ec5\u4e3aFPCC\u7684\u7ea615.6%\u3002\u5728\u591a\u8f93\u5165\u7a0b\u5e8f\u4e2d\uff0cMGDE\u5e73\u57470.6443\u79d2\u68c0\u6d4b\u51fa9\u4e2a\u9519\u8bef\uff0c\u800cFPCC\u5728\u5e73\u5747100\u79d2\u5185\u672a\u80fd\u53d1\u73b0\u4efb\u4f55\u9519\u8bef\u3002", "conclusion": "MGDE\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u68c0\u6d4b\u6548\u679c\u548c\u6548\u7387\u4e0a\u5747\u53d6\u5f97\u7a81\u7834\uff0c\u9a8c\u8bc1\u4e86\u6570\u5b66\u5f15\u5bfc\u7b56\u7565\u5728\u6d6e\u70b9\u9519\u8bef\u68c0\u6d4b\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.10818", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.10818", "abs": "https://arxiv.org/abs/2510.10818", "authors": ["Kevin Chalmers", "Jan B\u00e6kgaard Pedersen"], "title": "Fair Kernel-Lock-Free Claim/Release Protocol for Shared Object Access in Cooperatively Scheduled Runtimes", "comment": null, "summary": "We present the first spin-free, kernel-lock-free mutex that cooperates with\nuser-mode schedulers and is formally proven FIFO-fair and linearizable using\nCSP/FDR. Our fairness oracle and stability-based proof method are reusable\nacross coroutine runtime designs. We designed the claim/release protocol for a\nprocess-oriented language -- ProcessJ -- to manage the race for claiming shared\ninter-process communication channels. Internally, we use a lock-free queue to\npark waiting processes for gaining access to a shared object, such as exclusive\naccess to a shared channel to read from or write to. The queue ensures control\nand fairness for processes wishing to access a shared resource, as the protocol\nhandles claim requests in the order they are inserted into the queue. We\nproduce CSP models of our protocol and a mutex specification, demonstrating\nwith FDR that our protocol behaves as a locking mutex.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u81ea\u65cb\u3001\u65e0\u5185\u6838\u9501\u7684\u4e92\u65a5\u673a\u5236\uff0c\u652f\u6301\u7528\u6237\u6001\u8c03\u5ea6\u5668\uff0c\u5e76\u901a\u8fc7CSP/FDR\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5176\u5177\u5907FIFO\u516c\u5e73\u6027\u548c\u7ebf\u6027\u4e00\u81f4\u6027\u3002", "motivation": "\u4e3a\u8fdb\u7a0b\u5bfc\u5411\u8bed\u8a00\uff08\u5982ProcessJ\uff09\u8bbe\u8ba1\u4e00\u79cd\u80fd\u4e0e\u7528\u6237\u6001\u8c03\u5ea6\u5668\u534f\u4f5c\u3001\u4fdd\u8bc1\u516c\u5e73\u6027\u548c\u6b63\u786e\u6027\u7684\u4e92\u65a5\u673a\u5236\uff0c\u7528\u4e8e\u7ba1\u7406\u5bf9\u5171\u4eab\u901a\u4fe1\u901a\u9053\u7684\u8bbf\u95ee\u7ade\u4e89\u3002", "method": "\u91c7\u7528\u65e0\u9501\u961f\u5217\u505c\u653e\u7b49\u5f85\u8fdb\u7a0b\uff0c\u57fa\u4e8e\u5148\u5165\u5148\u51fa\u987a\u5e8f\u5904\u7406\u8d44\u6e90\u8bf7\u6c42\uff1b\u5229\u7528CSP\u5efa\u6a21\u548cFDR\u9a8c\u8bc1\u534f\u8bae\u7684\u4e92\u65a5\u3001\u516c\u5e73\u6027\u4e0e\u7ebf\u6027\u4e00\u81f4\u6027\uff0c\u5e76\u63d0\u51fa\u53ef\u590d\u7528\u7684\u516c\u5e73\u6027\u9a8c\u8bc1\u65b9\u6cd5\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u4e92\u65a5\u534f\u8bae\uff0c\u786e\u4fdd\u5bf9\u5171\u4eab\u8d44\u6e90\uff08\u5982\u901a\u9053\uff09\u7684\u8bbf\u95ee\u5177\u6709FIFO\u516c\u5e73\u6027\u548c\u7ebf\u6027\u4e00\u81f4\u6027\uff0c\u5e76\u9a8c\u8bc1\u5176\u884c\u4e3a\u7b26\u5408\u4e92\u65a5\u9501\u89c4\u8303\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e92\u65a5\u673a\u5236\u4e0d\u4ec5\u9002\u7528\u4e8eProcessJ\u8bed\u8a00\uff0c\u5176\u516c\u5e73\u6027\u9a8c\u8bc1\u65b9\u6cd5\u548c\u7a33\u5b9a\u6027\u8bc1\u660e\u7b56\u7565\u4e5f\u53ef\u590d\u7528\u4e8e\u5176\u4ed6\u534f\u7a0b\u8fd0\u884c\u65f6\u7cfb\u7edf\u8bbe\u8ba1\u3002"}}
{"id": "2510.10119", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.10119", "abs": "https://arxiv.org/abs/2510.10119", "authors": ["Liutong Han", "Zhiyuan Tan", "Hongbin Zhang", "Pengcheng Wang", "Chu Kang", "Mingjie Xing", "Yanjun Wu"], "title": "IntrinTrans: LLM-based Intrinsic Code Translator for RISC-V Vector", "comment": "9 pages", "summary": "The use of intrinsic functions to exploit hardware-specific capabilities is\nan important approach for optimizing library performance. Many mainstream\nlibraries implement a large number of vectorized algorithms on Arm or x86 SIMD\nintrinsic functions. With the rapid expansion of the RISC-V hardware-software\necosystem, there is a growing demand for support of the RISC-V Vector (RVV)\nextension. Translating existing vectorized intrinsic code onto RVV intrinsics\nis a practical and effective approach. However, current cross-architecture\ntranslation largely relies on manual rewriting, which is time-consuming and\nerror-prone. Furthermore, while some rule-based methods can reduce the need for\nmanual intervention, their translation success rate is limited by incomplete\nrule coverage and syntactic constraints, and the performance suffers from\ninadequate utilization of RVV-specific features. We present IntrinTrans, a\nLLM-based multi-agent approach that utilizes compile-and-test feedback to\ntranslate intrinsic code across architectures automatically, and further\noptimizes the generated RVV intrinsics using register-usage information derived\nfrom liveness analysis. To evaluate the effectiveness of our approach, we\ncollected 34 vectorized algorithm cases from open-source libraries. Each case\nincludes an Arm Neon intrinsics implementation and a RVV intrinsics\nimplementation contributed by the open-source community, together with\ncorrectness and performance tests. Our experiments show that advanced LLMs\nproduce semantically correct RISC-V Vector intrinsics in most cases within a\nlimited number of iterations, and in some cases achieve up to 5.93x the\nperformance of the native implementation from the open-source community.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faIntrinTrans\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u5c06Arm Neon\u7b49\u67b6\u6784\u7684\u5411\u91cf\u5316\u5185\u5efa\u51fd\u6570\u4ee3\u7801\u7ffb\u8bd1\u4e3aRISC-V Vector\uff08RVV\uff09\u5185\u5efa\u51fd\u6570\uff0c\u5e76\u7ed3\u5408\u7f16\u8bd1\u6d4b\u8bd5\u53cd\u9988\u4e0e\u6d3b\u8dc3\u6027\u5206\u6790\u4f18\u5316\u5bc4\u5b58\u5668\u4f7f\u7528\uff0c\u663e\u8457\u63d0\u5347\u7ffb\u8bd1\u6b63\u786e\u6027\u4e0e\u6027\u80fd\u3002", "motivation": "\u968f\u7740RISC-V\u751f\u6001\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u4e9f\u9700\u5c06\u73b0\u6709\u57fa\u4e8eArm\u6216x86 SIMD\u5185\u5efa\u51fd\u6570\u7684\u9ad8\u6027\u80fd\u5e93\u4ee3\u7801\u8fc1\u79fb\u5230RVV\u67b6\u6784\u3002\u5f53\u524d\u8de8\u67b6\u6784\u7ffb\u8bd1\u4f9d\u8d56\u4eba\u5de5\u91cd\u5199\uff0c\u6548\u7387\u4f4e\u4e14\u6613\u9519\uff1b\u800c\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u53d7\u9650\u4e8e\u89c4\u5219\u8986\u76d6\u4e0d\u5168\u548c\u8bed\u6cd5\u7ea6\u675f\uff0c\u96be\u4ee5\u5145\u5206\u5229\u7528RVV\u7279\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51faIntrinTrans\u6846\u67b6\uff0c\u5229\u7528\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u81ea\u52a8\u7ffb\u8bd1\u5185\u5efa\u51fd\u6570\u4ee3\u7801\uff0c\u5e76\u901a\u8fc7\u7f16\u8bd1-\u6d4b\u8bd5\u53cd\u9988\u5faa\u73af\u8fdb\u884c\u4fee\u6b63\uff1b\u8fdb\u4e00\u6b65\u7ed3\u5408\u6d3b\u8dc3\u6027\u5206\u6790\u63d0\u53d6\u5bc4\u5b58\u5668\u4f7f\u7528\u4fe1\u606f\uff0c\u5bf9\u751f\u6210\u7684RVV\u4ee3\u7801\u8fdb\u884c\u6027\u80fd\u4f18\u5316\u3002", "result": "\u572834\u4e2a\u6765\u81ea\u5f00\u6e90\u5e93\u7684\u5411\u91cf\u5316\u7b97\u6cd5\u6848\u4f8b\u4e0a\u8bc4\u4f30\uff0cIntrinTrans\u5728\u6709\u9650\u8fed\u4ee3\u5185\u751f\u6210\u8bed\u4e49\u6b63\u786e\u7684RVV\u4ee3\u7801\uff0c\u90e8\u5206\u6848\u4f8b\u6027\u80fd\u8fbe\u5230\u793e\u533a\u539f\u751f\u5b9e\u73b0\u76845.93\u500d\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u7ed3\u5408\u7f16\u8bd1\u53cd\u9988\u4e0e\u7a0b\u5e8f\u5206\u6790\uff0c\u80fd\u6709\u6548\u5b9e\u73b0\u8de8\u67b6\u6784\u5185\u5efa\u51fd\u6570\u81ea\u52a8\u7ffb\u8bd1\u4e0e\u4f18\u5316\uff0c\u4e3aRISC-V\u751f\u6001\u7684\u9ad8\u6027\u80fd\u5e93\u79fb\u690d\u63d0\u4f9b\u9ad8\u6548\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.11123", "categories": ["cs.NI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.11123", "abs": "https://arxiv.org/abs/2510.11123", "authors": ["Pedro E. G\u00f3ria Silva", "Eduardo S. Lima", "Jules M. Moualeu", "Mohamed Korium", "Pedro H. J. Nardelli"], "title": "Visible Light Communication for Vehicular Networks: A Tutorial", "comment": null, "summary": "The advent of the fifth-generation technology promises to bring about more\nvertical applications and emerging services that include vehicular networks and\nintelligent transportation systems (ITSs). To achieve their vision of real-time\nand safetyapplications, vehicular networks rely on short-range to medium-range\ncommunications. One emerging technology that aims to provide reliability and\nhigh-data rate in short-range communications is the visible light\ncommunications (VLC). Due to its remarkable advantages, some studies have\nrecently investigated the integration of VLC in vehicular networks and ITSs.\nDespite their attractive features, such networks also face several\nimplementation issues. This paper provides an extended tutorial on the\nimplementation of VLC-based vehicular networks. To begin with, we present the\nimplementation characteristics of these systems and discuss some related\nissues. The underlying system considers a general structure with transmitters,\nchannels, and receivers based on photodetectors and cameras, as well as\nstandardization efforts and types of topologies. In addition, we discuss the\nimpact of the sun and artificial light sources, flickering, dimming, throughput\nenhancement, uplink security, and mobility on practical implementation.\nFinally, we highlight some key challenges and potential solutions and provide\nsome directions for future research investigations that could constitute an\nadvancement toward the development of commercial VLC-based vehicular systems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u53ef\u89c1\u5149\u901a\u4fe1\uff08VLC\uff09\u7684\u8f66\u8054\u7f51\u7cfb\u7edf\u5b9e\u73b0\u65b9\u6cd5\uff0c\u6db5\u76d6\u7cfb\u7edf\u7ed3\u6784\u3001\u5173\u952e\u6280\u672f\u6311\u6218\uff08\u5982\u5149\u7167\u5e72\u6270\u3001\u95ea\u70c1\u3001\u4e0a\u884c\u5b89\u5168\u7b49\uff09\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4e3a\u5b9e\u73b0\u8f66\u8054\u7f51\u548c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u5bf9\u5b9e\u65f6\u6027\u4e0e\u5b89\u5168\u6027\u7684\u9700\u6c42\uff0c\u63a2\u7d22\u5177\u5907\u9ad8\u53ef\u9760\u6027\u548c\u9ad8\u6570\u636e\u901f\u7387\u7684\u77ed\u8ddd\u79bb\u901a\u4fe1\u6280\u672f\uff0c\u53ef\u89c1\u5149\u901a\u4fe1\uff08VLC\uff09\u6210\u4e3a\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5176\u5b9e\u9645\u90e8\u7f72\u4ecd\u9762\u4e34\u8bf8\u591a\u6311\u6218\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790VLC\u8f66\u8054\u7f51\u7684\u5b9e\u73b0\u7279\u6027\uff0c\u5305\u62ec\u53d1\u5c04\u5668\u3001\u4fe1\u9053\u3001\u63a5\u6536\u5668\u7ed3\u6784\u3001\u6807\u51c6\u5316\u8fdb\u5c55\u3001\u62d3\u6251\u7c7b\u578b\uff0c\u5e76\u63a2\u8ba8\u592a\u9633\u5149\u4e0e\u4eba\u5de5\u5149\u6e90\u5e72\u6270\u3001\u95ea\u70c1\u3001\u8c03\u5149\u3001\u541e\u5410\u91cf\u63d0\u5347\u3001\u4e0a\u884c\u5b89\u5168\u53ca\u79fb\u52a8\u6027\u7b49\u5b9e\u9645\u95ee\u9898\u3002", "result": "\u7cfb\u7edf\u68b3\u7406\u4e86VLC\u5728\u8f66\u8054\u7f51\u4e2d\u7684\u5b9e\u73b0\u67b6\u6784\u4e0e\u5173\u952e\u5f71\u54cd\u56e0\u7d20\uff0c\u8bc6\u522b\u51fa\u82e5\u5e72\u6280\u672f\u6311\u6218\u5e76\u63d0\u51fa\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "VLC\u5728\u8f66\u8054\u7f51\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u5149\u7167\u5e72\u6270\u3001\u79fb\u52a8\u6027\u652f\u6301\u3001\u6807\u51c6\u5316\u7b49\u5173\u952e\u95ee\u9898\uff1b\u672a\u6765\u7814\u7a76\u5e94\u805a\u7126\u4e8e\u63d0\u5347\u7cfb\u7edf\u9c81\u68d2\u6027\u4e0e\u5b9e\u7528\u6027\uff0c\u63a8\u52a8\u5546\u4e1a\u5316\u8fdb\u7a0b\u3002"}}
{"id": "2510.10833", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.10833", "abs": "https://arxiv.org/abs/2510.10833", "authors": ["Mehdi Zekriyapanah Gashti"], "title": "FIDRS: A Novel Framework for Integrated Distributed Reliable Systems", "comment": null, "summary": "In this paper we represent a new framework for integrated distributed and\nreliable systems. In the proposed framework we have used three parts to\nincrease Satisfaction and Performance of this framework. At first we analyze\nprevious frameworks related to integrated systems, then represent new proposed\nframework in order to improving previous framework, and we discuss its\ndifferent phases. Finally we compare the results of simulation of the new\nframework with previous ones. In FIDRS framework, the technique of\nheterogeneous distributed data base is used to improve Performance and speed in\nresponding to users and in this way we can improve dependability and\nreliability of framework simultaneously. In extraction phase of the new\nframework we have used RMSD algorithm that decreases responding time in big\ndatabase. Finally by using FDIRS framework we succeeded to increase Efficiency,\nPerformance and reliability of integrated systems and remove some of previous\nframeworks problems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFIDRS\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5f02\u6784\u5206\u5e03\u5f0f\u6570\u636e\u5e93\u548cRMSD\u7b97\u6cd5\u63d0\u5347\u96c6\u6210\u7cfb\u7edf\u7684\u6027\u80fd\u3001\u6548\u7387\u4e0e\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u96c6\u6210\u7cfb\u7edf\u6846\u67b6\u5728\u6027\u80fd\u3001\u54cd\u5e94\u901f\u5ea6\u548c\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u9ad8\u6548\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faFIDRS\u6846\u67b6\uff0c\u91c7\u7528\u5f02\u6784\u5206\u5e03\u5f0f\u6570\u636e\u5e93\u6280\u672f\u63d0\u5347\u54cd\u5e94\u901f\u5ea6\u4e0e\u53ef\u9760\u6027\uff0c\u5e76\u5728\u63d0\u53d6\u9636\u6bb5\u5f15\u5165RMSD\u7b97\u6cd5\u4ee5\u51cf\u5c11\u5927\u6570\u636e\u5e93\u4e2d\u7684\u54cd\u5e94\u65f6\u95f4\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u65b0\u6846\u67b6\u5728\u6548\u7387\u3001\u6027\u80fd\u548c\u53ef\u9760\u6027\u65b9\u9762\u4f18\u4e8e\u4ee5\u5f80\u6846\u67b6\uff0c\u5e76\u89e3\u51b3\u4e86\u90e8\u5206\u539f\u6709\u95ee\u9898\u3002", "conclusion": "FIDRS\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u96c6\u6210\u5206\u5e03\u5f0f\u7cfb\u7edf\u7684\u6574\u4f53\u8868\u73b0\uff0c\u4e3a\u6784\u5efa\u9ad8\u6027\u80fd\u3001\u9ad8\u53ef\u9760\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.10148", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.10148", "abs": "https://arxiv.org/abs/2510.10148", "authors": ["Mengyao Zhao", "Kaixuan Li", "Lyuye Zhang", "Wenjing Dang", "Chenggong Ding", "Sen Chen", "Zheli Liu"], "title": "A Systematic Study on Generating Web Vulnerability Proof-of-Concepts Using Large Language Models", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have brought remarkable\nprogress in code understanding and reasoning, creating new opportunities and\nraising new concerns for software security. Among many downstream tasks,\ngenerating Proof-of-Concept (PoC) exploits plays a central role in\nvulnerability reproduction, comprehension, and mitigation. While previous\nresearch has focused primarily on zero-day exploitation, the growing\navailability of rich public information accompanying disclosed CVEs leads to a\nnatural question: can LLMs effectively use this information to automatically\ngenerate valid PoCs? In this paper, we present the first empirical study of\nLLM-based PoC generation for web application vulnerabilities, focusing on the\npractical feasibility of leveraging publicly disclosed information. We evaluate\nGPT-4o and DeepSeek-R1 on 100 real-world and reproducible CVEs across three\nstages of vulnerability disclosure: (1) newly disclosed vulnerabilities with\nonly descriptions, (2) 1-day vulnerabilities with patches, and (3) N-day\nvulnerabilities with full contextual code. Our results show that LLMs can\nautomatically generate working PoCs in 8%-34% of cases using only public data,\nwith DeepSeek-R1 consistently outperforming GPT-4o. Further analysis shows that\nsupplementing code context improves success rates by 17%-20%, with\nfunction-level providing 9%-13% improvement than file-level ones. Further\nintegrating adaptive reasoning strategies to prompt refinement significantly\nimproves success rates to 68%-72%. Our findings suggest that LLMs could reshape\nvulnerability exploitation dynamics. To date, 23 newly generated PoCs have been\naccepted by NVD and Exploit DB.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5b9e\u8bc1\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5229\u7528\u516c\u5f00\u62ab\u9732\u4fe1\u606f\u81ea\u52a8\u751f\u6210Web\u5e94\u7528\u6f0f\u6d1e\u7684PoC\uff08\u6982\u5ff5\u9a8c\u8bc1\uff09\u65b9\u9762\u7684\u53ef\u884c\u6027\uff0c\u53d1\u73b0LLM\u5728\u4ec5\u4f7f\u7528\u516c\u5f00\u6570\u636e\u65f6\u53ef\u5b9e\u73b08%-34%\u7684\u6210\u529f\u7387\uff0c\u7ed3\u5408\u4ee3\u7801\u4e0a\u4e0b\u6587\u548c\u81ea\u9002\u5e94\u63a8\u7406\u7b56\u7565\u540e\u6210\u529f\u7387\u53ef\u63d0\u5347\u81f368%-72%\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7406\u89e3\u548c\u63a8\u7406\u65b9\u9762\u7684\u8fdb\u6b65\uff0c\u7814\u7a76\u5176\u662f\u5426\u80fd\u6709\u6548\u5229\u7528\u516c\u5f00\u62ab\u9732\u7684\u6f0f\u6d1e\u4fe1\u606f\uff08\u5982CVE\uff09\u81ea\u52a8\u751f\u6210\u6709\u6548\u7684PoC\uff0c\u5bf9\u6f0f\u6d1e\u590d\u73b0\u3001\u7406\u89e3\u548c\u7f13\u89e3\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f5c\u8005\u8bc4\u4f30\u4e86GPT-4o\u548cDeepSeek-R1\u5728100\u4e2a\u771f\u5b9e\u53ef\u590d\u73b0\u7684CVE\u4e0a\u7684\u8868\u73b0\uff0c\u6db5\u76d6\u6f0f\u6d1e\u62ab\u9732\u7684\u4e09\u4e2a\u9636\u6bb5\uff1a\u4ec5\u6709\u63cf\u8ff0\u7684\u65b0\u62ab\u9732\u6f0f\u6d1e\u3001\u6709\u8865\u4e01\u76841-day\u6f0f\u6d1e\u3001\u4ee5\u53ca\u5177\u6709\u5b8c\u6574\u4e0a\u4e0b\u6587\u4ee3\u7801\u7684N-day\u6f0f\u6d1e\uff1b\u5e76\u8fdb\u4e00\u6b65\u6d4b\u8bd5\u4e86\u8865\u5145\u4ee3\u7801\u4e0a\u4e0b\u6587\u548c\u81ea\u9002\u5e94\u63a8\u7406\u7b56\u7565\u5bf9\u751f\u6210\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "LLM\u5728\u4ec5\u4f7f\u7528\u516c\u5f00\u6570\u636e\u65f6\u53ef\u751f\u6210\u6709\u6548PoC\u7684\u6bd4\u4f8b\u4e3a8%-34%\uff0c\u5176\u4e2dDeepSeek-R1\u8868\u73b0\u4f18\u4e8eGPT-4o\uff1b\u8865\u5145\u4ee3\u7801\u4e0a\u4e0b\u6587\u53ef\u63d0\u5347\u6210\u529f\u738717%-20%\uff0c\u51fd\u6570\u7ea7\u4e0a\u4e0b\u6587\u6bd4\u6587\u4ef6\u7ea7\u63d0\u53479%-13%\uff1b\u7ed3\u5408\u81ea\u9002\u5e94\u63a8\u7406\u7b56\u7565\u540e\u6210\u529f\u7387\u53ef\u8fbe68%-72%\uff1b\u5df2\u670923\u4e2a\u65b0\u751f\u6210\u7684PoC\u88abNVD\u548cExploit DB\u6536\u5f55\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5229\u7528\u516c\u5f00\u4fe1\u606f\u81ea\u52a8\u751f\u6210\u6f0f\u6d1ePoC\u65b9\u9762\u5c55\u73b0\u51fa\u663e\u8457\u6f5c\u529b\uff0c\u53ef\u80fd\u91cd\u5851\u6f0f\u6d1e\u5229\u7528\u7684\u52a8\u6001\u683c\u5c40\uff0c\u5e76\u5bf9\u8f6f\u4ef6\u5b89\u5168\u5e26\u6765\u65b0\u7684\u673a\u9047\u4e0e\u6311\u6218\u3002"}}
{"id": "2510.10179", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10179", "abs": "https://arxiv.org/abs/2510.10179", "authors": ["Linghan Huang", "Peizhou Zhao", "Huaming Chen"], "title": "LLMs are All You Need? Improving Fuzz Testing for MOJO with Large Language Models", "comment": null, "summary": "The rapid development of large language models (LLMs) has revolutionized\nsoftware testing, particularly fuzz testing, by automating the generation of\ndiverse and effective test inputs. This advancement holds great promise for\nimproving software reliability. Meanwhile, the introduction of MOJO, a\nhigh-performance AI programming language blending Python's usability with the\nefficiency of C and C++, presents new opportunities to enhance AI model\nscalability and programmability. However, as a new language, MOJO lacks\ncomprehensive testing frameworks and a sufficient corpus for LLM-based testing,\nwhich exacerbates model hallucination. In this case, LLMs will generate\nsyntactically valid but semantically incorrect code, significantly reducing the\neffectiveness of fuzz testing. To address this challenge, we propose\nMOJOFuzzer, the first adaptive LLM-based fuzzing framework designed for\nzero-shot learning environments of emerging programming languages. MOJOFuzzer\nintegrates a mutil-phase framework that systematically eliminates low-quality\ngenerated inputs before execution, significantly improving test case validity.\nFurthermore, MOJOFuzzer dynamically adapts LLM prompts based on runtime\nfeedback for test case mutation, enabling an iterative learning process that\ncontinuously enhances fuzzing efficiency and bug detection performance. Our\nexperimental results demonstrate that MOJOFuzzer significantly enhances test\nvalidity, API coverage, and bug detection performance, outperforming\ntraditional fuzz testing and state-of-the-art LLM-based fuzzing approaches.\nUsing MOJOFuzzer, we have conducted a first large-scale fuzz testing evaluation\nof MOJO, uncorvering 13 previous unknown bugs. This study not only advances the\nfield of LLM-driven software testing but also establishes a foundational\nmethodology for leveraging LLMs in the testing of emerging programming\nlanguages.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MOJOFuzzer\uff0c\u9996\u4e2a\u9762\u5411\u65b0\u5174\u7f16\u7a0b\u8bed\u8a00\uff08\u5982MOJO\uff09\u7684\u81ea\u9002\u5e94LLM\u9a71\u52a8\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u8fc7\u6ee4\u548c\u52a8\u6001\u63d0\u793a\u8c03\u6574\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u6709\u6548\u6027\u3001API\u8986\u76d6\u7387\u548c\u6f0f\u6d1e\u53d1\u73b0\u80fd\u529b\u3002", "motivation": "\u65b0\u5174\u7f16\u7a0b\u8bed\u8a00MOJO\u7f3a\u4e4f\u5b8c\u5584\u7684\u6d4b\u8bd5\u6846\u67b6\u548cLLM\u8bad\u7ec3\u8bed\u6599\uff0c\u5bfc\u81f4LLM\u5728\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u65f6\u5bb9\u6613\u4ea7\u751f\u8bed\u4e49\u9519\u8bef\uff08\u5e7b\u89c9\uff09\uff0c\u964d\u4f4e\u6a21\u7cca\u6d4b\u8bd5\u6548\u679c\u3002", "method": "MOJOFuzzer\u91c7\u7528\u591a\u9636\u6bb5\u6846\u67b6\uff0c\u5728\u6267\u884c\u524d\u7cfb\u7edf\u6027\u8fc7\u6ee4\u4f4e\u8d28\u91cf\u8f93\u5165\uff0c\u5e76\u57fa\u4e8e\u8fd0\u884c\u65f6\u53cd\u9988\u52a8\u6001\u8c03\u6574LLM\u63d0\u793a\uff0c\u5b9e\u73b0\u6d4b\u8bd5\u7528\u4f8b\u7684\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMOJOFuzzer\u5728\u6d4b\u8bd5\u6709\u6548\u6027\u3001API\u8986\u76d6\u7387\u548c\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u548c\u73b0\u6709LLM\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u5e76\u5728MOJO\u4e2d\u9996\u6b21\u5927\u89c4\u6a21\u6d4b\u8bd5\u4e2d\u53d1\u73b013\u4e2a\u672a\u77e5\u6f0f\u6d1e\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a8\u8fdb\u4e86LLM\u9a71\u52a8\u7684\u8f6f\u4ef6\u6d4b\u8bd5\uff0c\u5e76\u4e3a\u65b0\u5174\u7f16\u7a0b\u8bed\u8a00\u7684\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u57fa\u7840\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2510.11211", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.11211", "abs": "https://arxiv.org/abs/2510.11211", "authors": ["Sheikh Azizul Hakim", "Saem Hasan"], "title": "An Explorative Study on Distributed Computing Techniques in Training and Inference of Large Language Models", "comment": null, "summary": "Large language models (LLM) are advanced AI systems trained on extensive\ntextual data, leveraging deep learning techniques to understand and generate\nhuman-like language. Today's LLMs with billions of parameters are so huge that\nhardly any single computing node can train, fine-tune, or infer from them.\nTherefore, several distributed computing techniques are being introduced in the\nliterature to properly utilize LLMs. We have explored the application of\ndistributed computing techniques in LLMs from two angles.\n  \\begin{itemize}\n  \\item We study the techniques that democratize the LLM, that is, how large\nmodels can be run on consumer-grade computers. Here, we also implement a novel\nmetaheuristics-based modification to an existing system.\n  \\item We perform a comparative study on three state-of-the-art LLM serving\ntechniques. \\end{itemize}", "AI": {"tldr": "\u672c\u6587\u4ece\u4e24\u4e2a\u89d2\u5ea6\u63a2\u8ba8\u4e86\u5206\u5e03\u5f0f\u8ba1\u7b97\u6280\u672f\u5728\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u5e94\u7528\uff1a\u4e00\u662f\u7814\u7a76\u5982\u4f55\u5728\u6d88\u8d39\u7ea7\u8ba1\u7b97\u673a\u4e0a\u8fd0\u884c\u5927\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5143\u542f\u53d1\u5f0f\u7684\u7cfb\u7edf\u6539\u8fdb\u65b9\u6cd5\uff1b\u4e8c\u662f\u5bf9\u4e09\u79cd\u6700\u5148\u8fdb\u7684LLM\u670d\u52a1\u6280\u672f\u8fdb\u884c\u6bd4\u8f83\u7814\u7a76\u3002", "motivation": "\u7531\u4e8e\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u53c2\u6570\u89c4\u6a21\u5e9e\u5927\uff0c\u5355\u4e2a\u8ba1\u7b97\u8282\u70b9\u96be\u4ee5\u627f\u62c5\u5176\u8bad\u7ec3\u3001\u5fae\u8c03\u6216\u63a8\u7406\u4efb\u52a1\uff0c\u56e0\u6b64\u9700\u8981\u501f\u52a9\u5206\u5e03\u5f0f\u8ba1\u7b97\u6280\u672f\u6765\u6709\u6548\u5229\u7528\u8fd9\u4e9b\u6a21\u578b\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u5206\u5e03\u5f0f\u65b9\u6cd5\u964d\u4f4eLLM\u4f7f\u7528\u95e8\u69db\u5e76\u8bc4\u4f30\u73b0\u6709\u670d\u52a1\u6280\u672f\u7684\u6027\u80fd\u3002", "method": "\u4e00\u65b9\u9762\uff0c\u7814\u7a76\u4f7fLLM\u80fd\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8fd0\u884c\u7684\u5206\u5e03\u5f0f\u6280\u672f\uff0c\u5e76\u5bf9\u73b0\u6709\u7cfb\u7edf\u5f15\u5165\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u5143\u542f\u53d1\u5f0f\u7684\u6539\u8fdb\u65b9\u6cd5\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u5bf9\u4e09\u79cd\u524d\u6cbf\u7684LLM\u670d\u52a1\u6280\u672f\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u5b9e\u73b0\u4e86\u9002\u7528\u4e8e\u6d88\u8d39\u7ea7\u8bbe\u5907\u7684LLM\u8fd0\u884c\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u5143\u542f\u53d1\u5f0f\u65b9\u6cd5\u4f18\u5316\u4e86\u73b0\u6709\u7cfb\u7edf\uff1b\u540c\u65f6\uff0c\u5bf9\u4e09\u79cd\u4e3b\u6d41LLM\u670d\u52a1\u6280\u672f\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u6bd4\u8f83\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u4f18\u52a3\u3002", "conclusion": "\u5206\u5e03\u5f0f\u8ba1\u7b97\u6280\u672f\u5bf9\u4e8e\u63a8\u52a8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\u548c\u9ad8\u6548\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002\u901a\u8fc7\u7b97\u6cd5\u4f18\u5316\u548c\u7cfb\u7edf\u6bd4\u8f83\uff0c\u672c\u6587\u4e3a\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u4f7f\u7528LLM\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\uff0c\u5e76\u4e3a\u670d\u52a1\u7cfb\u7edf\u9009\u578b\u63d0\u4f9b\u4e86\u53c2\u8003\u4f9d\u636e\u3002"}}
{"id": "2510.10290", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.10290", "abs": "https://arxiv.org/abs/2510.10290", "authors": ["Sayan Mandal", "Hua Jiang"], "title": "Grounded AI for Code Review: Resource-Efficient Large-Model Serving in Enterprise Pipelines", "comment": "Submitted to MLSys 2026", "summary": "Automated code review adoption lags in compliance-heavy settings, where\nstatic analyzers produce high-volume, low-rationale outputs, and naive LLM use\nrisks hallucination and incurring cost overhead. We present a production system\nfor grounded, PR-native review that pairs static-analysis findings with\nAST-guided context extraction and a single-GPU, on-demand serving stack\n(quantized open-weight model, multi-tier caching) to deliver concise\nexplanations and remediation guidance. Evaluated on safety-oriented C/C++\nstandards, the approach achieves sub-minute median first-feedback (offline p50\nbuild+LLM 59.8s) while maintaining competitive violation reduction and lower\nviolation rates versus larger proprietary models. The architecture is\ndecoupled: teams can adopt the grounding/prompting layer or the serving layer\nindependently. A small internal survey (n=8) provides directional signals of\nreduced triage effort and moderate perceived grounding, with participants\nreporting fewer human review iterations. We outline operational lessons and\nlimitations, emphasizing reproducibility, auditability, and pathways to broader\nstandards and assisted patching.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5408\u89c4\u8981\u6c42\u4e25\u683c\u73af\u5883\u7684\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u7cfb\u7edf\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u3001AST\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u63d0\u53d6\u548c\u8f7b\u91cf\u7ea7\u5355GPU\u6309\u9700\u670d\u52a1\u67b6\u6784\uff0c\u5728\u4fdd\u8bc1\u4f4e\u5ef6\u8fdf\u548c\u4f4e\u6210\u672c\u7684\u540c\u65f6\u63d0\u4f9b\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u7684\u5ba1\u67e5\u53cd\u9988\u3002", "motivation": "\u5728\u5408\u89c4\u8981\u6c42\u9ad8\u7684\u73af\u5883\u4e2d\uff0c\u73b0\u6709\u9759\u6001\u5206\u6790\u5de5\u5177\u8f93\u51fa\u91cf\u5927\u4f46\u7f3a\u4e4f\u89e3\u91ca\uff0c\u800c\u76f4\u63a5\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5b58\u5728\u5e7b\u89c9\u98ce\u9669\u548c\u9ad8\u6210\u672c\u95ee\u9898\uff0c\u963b\u788d\u4e86\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u7684\u843d\u5730\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u751f\u4ea7\u7ea7\u7cfb\u7edf\uff0c\u5c06\u9759\u6001\u5206\u6790\u7ed3\u679c\u4e0eAST\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u63d0\u53d6\u76f8\u7ed3\u5408\uff0c\u5e76\u91c7\u7528\u91cf\u5316\u5f00\u6e90\u6a21\u578b\u4e0e\u591a\u7ea7\u7f13\u5b58\u7684\u5355GPU\u6309\u9700\u670d\u52a1\u67b6\u6784\uff0c\u5b9e\u73b0\u7cbe\u51c6\u3001\u9ad8\u6548\u7684\u4ee3\u7801\u5ba1\u67e5\u53cd\u9988\u3002", "result": "\u5728\u9762\u5411\u5b89\u5168\u7684C/C++\u6807\u51c6\u4e0a\u8bc4\u4f30\uff0c\u7cfb\u7edf\u4e2d\u4f4d\u9996\u6b21\u53cd\u9988\u65f6\u95f4\u4f4e\u4e8e1\u5206\u949f\uff0859.8\u79d2\uff09\uff0c\u8fdd\u89c4\u51cf\u5c11\u6548\u679c\u4e0e\u5927\u578b\u95ed\u6e90\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\uff0c\u5185\u90e8\u5c0f\u89c4\u6a21\u8c03\u7814\uff08n=8\uff09\u663e\u793a\u4eba\u5de5\u5ba1\u67e5\u8f6e\u6b21\u51cf\u5c11\u3001\u5206\u7c7b\u8d1f\u62c5\u964d\u4f4e\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u67b6\u6784\u89e3\u8026\uff0c\u652f\u6301\u6a21\u5757\u5316\u91c7\u7528\uff0c\u5f3a\u8c03\u53ef\u590d\u73b0\u6027\u3001\u53ef\u5ba1\u8ba1\u6027\uff0c\u5e76\u4e3a\u652f\u6301\u66f4\u5e7f\u6cdb\u6807\u51c6\u548c\u8f85\u52a9\u4fee\u590d\u63d0\u4f9b\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2510.11513", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.11513", "abs": "https://arxiv.org/abs/2510.11513", "authors": ["Alex Elwood", "Tom Deakin", "Justin Lovegrove", "Chris Nelson"], "title": "An Asynchronous Many-Task Algorithm for Unstructured $S_{N}$ Transport on Shared Memory Systems", "comment": null, "summary": "Discrete ordinates $S_N$ transport solvers on unstructured meshes pose a\nchallenge to scale due to complex data dependencies, memory access patterns and\na high-dimensional domain. In this paper, we review the performance bottlenecks\nwithin the shared memory parallelization scheme of an existing transport solver\non modern many-core architectures with high core counts. With this analysis, we\nthen survey the performance of this solver across a variety of compute\nhardware. We then present a new Asynchronous Many-Task (AMT) algorithm for\nshared memory parallelism, present results showing an increase in computational\nperformance over the existing method, and evaluate why performance is improved.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u975e\u7ed3\u6784\u7f51\u683c\u4e0a\u79bb\u6563\u7eb5\u6807\uff08$S_N$\uff09\u8f93\u8fd0\u6c42\u89e3\u5668\u5728\u73b0\u4ee3\u591a\u6838\u67b6\u6784\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f02\u6b65\u591a\u4efb\u52a1\uff08AMT\uff09\u5171\u4eab\u5185\u5b58\u5e76\u884c\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6027\u80fd\u3002", "motivation": "\u975e\u7ed3\u6784\u7f51\u683c\u4e0a\u7684\u79bb\u6563\u7eb5\u6807\u8f93\u8fd0\u6c42\u89e3\u5668\u7531\u4e8e\u590d\u6742\u7684\u6570\u636e\u4f9d\u8d56\u3001\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u548c\u9ad8\u7ef4\u8ba1\u7b97\u57df\uff0c\u5728\u73b0\u4ee3\u591a\u6838\u67b6\u6784\u4e0a\u96be\u4ee5\u6709\u6548\u6269\u5c55\uff0c\u4e9f\u9700\u4f18\u5316\u5176\u5171\u4eab\u5185\u5b58\u5e76\u884c\u7b56\u7565\u3002", "method": "\u4f5c\u8005\u9996\u5148\u5206\u6790\u73b0\u6709\u6c42\u89e3\u5668\u5728\u5171\u4eab\u5185\u5b58\u5e76\u884c\u5316\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u5e76\u5728\u591a\u79cd\u8ba1\u7b97\u786c\u4ef6\u4e0a\u8bc4\u4f30\u5176\u6027\u80fd\uff1b\u968f\u540e\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5f02\u6b65\u591a\u4efb\u52a1\uff08AMT\uff09\u7b97\u6cd5\u7528\u4e8e\u5171\u4eab\u5185\u5b58\u5e76\u884c\u3002", "result": "\u65b0\u63d0\u51fa\u7684AMT\u7b97\u6cd5\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u6027\u80fd\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u901a\u8fc7\u5206\u6790\u63ed\u793a\u4e86\u6027\u80fd\u63d0\u5347\u7684\u539f\u56e0\u3002", "conclusion": "\u5f02\u6b65\u591a\u4efb\u52a1\uff08AMT\uff09\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u975e\u7ed3\u6784\u7f51\u683c$S_N$\u8f93\u8fd0\u6c42\u89e3\u5668\u5728\u591a\u6838\u67b6\u6784\u4e0a\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2d\u7684\u8f93\u8fd0\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u5e76\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.10320", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10320", "abs": "https://arxiv.org/abs/2510.10320", "authors": ["Lorena Poenaru-Olaru", "Wouter van 't Hof", "Adrian Stando", "Arkadiusz P. Trawinski", "Eileen Kapel", "Jan S. Rellermeyer", "Luis Cruz", "Arie van Deursen"], "title": "Prepared for the Unknown: Adapting AIOps Capacity Forecasting Models to Data Changes", "comment": null, "summary": "Capacity management is critical for software organizations to allocate\nresources effectively and meet operational demands. An important step in\ncapacity management is predicting future resource needs often relies on\ndata-driven analytics and machine learning (ML) forecasting models, which\nrequire frequent retraining to stay relevant as data evolves. Continuously\nretraining the forecasting models can be expensive and difficult to scale,\nposing a challenge for engineering teams tasked with balancing accuracy and\nefficiency. Retraining only when the data changes appears to be a more\ncomputationally efficient alternative, but its impact on accuracy requires\nfurther investigation. In this work, we investigate the effects of retraining\ncapacity forecasting models for time series based on detected changes in the\ndata compared to periodic retraining. Our results show that drift-based\nretraining achieves comparable forecasting accuracy to periodic retraining in\nmost cases, making it a cost-effective strategy. However, in cases where data\nis changing rapidly, periodic retraining is still preferred to maximize the\nforecasting accuracy. These findings offer actionable insights for software\nteams to enhance forecasting systems, reducing retraining overhead while\nmaintaining robust performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6570\u636e\u53d8\u5316\u89e6\u53d1\u7684\u91cd\u8bad\u7ec3\u7b56\u7565\uff08\u6f02\u79fb\u9a71\u52a8\u91cd\u8bad\u7ec3\uff09\u4e0e\u5b9a\u671f\u91cd\u8bad\u7ec3\u5728\u5bb9\u91cf\u9884\u6d4b\u6a21\u578b\u4e2d\u7684\u6548\u679c\u5bf9\u6bd4\uff0c\u53d1\u73b0\u524d\u8005\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u80fd\u4ee5\u66f4\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u76f8\u5f53\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4f46\u5728\u6570\u636e\u5feb\u901f\u53d8\u5316\u65f6\u4ecd\u9700\u4f9d\u8d56\u5b9a\u671f\u91cd\u8bad\u7ec3\u4ee5\u4fdd\u8bc1\u51c6\u786e\u6027\u3002", "motivation": "\u8f6f\u4ef6\u7ec4\u7ec7\u5728\u5bb9\u91cf\u7ba1\u7406\u4e2d\u9700\u9ad8\u6548\u5206\u914d\u8d44\u6e90\uff0c\u800c\u4f9d\u8d56\u673a\u5668\u5b66\u4e60\u7684\u9884\u6d4b\u6a21\u578b\u9700\u9891\u7e41\u91cd\u8bad\u7ec3\u4ee5\u5e94\u5bf9\u6570\u636e\u6f14\u5316\u3002\u7136\u800c\uff0c\u6301\u7eed\u91cd\u8bad\u7ec3\u6210\u672c\u9ad8\u3001\u96be\u6269\u5c55\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u91cd\u8bad\u7ec3\u7b56\u7565\u3002", "method": "\u5bf9\u6bd4\u57fa\u4e8e\u6570\u636e\u6f02\u79fb\u68c0\u6d4b\u89e6\u53d1\u7684\u91cd\u8bad\u7ec3\u4e0e\u5b9a\u671f\u91cd\u8bad\u7ec3\u4e24\u79cd\u7b56\u7565\uff0c\u5728\u65f6\u95f4\u5e8f\u5217\u5bb9\u91cf\u9884\u6d4b\u4efb\u52a1\u4e2d\u8bc4\u4f30\u5176\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u6f02\u79fb\u9a71\u52a8\u7684\u91cd\u8bad\u7ec3\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u80fd\u8fbe\u5230\u4e0e\u5b9a\u671f\u91cd\u8bad\u7ec3\u76f8\u5f53\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\uff1b\u4f46\u5728\u6570\u636e\u5feb\u901f\u53d8\u5316\u7684\u573a\u666f\u4e0b\uff0c\u5b9a\u671f\u91cd\u8bad\u7ec3\u4ecd\u66f4\u4f18\u3002", "conclusion": "\u5bf9\u4e8e\u8f6f\u4ef6\u56e2\u961f\u800c\u8a00\uff0c\u91c7\u7528\u57fa\u4e8e\u6570\u636e\u53d8\u5316\u7684\u91cd\u8bad\u7ec3\u7b56\u7565\u662f\u4e00\u79cd\u517c\u987e\u6548\u7387\u4e0e\u51c6\u786e\u6027\u7684\u53ef\u884c\u65b9\u6848\uff0c\u53ef\u5728\u591a\u6570\u573a\u666f\u4e2d\u51cf\u5c11\u91cd\u8bad\u7ec3\u8d1f\u62c5\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.10460", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10460", "abs": "https://arxiv.org/abs/2510.10460", "authors": ["Zongyi Lyu", "Songqiang Chen", "Zhenlan Ji", "Liwen Wang", "Shuai Wang", "Daoyuan Wu", "Wenxuan Wang", "Shing-Chi Cheung"], "title": "Testing and Enhancing Multi-Agent Systems for Robust Code Generation", "comment": "19pages, 5 figures", "summary": "Multi-agent systems (MASs) have emerged as a promising paradigm for automated\ncode generation, demonstrating impressive performance on established benchmarks\nby decomposing complex coding tasks across specialized agents with different\nroles. Despite their prosperous development and adoption, their robustness\nremains pressingly under-explored, raising critical concerns for real-world\ndeployment. This paper presents the first comprehensive study examining the\nrobustness of MASs for code generation through a fuzzing-based testing\napproach. By designing a fuzzing pipeline incorporating semantic-preserving\nmutation operators and a novel fitness function, we assess mainstream MASs\nacross multiple datasets and LLMs. Our findings reveal substantial robustness\nflaws of various popular MASs: they fail to solve 7.9%-83.3% of problems they\ninitially resolved successfully after applying the semantic-preserving\nmutations. Through comprehensive failure analysis, we identify a common yet\nlargely overlooked cause of the robustness issue: miscommunications between\nplanning and coding agents, where plans lack sufficient detail and coding\nagents misinterpret intricate logic, aligning with the challenges inherent in a\nmulti-stage information transformation process. Accordingly, we also propose a\nrepairing method that encompasses multi-prompt generation and introduces a new\nmonitor agent to address this issue. Evaluation shows that our repairing method\neffectively enhances the robustness of MASs by solving 40.0%-88.9% of\nidentified failures. Our work uncovers critical robustness flaws in MASs and\nprovides effective mitigation strategies, contributing essential insights for\ndeveloping more reliable MASs for code generation.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u53d1\u73b0\u4e3b\u6d41MAS\u5728\u8bed\u4e49\u4fdd\u6301\u7684\u6a21\u7cca\u6d4b\u8bd5\u4e0b\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u5e76\u63ed\u793a\u5176\u6839\u672c\u539f\u56e0\u5728\u4e8e\u89c4\u5212\u4e0e\u7f16\u7801\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u6c9f\u901a\u4e0d\u8db3\uff1b\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u5305\u542b\u591a\u63d0\u793a\u751f\u6210\u548c\u76d1\u63a7\u667a\u80fd\u4f53\u7684\u4fee\u590d\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86MAS\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5c3d\u7ba1\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u8fd9\u5bf9\u5176\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u90e8\u7f72\u6784\u6210\u6f5c\u5728\u98ce\u9669\uff0c\u56e0\u6b64\u4e9f\u9700\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e0e\u6539\u8fdb\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u6d4b\u8bd5\u7684\u8bc4\u4f30\u6d41\u7a0b\uff0c\u5305\u542b\u8bed\u4e49\u4fdd\u6301\u7684\u53d8\u5f02\u7b97\u5b50\u548c\u65b0\u9896\u7684\u9002\u5e94\u5ea6\u51fd\u6570\uff0c\u5bf9\u591a\u4e2a\u4e3b\u6d41MAS\u5728\u4e0d\u540c\u6570\u636e\u96c6\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff1b\u5e76\u63d0\u51fa\u4e00\u79cd\u4fee\u590d\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u63d0\u793a\u751f\u6210\u4e0e\u65b0\u589e\u7684\u76d1\u63a7\u667a\u80fd\u4f53\u4ee5\u6539\u5584\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u73b0\u6709MAS\u5728\u6a21\u7cca\u6d4b\u8bd5\u540e\u5bf9\u539f\u672c\u5df2\u89e3\u51b3\u7684\u95ee\u9898\u5931\u8d25\u7387\u8fbe7.9%\u201383.3%\uff1b\u6240\u63d0\u4fee\u590d\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b340.0%\u201388.9%\u7684\u5931\u8d25\u6848\u4f8b\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u9c81\u68d2\u6027\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u5b58\u5728\u4e25\u91cd\u7684\u9c81\u68d2\u6027\u7f3a\u9677\uff0c\u4e3b\u8981\u6e90\u4e8e\u89c4\u5212\u4e0e\u7f16\u7801\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u4fe1\u606f\u4f20\u9012\u4e0d\u5145\u5206\uff1b\u901a\u8fc7\u5f15\u5165\u76d1\u63a7\u673a\u5236\u548c\u591a\u63d0\u793a\u7b56\u7565\u53ef\u6709\u6548\u7f13\u89e3\u8be5\u95ee\u9898\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u7684MAS\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\u3002"}}
{"id": "2510.10551", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.10551", "abs": "https://arxiv.org/abs/2510.10551", "authors": ["Baris Ardic", "Quentin Le Dilavrec", "Andy Zaidman"], "title": "How Students Use Generative AI for Software Testing: An Observational Study", "comment": "39 pages, 6 figures, journal submission", "summary": "The integration of generative AI tools like ChatGPT into software engineering\nworkflows opens up new opportunities to boost productivity in tasks such as\nunit test engineering. However, these AI-assisted workflows can also\nsignificantly alter the developer's role, raising concerns about control,\noutput quality, and learning, particularly for novice developers. This study\ninvestigates how novice software developers with foundational knowledge in\nsoftware testing interact with generative AI for engineering unit tests. Our\ngoal is to examine the strategies they use, how heavily they rely on generative\nAI, and the benefits and challenges they perceive when using generative\nAI-assisted approaches for test engineering. We conducted an observational\nstudy involving 12 undergraduate students who worked with generative AI for\nunit testing tasks. We identified four interaction strategies, defined by\nwhether the test idea or the test implementation originated from generative AI\nor the participant. Additionally, we singled out prompting styles that focused\non one-shot or iterative test generation, which often aligned with the broader\ninteraction strategy. Students reported benefits including time-saving, reduced\ncognitive load, and support for test ideation, but also noted drawbacks such as\ndiminished trust, test quality concerns, and lack of ownership. While strategy\nand prompting styles influenced workflow dynamics, they did not significantly\naffect test effectiveness or test code quality as measured by mutation score or\ntest smells.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u521d\u7ea7\u8f6f\u4ef6\u5f00\u53d1\u8005\u5728\u4f7f\u7528\u751f\u6210\u5f0fAI\uff08\u5982ChatGPT\uff09\u8fdb\u884c\u5355\u5143\u6d4b\u8bd5\u65f6\u7684\u4ea4\u4e92\u7b56\u7565\u3001\u4f9d\u8d56\u7a0b\u5ea6\u53ca\u611f\u77e5\u7684\u4f18\u7f3a\u70b9\uff0c\u53d1\u73b0\u867d\u7136AI\u80fd\u8282\u7701\u65f6\u95f4\u5e76\u964d\u4f4e\u8ba4\u77e5\u8d1f\u62c5\uff0c\u4f46\u4e5f\u5e26\u6765\u4fe1\u4efb\u5ea6\u4e0b\u964d\u548c\u4ee3\u7801\u6240\u6709\u6743\u7f3a\u5931\u7b49\u95ee\u9898\uff0c\u4e14\u4e0d\u540c\u7b56\u7565\u5bf9\u6d4b\u8bd5\u6548\u679c\u548c\u4ee3\u7801\u8d28\u91cf\u5f71\u54cd\u4e0d\u5927\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5de5\u5177\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u5176\u5bf9\u5f00\u53d1\u8005\u89d2\u8272\u3001\u63a7\u5236\u611f\u3001\u8f93\u51fa\u8d28\u91cf\u53ca\u5b66\u4e60\u8fc7\u7a0b\u7684\u5f71\u54cd\u5f15\u53d1\u5173\u6ce8\uff0c\u5c24\u5176\u5bf9\u521d\u5b66\u8005\u800c\u8a00\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u7814\u7a76\u65b0\u624b\u5f00\u53d1\u8005\u5982\u4f55\u4e0e\u751f\u6210\u5f0fAI\u4e92\u52a8\u4ee5\u8fdb\u884c\u5355\u5143\u6d4b\u8bd5\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u89c2\u5bdf\u6027\u5b9e\u9a8c\uff0c\u62db\u52df12\u540d\u5177\u5907\u57fa\u7840\u8f6f\u4ef6\u6d4b\u8bd5\u77e5\u8bc6\u7684\u672c\u79d1\u751f\uff0c\u8ba9\u4ed6\u4eec\u4f7f\u7528\u751f\u6210\u5f0fAI\u5b8c\u6210\u5355\u5143\u6d4b\u8bd5\u4efb\u52a1\uff0c\u5206\u6790\u5176\u4ea4\u4e92\u7b56\u7565\u3001\u63d0\u793a\u98ce\u683c\u4ee5\u53ca\u5bf9AI\u8f85\u52a9\u6d4b\u8bd5\u7684\u4e3b\u89c2\u4f53\u9a8c\u3002", "result": "\u7814\u7a76\u8bc6\u522b\u51fa\u56db\u79cd\u4ea4\u4e92\u7b56\u7565\uff08\u57fa\u4e8e\u6d4b\u8bd5\u60f3\u6cd5\u4e0e\u5b9e\u73b0\u6765\u6e90\uff09\uff0c\u4ee5\u53ca\u4e00\u6b21\u6027\u63d0\u793a\u4e0e\u8fed\u4ee3\u63d0\u793a\u4e24\u79cd\u98ce\u683c\uff1b\u53c2\u4e0e\u8005\u666e\u904d\u8ba4\u4e3aAI\u6709\u52a9\u4e8e\u8282\u7701\u65f6\u95f4\u3001\u51cf\u8f7b\u8ba4\u77e5\u8d1f\u62c5\u548c\u6fc0\u53d1\u6d4b\u8bd5\u601d\u8def\uff0c\u4f46\u4e5f\u62c5\u5fe7\u6d4b\u8bd5\u8d28\u91cf\u3001\u4fe1\u4efb\u5ea6\u548c\u7f3a\u4e4f\u4ee3\u7801\u6240\u6709\u6743\uff1b\u4e0d\u540c\u7b56\u7565\u5bf9\u6d4b\u8bd5\u6709\u6548\u6027\uff08\u7a81\u53d8\u5206\u6570\uff09\u548c\u4ee3\u7801\u8d28\u91cf\uff08\u6d4b\u8bd5\u5f02\u5473\uff09\u65e0\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u5355\u5143\u6d4b\u8bd5\u4e2d\u4e3a\u65b0\u624b\u5f00\u53d1\u8005\u5e26\u6765\u6548\u7387\u63d0\u5347\uff0c\u4f46\u4e5f\u5f15\u53d1\u5bf9\u8d28\u91cf\u63a7\u5236\u548c\u5b66\u4e60\u6548\u679c\u7684\u62c5\u5fe7\uff1b\u4ea4\u4e92\u7b56\u7565\u867d\u5f71\u54cd\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4f46\u672a\u663e\u8457\u6539\u53d8\u6d4b\u8bd5\u4ea7\u51fa\u8d28\u91cf\uff0c\u63d0\u793a\u9700\u5728\u6559\u80b2\u548c\u5b9e\u8df5\u4e2d\u5e73\u8861AI\u8f85\u52a9\u4e0e\u5f00\u53d1\u8005\u81ea\u4e3b\u6027\u3002"}}
{"id": "2510.10819", "categories": ["cs.SE", "cs.AI", "68N01, 68T05, 68T07, 68T50", "D.2.2; D.2.5; D.2.6; D.2.8; I.2.6; I.2.7; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.10819", "abs": "https://arxiv.org/abs/2510.10819", "authors": ["Vivek Acharya"], "title": "Generative AI and the Transformation of Software Development Practices", "comment": "16 pages; 1 figure; preprint; v", "summary": "Generative AI is reshaping how software is designed, written, and maintained.\nAdvances in large language models (LLMs) are enabling new development styles -\nfrom chat-oriented programming and 'vibe coding' to agentic programming - that\ncan accelerate productivity and broaden access. This paper examines how\nAI-assisted techniques are changing software engineering practice, and the\nrelated issues of trust, accountability, and shifting skills. We survey\niterative chat-based development, multi-agent systems, dynamic prompt\norchestration, and integration via the Model Context Protocol (MCP). Using case\nstudies and industry data, we outline both the opportunities (faster cycles,\ndemocratized coding) and the challenges (model reliability and cost) of\napplying generative AI to coding. We describe new roles, skills, and best\npractices for using AI in a responsible and effective way.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u751f\u6210\u5f0fAI\uff08\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5982\u4f55\u6539\u53d8\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff0c\u6db5\u76d6\u804a\u5929\u5f0f\u7f16\u7a0b\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7b49\u65b0\u8303\u5f0f\uff0c\u5206\u6790\u5176\u5e26\u6765\u7684\u6548\u7387\u63d0\u5347\u4e0e\u53ef\u53ca\u6027\u6269\u5c55\uff0c\u540c\u65f6\u8ba8\u8bba\u6a21\u578b\u53ef\u9760\u6027\u3001\u6210\u672c\u3001\u4fe1\u4efb\u4e0e\u6280\u80fd\u8f6c\u578b\u7b49\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u8d1f\u8d23\u4efb\u4f7f\u7528AI\u7684\u65b0\u89d2\u8272\u4e0e\u6700\u4f73\u5b9e\u8df5\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u8f6f\u4ef6\u5f00\u53d1\u65b9\u5f0f\u6b63\u5728\u7ecf\u5386\u6df1\u523b\u53d8\u9769\u3002\u4f5c\u8005\u65e8\u5728\u7cfb\u7edf\u5206\u6790AI\u8f85\u52a9\u7f16\u7a0b\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u7684\u5f71\u54cd\uff0c\u5398\u6e05\u5176\u4e2d\u7684\u673a\u9047\u4e0e\u98ce\u9669\uff0c\u4e3a\u5f00\u53d1\u8005\u548c\u7ec4\u7ec7\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u7efc\u8ff0\u8fed\u4ee3\u5f0f\u804a\u5929\u5f00\u53d1\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3001\u52a8\u6001\u63d0\u793a\u7f16\u6392\u53ca\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u7b49\u6280\u672f\uff0c\u5e76\u7ed3\u5408\u6848\u4f8b\u7814\u7a76\u4e0e\u884c\u4e1a\u6570\u636e\u8fdb\u884c\u5206\u6790\u3002", "result": "\u63ed\u793a\u4e86\u751f\u6210\u5f0fAI\u5728\u52a0\u901f\u5f00\u53d1\u5468\u671f\u548c\u964d\u4f4e\u7f16\u7a0b\u95e8\u69db\u65b9\u9762\u7684\u663e\u8457\u4f18\u52bf\uff0c\u540c\u65f6\u4e5f\u8bc6\u522b\u51fa\u6a21\u578b\u53ef\u9760\u6027\u3001\u4f7f\u7528\u6210\u672c\u3001\u4fe1\u4efb\u673a\u5236\u548c\u6280\u80fd\u9700\u6c42\u8f6c\u53d8\u7b49\u5173\u952e\u6311\u6218\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u6b63\u6df1\u523b\u91cd\u5851\u8f6f\u4ef6\u5de5\u7a0b\uff0c\u9700\u901a\u8fc7\u5efa\u7acb\u65b0\u89d2\u8272\u3001\u57f9\u517b\u65b0\u6280\u80fd\u548c\u91c7\u7eb3\u6700\u4f73\u5b9e\u8df5\uff0c\u5728\u63d0\u5347\u6548\u7387\u7684\u540c\u65f6\u786e\u4fdd\u5176\u8d1f\u8d23\u4efb\u548c\u6709\u6548\u5e94\u7528\u3002"}}
{"id": "2510.10824", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10824", "abs": "https://arxiv.org/abs/2510.10824", "authors": ["Mohanakrishnan Hariharan", "Satish Arvapalli", "Seshu Barma", "Evangeline Sheela"], "title": "Agentic RAG for Software Testing with Hybrid Vector-Graph and Multi-Agent Orchestration", "comment": null, "summary": "We present an approach to software testing automation using Agentic\nRetrieval-Augmented Generation (RAG) systems for Quality Engineering (QE)\nartifact creation. We combine autonomous AI agents with hybrid vector-graph\nknowledge systems to automate test plan, case, and QE metric generation. Our\napproach addresses traditional software testing limitations by leveraging LLMs\nsuch as Gemini and Mistral, multi-agent orchestration, and enhanced\ncontextualization. The system achieves remarkable accuracy improvements from\n65% to 94.8% while ensuring comprehensive document traceability throughout the\nquality engineering lifecycle. Experimental validation of enterprise Corporate\nSystems Engineering and SAP migration projects demonstrates an 85% reduction in\ntesting timeline, an 85% improvement in test suite efficiency, and projected\n35% cost savings, resulting in a 2-month acceleration of go-live.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u667a\u80fd\u4f53\u589e\u5f3a\u68c0\u7d22\u751f\u6210\uff08Agentic RAG\uff09\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u81ea\u4e3bAI\u667a\u80fd\u4f53\u4e0e\u5411\u91cf-\u56fe\u6df7\u5408\u77e5\u8bc6\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u5de5\u4ef6\u751f\u6210\u7684\u51c6\u786e\u6027\u4e0e\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u6d4b\u8bd5\u5b58\u5728\u6548\u7387\u4f4e\u3001\u6210\u672c\u9ad8\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u4f5c\u8005\u65e8\u5728\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u5347\u8d28\u91cf\u5de5\u7a0b\u4e2d\u6d4b\u8bd5\u8ba1\u5212\u3001\u7528\u4f8b\u548c\u6307\u6807\u751f\u6210\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "method": "\u91c7\u7528Agentic RAG\u67b6\u6784\uff0c\u6574\u5408Gemini\u548cMistral\u7b49\u5927\u8bed\u8a00\u6a21\u578b\u3001\u591a\u667a\u80fd\u4f53\u534f\u540c\u673a\u5236\u4ee5\u53ca\u5411\u91cf-\u56fe\u6df7\u5408\u77e5\u8bc6\u5e93\uff0c\u5b9e\u73b0\u6d4b\u8bd5\u5de5\u4ef6\u7684\u81ea\u52a8\u751f\u6210\u4e0e\u5168\u751f\u547d\u5468\u671f\u8ffd\u6eaf\u3002", "result": "\u7cfb\u7edf\u5c06\u6d4b\u8bd5\u51c6\u786e\u6027\u4ece65%\u63d0\u5347\u81f394.8%\uff0c\u5728\u4f01\u4e1a\u7ea7\u7cfb\u7edf\u5de5\u7a0b\u548cSAP\u8fc1\u79fb\u9879\u76ee\u4e2d\u5b9e\u73b0\u6d4b\u8bd5\u5468\u671f\u7f29\u77ed85%\u3001\u6d4b\u8bd5\u5957\u4ef6\u6548\u7387\u63d0\u534785%\u3001\u9884\u8ba1\u8282\u770135%\u6210\u672c\uff0c\u5e76\u4f7f\u4e0a\u7ebf\u65f6\u95f4\u63d0\u524d2\u4e2a\u6708\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u514b\u670d\u4e86\u4f20\u7edf\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u3001\u51c6\u786e\u6027\u4e0e\u7ecf\u6d4e\u6548\u76ca\uff0c\u5177\u6709\u826f\u597d\u7684\u5de5\u7a0b\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2510.10840", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10840", "abs": "https://arxiv.org/abs/2510.10840", "authors": ["Seshu Barma", "Mohanakrishnan Hariharan", "Satish Arvapalli"], "title": "Software Defect Prediction using Autoencoder Transformer Model", "comment": null, "summary": "An AI-ML-powered quality engineering approach uses AI-ML to enhance software\nquality assessments by predicting defects. Existing ML models struggle with\nnoisy data types, imbalances, pattern recognition, feature extraction, and\ngeneralization. To address these challenges, we develop a new model, Adaptive\nDifferential Evolution (ADE) based Quantum Variational Autoencoder-Transformer\n(QVAET) Model (ADE-QVAET). ADE combines with QVAET to obtain high-dimensional\nlatent features and maintain sequential dependencies, resulting in enhanced\ndefect prediction accuracy. ADE optimization enhances model convergence and\npredictive performance. ADE-QVAET integrates AI-ML techniques such as tuning\nhyperparameters for scalable and accurate software defect prediction,\nrepresenting an AI-ML-driven technology for quality engineering. During\ntraining with a 90% training percentage, ADE-QVAET achieves high accuracy,\nprecision, recall, and F1-score of 98.08%, 92.45%, 94.67%, and 98.12%,\nrespectively, when compared to the Differential Evolution (DE) ML model.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aADE-QVAET\u7684\u65b0\u6a21\u578b\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u5dee\u5206\u8fdb\u5316\uff08ADE\uff09\u4e0e\u91cf\u5b50\u53d8\u5206\u81ea\u7f16\u7801\u5668-Transformer\uff08QVAET\uff09\uff0c\u4ee5\u63d0\u5347\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u566a\u58f0\u6570\u636e\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u3001\u6a21\u5f0f\u8bc6\u522b\u3001\u7279\u5f81\u63d0\u53d6\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u7684AI-ML\u65b9\u6cd5\u6765\u63d0\u5347\u8f6f\u4ef6\u8d28\u91cf\u5de5\u7a0b\u4e2d\u7684\u7f3a\u9677\u9884\u6d4b\u80fd\u529b\u3002", "method": "\u63d0\u51faADE-QVAET\u6a21\u578b\uff0c\u5c06\u81ea\u9002\u5e94\u5dee\u5206\u8fdb\u5316\u7b97\u6cd5\u4e0e\u91cf\u5b50\u53d8\u5206\u81ea\u7f16\u7801\u5668-Transformer\u7ed3\u5408\uff0c\u7528\u4e8e\u63d0\u53d6\u9ad8\u7ef4\u6f5c\u5728\u7279\u5f81\u3001\u4fdd\u6301\u5e8f\u5217\u4f9d\u8d56\u6027\uff0c\u5e76\u901a\u8fc7\u8d85\u53c2\u6570\u8c03\u4f18\u4f18\u5316\u6a21\u578b\u6536\u655b\u6027\u4e0e\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u572890%\u8bad\u7ec3\u6570\u636e\u6bd4\u4f8b\u4e0b\uff0cADE-QVAET\u5728\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u4e0a\u5206\u522b\u8fbe\u523098.08%\u300192.45%\u300194.67%\u548c98.12%\uff0c\u4f18\u4e8e\u4f20\u7edf\u5dee\u5206\u8fdb\u5316\uff08DE\uff09\u6a21\u578b\u3002", "conclusion": "ADE-QVAET\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86AI-ML\u9a71\u52a8\u7684\u8d28\u91cf\u5de5\u7a0b\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.10887", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10887", "abs": "https://arxiv.org/abs/2510.10887", "authors": ["Lakshana Iruni Assalaarachchi", "Zainab Masood", "Rashina Hoda", "John Grundy"], "title": "Generative AI for Software Project Management: Insights from a Review of Software Practitioner Literature", "comment": null, "summary": "Software practitioners are discussing GenAI transformations in software\nproject management openly and widely. To understand the state of affairs, we\nperformed a grey literature review using 47 publicly available practitioner\nsources including blogs, articles, and industry reports. We found that software\nproject managers primarily perceive GenAI as an \"assistant\", \"copilot\", or\n\"friend\" rather than as a \"PM replacement\", with support of GenAI in automating\nroutine tasks, predictive analytics, communication and collaboration, and in\nagile practices leading to project success. Practitioners emphasize responsible\nGenAI usage given concerns such as hallucinations, ethics and privacy, and lack\nof emotional intelligence and human judgment. We present upskilling\nrequirements for software project managers in the GenAI era mapped to the\nProject Management Institute's talent triangle. We share key recommendations\nfor both practitioners and researchers.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7070\u6587\u732e\u7efc\u8ff0\u5206\u6790\u4e8647\u4efd\u4ece\u4e1a\u8005\u8d44\u6599\uff0c\u63a2\u8ba8\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5728\u8f6f\u4ef6\u9879\u76ee\u7ba1\u7406\u4e2d\u7684\u89d2\u8272\u3001\u5f71\u54cd\u4e0e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u9762\u5411\u9879\u76ee\u7ba1\u7406\u4eba\u624d\u4e09\u89d2\u7684\u6280\u80fd\u63d0\u5347\u5efa\u8bae\u3002", "motivation": "\u4e86\u89e3\u8f6f\u4ef6\u4ece\u4e1a\u8005\u5982\u4f55\u770b\u5f85\u548c\u5e94\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5728\u8f6f\u4ef6\u9879\u76ee\u7ba1\u7406\u4e2d\u7684\u8f6c\u578b\uff0c\u8bc6\u522b\u5176\u4ef7\u503c\u3001\u6311\u6218\u53ca\u5bf9\u4ece\u4e1a\u8005\u80fd\u529b\u7684\u65b0\u8981\u6c42\u3002", "method": "\u91c7\u7528\u7070\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u679047\u4efd\u516c\u5f00\u7684\u4ece\u4e1a\u8005\u8d44\u6599\uff08\u5982\u535a\u5ba2\u3001\u6587\u7ae0\u548c\u884c\u4e1a\u62a5\u544a\uff09\uff0c\u5f52\u7eb3GenAI\u5728\u8f6f\u4ef6\u9879\u76ee\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u4e0e\u89c2\u70b9\u3002", "result": "\u4ece\u4e1a\u8005\u666e\u904d\u5c06GenAI\u89c6\u4e3a\u201c\u52a9\u624b\u201d\u3001\u201c\u526f\u9a7e\u9a76\u201d\u6216\u201c\u670b\u53cb\u201d\uff0c\u800c\u975e\u9879\u76ee\u7ecf\u7406\u7684\u66ff\u4ee3\u8005\uff1bGenAI\u5728\u81ea\u52a8\u5316\u5e38\u89c4\u4efb\u52a1\u3001\u9884\u6d4b\u5206\u6790\u3001\u6c9f\u901a\u534f\u4f5c\u53ca\u654f\u6377\u5b9e\u8df5\u4e2d\u52a9\u529b\u9879\u76ee\u6210\u529f\uff0c\u4f46\u4e5f\u5b58\u5728\u5e7b\u89c9\u3001\u4f26\u7406\u9690\u79c1\u3001\u7f3a\u4e4f\u60c5\u611f\u667a\u80fd\u7b49\u95ee\u9898\uff1b\u7814\u7a76\u63d0\u51fa\u4e86\u4e0ePMI\u4eba\u624d\u4e09\u89d2\u5bf9\u5e94\u7684\u6280\u80fd\u63d0\u5347\u65b9\u5411\u3002", "conclusion": "GenAI\u6b63\u5728\u91cd\u5851\u8f6f\u4ef6\u9879\u76ee\u7ba1\u7406\u5b9e\u8df5\uff0c\u9700\u5728\u53d1\u6325\u5176\u8f85\u52a9\u4ef7\u503c\u7684\u540c\u65f6\u5173\u6ce8\u4f26\u7406\u4e0e\u80fd\u529b\u9002\u914d\uff0c\u9879\u76ee\u7ba1\u7406\u8005\u5e94\u4e3b\u52a8\u63d0\u5347\u76f8\u5173\u6280\u80fd\uff0c\u7814\u7a76\u8005\u4e0e\u4ece\u4e1a\u8005\u5e94\u534f\u540c\u63a8\u8fdb\u8d1f\u8d23\u4efb\u7684GenAI\u5e94\u7528\u3002"}}
{"id": "2510.10956", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.10956", "abs": "https://arxiv.org/abs/2510.10956", "authors": ["Zhiqiang Yuan", "Wenjun Mao", "Zhuo Chen", "Xiyue Shang", "Chong Wang", "Yiling Lou", "Xin Peng"], "title": "Project-Level C-to-Rust Translation via Synergistic Integration of Knowledge Graphs and Large Language Models", "comment": null, "summary": "Translating C code into safe Rust is an effective way to ensure its memory\nsafety. Compared to rule-based translation which produces Rust code that\nremains largely unsafe, LLM-based methods can generate more idiomatic and safer\nRust code because LLMs have been trained on vast amount of human-written\nidiomatic code. Although promising, existing LLM-based methods still struggle\nwith project-level C-to-Rust translation. They typically partition a C project\ninto smaller units (\\eg{} functions) based on call graphs and translate them\nbottom-up to resolve program dependencies. However, this bottom-up,\nunit-by-unit paradigm often fails to translate pointers due to the lack of a\nglobal perspective on their usage. To address this problem, we propose a novel\nC-Rust Pointer Knowledge Graph (KG) that enriches a code-dependency graph with\ntwo types of pointer semantics: (i) pointer-usage information which record\nglobal behaviors such as points-to flows and map lower-level struct usage to\nhigher-level units; and (ii) Rust-oriented annotations which encode ownership,\nmutability, nullability, and lifetime. Synthesizing the \\kg{} with LLMs, we\nfurther propose \\ourtool{}, which implements a project-level C-to-Rust\ntranslation technique. In \\ourtool{}, the \\kg{} provides LLMs with\ncomprehensive pointer semantics from a global perspective, thus guiding LLMs\ntowards generating safe and idiomatic Rust code from a given C project. Our\nexperiments show that \\ourtool{} reduces unsafe usages in translated Rust by\n99.9\\% compared to both rule-based translation and traditional LLM-based\nrewriting, while achieving an average 29.3\\% higher functional correctness than\nthose fuzzing-enhanced LLM methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6307\u9488\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u9879\u76ee\u7ea7C\u5230Rust\u7ffb\u8bd1\u65b9\u6cd5\uff08\\ourtool{}\uff09\uff0c\u901a\u8fc7\u5728\u4ee3\u7801\u4f9d\u8d56\u56fe\u4e2d\u5f15\u5165\u5168\u5c40\u6307\u9488\u8bed\u4e49\uff08\u5982\u6307\u5411\u5173\u7cfb\u3001\u6240\u6709\u6743\u3001\u53ef\u53d8\u6027\u7b49\uff09\uff0c\u663e\u8457\u51cf\u5c11\u751f\u6210Rust\u4ee3\u7801\u4e2d\u7684unsafe\u7528\u6cd5\uff0c\u5e76\u63d0\u5347\u529f\u80fd\u6b63\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684C\u5230Rust\u7ffb\u8bd1\u65b9\u6cd5\u5728\u9879\u76ee\u7ea7\u522b\u4e0a\u96be\u4ee5\u6b63\u786e\u5904\u7406\u6307\u9488\uff0c\u56e0\u5176\u91c7\u7528\u81ea\u5e95\u5411\u4e0a\u7684\u5355\u5143\u7ffb\u8bd1\u7b56\u7565\uff0c\u7f3a\u4e4f\u5bf9\u6307\u9488\u5168\u5c40\u4f7f\u7528\u60c5\u51b5\u7684\u628a\u63e1\uff0c\u5bfc\u81f4\u751f\u6210\u7684Rust\u4ee3\u7801\u4ecd\u5305\u542b\u5927\u91cfunsafe\u5757\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2aC-Rust\u6307\u9488\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\uff0c\u5728\u4f20\u7edf\u8c03\u7528\u56fe\u57fa\u7840\u4e0a\u589e\u52a0\u4e24\u7c7b\u6307\u9488\u8bed\u4e49\u4fe1\u606f\uff1a\uff08i\uff09\u8bb0\u5f55\u5168\u5c40\u6307\u9488\u884c\u4e3a\uff08\u5982\u6307\u5411\u6d41\u3001\u7ed3\u6784\u4f53\u4f7f\u7528\u6620\u5c04\uff09\uff1b\uff08ii\uff09\u6807\u6ce8Rust\u76f8\u5173\u5c5e\u6027\uff08\u5982\u6240\u6709\u6743\u3001\u53ef\u53d8\u6027\u3001\u53ef\u7a7a\u6027\u3001\u751f\u547d\u5468\u671f\uff09\u3002\u8be5KG\u4e0eLLM\u7ed3\u5408\uff0c\u7528\u4e8e\u6307\u5bfc\u9879\u76ee\u7ea7C\u4ee3\u7801\u7ffb\u8bd1\u4e3a\u5b89\u5168\u4e14\u7b26\u5408Rust\u60ef\u7528\u6cd5\u7684\u4ee3\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\\ourtool{}\u76f8\u6bd4\u57fa\u4e8e\u89c4\u5219\u548c\u4f20\u7edfLLM\u7684\u65b9\u6cd5\uff0c\u5c06\u7ffb\u8bd1\u540eRust\u4ee3\u7801\u4e2d\u7684unsafe\u4f7f\u7528\u51cf\u5c11\u4e8699.9%\uff0c\u5e76\u5728\u529f\u80fd\u6b63\u786e\u6027\u4e0a\u5e73\u5747\u9ad8\u51fa29.3%\uff08\u5bf9\u6bd4\u7ed3\u5408\u6a21\u7cca\u6d4b\u8bd5\u7684LLM\u65b9\u6cd5\uff09\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5168\u5c40\u6307\u9488\u8bed\u4e49\u77e5\u8bc6\u56fe\u8c31\uff0c\\ourtool{}\u6709\u6548\u89e3\u51b3\u4e86\u9879\u76ee\u7ea7C\u5230Rust\u7ffb\u8bd1\u4e2d\u6307\u9488\u5904\u7406\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u4e0e\u6b63\u786e\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u9057\u7559C\u4ee3\u7801\u8fc1\u79fb\u81f3Rust\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.11039", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.11039", "abs": "https://arxiv.org/abs/2510.11039", "authors": ["Yifeng Zhu", "Xianlin Zhao", "Xutian Li", "Yanzhen Zou", "Haizhuo Yuan", "Yue Wang", "Bing Xie"], "title": "RepoSummary: Feature-Oriented Summarization and Documentation Generation for Code Repositories", "comment": null, "summary": "Repository summarization is a crucial research question in development and\nmaintenance for software engineering. Existing repository summarization\ntechniques primarily focus on summarizing code according to the directory tree,\nwhich is insufficient for tracing high-level features to the methods that\ncollaboratively implement them. To address these limitations, we propose\nRepoSummary, a feature-oriented code repository summarization approach that\nsimultaneously generates repository documentation automatically. Furthermore,\nit establishes more accurate traceability links from functional features to the\ncorresponding code elements, enabling developers to rapidly locate relevant\nmethods and files during code comprehension and maintenance. Comprehensive\nexperiments against the state-of-the-art baseline (HGEN) demonstrate that\nRepoSummary achieves higher feature coverage and more accurate traceability. On\naverage, it increases the rate of completely covered features in manual\ndocumentation from 61.2% to 71.1%, improves file-level traceability recall from\n29.9% to 53.0%, and generates documentation that is more conceptually\nconsistent, easier to understand, and better formatted than that produced by\nexisting approaches.", "AI": {"tldr": "RepoSummary \u662f\u4e00\u79cd\u9762\u5411\u529f\u80fd\u7684\u4ee3\u7801\u4ed3\u5e93\u6458\u8981\u65b9\u6cd5\uff0c\u80fd\u81ea\u52a8\u751f\u6210\u6587\u6863\u5e76\u5efa\u7acb\u4ece\u529f\u80fd\u5230\u4ee3\u7801\u5143\u7d20\u7684\u51c6\u786e\u8ffd\u6eaf\u94fe\u63a5\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u4ed3\u5e93\u6458\u8981\u6280\u672f\u4e3b\u8981\u57fa\u4e8e\u76ee\u5f55\u6811\u5bf9\u4ee3\u7801\u8fdb\u884c\u6458\u8981\uff0c\u96be\u4ee5\u5c06\u9ad8\u5c42\u529f\u80fd\u8ffd\u6eaf\u5230\u534f\u540c\u5b9e\u73b0\u8fd9\u4e9b\u529f\u80fd\u7684\u5177\u4f53\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa RepoSummary \u65b9\u6cd5\uff0c\u9762\u5411\u529f\u80fd\u8fdb\u884c\u4ee3\u7801\u4ed3\u5e93\u6458\u8981\uff0c\u540c\u65f6\u81ea\u52a8\u751f\u6210\u4ed3\u5e93\u6587\u6863\uff0c\u5e76\u5efa\u7acb\u4ece\u529f\u80fd\u5230\u4ee3\u7801\u5143\u7d20\u7684\u51c6\u786e\u8ffd\u6eaf\u94fe\u63a5\u3002", "result": "\u4e0e\u5f53\u524d\u6700\u4f18\u57fa\u7ebf HGEN \u76f8\u6bd4\uff0cRepoSummary \u5728\u529f\u80fd\u8986\u76d6\u7387\u548c\u8ffd\u6eaf\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff1a\u624b\u52a8\u6587\u6863\u4e2d\u5b8c\u5168\u8986\u76d6\u7684\u529f\u80fd\u6bd4\u4f8b\u4ece 61.2% \u63d0\u5347\u81f3 71.1%\uff0c\u6587\u4ef6\u7ea7\u8ffd\u6eaf\u53ec\u56de\u7387\u4ece 29.9% \u63d0\u5347\u81f3 53.0%\uff0c\u751f\u6210\u7684\u6587\u6863\u5728\u6982\u5ff5\u4e00\u81f4\u6027\u3001\u53ef\u8bfb\u6027\u548c\u683c\u5f0f\u65b9\u9762\u4e5f\u66f4\u4f18\u3002", "conclusion": "RepoSummary \u80fd\u6709\u6548\u63d0\u5347\u4ee3\u7801\u4ed3\u5e93\u6458\u8981\u7684\u529f\u80fd\u8986\u76d6\u548c\u8ffd\u6eaf\u80fd\u529b\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u5728\u4ee3\u7801\u7406\u89e3\u548c\u7ef4\u62a4\u8fc7\u7a0b\u4e2d\u5feb\u901f\u5b9a\u4f4d\u76f8\u5173\u4ee3\u7801\u3002"}}
{"id": "2510.11059", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.11059", "abs": "https://arxiv.org/abs/2510.11059", "authors": ["Jian Wang", "Xiaofei Xie", "Qiang Hu", "Shangqing Liu", "Jiongchi Yu", "Jiaolong Klong", "Yi Li"], "title": "Defects4C: Benchmarking Large Language Model Repair Capability with C/C++ Bugs", "comment": "ASE-2025 main research paper", "summary": "Automated Program Repair (APR) plays a critical role in enhancing the quality\nand reliability of software systems. While substantial progress has been made\nin Java-based APR, largely facilitated by benchmarks like Defects4J, there\nremains a significant gap in research on C/C++ program repair, despite the\nwidespread use of C/C++ and the prevalence of associated vulnerabilities. This\ngap is primarily due to the lack of high-quality, open-source benchmarks\ntailored for C/C++.\n  To address this issue, we introduce Defects4C, a comprehensive and executable\nbenchmark specifically designed for C/C++ program repair. Our dataset is\nconstructed from real-world C/C++ repositories and includes a large collection\nof bug-relevant commits (9M in total), 248 high-quality buggy functions, and\n102 vulnerable functions, all paired with test cases for reproduction. These\nresources enable rigorous evaluation of repair techniques and support the\nretraining of learning-based approaches for enhanced performance.\n  Using Defects4C, we conduct a comprehensive empirical study evaluating the\neffectiveness of 24 state-of-the-art large language models (LLMs) in repairing\nC/C++ faults. Our findings offer valuable insights into the strengths and\nlimitations of current LLM-based APR techniques in this domain, highlighting\nboth the need for more robust methods and the critical role of Defects4C in\nadvancing future research", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86 Defects4C\u2014\u2014\u4e00\u4e2a\u4e13\u4e3a C/C++ \u7a0b\u5e8f\u4fee\u590d\u8bbe\u8ba1\u7684\u9ad8\u8d28\u91cf\u53ef\u6267\u884c\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8e\u8be5\u6570\u636e\u96c6\u5bf9 24 \u4e2a\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728 C/C++ \u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002", "motivation": "\u5c3d\u7ba1 C/C++ \u88ab\u5e7f\u6cdb\u4f7f\u7528\u4e14\u76f8\u5173\u6f0f\u6d1e\u9891\u53d1\uff0c\u4f46\u5176\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u7814\u7a76\u8fdc\u843d\u540e\u4e8e Java\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u3001\u5f00\u6e90\u7684 C/C++ \u4fee\u590d\u57fa\u51c6\u3002", "method": "\u6784\u5efa Defects4C \u57fa\u51c6\uff0c\u5305\u542b\u6765\u81ea\u771f\u5b9e C/C++ \u9879\u76ee\u7684 900 \u4e07 bug \u76f8\u5173\u63d0\u4ea4\u3001248 \u4e2a\u9ad8\u8d28\u91cf\u7f3a\u9677\u51fd\u6570\u548c 102 \u4e2a\u6f0f\u6d1e\u51fd\u6570\uff0c\u5e76\u914d\u5907\u53ef\u590d\u73b0\u7684\u6d4b\u8bd5\u7528\u4f8b\uff1b\u968f\u540e\u5229\u7528\u8be5\u57fa\u51c6\u5bf9 24 \u4e2a\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4fee\u590d\u80fd\u529b\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e86\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728 C/C++ \u7a0b\u5e8f\u4fee\u590d\u4e2d\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\uff0c\u9a8c\u8bc1\u4e86 Defects4C \u5bf9\u8bc4\u4f30\u548c\u63a8\u52a8 APR \u6280\u672f\u53d1\u5c55\u7684\u6709\u6548\u6027\u3002", "conclusion": "Defects4C \u586b\u8865\u4e86 C/C++ \u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u9886\u57df\u57fa\u51c6\u7f3a\u5931\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765 APR \u65b9\u6cd5\u7684\u5f00\u53d1\u4e0e\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5173\u952e\u57fa\u7840\u8bbe\u65bd\uff0c\u5e76\u6307\u51fa\u4e86\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2510.11076", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.11076", "abs": "https://arxiv.org/abs/2510.11076", "authors": ["Lingyue Fu", "Haowei Yuan", "Datong Chen", "Xinyi Dai", "Qingyao Li", "Weinan Zhang", "Weiwen Liu", "Yong Yu"], "title": "DebugTA: An LLM-Based Agent for Simplifying Debugging and Teaching in Programming Education", "comment": null, "summary": "In programming education, Debugging and Teaching (DT) task is a common\nscenario where students receive assistance in correcting their erroneous code.\nThe task involves multiple inputs, including erroneous code, error messages,\nreference solutions, and the question description, with the goal of generating\nmodification suggestions to the erroneous code. However, two key challenges\nhinder the effectiveness of existing approaches. Firstly, the complexity and\nheterogeneity of inputs inherent in DT tasks significantly elevate the\nreasoning challenges faced by LLMs. Second, existing approaches often fail to\nfully leverage the availability of standard code in DT tasks, forcing models to\nrely solely on complex multi-step reasoning, which limits the potential of LLMs\nin addressing DT tasks effectively. To address these challenges, we propose\nDebugTA, a novel LLM-based debugging and teaching agent with specialized tools\nfor standard code retrieval, variable substitution to align reference code, and\nan external compiler for real-time code analysis. Guided by explicit\npedagogical and debugging principles, DebugTA acts as an agent that decomposes\na complex task into sequential LLM interactions, each utilizing distinct tools\nfor specific subtasks, thereby simplifying the logical reasoning at each step\nand reducing overall reasoning complexity. Furthermore, DebugTA utilizes tool\ncalls to align the standard code with the erroneous code as much as possible,\nallowing the LLM to focus on logic errors within the erroneous code and\nimproving the accuracy of the generated suggestions. To rigorously assess the\nquality of modification suggestions, we introduce a student simulator-teacher\ninteraction paradigm. Experimental results on three real-world code datasets\ndemonstrate that DebugTA consistently improves teaching effectiveness while\nsignificantly reducing computational costs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDebugTA\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8c03\u8bd5\u4e0e\u6559\u5b66\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u4e13\u7528\u5de5\u5177\uff08\u5982\u6807\u51c6\u4ee3\u7801\u68c0\u7d22\u3001\u53d8\u91cf\u66ff\u6362\u548c\u5916\u90e8\u7f16\u8bd1\u5668\uff09\u7b80\u5316\u590d\u6742\u63a8\u7406\u8fc7\u7a0b\uff0c\u6709\u6548\u63d0\u5347\u7f16\u7a0b\u6559\u80b2\u4e2d\u9519\u8bef\u4ee3\u7801\u4fee\u6539\u5efa\u8bae\u7684\u51c6\u786e\u6027\u548c\u6559\u5b66\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u8c03\u8bd5\u4e0e\u6559\u5b66\uff08DT\uff09\u4efb\u52a1\u65f6\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a\u4e00\u662fDT\u4efb\u52a1\u8f93\u5165\u590d\u6742\u4e14\u5f02\u6784\uff0c\u589e\u52a0\u4e86LLM\u7684\u63a8\u7406\u96be\u5ea6\uff1b\u4e8c\u662f\u672a\u80fd\u5145\u5206\u5229\u7528\u6807\u51c6\u4ee3\u7801\uff0c\u5bfc\u81f4\u6a21\u578b\u4f9d\u8d56\u590d\u6742\u7684\u591a\u6b65\u63a8\u7406\uff0c\u9650\u5236\u4e86LLM\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faDebugTA\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u660e\u786e\u7684\u6559\u5b66\u4e0e\u8c03\u8bd5\u539f\u5219\uff0c\u5c06\u590d\u6742\u4efb\u52a1\u5206\u89e3\u4e3a\u591a\u4e2a\u5b50\u4efb\u52a1\uff0c\u901a\u8fc7\u4f9d\u6b21\u8c03\u7528\u4e13\u7528\u5de5\u5177\uff08\u5305\u62ec\u6807\u51c6\u4ee3\u7801\u68c0\u7d22\u3001\u53d8\u91cf\u66ff\u6362\u5bf9\u9f50\u53c2\u8003\u4ee3\u7801\u3001\u5916\u90e8\u7f16\u8bd1\u5668\u5b9e\u65f6\u5206\u6790\uff09\u8fdb\u884c\u5206\u6b65\u63a8\u7406\uff0c\u5e76\u5f15\u5165\u5b66\u751f\u6a21\u62df\u5668-\u6559\u5e08\u4ea4\u4e92\u8303\u5f0f\u8bc4\u4f30\u4fee\u6539\u5efa\u8bae\u8d28\u91cf\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u4ee3\u7801\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDebugTA\u5728\u63d0\u5347\u6559\u5b66\u6548\u679c\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "DebugTA\u901a\u8fc7\u5de5\u5177\u8c03\u7528\u4e0e\u4efb\u52a1\u5206\u89e3\u6709\u6548\u7f13\u89e3\u4e86LLM\u5728DT\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u8d1f\u62c5\uff0c\u63d0\u9ad8\u4e86\u4fee\u6539\u5efa\u8bae\u7684\u51c6\u786e\u6027\u4e0e\u6559\u5b66\u6548\u7387\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u7f16\u7a0b\u6559\u80b2\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.11138", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2510.11138", "abs": "https://arxiv.org/abs/2510.11138", "authors": ["Zitao Wang", "Zhimin Zhao", "Michael W. Godfrey"], "title": "What Slows Down FMware Development? An Empirical Study of Developer Challenges and Resolution Times", "comment": null, "summary": "Foundation Models (FMs), such as OpenAI's GPT, are fundamentally transforming\nthe practice of software engineering by enabling the development of\n\\emph{FMware} -- applications and infrastructures built around these models.\nFMware systems now support tasks such as code generation, natural-language\ninteraction, knowledge integration, and multi-modal content creation,\nunderscoring their disruptive impact on current software engineering workflows.\nHowever, the design, implementation, and evolution of FMware present\nsignificant new challenges, particularly across cloud-based and on-premise\nplatforms where goals, processes, and tools often diverge from those of\ntraditional software development.\n  To our knowledge, this is the first large-scale analysis of FMware\ndevelopment across both cloud-based platforms and open-source repositories. We\nempirically investigate the FMware ecosystem through three focus areas: (1) the\nmost common application domains of FMware, (2) the key challenges developers\nencounter, and (3) the types of issues that demand the greatest effort to\nresolve. Our analysis draws on data from GitHub repositories and from leading\nFMware platforms, including HuggingFace, GPTStore, Ora, and Poe. Our findings\nreveal a strong focus on education, content creation, and business strategy,\nalongside persistent technical challenges in memory management, dependency\nhandling, and tokenizer configuration. On GitHub, bug reports and core\nfunctionality issues are the most frequently reported problems, while code\nreview, similarity search, and prompt template design are the most\ntime-consuming to resolve.\n  By uncovering developer practices and pain points, this study points to\nopportunities to improve FMware tools, workflows, and community support, and\nprovides actionable insights to help guide the future of FMware development.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u4e91\u5e73\u53f0\u548c\u5f00\u6e90\u4ed3\u5e93\u4e2d\u7684FMware\uff08\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u6784\u5efa\u7684\u8f6f\u4ef6\uff09\u5f00\u53d1\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5176\u4e3b\u6d41\u5e94\u7528\u9886\u57df\u3001\u5f00\u53d1\u8005\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u53ca\u6700\u8017\u65f6\u89e3\u51b3\u7684\u95ee\u9898\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\uff08\u5982GPT\uff09\u6b63\u6df1\u523b\u6539\u53d8\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff0c\u50ac\u751f\u4e86FMware\u8fd9\u4e00\u65b0\u578b\u8f6f\u4ef6\u5f62\u6001\u3002\u7136\u800c\uff0cFMware\u5728\u8bbe\u8ba1\u3001\u5b9e\u73b0\u548c\u6f14\u8fdb\u8fc7\u7a0b\u4e2d\u5e26\u6765\u4e86\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u672a\u66fe\u9762\u5bf9\u7684\u65b0\u6311\u6218\uff0c\u5c24\u5176\u5728\u4e91\u5e73\u53f0\u4e0e\u672c\u5730\u90e8\u7f72\u73af\u5883\u4e2d\u5dee\u5f02\u663e\u8457\uff0c\u4e9f\u9700\u7cfb\u7edf\u6027\u7814\u7a76\u4ee5\u7406\u89e3\u5176\u5f00\u53d1\u751f\u6001\u4e0e\u75db\u70b9\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790GitHub\u5f00\u6e90\u4ed3\u5e93\u53caHuggingFace\u3001GPTStore\u3001Ora\u548cPoe\u7b49\u4e3b\u6d41FMware\u5e73\u53f0\u7684\u6570\u636e\uff0c\u805a\u7126\u4e09\u5927\u65b9\u5411\uff1aFMware\u7684\u5e38\u89c1\u5e94\u7528\u9886\u57df\u3001\u5f00\u53d1\u8005\u9047\u5230\u7684\u4e3b\u8981\u6311\u6218\uff0c\u4ee5\u53ca\u6700\u8017\u8d39\u7cbe\u529b\u89e3\u51b3\u7684\u95ee\u9898\u7c7b\u578b\u3002", "result": "\u7814\u7a76\u53d1\u73b0FMware\u4e3b\u8981\u5e94\u7528\u4e8e\u6559\u80b2\u3001\u5185\u5bb9\u521b\u4f5c\u548c\u5546\u4e1a\u7b56\u7565\u9886\u57df\uff1b\u6280\u672f\u5c42\u9762\u666e\u904d\u5b58\u5728\u5185\u5b58\u7ba1\u7406\u3001\u4f9d\u8d56\u5904\u7406\u548c\u5206\u8bcd\u5668\u914d\u7f6e\u7b49\u96be\u9898\uff1bGitHub\u4e0a\u6700\u5e38\u89c1\u7684\u95ee\u9898\u662f\u7f3a\u9677\u62a5\u544a\u548c\u6838\u5fc3\u529f\u80fd\u95ee\u9898\uff0c\u800c\u4ee3\u7801\u5ba1\u67e5\u3001\u76f8\u4f3c\u6027\u641c\u7d22\u548c\u63d0\u793a\u6a21\u677f\u8bbe\u8ba1\u6700\u8017\u65f6\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86FMware\u5f00\u53d1\u8005\u7684\u5b9e\u8df5\u6a21\u5f0f\u4e0e\u75db\u70b9\uff0c\u4e3a\u6539\u8fdbFMware\u5f00\u53d1\u5de5\u5177\u3001\u4f18\u5316\u5de5\u4f5c\u6d41\u53ca\u52a0\u5f3a\u793e\u533a\u652f\u6301\u63d0\u4f9b\u4e86\u4f9d\u636e\uff0c\u5e76\u4e3aFMware\u7684\u672a\u6765\u53d1\u5c55\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6d1e\u89c1\u3002"}}
{"id": "2510.11179", "categories": ["cs.SE", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2510.11179", "abs": "https://arxiv.org/abs/2510.11179", "authors": ["David Georg Reichelt", "Shinhyung Yang", "Wilhelm Hasselbring"], "title": "Interoperability From OpenTelemetry to Kieker: Demonstrated as Export from the Astronomy Shop", "comment": "Accepted for publication in Symposium on Software Performance 2025", "summary": "The observability framework Kieker provides a range of analysis capabilities,\nbut it is currently only able to instrument a smaller selection of languages\nand technologies, including Java, C, Fortran, and Python. The OpenTelemetry\nstandard aims for providing reference implementations for most programming\nlanguages, including C# and JavaScript, that are currently not supported by\nKieker. In this work, we describe how to transform OpenTelemetry tracing data\ninto the Kieker framework. Thereby, it becomes possible to create for example\ncall trees from OpenTelemetry instrumentations. We demonstrate the usability of\nour approach by visualizing trace data of the Astronomy Shop, which is an\nOpenTelemetry demo application.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06OpenTelemetry\u8ffd\u8e2a\u6570\u636e\u8f6c\u6362\u4e3aKieker\u6846\u67b6\u683c\u5f0f\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u6269\u5c55Kieker\u5bf9C#\u3001JavaScript\u7b49\u8bed\u8a00\u7684\u652f\u6301\uff0c\u5e76\u901a\u8fc7Astronomy Shop\u793a\u4f8b\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u3002", "motivation": "Kieker\u5f53\u524d\u4ec5\u652f\u6301\u6709\u9650\u7684\u7f16\u7a0b\u8bed\u8a00\uff08\u5982Java\u3001C\u3001Fortran\u548cPython\uff09\uff0c\u800cOpenTelemetry\u63d0\u4f9b\u4e86\u5bf9\u66f4\u591a\u8bed\u8a00\uff08\u5982C#\u548cJavaScript\uff09\u7684\u8ffd\u8e2a\u652f\u6301\u3002\u4e3a\u5229\u7528Kieker\u7684\u5206\u6790\u80fd\u529b\u5904\u7406\u8fd9\u4e9b\u8bed\u8a00\u7684\u8ffd\u8e2a\u6570\u636e\uff0c\u9700\u5b9e\u73b0OpenTelemetry\u5230Kieker\u7684\u6570\u636e\u8f6c\u6362\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u79cd\u5c06OpenTelemetry\u751f\u6210\u7684\u8ffd\u8e2a\u6570\u636e\u8f6c\u6362\u4e3aKieker\u6846\u67b6\u53ef\u5904\u7406\u683c\u5f0f\u7684\u65b9\u6cd5\uff0c\u4f7f\u5f97Kieker\u80fd\u591f\u5bf9\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u5206\u6790\uff08\u5982\u751f\u6210\u8c03\u7528\u6811\uff09\u3002", "result": "\u6210\u529f\u5c06OpenTelemetry\u7684\u8ffd\u8e2a\u6570\u636e\u8f6c\u6362\u4e3aKieker\u683c\u5f0f\uff0c\u5e76\u5728Astronomy Shop\u8fd9\u4e00OpenTelemetry\u6f14\u793a\u5e94\u7528\u4e2d\u5b9e\u73b0\u4e86\u8ffd\u8e2a\u6570\u636e\u7684\u53ef\u89c6\u5316\u3002", "conclusion": "\u901a\u8fc7\u5c06OpenTelemetry\u4e0eKieker\u96c6\u6210\uff0c\u6269\u5c55\u4e86Kieker\u5bf9\u591a\u8bed\u8a00\u8ffd\u8e2a\u6570\u636e\u7684\u652f\u6301\uff0c\u589e\u5f3a\u4e86\u5176\u5728\u5f02\u6784\u7cfb\u7edf\u4e2d\u7684\u53ef\u89c2\u6d4b\u6027\u5206\u6790\u80fd\u529b\u3002"}}
{"id": "2510.11516", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11516", "abs": "https://arxiv.org/abs/2510.11516", "authors": ["Jeena Javahar", "Tanya Budhrani", "Manaal Basha", "Cleidson R. B. de Souza", "Ivan Beschastnikh", "Gema Rodriguez-Perez"], "title": "Cracking CodeWhisperer: Analyzing Developers' Interactions and Patterns During Programming Tasks", "comment": "VL/HCC 2025 Short Paper", "summary": "The use of AI code-generation tools is becoming increasingly common, making\nit important to understand how software developers are adopting these tools. In\nthis study, we investigate how developers engage with Amazon's CodeWhisperer,\nan LLM-based code-generation tool. We conducted two user studies with two\ngroups of 10 participants each, interacting with CodeWhisperer - the first to\nunderstand which interactions were critical to capture and the second to\ncollect low-level interaction data using a custom telemetry plugin. Our\nmixed-methods analysis identified four behavioral patterns: 1) incremental code\nrefinement, 2) explicit instruction using natural language comments, 3)\nbaseline structuring with model suggestions, and 4) integrative use with\nexternal sources. We provide a comprehensive analysis of these patterns .", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4e24\u9879\u7528\u6237\u5b9e\u9a8c\uff0c\u5206\u6790\u5f00\u53d1\u8005\u5982\u4f55\u4e0eAI\u4ee3\u7801\u751f\u6210\u5de5\u5177CodeWhisperer\u4e92\u52a8\uff0c\u8bc6\u522b\u51fa\u56db\u79cd\u5178\u578b\u884c\u4e3a\u6a21\u5f0f\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7801\u751f\u6210\u5de5\u5177\u7684\u666e\u53ca\uff0c\u7406\u89e3\u5f00\u53d1\u8005\u5982\u4f55\u5b9e\u9645\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f00\u5c55\u4e24\u8f6e\u7528\u6237\u7814\u7a76\uff0c\u6bcf\u7ec410\u540d\u53c2\u4e0e\u8005\uff0c\u7b2c\u4e00\u8f6e\u786e\u5b9a\u5173\u952e\u4e92\u52a8\u7c7b\u578b\uff0c\u7b2c\u4e8c\u8f6e\u901a\u8fc7\u81ea\u5b9a\u4e49\u9065\u6d4b\u63d2\u4ef6\u6536\u96c6\u4f4e\u5c42\u7ea7\u4ea4\u4e92\u6570\u636e\uff0c\u5e76\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u8fdb\u884c\u5206\u6790\u3002", "result": "\u8bc6\u522b\u51fa\u56db\u79cd\u5f00\u53d1\u8005\u884c\u4e3a\u6a21\u5f0f\uff1a1\uff09\u6e10\u8fdb\u5f0f\u4ee3\u7801\u4f18\u5316\uff0c2\uff09\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u6ce8\u91ca\u8fdb\u884c\u663e\u5f0f\u6307\u4ee4\uff0c3\uff09\u5229\u7528\u6a21\u578b\u5efa\u8bae\u8fdb\u884c\u57fa\u7840\u7ed3\u6784\u642d\u5efa\uff0c4\uff09\u4e0e\u5916\u90e8\u8d44\u6e90\u7ed3\u5408\u4f7f\u7528\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf9\u5f00\u53d1\u8005\u4e0eAI\u4ee3\u7801\u751f\u6210\u5de5\u5177\u4e92\u52a8\u65b9\u5f0f\u7684\u6df1\u5165\u7406\u89e3\uff0c\u63ed\u793a\u4e86\u56db\u79cd\u6838\u5fc3\u4f7f\u7528\u6a21\u5f0f\uff0c\u6709\u52a9\u4e8e\u672a\u6765\u5de5\u5177\u8bbe\u8ba1\u548c\u5f00\u53d1\u8005\u652f\u6301\u7b56\u7565\u7684\u4f18\u5316\u3002"}}
{"id": "2510.11536", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.11536", "abs": "https://arxiv.org/abs/2510.11536", "authors": ["Manaal Basha", "Aime\u00ea M. Ribeiro", "Jeena Javahar", "Cleidson R. B. de Souza", "Gema Rodr\u00edguez-P\u00e9rez"], "title": "CodeWatcher: IDE Telemetry Data Extraction Tool for Understanding Coding Interactions with LLMs", "comment": "ICSME 2025 Tool Demonstration Track", "summary": "Understanding how developers interact with code generation tools (CGTs)\nrequires detailed, real-time data on programming behavior which is often\ndifficult to collect without disrupting workflow. We present\n\\textit{CodeWatcher}, a lightweight, unobtrusive client-server system designed\nto capture fine-grained interaction events from within the Visual Studio Code\n(VS Code) editor. \\textit{CodeWatcher} logs semantically meaningful events such\nas insertions made by CGTs, deletions, copy-paste actions, and focus shifts,\nenabling continuous monitoring of developer activity without modifying user\nworkflows. The system comprises a VS Code plugin, a Python-based RESTful API,\nand a MongoDB backend, all containerized for scalability and ease of\ndeployment. By structuring and timestamping each event, \\textit{CodeWatcher}\nenables post-hoc reconstruction of coding sessions and facilitates rich\nbehavioral analyses, including how and when CGTs are used during development.\nThis infrastructure is crucial for supporting research on responsible AI,\ndeveloper productivity, and the human-centered evaluation of CGTs. Please find\nthe demo, diagrams, and tool here: https://osf.io/j2kru/overview.", "AI": {"tldr": "CodeWatcher \u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u65e0\u5e72\u6270\u7684\u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728 VS Code \u4e2d\u6355\u83b7\u5f00\u53d1\u8005\u4e0e\u4ee3\u7801\u751f\u6210\u5de5\u5177\uff08CGT\uff09\u4ea4\u4e92\u7684\u7ec6\u7c92\u5ea6\u4e8b\u4ef6\uff0c\u652f\u6301\u5bf9\u7f16\u7a0b\u884c\u4e3a\u7684\u6df1\u5165\u7814\u7a76\u3002", "motivation": "\u7814\u7a76\u5f00\u53d1\u8005\u5982\u4f55\u4e0e\u4ee3\u7801\u751f\u6210\u5de5\u5177\u4e92\u52a8\u9700\u8981\u8be6\u7ec6\u4e14\u5b9e\u65f6\u7684\u7f16\u7a0b\u884c\u4e3a\u6570\u636e\uff0c\u4f46\u8fd9\u7c7b\u6570\u636e\u901a\u5e38\u96be\u4ee5\u5728\u4e0d\u5e72\u6270\u5de5\u4f5c\u6d41\u7684\u60c5\u51b5\u4e0b\u6536\u96c6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3a CodeWatcher \u7684\u7cfb\u7edf\uff0c\u5305\u62ec VS Code \u63d2\u4ef6\u3001\u57fa\u4e8e Python \u7684 RESTful API \u548c MongoDB \u540e\u7aef\uff0c\u6240\u6709\u7ec4\u4ef6\u5747\u5bb9\u5668\u5316\uff0c\u7528\u4e8e\u8bb0\u5f55\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u7684\u7f16\u8f91\u4e8b\u4ef6\uff08\u5982 CGT \u63d2\u5165\u3001\u5220\u9664\u3001\u590d\u5236\u7c98\u8d34\u548c\u7126\u70b9\u5207\u6362\uff09\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u4e8b\u4ef6\u6dfb\u52a0\u65f6\u95f4\u6233\u3002", "result": "CodeWatcher \u80fd\u591f\u5728\u4e0d\u6539\u53d8\u7528\u6237\u5de5\u4f5c\u6d41\u7684\u524d\u63d0\u4e0b\u6301\u7eed\u76d1\u63a7\u5f00\u53d1\u8005\u6d3b\u52a8\uff0c\u5e76\u652f\u6301\u5bf9\u7f16\u7801\u4f1a\u8bdd\u7684\u4e8b\u540e\u91cd\u5efa\u548c\u4e30\u5bcc\u7684\u884c\u4e3a\u5206\u6790\uff0c\u7279\u522b\u662f CGT \u7684\u4f7f\u7528\u65f6\u673a\u4e0e\u65b9\u5f0f\u3002", "conclusion": "CodeWatcher \u4e3a\u8d1f\u8d23\u4efb AI\u3001\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u4ee5\u53ca\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684 CGT \u8bc4\u4f30\u7b49\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2510.11658", "categories": ["cs.SE", "97P50", "D.2.5; K.3.2"], "pdf": "https://arxiv.org/pdf/2510.11658", "abs": "https://arxiv.org/abs/2510.11658", "authors": ["Florian Oberm\u00fcller", "Gordon Fraser"], "title": "Automatically Generating Questions About Scratch Programs", "comment": "Accepted at CompEd 2025", "summary": "When learning to program, students are usually assessed based on the code\nthey wrote. However, the mere completion of a programming task does not\nguarantee actual comprehension of the underlying concepts. Asking learners\nquestions about the code they wrote has therefore been proposed as a means to\nassess program comprehension. As creating targeted questions for individual\nstudent programs can be tedious and challenging, prior work has proposed to\ngenerate such questions automatically. In this paper we generalize this idea to\nthe block-based programming language Scratch. We propose a set of 30 different\nquestions for Scratch code covering an established program comprehension model,\nand extend the LitterBox static analysis tool to automatically generate\ncorresponding questions for a given Scratch program. On a dataset of 600,913\nprojects we generated 54,118,694 questions automatically. Our initial\nexperiments with 34 ninth graders demonstrate that this approach can indeed\ngenerate meaningful questions for Scratch programs, and we find that the\nability of students to answer these questions on their programs relates to\ntheir overall performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728Scratch\u7f16\u7a0b\u73af\u5883\u4e2d\u81ea\u52a8\u751f\u6210\u7a0b\u5e8f\u7406\u89e3\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6269\u5c55LitterBox\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u57fa\u4e8e\u5df2\u6709\u7684\u7a0b\u5e8f\u7406\u89e3\u6a21\u578b\u751f\u621030\u7c7b\u95ee\u9898\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\u4e0e\u6709\u6548\u6027\u3002", "motivation": "\u4ec5\u901a\u8fc7\u5b66\u751f\u662f\u5426\u5b8c\u6210\u7f16\u7a0b\u4efb\u52a1\u6765\u8bc4\u4f30\u5176\u5b66\u4e60\u6548\u679c\u65e0\u6cd5\u53cd\u6620\u5176\u5bf9\u7f16\u7a0b\u6982\u5ff5\u7684\u771f\u5b9e\u7406\u89e3\uff0c\u800c\u4eba\u5de5\u4e3a\u6bcf\u4e2a\u5b66\u751f\u7a0b\u5e8f\u8bbe\u8ba1\u7406\u89e3\u6027\u95ee\u9898\u65e2\u7e41\u7410\u53c8\u56f0\u96be\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u5df2\u5efa\u7acb\u7684\u7a0b\u5e8f\u7406\u89e3\u6a21\u578b\uff0c\u4e3aScratch\u5757\u7f16\u7a0b\u8bed\u8a00\u8bbe\u8ba1\u4e8630\u79cd\u95ee\u9898\u7c7b\u578b\uff0c\u5e76\u6269\u5c55LitterBox\u9759\u6001\u5206\u6790\u5de5\u5177\uff0c\u4f7f\u5176\u80fd\u9488\u5bf9\u4efb\u610fScratch\u7a0b\u5e8f\u81ea\u52a8\u751f\u6210\u76f8\u5e94\u7684\u95ee\u9898\u3002", "result": "\u5728\u5305\u542b600,913\u4e2a\u9879\u76ee\u7684\u5927\u578b\u6570\u636e\u96c6\u4e0a\uff0c\u7cfb\u7edf\u81ea\u52a8\u751f\u6210\u4e8654,118,694\u4e2a\u95ee\u9898\uff1b\u5bf934\u540d\u4e5d\u5e74\u7ea7\u5b66\u751f\u7684\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u4e9b\u95ee\u9898\u5177\u6709\u5b9e\u9645\u610f\u4e49\uff0c\u4e14\u5b66\u751f\u56de\u7b54\u8fd9\u4e9b\u95ee\u9898\u7684\u80fd\u529b\u4e0e\u5176\u6574\u4f53\u8868\u73b0\u76f8\u5173\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u5728Scratch\u4e2d\u81ea\u52a8\u751f\u6210\u7a0b\u5e8f\u7406\u89e3\u95ee\u9898\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u8bc4\u4f30\u5b66\u751f\u5bf9\u7f16\u7a0b\u6982\u5ff5\u7684\u7406\u89e3\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u3002"}}
