<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 6]
- [cs.SE](#cs.SE) [Total: 7]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Sharded Elimination and Combining for Highly-Efficient Concurrent Stacks](https://arxiv.org/abs/2601.04523)
*Ajay Singh,Nikos Metaxakis,Panagiota Fatourou*

Main category: cs.DC

TL;DR: 提出一种基于分片和fetch&increment的高性能并发栈实现，显著优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 提升并发栈在高竞争和多线程环境下的性能表现。

Method: 结合新颖的消除机制与组合方法，利用分片和fetch&increment技术降低竞争、增强并行性。

Result: 实验表明，在多数负载下性能提升最高达2倍，尤其适合高线程数和高竞争场景。

Conclusion: 该实现通过高效混合新机制，实现了当前最优的并发栈性能。

Abstract: We present a new blocking linearizable stack implementation which utilizes sharding and fetch&increment to achieve significantly better performance than all existing concurrent stacks. The proposed implementation is based on a novel elimination mechanism and a new combining approach that are efficiently blended to gain high performance. Our implementation results in enhanced parallelism and low contention when accessing the shared stack. Experiments show that the proposed stack implementation outperforms all existing concurrent stacks by up to 2X in most workloads. It is particularly efficient in systems supporting a large number of threads and in high contention scenarios.

</details>


### [2] [Quantifying Autoscaler Vulnerabilities: An Empirical Study of Resource Misallocation Induced by Cloud Infrastructure Faults](https://arxiv.org/abs/2601.04659)
*Gijun Park*

Main category: cs.DC

TL;DR: 本文通过模拟实验研究基础设施故障对云环境中自动扩缩容机制的影响，发现存储故障导致最高成本开销，而路由异常易引发资源分配不足。


<details>
  <summary>Details</summary>
Motivation: 基础设施故障会扭曲性能指标，导致自动扩缩容决策失误，增加成本或降低服务可靠性，亟需研究其影响以改进策略。

Method: 通过控制模拟实验，测试四类常见故障对垂直与水平扩缩容行为在不同实例配置和SLO阈值下的影响。

Result: 存储故障在水平扩缩容下每月最多增加258美元成本；路由异常导致持续性资源分配不足；水平扩缩容对瞬态异常更敏感，尤其在阈值边界附近。

Conclusion: 应设计能区分真实负载波动与故障伪影的容错扩缩容策略，以提升云系统经济性与可靠性。

Abstract: Resource autoscaling mechanisms in cloud environments depend on accurate performance metrics to make optimal provisioning decisions. When infrastructure faults including hardware malfunctions, network disruptions, and software anomalies corrupt these metrics, autoscalers may systematically over- or under-provision resources, resulting in elevated operational expenses or degraded service reliability. This paper conducts controlled simulation experiments to measure how four prevalent fault categories affect both vertical and horizontal autoscaling behaviors across multiple instance configurations and service level objective (SLO) thresholds. Experimental findings demonstrate that storage-related faults generate the largest cost overhead, adding up to $258 monthly under horizontal scaling policies, whereas routing anomalies consistently bias autoscalers toward insufficient resource allocation. The sensitivity to fault-induced metric distortions differs markedly between scaling strategies: horizontal autoscaling exhibits greater susceptibility to transient anomalies, particularly near threshold boundaries. These empirically-grounded insights offer actionable recommendations for designing fault-tolerant autoscaling policies that distinguish genuine workload fluctuations from failure artifacts.

</details>


### [3] [Cognitive Infrastructure: A Unified DCIM Framework for AI Data Centers](https://arxiv.org/abs/2601.04750)
*Krishna Chaitanya Sunkara*

Main category: cs.DC

TL;DR: DCIM 3.0 是一个整合语义推理、预测分析、自主编排与统一连接的下一代AI数据中心管理框架。


<details>
  <summary>Details</summary>
Motivation: 解决数据中心在基础设施自动化、可持续性及数字孪生设计中的关键挑战。

Method: 采用基于知识图谱的智能技术、热建模方法与统一设备连接协议（UDCP）。

Result: 实现更高效、智能且可持续的数据中心管理能力。

Conclusion: 该框架为AI时代数据中心运维提供了系统性解决方案。

Abstract: This work presents DCIM 3.0, a unified framework integrating semantic reasoning, predictive analytics, autonomous orchestration, and unified connectivity for next-generation AI data center management. The framework addresses critical challenges in infrastructure automation, sustainability, and digital-twin design through knowledge graph-based intelligence, thermal modeling, and the Unified Device Connectivity Protocol (UDCP).Keywords-Data Center Infrastructure Management, DCIM, AI Data Centers, Knowledge Graphs, Digital Twin, Thermal Management, Infrastructure Automation, Sustainability, GPU Computing, Data Center

</details>


### [4] [Proof of Commitment: A Human-Centric Resource for Permissionless Consensus](https://arxiv.org/abs/2601.04813)
*Homayoun Maleki,Nekane Sainz,Jon Legarda*

Main category: cs.DC

TL;DR: 提出Proof of Commitment共识机制，以人类实时参与作为抗女巫攻击的稀缺资源，实现线性边际成本与公平性。


<details>
  <summary>Details</summary>
Motivation: 现有共识机制依赖可并行资源，导致女巫攻击边际成本趋近于零，需寻找不可并行化的新资源基础。

Method: 设计基于人类挑战预言机的身份绑定、时间敏感挑战机制，强制验证者累积真实人力投入，并通过加权骨干分析证明协议安全性。

Result: 理论与仿真表明PoCmt能实现安全、活性与比例公平性，且攻击者唯一瓶颈为人类时间容量。

Conclusion: PoCmt开创了以持续人力投入而非算力或资本为基础的新型无许可共识范式。

Abstract: Permissionless consensus protocols require a scarce resource to regulate leader election and provide Sybil resistance. Existing paradigms such as Proof of Work and Proof of Stake instantiate this scarcity through parallelizable resources like computation or capital. Once acquired, these resources can be subdivided across many identities at negligible marginal cost, making linear Sybil cost fundamentally unattainable.
  We introduce Proof of Commitment (PoCmt), a consensus primitive grounded in a non-parallelizable resource: real-time human engagement. Validators maintain a commitment state capturing cumulative human effort, protocol participation, and online availability. Engagement is enforced through a Human Challenge Oracle that issues identity-bound, time-sensitive challenges, limiting the number of challenges solvable within each human window.
  Under this model, sustaining multiple active identities requires proportional human-time effort. We establish a cost-theoretic separation showing that protocols based on parallelizable resources admit zero marginal Sybil cost, whereas PoCmt enforces a strictly linear cost profile. Using a weighted-backbone analysis, we show that PoCmt achieves safety, liveness, and commitment-proportional fairness under partial synchrony.
  Simulations complement the analysis by isolating human-time capacity as the sole adversarial bottleneck and validating the predicted commitment drift and fairness properties. These results position PoCmt as a new point in the consensus design space, grounding permissionless security in sustained human effort rather than computation or capital.

</details>


### [5] [Nalar: An agent serving framework](https://arxiv.org/abs/2601.05109)
*Marco Laju,Donghyun Son,Saurabh Agarwal,Nitin Kedia,Myungjin Lee,Jayanth Srinivasa,Aditya Akella*

Main category: cs.DC

TL;DR: Nalar 是一个专为高效服务 LLM 驱动的智能体应用而设计的框架，通过分离工作流规范与执行、管理状态和两级控制架构，显著降低尾延迟并提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 当前 LLM 智能体应用因组件异构、控制流动态、状态持久和延迟不可预测，导致服务效率低下，亟需专用框架优化性能。

Method: Nalar 采用轻量存根生成未来对象、解耦逻辑与物理状态、两级控制架构（全局策略+本地事件驱动）实现自适应调度与资源管理。

Result: 在三个智能体负载中，Nalar 尾延迟降低 34–74%，速度提升最高达 2.9 倍，支持 80 RPS（基线失败），可扩展至 13 万 future 对象且控制开销低于 500ms。

Conclusion: Nalar 在不增加开发者负担的前提下，实现了异构智能体应用的高效、可扩展、策略驱动的服务能力。

Abstract: LLM-driven agentic applications increasingly automate complex, multi-step tasks, but serving them efficiently remains challenging due to heterogeneous components, dynamic and model-driven control flow, long-running state, and unpredictable latencies. Nalar is a ground-up agent-serving framework that cleanly separates workflow specification from execution while providing the runtime visibility and control needed for robust performance. Nalar preserves full Python expressiveness, using lightweight auto-generated stubs that turn agent and tool invocations into futures carrying dependency and context metadata. A managed state layer decouples logical state from physical placement, enabling safe reuse, migration, and consistent retry behavior. A two-level control architecture combines global policy computation with local event-driven enforcement to support adaptive routing, scheduling, and resource management across evolving workflows. Together, these mechanisms allow Nalar to deliver scalable, efficient, and policy-driven serving of heterogeneous agentic applications without burdening developers with orchestration logic. Across three agentic workloads, Nalar cuts tail latency by 34--74\%, achieves up to $2.9\times$ speedups, sustains 80 RPS where baselines fail, and scales to 130K futures with sub-500 ms control overhead.

</details>


### [6] [Asynchronous Secure Federated Learning with Byzantine aggregators](https://arxiv.org/abs/2601.04930)
*Antonella Del Pozzo,Achille Desreumaux,Mathieu Gestin,Alexandre Rapetti,Sara Tucci-Piergiovanni*

Main category: cs.DC

TL;DR: 本文提出了一种在异步通信和恶意聚合器环境下保护客户端隐私的联邦平均新方案，结合安全聚合与差分隐私，在不依赖聚合器共识的前提下维持训练活性与性能。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方案难以应对异步通信中恶意聚合器攻击及客户端参与不均导致的隐私泄露与训练偏差问题。

Method: 通过复制聚合器容忍部分恶意节点、客户端添加高斯噪声并掩码模型、引入包含机制均衡客户端参与频率，避免依赖共识协议。

Result: 方案在异步拜占庭环境下保持与现有最优方法相当的性能，同时提升隐私保护强度与系统可用性。

Conclusion: 该方法有效解决了异步联邦学习中的隐私与鲁棒性挑战，无需共识机制即可保障训练持续进行，具有更高实用价值。

Abstract: Privacy-preserving federated averaging is a central approach for protecting client privacy in federated learning. In this paper, we study this problem in an asynchronous communications setting with malicious aggregators. We propose a new solution to provide federated averaging in this model while protecting the client's data privacy through secure aggregation and differential privacy. Our solution maintains the same performance as the state of the art across all metrics. The main contributions of this paper are threefold. First, unlike existing single- or multi-server solutions, we consider malicious aggregation servers that may manipulate the model to leak clients' data or halt computation. To tolerate this threat, we replicate the aggregators, allowing a fraction of them to be corrupted. Second, we propose a new privacy preservation protocol for protocols in asynchronous communication models with Byzantine aggregators. In this protocol, clients mask their values and add Gaussian noise to their models. In contrast with previous works, we use the replicated servers to unmask the models, while ensuring the liveness of training even if aggregators misbehave. Third, the asynchronous communication model introduces new challenges not present in existing approaches. In such a setting, faster clients may contribute more frequently, potentially reducing their privacy and biasing the training. To address this, we introduce an inclusion mechanism that ensures uniform client participation and balanced privacy budgets. Interestingly, the solution presented in this paper does not rely on agreement between aggregators. Thus, we circumvent the known impossibility of consensus in asynchronous settings where processes might crash. Additionally, this feature increases availability, as a consensus-based algorithm only progresses in periods of low latency.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Sphinx: Benchmarking and Modeling for LLM-Driven Pull Request Review](https://arxiv.org/abs/2601.04252)
*Daoan Zhang,Shuo Zhang,Zijian Jin,Jiebo Luo,Shengyu Fu,Elsie Nallipogu*

Main category: cs.SE

TL;DR: Sphinx是一个基于LLM的PR审查框架，通过结构化数据生成、检查表评估和CRPO训练方法，显著提升审查质量和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决PR审查自动化中的噪声监督、上下文理解不足和评估指标不完善问题。

Method: 提出三部分框架：结构化数据生成管道、基于检查表的评估基准、CRPO训练范式。

Result: 在审查完整性和精确性上达到SOTA，检查表覆盖率比基线高40%。

Conclusion: Sphinx使PR审查模型更流畅、上下文感知、技术精准且可实际部署。

Abstract: Pull request (PR) review is essential for ensuring software quality, yet automating this task remains challenging due to noisy supervision, limited contextual understanding, and inadequate evaluation metrics. We present Sphinx, a unified framework for LLM-based PR review that addresses these limitations through three key components: (1) a structured data generation pipeline that produces context-rich, semantically grounded review comments by comparing pseudo-modified and merged code; (2) a checklist-based evaluation benchmark that assesses review quality based on structured coverage of actionable verification points, moving beyond surface-level metrics like BLEU; and (3) Checklist Reward Policy Optimization (CRPO), a novel training paradigm that uses rule-based, interpretable rewards to align model behavior with real-world review practices. Extensive experiments show that models trained with Sphinx achieve state-of-the-art performance on review completeness and precision, outperforming both proprietary and open-source baselines by up to 40\% in checklist coverage. Together, Sphinx enables the development of PR review models that are not only fluent but also context-aware, technically precise, and practically deployable in real-world development workflows. The data will be released after review.

</details>


### [8] [Advancing Language Models for Code-related Tasks](https://arxiv.org/abs/2601.04526)
*Zhao Tian*

Main category: cs.SE

TL;DR: 本研究通过数据增强、架构优化和推理改进三方面提升语言模型在软件工程中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在复杂编程场景中受限于数据质量、模型架构和推理能力。

Method: 提出CODA与CodeDenoise提升数据质量，LEAM系列优化架构，muFiX与Specine增强推理能力。

Result: 有效推动语言模型在软件开发中的实际落地，促进智能软件工程发展。

Conclusion: 综合方法显著提升语言模型在复杂编程任务中的表现与实用性。

Abstract: Recent advances in language models (LMs) have driven significant progress in various software engineering tasks. However, existing LMs still struggle with complex programming scenarios due to limitations in data quality, model architecture, and reasoning capability. This research systematically addresses these challenges through three complementary directions: (1) improving code data quality with a code difference-guided adversarial augmentation technique (CODA) and a code denoising technique (CodeDenoise); (2) enhancing model architecture via syntax-guided code LMs (LEAM and LEAM++); and (3) advancing model reasoning with a prompting technique (muFiX) and an agent-based technique (Specine). These techniques aim to promote the practical adoption of LMs in software development and further advance intelligent software engineering.

</details>


### [9] [AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation](https://arxiv.org/abs/2601.04540)
*Tanghaoran Zhang,Xinjun Mao,Shangwen Wang,Yuxin Zhao,Yao Lu,Jin Zhang,Zhang Zhang,Kang Yang,Yue Yu*

Main category: cs.SE

TL;DR: 提出AdaptEval基准，评估大语言模型在代码片段适配中的表现，填补现有评估空白。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏评估大语言模型在代码复用中适配能力的基准，导致其实际效用不明。

Method: 构建包含实践上下文、多粒度标注和细粒度评估三特征的AdaptEval基准，并对六种指令调优及三种推理型大语言模型进行实证研究。

Result: 实验表明AdaptEval可从多角度评估模型适配能力，并揭示其难以遵循明确指令等局限。

Conclusion: AdaptEval有助于推动大语言模型在代码适配领域的能力提升与实际应用。

Abstract: Recent advancements in large language models (LLMs) have automated various software engineering tasks, with benchmarks emerging to evaluate their capabilities. However, for adaptation, a critical activity during code reuse, there is no benchmark to assess LLMs' performance, leaving their practical utility in this area unclear. To fill this gap, we propose AdaptEval, a benchmark designed to evaluate LLMs on code snippet adaptation. Unlike existing benchmarks, AdaptEval incorporates the following three distinctive features: First, Practical Context. Tasks in AdaptEval are derived from developers' practices, preserving rich contextual information from Stack Overflow and GitHub communities. Second, Multi-granularity Annotation. Each task is annotated with requirements at both task and adaptation levels, supporting the evaluation of LLMs across diverse adaptation scenarios. Third, Fine-grained Evaluation. AdaptEval includes a two-tier testing framework combining adaptation-level and function-level tests, which enables evaluating LLMs' performance across various individual adaptations. Based on AdaptEval, we conduct the first empirical study to evaluate six instruction-tuned LLMs and especially three reasoning LLMs on code snippet adaptation. Experimental results demonstrate that AdaptEval enables the assessment of LLMs' adaptation capabilities from various perspectives. It also provides critical insights into their current limitations, particularly their struggle to follow explicit instructions. We hope AdaptEval can facilitate further investigation and enhancement of LLMs' capabilities in code snippet adaptation, supporting their real-world applications.

</details>


### [10] [4D-ARE: Bridging the Attribution Gap in LLM Agent Requirements Engineering](https://arxiv.org/abs/2601.04556)
*Bo Yu,Lei Zhao*

Main category: cs.SE

TL;DR: 提出4D-ARE方法论，系统化指定LLM智能体应推理的内容，以补足现有运行时推理框架的不足。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体虽具备推理能力，但缺乏设计阶段对‘应推理什么’的明确规范，导致输出偏离用户真实需求（如归因解释）。

Method: 基于Pearl因果层级构建四维归因框架（结果→过程→支持→长期），通过五层结构生成可编译为系统提示的工件，指导智能体聚焦归因推理。

Result: 在金融服务业试点部署验证了4D-ARE的初步可行性，能有效引导智能体输出符合决策者需求的归因分析而非单纯指标数据。

Conclusion: 系统化的需求工程方法可放大现有推理框架效能，未来需开展严谨实证评估以完善该方法论。

Abstract: We deployed an LLM agent with ReAct reasoning and full data access. It executed flawlessly, yet when asked "Why is completion rate 80%?", it returned metrics instead of causal explanation. The agent knew how to reason but we had not specified what to reason about. This reflects a gap: runtime reasoning frameworks (ReAct, Chain-of-Thought) have transformed LLM agents, but design-time specification--determining what domain knowledge agents need--remains under-explored. We propose 4D-ARE (4-Dimensional Attribution-Driven Agent Requirements Engineering), a preliminary methodology for specifying attribution-driven agents. The core insight: decision-makers seek attribution, not answers. Attribution concerns organize into four dimensions (Results -> Process -> Support -> Long-term), motivated by Pearl's causal hierarchy. The framework operationalizes through five layers producing artifacts that compile directly to system prompts. We demonstrate the methodology through an industrial pilot deployment in financial services. 4D-ARE addresses what agents should reason about, complementing runtime frameworks that address how. We hypothesize systematic specification amplifies the power of these foundational advances. This paper presents a methodological proposal with preliminary industrial validation; rigorous empirical evaluation is planned for future work.

</details>


### [11] [Extending Delta Debugging Minimization for Spectrum-Based Fault Localization](https://arxiv.org/abs/2601.04689)
*Charaka Geethal Kapugama*

Main category: cs.SE

TL;DR: DDMIN-LOC结合Delta Debugging与频谱故障定位，仅需一个失败输入即可高效定位字符串输入程序中的缺陷语句。


<details>
  <summary>Details</summary>
Motivation: 解决DDMIN无法指出具体故障语句的问题，提升调试效率。

Method: 利用DDMIN生成的通过/失败输入，结合SBFL算法计算语句可疑度并排序。

Result: 在136个基准程序中，使用Jaccard算法时多数情况下只需检查20%以内代码行，且故障语句多排在前3位。

Conclusion: DDMIN-LOC显著提升了仅凭单一失败输入定位程序缺陷的能力，尤其适用于字符串输入场景。

Abstract: This paper introduces DDMIN-LOC, a technique that combines Delta Debugging Minimization (DDMIN) with Spectrum-Based Fault Localization (SBFL). It can be applied to programs taking string inputs, even when only a single failure-inducing input is available. DDMIN is an algorithm that systematically explores the minimal failure-inducing input that exposes a bug, given an initial failing input. However, it does not provide information about the faulty statements responsible for the failure. DDMIN-LOC addresses this limitation by collecting the passing and failing inputs generated during the DDMIN process and computing suspiciousness scores for program statements and predicates using SBFL algorithms. These scores are then combined to rank statements according to their likelihood of being faulty. DDMIN-LOC requires only one failing input of the buggy program, although it can be applied only to programs that take string inputs. DDMIN-LOC was evaluated on 136 programs selected from the QuixBugs and Codeflaws benchmarks using the SBFL algorithms Tarantula, Ochiai, GenProg, Jaccard and DStar. Experimental results show that DDMIN-LOC performs best with Jaccard: in most subjects, fewer than 20% executable lines need to be examined to locate the faulty statements. Moreover, in most subjects, faulty statements are ranked within the top 3 positions in all the generated test suites derived from different failing inputs.

</details>


### [12] [A Longitudinal Analysis of Gamification in Untappd: Ethical Reflections on a Social Drinking Application](https://arxiv.org/abs/2601.04841)
*Jefferson Seide Molléri,Sami Hyrynsalmi,Antti Hakkala,Kai K. Kimppa,Jouni Smed*

Main category: cs.SE

TL;DR: 本文纵向分析了社交饮酒应用Untappd的伦理演变，指出其游戏化设计仍存伦理问题，呼吁将伦理反思嵌入软件生命周期。


<details>
  <summary>Details</summary>
Motivation: 探讨Untappd平台游戏化功能如何影响用户自主性与福祉，并推动软件工程中持续伦理反思。

Method: 基于2020年初步研究，2025年重访平台，结合传统伦理理论与软件工程框架，分析五类徽章设计。

Result: 尽管有小幅调整和免责声明，原始伦理问题大多仍存，游戏化设计仍可能助长风险行为。

Conclusion: 应将连续伦理反思机制内嵌于软件开发生命周期，以防止通过设计使高风险行为常态化。

Abstract: This paper presents a longitudinal ethical analysis of Untappd, a social drinking application that gamifies beer consumption through badges, streaks, and social sharing. Building on an exploratory study conducted in 2020, we revisit the platform in 2025 to examine how its gamification features and ethical framings have evolved. Drawing on traditional ethical theory and practical frameworks for Software Engineering, we analyze five categories of badges and their implications for user autonomy and well-being. Our findings show that, despite small adjustments and superficial disclaimers, many of the original ethical issues remain. We argue for continuous ethical reflection built embedded into software lifecycles to prevent the normalization of risky behaviors through design.

</details>


### [13] [AVX / NEON Intrinsic Functions: When Should They Be Used?](https://arxiv.org/abs/2601.04922)
*Théo Boivin,Joeffrey Legaux*

Main category: cs.SE

TL;DR: 该论文通过跨配置基准测试评估AVX/NEON内联函数在不同开发环境下的性能表现，指导开发者何时应手动使用内联函数优化代码。


<details>
  <summary>Details</summary>
Motivation: 帮助开发者根据操作系统、架构和编译器选择是否使用内联函数进行向量化优化。

Method: 设计跨配置基准测试，比较内联函数与普通代码及编译器自动向量化的执行效率。

Result: 内联函数在条件分支中效率极高（执行时间约为普通代码的5%），但在多数情况下编译器已能良好自动向量化，无需手动优化。

Conclusion: 仅在特定场景（如复杂条件分支）推荐使用内联函数，其他情况依赖编译器自动优化即可。

Abstract: A cross-configuration benchmark is proposed to explore the capacities and limitations of AVX / NEON intrinsic functions in a generic context of development project, when a vectorisation strategy is required to optimise the code. The main aim is to guide developers to choose when using intrinsic functions, depending on the OS, architecture and/or available compiler. Intrinsic functions were observed highly efficient in conditional branching, with intrinsic version execution time reaching around 5% of plain code execution time. However, intrinsic functions were observed as unnecessary in many cases, as the compilers already well auto-vectorise the code.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [14] [MPM-LLM4DSE: Reaching the Pareto Frontier in HLS with Multimodal Learning and LLM-Driven Exploration](https://arxiv.org/abs/2601.04801)
*Lei Xu,Shanshan Wang,Chenglong Xiao*

Main category: cs.AR

TL;DR: 提出MPM-LLM4DSE框架，融合多模态预测与大语言模型优化，显著提升HLS设计空间探索效率。


<details>
  <summary>Details</summary>
Motivation: 现有GNN预测方法难以充分捕捉行为描述语义特征，传统多目标优化算法未有效利用pragma对QoR影响的领域知识。

Method: 构建多模态预测模型融合行为描述与数据流图特征，并采用大语言模型结合定制提示工程进行优化。

Result: 预测模型较ProgSG提升达10.25倍，DSE任务平均性能增益39.90%。

Conclusion: MPM-LLM4DSE框架在HLS设计空间探索中展现出显著优越性，验证了提示工程方法的有效性。

Abstract: High-Level Synthesis (HLS) design space exploration (DSE) seeks Pareto-optimal designs within expansive pragma configuration spaces. To accelerate HLS DSE, graph neural networks (GNNs) are commonly employed as surrogates for HLS tools to predict quality of results (QoR) metrics, while multi-objective optimization algorithms expedite the exploration. However, GNN-based prediction methods may not fully capture the rich semantic features inherent in behavioral descriptions, and conventional multi-objective optimization algorithms often do not explicitly account for the domain-specific knowledge regarding how pragma directives influence QoR. To address these limitations, this paper proposes the MPM-LLM4DSE framework, which incorporates a multimodal prediction model (MPM) that simultaneously fuses features from behavioral descriptions and control and data flow graphs. Furthermore, the framework employs a large language model (LLM) as an optimizer, accompanied by a tailored prompt engineering methodology. This methodology incorporates pragma impact analysis on QoR to guide the LLM in generating high-quality configurations (LLM4DSE). Experimental results demonstrate that our multimodal predictive model significantly outperforms state-of-the-art work ProgSG by up to 10.25$\times$. Furthermore, in DSE tasks, the proposed LLM4DSE achieves an average performance gain of 39.90\% over prior methods, validating the effectiveness of our prompting methodology. Code and models are available at https://github.com/wslcccc/MPM-LLM4DSE.

</details>


### [15] [Challenges and Research Directions for Large Language Model Inference Hardware](https://arxiv.org/abs/2601.05047)
*Xiaoyu Ma,David Patterson*

Main category: cs.AR

TL;DR: 本文探讨了大语言模型推理中的内存与互连瓶颈，并提出四项架构研究方向以优化性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型推理因自回归解码阶段与训练不同，面临内存和互连瓶颈，而非计算瓶颈。

Method: 提出高带宽闪存、近内存处理、3D堆叠及低延迟互连四项架构优化方案。

Result: 这些方案有望显著提升数据中心AI推理效率，并部分适用于移动设备。

Conclusion: 未来AI架构应聚焦内存与通信优化，而非单纯提升算力。

Abstract: Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup communication. While our focus is datacenter AI, we also review their applicability for mobile devices.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [16] [From Idea to Co-Creation: A Planner-Actor-Critic Framework for Agent Augmented 3D Modeling](https://arxiv.org/abs/2601.05016)
*Jin Gao,Saichandu Juluri*

Main category: cs.MA

TL;DR: 本文提出一种基于多智能体自省与人机协同监督的3D建模框架，相较单提示方法显著提升模型几何精度、美学质量与任务完成率。


<details>
  <summary>Details</summary>
Motivation: 现有单提示建模方法缺乏迭代反馈与人类指导，导致错误率高、输出质量受限。

Method: 构建Planner-Actor-Critic架构：Planner规划步骤，Actor执行操作，Critic提供反馈，人类全程担任监督与顾问角色，并通过Blender实时同步实现高效工作流集成。

Result: 实验表明该方法在多种3D建模场景中均优于单提示方法，有效降低错误、提升复杂度与输出质量。

Conclusion: 结构化智能体自省结合人类监督可稳定生成高质量3D模型，同时保持高效工作流整合能力。

Abstract: We present a framework that extends the Actor-Critic architecture to creative 3D modeling through multi-agent self-reflection and human-in-the-loop supervision. While existing approaches rely on single-prompt agents that directly execute modeling commands via tools like Blender MCP, our approach introduces a Planner-Actor-Critic architecture. In this design, the Planner coordinates modeling steps, the Actor executes them, and the Critic provides iterative feedback, while human users act as supervisors and advisors throughout the process. Through systematic comparison between single-prompt modeling and our reflective multi-agent approach, we demonstrate improvements in geometric accuracy, aesthetic quality, and task completion rates across diverse 3D modeling scenarios. Our evaluation reveals that critic-guided reflection, combined with human supervisory input, reduces modeling errors and increases complexity and quality of the result compared to direct single-prompt execution. This work establishes that structured agent self-reflection, when augmented by human oversight and advisory guidance, produces higher-quality 3D models while maintaining efficient workflow integration through real-time Blender synchronization.

</details>
