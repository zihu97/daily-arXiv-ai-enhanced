{"id": "2511.15862", "categories": ["cs.MA", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15862", "abs": "https://arxiv.org/abs/2511.15862", "authors": ["Devang Kulshreshtha", "Wanyu Du", "Raghav Jain", "Srikanth Doss", "Hang Su", "Sandesh Swamy", "Yanjun Qi"], "title": "The Subtle Art of Defection: Understanding Uncooperative Behaviors in LLM based Multi-Agent Systems", "comment": null, "summary": "This paper introduces a novel framework for simulating and analyzing how uncooperative behaviors can destabilize or collapse LLM-based multi-agent systems. Our framework includes two key components: (1) a game theory-based taxonomy of uncooperative agent behaviors, addressing a notable gap in the existing literature; and (2) a structured, multi-stage simulation pipeline that dynamically generates and refines uncooperative behaviors as agents' states evolve. We evaluate the framework via a collaborative resource management setting, measuring system stability using metrics such as survival time and resource overuse rate. Empirically, our framework achieves 96.7% accuracy in generating realistic uncooperative behaviors, validated by human evaluations. Our results reveal a striking contrast: cooperative agents maintain perfect system stability (100% survival over 12 rounds with 0% resource overuse), while any uncooperative behavior can trigger rapid system collapse within 1 to 7 rounds. These findings demonstrate that uncooperative agents can significantly degrade collective outcomes, highlighting the need for designing more resilient multi-agent systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u548c\u5206\u6790\u4e0d\u5408\u4f5c\u884c\u4e3a\u5982\u4f55\u7834\u574f\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u8d44\u6e90\u7ba1\u7406\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4e0d\u5408\u4f5c\u884c\u4e3a\u7684\u7cfb\u7edf\u6027\u5206\u7c7b\u4e0e\u52a8\u6001\u6a21\u62df\u65b9\u6cd5\uff0c\u96be\u4ee5\u8bc4\u4f30\u5176\u5bf9\u7cfb\u7edf\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e24\u90e8\u5206\u7684\u6846\u67b6\uff1a(1) \u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u4e0d\u5408\u4f5c\u884c\u4e3a\u5206\u7c7b\u4f53\u7cfb\uff1b(2) \u591a\u9636\u6bb5\u52a8\u6001\u4eff\u771f\u6d41\u7a0b\uff0c\u968f\u667a\u80fd\u4f53\u72b6\u6001\u6f14\u5316\u751f\u6210\u5e76\u4f18\u5316\u4e0d\u5408\u4f5c\u884c\u4e3a\u3002\u5728\u534f\u4f5c\u8d44\u6e90\u7ba1\u7406\u573a\u666f\u4e2d\uff0c\u901a\u8fc7\u751f\u5b58\u65f6\u95f4\u548c\u8d44\u6e90\u6ee5\u7528\u7387\u7b49\u6307\u6807\u8bc4\u4f30\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002", "result": "\u6846\u67b6\u751f\u6210\u4e0d\u5408\u4f5c\u884c\u4e3a\u7684\u51c6\u786e\u7387\u8fbe96.7%\uff08\u7ecf\u4eba\u5de5\u9a8c\u8bc1\uff09\uff1b\u5b9e\u9a8c\u663e\u793a\uff0c\u5408\u4f5c\u667a\u80fd\u4f53\u53ef\u7ef4\u6301100%\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0812\u8f6e\u5185\u65e0\u8d44\u6e90\u6ee5\u7528\uff09\uff0c\u800c\u4e0d\u5408\u4f5c\u884c\u4e3a\u53ef\u57281\u81f37\u8f6e\u5185\u5bfc\u81f4\u7cfb\u7edf\u8fc5\u901f\u5d29\u6e83\u3002", "conclusion": "\u4e0d\u5408\u4f5c\u884c\u4e3a\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u96c6\u4f53\u6027\u80fd\u5177\u6709\u663e\u8457\u7834\u574f\u6027\uff0c\u7814\u7a76\u5f3a\u8c03\u4e86\u8bbe\u8ba1\u66f4\u5177\u97e7\u6027\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2511.15977", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2511.15977", "abs": "https://arxiv.org/abs/2511.15977", "authors": ["Daniel Mas Montserrat", "Ray Verma", "M\u00edriam Barrab\u00e9s", "Francisco M. de la Vega", "Carlos D. Bustamante", "Alexander G. Ioannidis"], "title": "Efficient Chromosome Parallelization for Precision Medicine Genomic Workflows", "comment": "Accepted at AAAI 2026", "summary": "Large-scale genomic workflows used in precision medicine can process datasets spanning tens to hundreds of gigabytes per sample, leading to high memory spikes, intensive disk I/O, and task failures due to out-of-memory errors. Simple static resource allocation methods struggle to handle the variability in per-chromosome RAM demands, resulting in poor resource utilization and long runtimes. In this work, we propose multiple mechanisms for adaptive, RAM-efficient parallelization of chromosome-level bioinformatics workflows. First, we develop a symbolic regression model that estimates per-chromosome memory consumption for a given task and introduces an interpolating bias to conservatively minimize over-allocation. Second, we present a dynamic scheduler that adaptively predicts RAM usage with a polynomial regression model, treating task packing as a Knapsack problem to optimally batch jobs based on predicted memory requirements. Additionally, we present a static scheduler that optimizes chromosome processing order to minimize peak memory while preserving throughput. Our proposed methods, evaluated on simulations and real-world genomic pipelines, provide new mechanisms to reduce memory overruns and balance load across threads. We thereby achieve faster end-to-end execution, showcasing the potential to optimize large-scale genomic workflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u79cd\u81ea\u9002\u5e94\u3001\u5185\u5b58\u9ad8\u6548\u7684\u67d3\u8272\u4f53\u7ea7\u751f\u7269\u4fe1\u606f\u5b66\u5de5\u4f5c\u6d41\u5e76\u884c\u5316\u673a\u5236\uff0c\u5305\u62ec\u57fa\u4e8e\u7b26\u53f7\u56de\u5f52\u7684\u5185\u5b58\u9884\u6d4b\u6a21\u578b\u3001\u52a8\u6001\u8c03\u5ea6\u5668\u548c\u9759\u6001\u8c03\u5ea6\u7b56\u7565\uff0c\u4ee5\u4f18\u5316\u5927\u89c4\u6a21\u57fa\u56e0\u7ec4\u5de5\u4f5c\u6d41\u7684\u5185\u5b58\u4f7f\u7528\u548c\u6267\u884c\u6548\u7387\u3002", "motivation": "\u5927\u89c4\u6a21\u57fa\u56e0\u7ec4\u5de5\u4f5c\u6d41\u5728\u7cbe\u51c6\u533b\u5b66\u4e2d\u5904\u7406\u7684\u6570\u636e\u91cf\u5de8\u5927\uff0c\u5e38\u5bfc\u81f4\u5185\u5b58\u5cf0\u503c\u9ad8\u3001\u78c1\u76d8I/O\u5bc6\u96c6\u4ee5\u53ca\u56e0\u5185\u5b58\u4e0d\u8db3\u800c\u4efb\u52a1\u5931\u8d25\uff1b\u4f20\u7edf\u9759\u6001\u8d44\u6e90\u5206\u914d\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u4e0d\u540c\u67d3\u8272\u4f53\u4efb\u52a1\u95f4\u5185\u5b58\u9700\u6c42\u7684\u5dee\u5f02\uff0c\u9020\u6210\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u548c\u8fd0\u884c\u65f6\u95f4\u957f\u3002", "method": "1\uff09\u6784\u5efa\u7b26\u53f7\u56de\u5f52\u6a21\u578b\u4f30\u7b97\u6bcf\u4e2a\u67d3\u8272\u4f53\u4efb\u52a1\u7684\u5185\u5b58\u6d88\u8017\uff0c\u5e76\u5f15\u5165\u63d2\u503c\u504f\u5dee\u4ee5\u4fdd\u5b88\u5730\u51cf\u5c11\u5185\u5b58\u8fc7\u5ea6\u5206\u914d\uff1b2\uff09\u8bbe\u8ba1\u52a8\u6001\u8c03\u5ea6\u5668\uff0c\u5229\u7528\u591a\u9879\u5f0f\u56de\u5f52\u9884\u6d4b\u5185\u5b58\u4f7f\u7528\uff0c\u5e76\u5c06\u4efb\u52a1\u6253\u5305\u5efa\u6a21\u4e3a\u80cc\u5305\u95ee\u9898\u4ee5\u6700\u4f18\u6279\u5904\u7406\u4f5c\u4e1a\uff1b3\uff09\u63d0\u51fa\u9759\u6001\u8c03\u5ea6\u5668\uff0c\u4f18\u5316\u67d3\u8272\u4f53\u5904\u7406\u987a\u5e8f\u4ee5\u964d\u4f4e\u5cf0\u503c\u5185\u5b58\u540c\u65f6\u4fdd\u6301\u541e\u5410\u91cf\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u57fa\u56e0\u7ec4\u6d41\u7a0b\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11\u5185\u5b58\u6ea2\u51fa\u3001\u5747\u8861\u7ebf\u7a0b\u8d1f\u8f7d\uff0c\u5e76\u52a0\u5feb\u7aef\u5230\u7aef\u6267\u884c\u901f\u5ea6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u5185\u5b58\u9ad8\u6548\u8c03\u5ea6\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u57fa\u56e0\u7ec4\u5de5\u4f5c\u6d41\u7684\u6027\u80fd\u4e0e\u8d44\u6e90\u5229\u7528\u7387\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4f18\u5316\u6b64\u7c7b\u8ba1\u7b97\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.15733", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15733", "abs": "https://arxiv.org/abs/2511.15733", "authors": ["Eitan Farchi", "Kiran Nayak", "Papia Ghosh Majumdar", "Saritha Route"], "title": "Technique to Baseline QE Artefact Generation Aligned to Quality Metrics", "comment": null, "summary": "Large Language Models (LLMs) are transforming Quality Engineering (QE) by automating the generation of artefacts such as requirements, test cases, and Behavior Driven Development (BDD) scenarios. However, ensuring the quality of these outputs remains a challenge. This paper presents a systematic technique to baseline and evaluate QE artefacts using quantifiable metrics. The approach combines LLM-driven generation, reverse generation , and iterative refinement guided by rubrics technique for clarity, completeness, consistency, and testability. Experimental results across 12 projects show that reverse-generated artefacts can outperform low-quality inputs and maintain high standards when inputs are strong. The framework enables scalable, reliable QE artefact validation, bridging automation with accountability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u3001\u53cd\u5411\u751f\u6210\u4e0e\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8fed\u4ee3\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u7cfb\u7edf\u5316\u8bc4\u4f30\u548c\u63d0\u5347\u8d28\u91cf\u5de5\u7a0b\uff08QE\uff09\u5236\u54c1\uff08\u5982\u9700\u6c42\u3001\u6d4b\u8bd5\u7528\u4f8b\u3001BDD\u573a\u666f\uff09\u7684\u8d28\u91cf\uff0c\u5e76\u572812\u4e2a\u9879\u76ee\u4e2d\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u751f\u6210\u8d28\u91cf\u5de5\u7a0b\u5236\u54c1\u65b9\u9762\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5982\u4f55\u786e\u4fdd\u8fd9\u4e9b\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u4ecd\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u8be5\u65b9\u6cd5\u878d\u5408\u4e86LLM\u9a71\u52a8\u7684\u751f\u6210\u3001\u53cd\u5411\u751f\u6210\u4ee5\u53ca\u7531\u8bc4\u5206\u6807\u51c6\u5f15\u5bfc\u7684\u8fed\u4ee3\u4f18\u5316\uff0c\u4ece\u6e05\u6670\u6027\u3001\u5b8c\u6574\u6027\u3001\u4e00\u81f4\u6027\u548c\u53ef\u6d4b\u8bd5\u6027\u56db\u4e2a\u7ef4\u5ea6\u5bf9QE\u5236\u54c1\u8fdb\u884c\u8bc4\u4f30\u548c\u6539\u8fdb\u3002", "result": "\u572812\u4e2a\u9879\u76ee\u7684\u5b9e\u9a8c\u4e2d\uff0c\u53cd\u5411\u751f\u6210\u7684\u5236\u54c1\u4e0d\u4ec5\u4f18\u4e8e\u4f4e\u8d28\u91cf\u8f93\u5165\uff0c\u800c\u4e14\u5728\u8f93\u5165\u8d28\u91cf\u8f83\u9ad8\u65f6\u4e5f\u80fd\u7ef4\u6301\u9ad8\u6807\u51c6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684QE\u5236\u54c1\u9a8c\u8bc1\u673a\u5236\uff0c\u5728\u81ea\u52a8\u5316\u4e0e\u8d28\u91cf\u95ee\u8d23\u4e4b\u95f4\u5efa\u7acb\u4e86\u6709\u6548\u6865\u6881\u3002"}}
{"id": "2511.16041", "categories": ["cs.DC", "cs.AR", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.16041", "abs": "https://arxiv.org/abs/2511.16041", "authors": ["Chengyue Wang", "Wesley Pang", "Xinrui Wu", "Gregory Jun", "Luis Romero", "Endri Taka", "Diana Marculescu", "Tony Nowatzki", "Pranathi Vasireddy", "Joseph Melber", "Deming Chen", "Jason Cong"], "title": "Can Asymmetric Tile Buffering Be Beneficial?", "comment": null, "summary": "General matrix multiplication (GEMM) is the computational backbone of modern AI workloads, and its efficiency is critically dependent on effective tiling strategies. Conventional approaches employ symmetric tile buffering, where the buffered tile size of the input $A$ along the dimension $M$ matches the output tile size of $C$.\n  In this paper, we introduce asymmetric tile buffering (ATB), a simple but powerful technique that decouples the buffered tile dimensions of the input and output operands. We show, for the first time, that ATB is both practical and highly beneficial. To explain this effect, we develop a performance model that incorporates both the benefits of ATB (higher arithmetic intensity) and its overheads (higher kernel switching costs), providing insight into how to select effective ATB tiling factors. As a case study, we apply ATB to AMD's latest XDNA2 AI Engine (AIE), achieving up to a 4.54x speedup, from 4.8 to 24.6 TFLOPS on mixed-precision BFP16--BF16 GEMM, establishing a new performance record for XDNA2 AIE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u975e\u5bf9\u79f0\u5206\u5757\u7f13\u5b58\uff08ATB\uff09\u7684\u65b0\u6280\u672f\uff0c\u901a\u8fc7\u89e3\u8026\u8f93\u5165\u4e0e\u8f93\u51fa\u64cd\u4f5c\u6570\u7684\u5206\u5757\u7ef4\u5ea6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u901a\u7528\u77e9\u9635\u4e58\u6cd5\uff08GEMM\uff09\u5728AI\u52a0\u901f\u5668\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u5728AMD XDNA2 AI\u5f15\u64ce\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad84.54\u500d\u7684\u52a0\u901f\u3002", "motivation": "\u4f20\u7edfGEMM\u5b9e\u73b0\u91c7\u7528\u5bf9\u79f0\u5206\u5757\u7f13\u5b58\u7b56\u7565\uff0c\u9650\u5236\u4e86\u7b97\u672f\u5f3a\u5ea6\u548c\u6027\u80fd\u4f18\u5316\u7a7a\u95f4\u3002\u4f5c\u8005\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u5206\u5757\u65b9\u6cd5\u4ee5\u7a81\u7834\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u63d0\u51fa\u975e\u5bf9\u79f0\u5206\u5757\u7f13\u5b58\uff08ATB\uff09\u6280\u672f\uff0c\u5e76\u6784\u5efa\u5305\u542b\u7b97\u672f\u5f3a\u5ea6\u589e\u76ca\u4e0e\u6838\u5207\u6362\u5f00\u9500\u7684\u6027\u80fd\u6a21\u578b\uff0c\u7528\u4e8e\u6307\u5bfcATB\u5206\u5757\u56e0\u5b50\u7684\u9009\u62e9\u3002", "result": "\u5728AMD XDNA2 AI Engine\u4e0a\uff0cATB\u5c06\u6df7\u5408\u7cbe\u5ea6BFP16\u2013BF16 GEMM\u6027\u80fd\u4ece4.8 TFLOPS\u63d0\u5347\u81f324.6 TFLOPS\uff0c\u63d0\u901f\u8fbe4.54\u500d\uff0c\u521b\u4e0b\u8be5\u5e73\u53f0\u65b0\u7eaa\u5f55\u3002", "conclusion": "\u975e\u5bf9\u79f0\u5206\u5757\u7f13\u5b58\u662f\u4e00\u79cd\u5b9e\u7528\u4e14\u9ad8\u6548\u7684GEMM\u4f18\u5316\u6280\u672f\uff0c\u901a\u8fc7\u5408\u7406\u6743\u8861\u8ba1\u7b97\u5f3a\u5ea6\u4e0e\u8c03\u5ea6\u5f00\u9500\uff0c\u53ef\u663e\u8457\u63d0\u5347AI\u786c\u4ef6\u4e0a\u7684\u77e9\u9635\u4e58\u6027\u80fd\u3002"}}
{"id": "2511.15757", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15757", "abs": "https://arxiv.org/abs/2511.15757", "authors": ["Kareem Shehada", "Yifan Wu", "Wyatt D. Feng", "Adithya Iyer", "Gryphon Kumfert", "Yangruibo Ding", "Zhiyun Qian"], "title": "Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling", "summary": "Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on userspace applications and overlook the complexities of kernel-space debugging and repair. The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions. Prior efforts such as KGym and CrashFixer have highlighted the difficulty of APR in this domain, reporting low success rates or relying on costly and complex pipelines and pricey cloud infrastructure. In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. Built on RGym, we propose a simple yet effective APR pipeline leveraging specialized localization techniques (e.g., call stacks and blamed commits) to overcome the unrealistic usage of oracles in KGym. We test on a filtered and verified dataset of 143 bugs. Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug. We further conduct an ablation study to analyze contributions from our proposed localization strategy, prompt structure, and model choice, and demonstrate that feedback-based retries can significantly enhance success rates.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RGym\uff0c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u5e73\u53f0\u65e0\u5173\u7684Linux\u5185\u6838\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u57fa\u4e8e\u8be5\u6846\u67b6\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u9ad8\u6548\u4f4e\u6210\u672c\u7684APR\u6d41\u7a0b\uff0c\u5728143\u4e2a\u771f\u5b9e\u5185\u6838\u7f3a\u9677\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad843.36%\u7684\u4fee\u590d\u6210\u529f\u7387\uff0c\u5355\u6b21\u4fee\u590d\u6210\u672c\u4f4e\u4e8e0.2\u7f8e\u5143\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u57fa\u51c6\uff08\u5982SWE-Bench\uff09\u4e3b\u8981\u5173\u6ce8\u7528\u6237\u7a7a\u95f4\u5e94\u7528\uff0c\u5ffd\u89c6\u4e86\u5185\u6838\u7a7a\u95f4\u8c03\u8bd5\u4e0e\u4fee\u590d\u7684\u590d\u6742\u6027\uff1b\u800cLinux\u5185\u6838\u56e0\u5176\u5355\u4f53\u5185\u6838\u7ed3\u6784\u3001\u5e76\u53d1\u6027\u548c\u5e95\u5c42\u786c\u4ef6\u4ea4\u4e92\u7b49\u7279\u70b9\uff0c\u7ed9APR\u5e26\u6765\u72ec\u7279\u6311\u6218\u3002\u6b64\u524d\u65b9\u6cd5\u5982KGym\u548cCrashFixer\u6216\u6210\u529f\u7387\u4f4e\uff0c\u6216\u4f9d\u8d56\u6602\u8d35\u590d\u6742\u7684\u4e91\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86RGym\u6846\u67b6\uff0c\u53ef\u5728\u672c\u5730\u666e\u901a\u786c\u4ef6\u4e0a\u8fd0\u884c\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u4e13\u7528\u5b9a\u4f4d\u6280\u672f\uff08\u5982\u8c03\u7528\u6808\u548c\u5f52\u8d23\u63d0\u4ea4\uff09\u7684\u7b80\u5355\u6709\u6548APR\u6d41\u7a0b\uff0c\u907f\u514dKGym\u4e2d\u4e0d\u5207\u5b9e\u9645\u7684\u9884\u8a00\u673a\u4f7f\u7528\uff1b\u540c\u65f6\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u5b9a\u4f4d\u7b56\u7565\u3001\u63d0\u793a\u7ed3\u6784\u548c\u6a21\u578b\u9009\u62e9\u7684\u5f71\u54cd\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u53cd\u9988\u7684\u91cd\u8bd5\u673a\u5236\u3002", "result": "\u5728143\u4e2a\u7ecf\u8fc7\u7b5b\u9009\u9a8c\u8bc1\u7684Linux\u5185\u6838\u7f3a\u9677\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528GPT-5 Thinking\u6a21\u578b\u8fbe\u5230\u6700\u9ad843.36%\u7684\u901a\u8fc7\u7387\uff0c\u5355\u7f3a\u9677\u4fee\u590d\u6210\u672c\u4f4e\u4e8e0.20\u7f8e\u5143\uff1b\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u6240\u63d0\u5b9a\u4f4d\u7b56\u7565\u548c\u53cd\u9988\u91cd\u8bd5\u663e\u8457\u63d0\u5347\u4fee\u590d\u6548\u679c\u3002", "conclusion": "RGym\u4e3aLinux\u5185\u6838APR\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u91cf\u3001\u4f4e\u6210\u672c\u4e14\u9ad8\u6548\u7684\u8bc4\u4f30\u4e0e\u4fee\u590d\u65b9\u6848\uff0c\u8bc1\u660e\u5728\u672c\u5730\u786c\u4ef6\u4e0a\u5b9e\u73b0\u9ad8\u6027\u80fd\u5185\u6838\u4fee\u590d\u662f\u53ef\u884c\u7684\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5b9a\u4f4d\u4fe1\u606f\u548c\u6a21\u578b\u4ea4\u4e92\u7b56\u7565\u5bf9\u4fee\u590d\u6210\u529f\u7387\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2511.15957", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.15957", "abs": "https://arxiv.org/abs/2511.15957", "authors": ["Nasit S Sony", "Xianzhong Ding"], "title": "Optimizing Communication in Byzantine Agreement Protocols with Slim-HBBFT", "comment": "4", "summary": "Byzantine agreement protocols in asynchronous networks have received renewed interest because they do not rely on network behavior to achieve termination. Conventional asynchronous Byzantine agreement protocols require every party to broadcast its requests (e.g., transactions), and at the end of the protocol, parties agree on one party's request. If parties agree on one party's requests while exchanging every party's request, the protocol becomes expensive. These protocols are used to design an atomic broadcast (ABC) protocol where parties agree on $\\langle n-f \\rangle$ parties' requests (assuming $n=3f+1$, where $n$ is the total number of parties, and $f$ is the number of Byzantine parties). Although the parties agree on a subset of requests in the ABC protocol, if the requests do not vary (are duplicated), investing in a costly protocol is not justified. We propose Slim-HBBFT, an atomic broadcast protocol that considers requests from a fraction of $n$ parties and improves communication complexity by a factor of $O(n)$. At the core of our design is a prioritized provable-broadcast (P-PB) protocol that generates proof of broadcast only for selected parties. We use the P-PB protocol to design the Slim-HBBFT atomic broadcast protocol. Additionally, we conduct a comprehensive security analysis to demonstrate that Slim-HBBFT satisfies the properties of the Asynchronous Common Subset protocol, ensuring robust security and reliability.", "AI": {"tldr": "Slim-HBBFT \u662f\u4e00\u79cd\u65b0\u578b\u539f\u5b50\u5e7f\u64ad\u534f\u8bae\uff0c\u901a\u8fc7\u4ec5\u5904\u7406\u90e8\u5206\u53c2\u4e0e\u65b9\u7684\u8bf7\u6c42\u5e76\u5f15\u5165\u4f18\u5148\u53ef\u8bc1\u660e\u5e7f\u64ad\uff08P-PB\uff09\u673a\u5236\uff0c\u5c06\u901a\u4fe1\u590d\u6742\u5ea6\u964d\u4f4e O(n) \u500d\uff0c\u540c\u65f6\u4fdd\u8bc1\u5f02\u6b65\u901a\u7528\u5b50\u96c6\u534f\u8bae\u6240\u9700\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edf\u5f02\u6b65\u62dc\u5360\u5ead\u5bb9\u9519\u534f\u8bae\u8981\u6c42\u6240\u6709\u53c2\u4e0e\u65b9\u5e7f\u64ad\u5176\u8bf7\u6c42\uff0c\u5373\u4f7f\u6700\u7ec8\u53ea\u5c31\u67d0\u4e00\u65b9\u6216\u90e8\u5206\u8bf7\u6c42\u8fbe\u6210\u4e00\u81f4\uff0c\u4e5f\u4f1a\u9020\u6210\u9ad8\u6602\u901a\u4fe1\u5f00\u9500\uff1b\u5c24\u5176\u5f53\u8bf7\u6c42\u91cd\u590d\u65f6\uff0c\u8fd9\u79cd\u4ee3\u4ef7\u4e0d\u5408\u7406\u3002\u56e0\u6b64\u9700\u8981\u66f4\u9ad8\u6548\u7684\u539f\u5b50\u5e7f\u64ad\u534f\u8bae\u3002", "method": "\u63d0\u51fa Slim-HBBFT \u534f\u8bae\uff0c\u6838\u5fc3\u662f\u4f18\u5148\u53ef\u8bc1\u660e\u5e7f\u64ad\uff08P-PB\uff09\u534f\u8bae\uff0c\u4ec5\u5bf9\u9009\u5b9a\u53c2\u4e0e\u65b9\u751f\u6210\u5e7f\u64ad\u8bc1\u660e\uff0c\u5e76\u4ee5\u6b64\u6784\u5efa\u539f\u5b50\u5e7f\u64ad\u534f\u8bae\u3002", "result": "Slim-HBBFT \u5728\u4fdd\u6301\u5b89\u5168\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u5c06\u901a\u4fe1\u590d\u6742\u5ea6\u964d\u4f4e\u4e86 O(n) \u500d\uff0c\u5e76\u6ee1\u8db3\u5f02\u6b65\u901a\u7528\u5b50\u96c6\u534f\u8bae\u7684\u5c5e\u6027\u3002", "conclusion": "Slim-HBBFT \u6709\u6548\u4f18\u5316\u4e86\u5f02\u6b65\u62dc\u5360\u5ead\u539f\u5b50\u5e7f\u64ad\u7684\u6548\u7387\uff0c\u5728\u8bf7\u6c42\u91cd\u590d\u6216\u65e0\u9700\u5168\u7f51\u5e7f\u64ad\u573a\u666f\u4e0b\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u540c\u65f6\u901a\u8fc7\u4e25\u683c\u5b89\u5168\u5206\u6790\u9a8c\u8bc1\u5176\u53ef\u9760\u6027\u3002"}}
{"id": "2511.15817", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15817", "abs": "https://arxiv.org/abs/2511.15817", "authors": ["Alejandro Velasco", "Daniel Rodriguez-Cardenas", "Dipin Khati", "David N. Palacio", "Luftar Rahman Alif", "Denys Poshyvanyk"], "title": "A Causal Perspective on Measuring, Explaining and Mitigating Smells in \\llm-Generated Code", "comment": null, "summary": "Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.\n  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u201c\u4ee3\u7801\u5f02\u5473\u201d\u95ee\u9898\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u540d\u4e3aPSC\uff08Propensity Smelly Score\uff09\u7684\u6307\u6807\uff0c\u7528\u4e8e\u8861\u91cf\u548c\u89e3\u91ca\u5f02\u5473\u503e\u5411\uff0c\u5e76\u636e\u6b64\u63a2\u7d22\u7f13\u89e3\u7b56\u7565\u3002\u7814\u7a76\u53d1\u73b0\u63d0\u793a\u8bbe\u8ba1\u548c\u6a21\u578b\u67b6\u6784\u5bf9\u5f02\u5473\u4ea7\u751f\u5177\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\uff0c\u4e14PSC\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u8bc4\u4f30\u4ee3\u7801\u8d28\u91cf\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5176\u751f\u6210\u4ee3\u7801\u5e38\u5305\u542b\u4e0d\u826f\u7f16\u7a0b\u5b9e\u8df5\uff0c\u5373\u201c\u4ee3\u7801\u5f02\u5473\u201d\uff0c\u5f71\u54cd\u4ee3\u7801\u7684\u53ef\u8bfb\u6027\u3001\u53ef\u7ef4\u62a4\u6027\u548c\u8bbe\u8ba1\u5b8c\u6574\u6027\u3002\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u4e8e\u68c0\u6d4b\u6216\u4fee\u590d\u5f02\u5473\uff0c\u7f3a\u4e4f\u5bf9\u5176\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u5982\u4f55\u53ca\u4f55\u65f6\u51fa\u73b0\u7684\u7cfb\u7edf\u7406\u89e3\u3002", "method": "\u4f5c\u8005\u57fa\u4e8ePSC\uff08\u4e00\u79cd\u4f30\u8ba1\u751f\u6210\u7279\u5b9a\u7c7b\u578b\u5f02\u5473\u53ef\u80fd\u6027\u7684\u6982\u7387\u6307\u6807\uff09\uff0c\u5c06\u5176\u4f5c\u4e3a\u56e0\u679c\u5206\u6790\u5de5\u5177\uff0c\u7cfb\u7edf\u6d4b\u91cf\u5e76\u89e3\u91ca\u4e0d\u540c\u56e0\u7d20\uff08\u5982\u751f\u6210\u7b56\u7565\u3001\u6a21\u578b\u89c4\u6a21\u3001\u67b6\u6784\u548c\u63d0\u793a\u8bbe\u8ba1\uff09\u5bf9\u4ee3\u7801\u7ed3\u6784\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u7f13\u89e3\u7b56\u7565\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1PSC\u5bf9\u5f00\u53d1\u8005\u5224\u65ad\u7684\u652f\u6301\u4f5c\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u63d0\u793a\u8bbe\u8ba1\u548c\u6a21\u578b\u67b6\u6784\u5bf9\u5f02\u5473\u503e\u5411\u8d77\u51b3\u5b9a\u6027\u4f5c\u7528\uff1b\u63d0\u51fa\u7684\u7f13\u89e3\u7b56\u7565\u80fd\u6709\u6548\u51cf\u5c11\u5f02\u5473\u53d1\u751f\uff1b\u7528\u6237\u7814\u7a76\u8868\u660ePSC\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u7406\u89e3\u548c\u8bc4\u4f30\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u5c06\u8d28\u91cf\u611f\u77e5\u8bc4\u4f30\u6574\u5408\u5230\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u751f\u6210\u7684\u8bc4\u4f30\u4e0e\u90e8\u7f72\u6d41\u7a0b\u4e2d\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86\u5728\u6a21\u578b\u4f7f\u7528\u4e2d\u8003\u8651\u7ed3\u6784\u6027\u8d28\u91cf\u95ee\u9898\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.15852", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15852", "abs": "https://arxiv.org/abs/2511.15852", "authors": ["Monu Sharma"], "title": "AI-Enabled Orchestration of Event-Driven Business Processes in Workday ERP for Healthcare Enterprises", "comment": "10 Pages, 6 figures , 2 Tables", "summary": "The adoption of cloud-based Enterprise Resource Planning (ERP) platforms such as Workday has transformed healthcare operations by integrating financial, supply-chain, and workforce processes into a unified ecosystem. However, traditional workflow logic in ERP systems often lacks the adaptability required to manage event-driven and data-intensive healthcare environments.\n  This study proposes an AI-enabled event-driven orchestration framework within Workday ERP that intelligently synchronizes financial and supply-chain workflows across distributed healthcare entities. The framework employs machine-learning triggers, anomaly detection, and process mining analytics to anticipate and automate responses to operational events such as inventory depletion, payment delays, or patient demand fluctuations. A multi-organization case analysis demonstrates measurable gains in process efficiency, cost visibility, and decision accuracy.\n  Results confirm that embedding AI capabilities into Workday's event-based architecture enhances operational resilience, governance, and scalability. The proposed model contributes to the broader understanding of intelligent ERP integration and establishes a reference for next-generation automation strategies in healthcare enterprises.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728Workday ERP\u4e2d\u5d4c\u5165AI\u80fd\u529b\u7684\u4e8b\u4ef6\u9a71\u52a8\u578b\u7f16\u6392\u6846\u67b6\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u89e6\u53d1\u5668\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u6d41\u7a0b\u6316\u6398\u6280\u672f\uff0c\u5b9e\u73b0\u533b\u7597\u73af\u5883\u4e2d\u8d22\u52a1\u4e0e\u4f9b\u5e94\u94fe\u5de5\u4f5c\u6d41\u7684\u667a\u80fd\u540c\u6b65\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fd0\u8425\u6548\u7387\u4e0e\u51b3\u7b56\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edfERP\u7cfb\u7edf\u7684\u5de5\u4f5c\u6d41\u903b\u8f91\u96be\u4ee5\u9002\u5e94\u533b\u7597\u884c\u4e1a\u9ad8\u5ea6\u6570\u636e\u9a71\u52a8\u548c\u4e8b\u4ef6\u5bc6\u96c6\u7684\u8fd0\u8425\u73af\u5883\uff0c\u4e9f\u9700\u66f4\u5177\u9002\u5e94\u6027\u7684\u667a\u80fd\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5728Workday ERP\u5e73\u53f0\u4e2d\u6784\u5efaAI\u9a71\u52a8\u7684\u4e8b\u4ef6\u9a71\u52a8\u7f16\u6392\u6846\u67b6\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u89e6\u53d1\u5668\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u6d41\u7a0b\u6316\u6398\u5206\u6790\uff0c\u81ea\u52a8\u54cd\u5e94\u5e93\u5b58\u8017\u5c3d\u3001\u4ed8\u6b3e\u5ef6\u8fdf\u548c\u60a3\u8005\u9700\u6c42\u6ce2\u52a8\u7b49\u8fd0\u8425\u4e8b\u4ef6\u3002", "result": "\u591a\u673a\u6784\u6848\u4f8b\u5206\u6790\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u6d41\u7a0b\u6548\u7387\u3001\u6210\u672c\u53ef\u89c1\u6027\u548c\u51b3\u7b56\u51c6\u786e\u6027\uff0c\u5e76\u589e\u5f3a\u4e86\u7cfb\u7edf\u7684\u8fd0\u8425\u97e7\u6027\u3001\u6cbb\u7406\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u5c06AI\u80fd\u529b\u5d4c\u5165Workday\u7684\u4e8b\u4ef6\u9a71\u52a8\u67b6\u6784\u53ef\u6709\u6548\u63d0\u5347\u533b\u7597\u4f01\u4e1aERP\u7cfb\u7edf\u7684\u667a\u80fd\u5316\u6c34\u5e73\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u533b\u7597\u81ea\u52a8\u5316\u7b56\u7565\u63d0\u4f9b\u53c2\u8003\u6a21\u578b\u3002"}}
{"id": "2511.15859", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15859", "abs": "https://arxiv.org/abs/2511.15859", "authors": ["Hina Saeeda", "Mazen Mohamad", "Eric Knauss", "Jennifer Horkoff", "Ali Nouri"], "title": "RE for AI in Practice: Managing Data Annotation Requirements for AI Autonomous Driving Systems", "comment": null, "summary": "High-quality data annotation requirements are crucial for the development of safe and reliable AI-enabled perception systems (AIePS) in autonomous driving. Although these requirements play a vital role in reducing bias and enhancing performance, their formulation and management remain underexplored, leading to inconsistencies, safety risks, and regulatory concerns. Our study investigates how annotation requirements are defined and used in practice, the challenges in ensuring their quality, practitioner-recommended improvements, and their impact on AIePS development and performance. We conducted $19$ semi-structured interviews with participants from six international companies and four research organisations. Our thematic analysis reveals five main key challenges: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints and three main categories of best practices, including ensuring compliance with ethical standards, improving data annotation requirements guidelines, and embedded quality assurance for data annotation requirements. We also uncover critical interrelationships between annotation requirements, annotation practices, annotated data quality, and AIePS performance and development, showing how requirement flaws propagate through the AIePS development pipeline. To the best of our knowledge, this study is the first to offer empirically grounded guidance on improving annotation requirements, offering actionable insights to enhance annotation quality, regulatory compliance, and system reliability. It also contributes to the emerging fields of Software Engineering (SE for AI) and Requirements Engineering (RE for AI) by bridging the gap between RE and AI in a timely and much-needed manner.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc719\u6b21\u8bbf\u8c08\u63ed\u793a\u4e86\u81ea\u52a8\u9a7e\u9a76AI\u611f\u77e5\u7cfb\u7edf\u4e2d\u6570\u636e\u6807\u6ce8\u9700\u6c42\u7684\u4e94\u5927\u6311\u6218\uff08\u6a21\u7cca\u6027\u3001\u8fb9\u7f18\u6848\u4f8b\u590d\u6742\u6027\u3001\u9700\u6c42\u6f14\u53d8\u3001\u4e0d\u4e00\u81f4\u6027\u3001\u8d44\u6e90\u9650\u5236\uff09\u548c\u4e09\u7c7b\u6700\u4f73\u5b9e\u8df5\uff08\u4f26\u7406\u5408\u89c4\u3001\u6539\u8fdb\u6307\u5357\u3001\u5d4c\u5165\u5f0f\u8d28\u91cf\u4fdd\u969c\uff09\uff0c\u5e76\u9610\u660e\u4e86\u6807\u6ce8\u9700\u6c42\u5982\u4f55\u5f71\u54cd\u6574\u4e2aAI\u7cfb\u7edf\u5f00\u53d1\u6d41\u7a0b\u3002", "motivation": "\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u6807\u6ce8\u9700\u6c42\u5bf9\u5f00\u53d1\u5b89\u5168\u53ef\u9760\u7684\u81ea\u52a8\u9a7e\u9a76AI\u611f\u77e5\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u5236\u5b9a\u4e0e\u7ba1\u7406\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u5bfc\u81f4\u4e0d\u4e00\u81f4\u3001\u5b89\u5168\u9690\u60a3\u548c\u76d1\u7ba1\u95ee\u9898\u3002", "method": "\u5bf9\u6765\u81ea\u516d\u5bb6\u56fd\u9645\u516c\u53f8\u548c\u56db\u5bb6\u7814\u7a76\u673a\u6784\u768419\u540d\u4ece\u4e1a\u8005\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u5e76\u91c7\u7528\u4e3b\u9898\u5206\u6790\u6cd5\u63d0\u70bc\u5173\u952e\u53d1\u73b0\u3002", "result": "\u8bc6\u522b\u51fa\u4e94\u5927\u5173\u952e\u6311\u6218\u548c\u4e09\u7c7b\u6700\u4f73\u5b9e\u8df5\uff0c\u63ed\u793a\u4e86\u6807\u6ce8\u9700\u6c42\u3001\u6807\u6ce8\u5b9e\u8df5\u3001\u6570\u636e\u8d28\u91cf\u548cAI\u7cfb\u7edf\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u952e\u76f8\u4e92\u5173\u7cfb\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u63d0\u4f9b\u4e86\u57fa\u4e8e\u5b9e\u8bc1\u7684\u6807\u6ce8\u9700\u6c42\u6539\u8fdb\u5efa\u8bae\uff0c\u4e3a\u63d0\u5347\u6807\u6ce8\u8d28\u91cf\u3001\u5408\u89c4\u6027\u548c\u7cfb\u7edf\u53ef\u9760\u6027\u63d0\u4f9b\u53ef\u884c\u6d1e\u89c1\uff0c\u5e76\u63a8\u52a8\u4e86AI\u9886\u57df\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4e0e\u9700\u6c42\u5de5\u7a0b\u53d1\u5c55\u3002"}}
{"id": "2511.16177", "categories": ["cs.DC", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.16177", "abs": "https://arxiv.org/abs/2511.16177", "authors": ["Thomas Collignon", "Kouds Halitim", "Rapha\u00ebl Bleuse", "Sophie Cerf", "Bogdan Robu", "\u00c9ric Rutten", "Lionel Seinturier", "Alexandre van Kempen"], "title": "Mitigating Shared Storage Congestion Using Control Theory", "comment": null, "summary": "Efficient data access in High-Performance Computing (HPC) systems is essential to the performance of intensive computing tasks. Traditional optimizations of the I/O stack aim to improve peak performance but are often workload specific and require deep expertise, making them difficult to generalize or re-use. In shared HPC environments, resource congestion can lead to unpredictable performance, causing slowdowns and timeouts. To address these challenges, we propose a self-adaptive approach based on Control Theory to dynamically regulate client-side I/O rates. Our approach leverages a small set of runtime system load metrics to reduce congestion and enhance performance stability. We implement a controller in a multi-node cluster and evaluate it on a real testbed under a representative workload. Experimental results demonstrate that our method effectively mitigates I/O congestion, reducing total runtime by up to 20% and lowering tail latency, while maintaining stable performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u63a7\u5236\u7406\u8bba\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u8282\u5ba2\u6237\u7aefI/O\u901f\u7387\u6765\u7f13\u89e3HPC\u7cfb\u7edf\u4e2d\u7684I/O\u62e5\u585e\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u9a8c\u8bc1\u4e86\u5176\u53ef\u51cf\u5c11\u6700\u591a20%\u603b\u8fd0\u884c\u65f6\u95f4\u5e76\u964d\u4f4e\u5c3e\u90e8\u5ef6\u8fdf\u3002", "motivation": "\u4f20\u7edfI/O\u6808\u4f18\u5316\u65b9\u6cd5\u901a\u5e38\u9488\u5bf9\u7279\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u3001\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\uff0c\u96be\u4ee5\u6cdb\u5316\uff1b\u5728\u5171\u4eabHPC\u73af\u5883\u4e2d\uff0c\u8d44\u6e90\u4e89\u7528\u5bfc\u81f4\u6027\u80fd\u4e0d\u53ef\u9884\u6d4b\uff0c\u51fa\u73b0\u51cf\u901f\u548c\u8d85\u65f6\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u63a7\u5236\u7406\u8bba\u8bbe\u8ba1\u81ea\u9002\u5e94\u63a7\u5236\u5668\uff0c\u5229\u7528\u5c11\u91cf\u8fd0\u884c\u65f6\u7cfb\u7edf\u8d1f\u8f7d\u6307\u6807\u52a8\u6001\u8c03\u8282\u5ba2\u6237\u7aefI/O\u901f\u7387\uff0c\u4ee5\u51cf\u8f7b\u62e5\u585e\u5e76\u63d0\u5347\u6027\u80fd\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u591a\u8282\u70b9\u96c6\u7fa4\u7684\u771f\u5b9e\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u7f13\u89e3I/O\u62e5\u585e\uff0c\u6700\u591a\u51cf\u5c1120%\u603b\u8fd0\u884c\u65f6\u95f4\uff0c\u540c\u65f6\u964d\u4f4e\u5c3e\u90e8\u5ef6\u8fdf\u5e76\u4fdd\u6301\u6027\u80fd\u7a33\u5b9a\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94I/O\u8c03\u63a7\u65b9\u6cd5\u80fd\u6709\u6548\u5e94\u5bf9HPC\u73af\u5883\u4e2d\u7684\u6027\u80fd\u6ce2\u52a8\u95ee\u9898\uff0c\u5177\u6709\u826f\u597d\u7684\u5b9e\u7528\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.16182", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2511.16182", "abs": "https://arxiv.org/abs/2511.16182", "authors": ["Giuseppe Tomei", "Andrea Mayer", "Giuseppe Alcini", "Stefano Salsano"], "title": "Green Distributed AI Training: Orchestrating Compute Across Renewable-Powered Micro Datacenters", "comment": "Extended version of a paper submitted - v01 November 2025", "summary": "The accelerating expansion of AI workloads is colliding with an energy landscape increasingly dominated by intermittent renewable generation. While vast quantities of zero-carbon energy are routinely curtailed, today's centralized datacenter architectures remain poorly matched to this reality in both energy proportionality and geographic flexibility. This work envisions a shift toward a distributed fabric of renewable-powered micro-datacenters that dynamically follow the availability of surplus green energy through live workload migration.\n  At the core of this vision lies a formal feasibility-domain model that delineates when migratory AI computation is practically achievable. By explicitly linking checkpoint size, wide-area bandwidth, and renewable-window duration, the model reveals that migration is almost always energetically justified, and that time-not energy-is the dominant constraint shaping feasibility. This insight enables the design of a feasibility-aware orchestration framework that transforms migration from a best-effort heuristic into a principled control mechanism. Trace-driven evaluation shows that such orchestration can simultaneously reduce non-renewable energy use and improve performance stability, overcoming the tradeoffs of purely energy-driven strategies.\n  Beyond the immediate feasibility analysis, the extended version explores the architectural horizon of renewable-aware AI infrastructures. It examines the role of emerging ultra-efficient GPU-enabled edge platforms, anticipates integration with grid-level control and demand-response ecosystems, and outlines paths toward supporting partially migratable and distributed workloads. The work positions feasibility-aware migration as a foundational building block for a future computing paradigm in which AI execution becomes fluid, geographically adaptive, and aligned with renewable energy availability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u53ef\u518d\u751f\u80fd\u6e90\u7684\u5206\u5e03\u5f0f\u5fae\u6570\u636e\u4e2d\u5fc3\u67b6\u6784\uff0c\u901a\u8fc7\u53ef\u884c\u6027\u611f\u77e5\u7684\u5b9e\u65f6\u8fc1\u79fb\u673a\u5236\uff0c\u4f7fAI\u5de5\u4f5c\u8d1f\u8f7d\u52a8\u6001\u8ffd\u8e2a\u7eff\u8272\u80fd\u6e90\u76c8\u4f59\uff0c\u5728\u964d\u4f4e\u975e\u53ef\u518d\u751f\u80fd\u8017\u7684\u540c\u65f6\u63d0\u5347\u6027\u80fd\u7a33\u5b9a\u6027\u3002", "motivation": "\u5f53\u524d\u96c6\u4e2d\u5f0f\u6570\u636e\u4e2d\u5fc3\u5728\u80fd\u6e90\u6bd4\u4f8b\u6027\u548c\u5730\u7406\u7075\u6d3b\u6027\u65b9\u9762\u96be\u4ee5\u9002\u914d\u4ee5\u95f4\u6b47\u6027\u53ef\u518d\u751f\u80fd\u6e90\u4e3a\u4e3b\u7684\u80fd\u6e90\u683c\u5c40\uff0c\u5bfc\u81f4\u5927\u91cf\u96f6\u78b3\u80fd\u6e90\u88ab\u5f03\u7528\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u5f62\u5f0f\u5316\u7684\u53ef\u884c\u6027\u57df\u6a21\u578b\uff0c\u5c06\u68c0\u67e5\u70b9\u5927\u5c0f\u3001\u5e7f\u57df\u5e26\u5bbd\u548c\u53ef\u518d\u751f\u7a97\u53e3\u65f6\u957f\u5173\u8054\u8d77\u6765\uff0c\u5e76\u636e\u6b64\u8bbe\u8ba1\u53ef\u884c\u6027\u611f\u77e5\u7684\u7f16\u6392\u6846\u67b6\uff0c\u5b9e\u73b0AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u52a8\u6001\u8fc1\u79fb\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u8f68\u8ff9\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u540c\u65f6\u51cf\u5c11\u975e\u53ef\u518d\u751f\u80fd\u6e90\u4f7f\u7528\u5e76\u63d0\u9ad8\u6027\u80fd\u7a33\u5b9a\u6027\uff0c\u4f18\u4e8e\u7eaf\u80fd\u8017\u9a71\u52a8\u7b56\u7565\uff1b\u6269\u5c55\u90e8\u5206\u8fd8\u63a2\u8ba8\u4e86\u9762\u5411\u672a\u6765\u7684\u53ef\u518d\u751f\u80fd\u6e90\u611f\u77e5AI\u57fa\u7840\u8bbe\u65bd\u67b6\u6784\u3002", "conclusion": "\u53ef\u884c\u6027\u611f\u77e5\u8fc1\u79fb\u662f\u6784\u5efa\u672a\u6765AI\u8ba1\u7b97\u8303\u5f0f\u7684\u5173\u952e\u57fa\u77f3\uff0c\u53ef\u4f7fAI\u6267\u884c\u5177\u5907\u6d41\u52a8\u6027\u3001\u5730\u7406\u9002\u5e94\u6027\uff0c\u5e76\u4e0e\u53ef\u518d\u751f\u80fd\u6e90\u4f9b\u5e94\u5bf9\u9f50\u3002"}}
{"id": "2511.16004", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16004", "abs": "https://arxiv.org/abs/2511.16004", "authors": ["KeFan Li", "Mengfei Wang", "Hengzhi Zhang", "Zhichao Li", "Yuan Yuan", "Mu Li", "Xiang Gao", "Hailong Sun", "Chunming Hu", "Weifeng Lv"], "title": "InfCode: Adversarial Iterative Refinement of Tests and Patches for Reliable Software Issue Resolution", "comment": null, "summary": "Large language models have advanced software engineering automation, yet resolving real-world software issues remains difficult because it requires repository-level reasoning, accurate diagnostics, and strong verification signals. Existing agent-based and pipeline-based methods often rely on insufficient tests, which can lead to patches that satisfy verification but fail to fix the underlying defect. We present InfCode, an adversarial multi-agent framework for automated repository-level issue resolution. InfCode iteratively refines both tests and patches through adversarial interaction between a Test Patch Generator and a Code Patch Generator, while a Selector agent identifies the most reliable fix. The framework runs inside a containerized environment that supports realistic repository inspection, modification, and validation. Experiments on SWE-bench Lite and SWE-bench Verified using models such as DeepSeek-V3 and Claude 4.5 Sonnet show that InfCode consistently outperforms strong baselines. It achieves 79.4% performance on SWE-bench Verified, establishing a new state-of-the-art. We have released InfCode as an open-source project at https://github.com/Tokfinity/InfCode.", "AI": {"tldr": "InfCode \u662f\u4e00\u4e2a\u57fa\u4e8e\u5bf9\u6297\u591a\u667a\u80fd\u4f53\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u6d4b\u8bd5\u751f\u6210\u5668\u4e0e\u4ee3\u7801\u8865\u4e01\u751f\u6210\u5668\u7684\u5bf9\u6297\u4ea4\u4e92\uff0c\u8fed\u4ee3\u4f18\u5316\u6d4b\u8bd5\u4e0e\u8865\u4e01\uff0c\u5e76\u5728\u5bb9\u5668\u5316\u73af\u5883\u4e2d\u5b9e\u73b0\u4ed3\u5e93\u7ea7\u95ee\u9898\u4fee\u590d\uff0c\u5728 SWE-bench Verified \u4e0a\u8fbe\u5230 79.4% \u7684\u65b0 SOTA\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u667a\u80fd\u4f53\u6216\u6d41\u6c34\u7ebf\u7684\u65b9\u6cd5\u5e38\u4f9d\u8d56\u4e0d\u5145\u5206\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u8865\u4e01\u867d\u901a\u8fc7\u9a8c\u8bc1\u5374\u672a\u771f\u6b63\u4fee\u590d\u7f3a\u9677\uff1b\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u8fdb\u884c\u4ed3\u5e93\u7ea7\u63a8\u7406\u3001\u51c6\u786e\u8bca\u65ad\u5e76\u63d0\u4f9b\u5f3a\u9a8c\u8bc1\u4fe1\u53f7\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa InfCode \u6846\u67b6\uff0c\u5305\u542b\u6d4b\u8bd5\u8865\u4e01\u751f\u6210\u5668\u3001\u4ee3\u7801\u8865\u4e01\u751f\u6210\u5668\u548c\u9009\u62e9\u5668\u4e09\u4e2a\u667a\u80fd\u4f53\uff0c\u5728\u5bb9\u5668\u5316\u73af\u5883\u4e2d\u901a\u8fc7\u5bf9\u6297\u673a\u5236\u8fed\u4ee3\u4f18\u5316\u6d4b\u8bd5\u4e0e\u8865\u4e01\uff0c\u6700\u7ec8\u7531\u9009\u62e9\u5668\u9009\u51fa\u6700\u53ef\u9760\u7684\u4fee\u590d\u65b9\u6848\u3002", "result": "\u5728 SWE-bench Lite \u548c SWE-bench Verified \u57fa\u51c6\u4e0a\u4f7f\u7528 DeepSeek-V3 \u548c Claude 4.5 Sonnet \u7b49\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0cInfCode \u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728 SWE-bench Verified \u4e0a\u8fbe\u5230 79.4% \u7684\u89e3\u51b3\u7387\u3002", "conclusion": "InfCode \u901a\u8fc7\u5bf9\u6297\u591a\u667a\u80fd\u4f53\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u4ed3\u5e93\u7ea7\u8f6f\u4ef6\u95ee\u9898\u81ea\u52a8\u4fee\u590d\u7684\u51c6\u786e\u6027\u4e0e\u53ef\u9760\u6027\uff0c\u662f\u5f53\u524d\u8be5\u4efb\u52a1\u4e0a\u7684\u6700\u4f18\u65b9\u6cd5\uff0c\u5e76\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.16193", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16193", "abs": "https://arxiv.org/abs/2511.16193", "authors": ["Rongxin Cheng", "Kai Zhou", "Xingda Wei", "Siyuan Liu", "Mingcong Han", "Mingjing Ai", "Yeju Zhou", "Baoquan Zhong", "Wencong Xiao", "Xin Liu", "Rong Chen", "Haibo Chen"], "title": "Fast LLM Post-training via Decoupled and Best-of-N Speculation", "comment": null, "summary": "Rollout dominates the training time in large language model (LLM) post-training, where the trained model is used to generate tokens given a batch of prompts. SpecActor achieves fast rollout with speculative decoding that deploys a fast path (e.g., a smaller model) to accelerate the unparallelizable generation, while the correctness is guaranteed by fast parallel verification of the outputs with the original model. SpecActor addresses two foundational challenges in speculative rollout by (1) a \\emph{dynamic decoupled speculation} execution method that maximizes the GPU computational efficiency to realize speedup for large-batch execution -- a configuration common in training but unfriendly to speculative execution and (2) a \\emph{dynamic Best-of-N speculation} method that selects and combines different drafting methods according to the rollout progress. It substantially improves the speculation accuracy even when the best drafting method is unknown a priori, meanwhile without requiring adding extra computation resources. {\\sys} is {1.3--1.7}\\,$\\times$ faster than common post-training baselines, and is {1.3--1.5}\\,$\\times$ faster compared to naively adopting speculative decoding for rollout.", "AI": {"tldr": "SpecActor\u901a\u8fc7\u52a8\u6001\u89e3\u8026\u63a8\u6d4b\u548c\u52a8\u6001Best-of-N\u63a8\u6d4b\u65b9\u6cd5\uff0c\u663e\u8457\u52a0\u901f\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u4e2d\u7684rollout\u8fc7\u7a0b\uff0c\u5728\u4e0d\u589e\u52a0\u989d\u5916\u8ba1\u7b97\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\uff0c\u6bd4\u5e38\u89c4\u57fa\u7ebf\u5feb1.3\u20131.7\u500d\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u4e2drollout\u9636\u6bb5\u8017\u65f6\u4e25\u91cd\uff0c\u800c\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u5728\u5927\u6279\u91cf\u8bad\u7ec3\u573a\u666f\u4e0b\u6548\u7387\u4f4e\u4e0b\u4e14\u96be\u4ee5\u4fdd\u8bc1\u63a8\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faSpecActor\u6846\u67b6\uff0c\u5305\u542b\uff081\uff09\u52a8\u6001\u89e3\u8026\u63a8\u6d4b\u6267\u884c\u65b9\u6cd5\uff0c\u63d0\u5347GPU\u8ba1\u7b97\u6548\u7387\u4ee5\u9002\u914d\u5927\u6279\u91cf\u573a\u666f\uff1b\uff082\uff09\u52a8\u6001Best-of-N\u63a8\u6d4b\u65b9\u6cd5\uff0c\u6839\u636erollout\u8fdb\u5ea6\u52a8\u6001\u9009\u62e9\u5e76\u7ec4\u5408\u4e0d\u540c\u8349\u7a3f\u6a21\u578b\uff0c\u63d0\u9ad8\u63a8\u6d4b\u51c6\u786e\u6027\u3002", "result": "SpecActor\u6bd4\u5e38\u89c4\u540e\u8bad\u7ec3\u57fa\u7ebf\u5feb1.3\u20131.7\u500d\uff0c\u6bd4\u76f4\u63a5\u5e94\u7528\u63a8\u6d4b\u89e3\u7801\u7684\u65b9\u6cd5\u5feb1.3\u20131.5\u500d\u3002", "conclusion": "SpecActor\u6709\u6548\u89e3\u51b3\u4e86\u63a8\u6d4brollout\u4e2d\u7684\u4e24\u5927\u6838\u5fc3\u6311\u6218\uff0c\u5728\u4e0d\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2511.16450", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.16450", "abs": "https://arxiv.org/abs/2511.16450", "authors": ["Ziyue Xu", "Zhihong Zhang", "Holger R. Roth", "Chester Chen", "Yan Cheng", "Andrew Feng"], "title": "Optimizing Federated Learning in the Era of LLMs: Message Quantization and Streaming", "comment": "FLLM 2025", "summary": "Federated Learning (FL) offers a promising solution for training machine learning models across distributed data sources while preserving data privacy. However, FL faces critical challenges related to communication overhead and local resource constraints, especially in the era of Large Language Models (LLMs) with billions of parameters. The sheer size of these models exacerbates both memory and communication constraints, making efficient transmission and processing essential for practical deployment. NVIDIA FLARE, an open-source SDK for federated learning, addresses these challenges by introducing advanced communication capabilities. Building upon existing solutions for large object streaming, we enhance FL workflows for LLMs through two key techniques: message quantization and container/file streaming. Quantization reduces message size, while streaming enables efficient memory management, improving scalability and integration with existing workflows. These advancements significantly enhance the robustness and efficiency of FL with LLMs, ensuring better performance in real-world federated learning scenarios.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u4e2d\u9762\u4e34\u7684\u901a\u4fe1\u5f00\u9500\u548c\u8d44\u6e90\u9650\u5236\u95ee\u9898\uff0c\u63d0\u51fa\u901a\u8fc7\u6d88\u606f\u91cf\u5316\u548c\u5bb9\u5668/\u6587\u4ef6\u6d41\u5f0f\u4f20\u8f93\u4e24\u79cd\u6280\u672f\u4f18\u5316NVIDIA FLARE\u6846\u67b6\uff0c\u4ee5\u63d0\u5347FL\u5728LLM\u573a\u666f\u4e0b\u7684\u6548\u7387\u4e0e\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u53c2\u6570\u91cf\u5e9e\u5927\uff0c\u5bfc\u81f4\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u548c\u5185\u5b58\u538b\u529b\u663e\u8457\u589e\u52a0\uff0c\u4e9f\u9700\u9ad8\u6548\u4f20\u8f93\u4e0e\u5904\u7406\u673a\u5236\u4ee5\u652f\u6301\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u5728NVIDIA FLARE\u5f00\u6e90SDK\u57fa\u7840\u4e0a\uff0c\u5f15\u5165\u6d88\u606f\u91cf\u5316\u4ee5\u51cf\u5c0f\u4f20\u8f93\u6570\u636e\u91cf\uff0c\u5e76\u91c7\u7528\u5bb9\u5668/\u6587\u4ef6\u6d41\u5f0f\u4f20\u8f93\u6280\u672f\u4f18\u5316\u5185\u5b58\u7ba1\u7406\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u5927\u8bed\u8a00\u6a21\u578b\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u3001\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u66f4\u597d\u5730\u517c\u5bb9\u73b0\u6709\u5de5\u4f5c\u6d41\u3002", "conclusion": "\u901a\u8fc7\u91cf\u5316\u4e0e\u6d41\u5f0f\u4f20\u8f93\u6280\u672f\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u4e0e\u8d44\u6e90\u74f6\u9888\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.16092", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16092", "abs": "https://arxiv.org/abs/2511.16092", "authors": ["Xing Hu", "Raula Gaikovina Kula", "Christoph Treude"], "title": "The Future of Development Environments with AI Foundation Models: NII Shonan Meeting 222 Report", "comment": null, "summary": "Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222. This is the report", "AI": {"tldr": "\u672c\u6587\u62a5\u544a\u4e86Shonan Meeting 222\u4e0a33\u4f4d\u4e13\u5bb6\u5bf9\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5728\u96c6\u6210\u5f00\u53d1\u73af\u5883\uff08IDE\uff09\u4e2d\u5f71\u54cd\u7684\u8ba8\u8bba\uff0c\u63a2\u8ba8\u5176\u5e26\u6765\u7684\u6311\u6218\u4e0e\u673a\u9047\u3002", "motivation": "\u968f\u7740GenAI\u5728\u4ee3\u7801\u751f\u6210\u3001\u6d4b\u8bd5\u3001\u5ba1\u67e5\u548c\u4fee\u590d\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u5353\u8d8a\uff0c\u6709\u5fc5\u8981\u6df1\u5165\u7406\u89e3\u5176\u5982\u4f55\u6539\u53d8\u5f00\u53d1\u8005\u4e0eIDE\u4e4b\u95f4\u7684\u4eba\u673a\u4ea4\u4e92\u65b9\u5f0f\u3002", "method": "\u7ec4\u7ec7\u6765\u81ea\u8f6f\u4ef6\u5de5\u7a0b\u3001\u4eba\u5de5\u667a\u80fd\u548c\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u768433\u4f4d\u4e13\u5bb6\u53ec\u5f00Shonan Meeting 222\uff0c\u901a\u8fc7\u7814\u8ba8\u5f62\u5f0f\u5206\u6790GenAI\u5bf9IDE\u7684\u5f71\u54cd\u3002", "result": "\u4f1a\u8bae\u8bc6\u522b\u51faGenAI\u5728\u63d0\u5347\u62bd\u8c61\u5c42\u6b21\u3001\u6539\u53d8\u7f16\u7a0b\u8303\u5f0f\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u660e\u786e\u4e86\u5f53\u524d\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u4e0e\u672a\u6765\u7814\u7a76\u673a\u4f1a\u3002", "conclusion": "GenAI\u6709\u671b\u91cd\u5851IDE\u4e2d\u7684\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\uff0c\u4f46\u9700\u8de8\u5b66\u79d1\u5408\u4f5c\u89e3\u51b3\u6280\u672f\u3001\u4ea4\u4e92\u4e0e\u4f26\u7406\u7b49\u65b9\u9762\u7684\u6311\u6218\u3002"}}
{"id": "2511.16123", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16123", "abs": "https://arxiv.org/abs/2511.16123", "authors": ["Linyi Han", "Shidong Pan", "Zhenchang Xing", "Sofonias Yitagesu", "Xiaowang Zhang", "Zhiyong Feng", "Jiamou Sun", "Qing Huang"], "title": "Domain-constrained Synthesis of Inconsistent Key Aspects in Textual Vulnerability Descriptions", "comment": null, "summary": "Textual Vulnerability Descriptions (TVDs) are crucial for security analysts to understand and address software vulnerabilities. However, the key aspect inconsistencies in TVDs from different repositories pose challenges for achieving a comprehensive understanding of vulnerabilities. Existing approaches aim to mitigate inconsistencies by aligning TVDs with external knowledge bases, but they often discard valuable information and fail to synthesize comprehensive representations. In this paper, we propose a domain-constrained LLM-based synthesis framework for unifying key aspects of TVDs. Our framework consists of three stages: 1) Extraction, guided by rule-based templates to ensure all critical details are captured; 2) Self-evaluation, using domain-specific anchor words to assess semantic variability across sources; and 3) Fusion, leveraging information entropy to reconcile inconsistencies and prioritize relevant details. This framework improves synthesis performance, increasing the F1 score for key aspect augmentation from 0.82 to 0.87, while enhancing comprehension and efficiency by over 30\\%. We further develop Digest Labels, a practical tool for visualizing TVDs, which human evaluations show significantly boosts usability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9886\u57df\u7ea6\u675f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6587\u672c\u6f0f\u6d1e\u63cf\u8ff0\uff08TVD\uff09\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u53d6\u3001\u81ea\u8bc4\u4f30\u548c\u878d\u5408\u4e09\u4e2a\u9636\u6bb5\u6709\u6548\u7f13\u89e3\u4e0d\u540c\u6765\u6e90TVD\u4e2d\u7684\u5173\u952e\u4fe1\u606f\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u53ef\u89c6\u5316\u5de5\u5177Digest Labels\u4ee5\u63d0\u5347\u53ef\u7528\u6027\u3002", "motivation": "\u4e0d\u540c\u6f0f\u6d1e\u5e93\u4e2d\u7684\u6587\u672c\u6f0f\u6d1e\u63cf\u8ff0\uff08TVD\uff09\u5b58\u5728\u5173\u952e\u4fe1\u606f\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u5b89\u5168\u5206\u6790\u5e08\u5bf9\u6f0f\u6d1e\u7684\u5168\u9762\u7406\u89e3\uff1b\u73b0\u6709\u65b9\u6cd5\u5728\u5bf9\u9f50\u5916\u90e8\u77e5\u8bc6\u5e93\u65f6\u5f80\u5f80\u4e22\u5931\u6709\u4ef7\u503c\u7684\u4fe1\u606f\uff0c\u96be\u4ee5\u751f\u6210\u7efc\u5408\u6027\u8868\u793a\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4e09\u9636\u6bb5\u7684\u9886\u57df\u7ea6\u675fLLM\u5408\u6210\u6846\u67b6\uff1a1\uff09\u57fa\u4e8e\u89c4\u5219\u6a21\u677f\u7684\u63d0\u53d6\uff0c\u786e\u4fdd\u6355\u83b7\u6240\u6709\u5173\u952e\u7ec6\u8282\uff1b2\uff09\u5229\u7528\u9886\u57df\u951a\u8bcd\u8fdb\u884c\u81ea\u8bc4\u4f30\uff0c\u8861\u91cf\u8bed\u4e49\u5dee\u5f02\uff1b3\uff09\u57fa\u4e8e\u4fe1\u606f\u71b5\u8fdb\u884c\u878d\u5408\uff0c\u8c03\u548c\u4e0d\u4e00\u81f4\u6027\u5e76\u4f18\u5148\u4fdd\u7559\u76f8\u5173\u4fe1\u606f\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u53ef\u89c6\u5316\u5de5\u5177Digest Labels\u3002", "result": "\u8be5\u6846\u67b6\u5c06\u5173\u952e\u65b9\u9762\u589e\u5f3a\u7684F1\u5206\u6570\u4ece0.82\u63d0\u5347\u81f30.87\uff0c\u5e76\u4f7f\u7406\u89e3\u548c\u5904\u7406\u6548\u7387\u63d0\u5347\u8d85\u8fc730%\uff1b\u4eba\u5de5\u8bc4\u4f30\u8868\u660eDigest Labels\u663e\u8457\u63d0\u9ad8\u4e86TVD\u7684\u53ef\u7528\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86TVD\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6f0f\u6d1e\u4fe1\u606f\u7684\u7efc\u5408\u8868\u8fbe\u4e0e\u5b9e\u7528\u6027\uff0c\u4e3a\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u51c6\u786e\u7684\u652f\u6301\u3002"}}
{"id": "2511.16224", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16224", "abs": "https://arxiv.org/abs/2511.16224", "authors": ["Francesco Salzano", "Simone Scalabrino", "Rocco Oliveto", "Simone Scalabrino"], "title": "Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts", "comment": "20 pages", "summary": "Smart Contracts are critical components of blockchain ecosystems, with Solidity as the dominant programming language. While LLMs excel at general-purpose code generation, the unique constraints of Smart Contracts, such as gas consumption, security, and determinism, raise open questions about the reliability of LLM-generated Solidity code. Existing studies lack a comprehensive evaluation of these critical functional and non-functional properties. We benchmark four state-of-the-art models under zero-shot and retrieval-augmented generation settings across 500 real-world functions. Our multi-faceted assessment employs code similarity metrics, semantic embeddings, automated test execution, gas profiling, and cognitive and cyclomatic complexity analysis. Results show that while LLMs produce code with high semantic similarity to real contracts, their functional correctness is low: only 20% to 26% of zero-shot generations behave identically to ground-truth implementations under testing. The generated code is consistently simpler, with significantly lower complexity and gas consumption, often due to omitted validation logic. Retrieval-Augmented Generation markedly improves performance, boosting functional correctness by up to 45% and yielding more concise and efficient code. Our findings reveal a significant gap between semantic similarity and functional plausibility in LLM-generated Smart Contracts. We conclude that while RAG is a powerful enhancer, achieving robust, production-ready code generation remains a substantial challenge, necessitating careful expert validation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u751f\u6210Solidity\u667a\u80fd\u5408\u7ea6\u4ee3\u7801\u65f6\u7684\u529f\u80fd\u6b63\u786e\u6027\u4e0e\u975e\u529f\u80fd\u6027\u5c5e\u6027\uff08\u5982Gas\u6d88\u8017\u3001\u590d\u6742\u5ea6\u7b49\uff09\uff0c\u53d1\u73b0\u5c3d\u7ba1\u751f\u6210\u4ee3\u7801\u5728\u8bed\u4e49\u4e0a\u4e0e\u771f\u5b9e\u5408\u7ea6\u9ad8\u5ea6\u76f8\u4f3c\uff0c\u4f46\u529f\u80fd\u6b63\u786e\u7387\u4ec5\u4e3a20%-26%\uff1b\u5f15\u5165\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u53ef\u5c06\u6b63\u786e\u7387\u63d0\u5347\u81f3\u6700\u591a45%\uff0c\u4f46\u4ecd\u9700\u4e13\u5bb6\u9a8c\u8bc1\u624d\u80fd\u7528\u4e8e\u751f\u4ea7\u73af\u5883\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9LLM\u751f\u6210\u7684Solidity\u667a\u80fd\u5408\u7ea6\u5728\u5173\u952e\u529f\u80fd\u548c\u975e\u529f\u80fd\u5c5e\u6027\uff08\u5982\u5b89\u5168\u6027\u3001Gas\u6d88\u8017\u3001\u786e\u5b9a\u6027\uff09\u65b9\u9762\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u800c\u8fd9\u4e9b\u5c5e\u6027\u5bf9\u667a\u80fd\u5408\u7ea6\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5728\u96f6\u6837\u672c\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e24\u79cd\u8bbe\u7f6e\u4e0b\uff0c\u5bf9\u56db\u79cd\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u5728500\u4e2a\u771f\u5b9e\u51fd\u6570\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff1b\u91c7\u7528\u4ee3\u7801\u76f8\u4f3c\u6027\u6307\u6807\u3001\u8bed\u4e49\u5d4c\u5165\u3001\u81ea\u52a8\u5316\u6d4b\u8bd5\u3001Gas\u5206\u6790\u53ca\u8ba4\u77e5\u4e0e\u5708\u590d\u6742\u5ea6\u5206\u6790\u7b49\u591a\u7ef4\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "LLM\u751f\u6210\u7684\u4ee3\u7801\u8bed\u4e49\u76f8\u4f3c\u5ea6\u9ad8\uff0c\u4f46\u529f\u80fd\u6b63\u786e\u7387\u4f4e\uff0820%-26%\uff09\uff1b\u4ee3\u7801\u590d\u6742\u5ea6\u548cGas\u6d88\u8017\u663e\u8457\u66f4\u4f4e\uff0c\u5e38\u56e0\u7701\u7565\u9a8c\u8bc1\u903b\u8f91\u6240\u81f4\uff1bRAG\u663e\u8457\u63d0\u5347\u529f\u80fd\u6b63\u786e\u7387\uff08\u6700\u9ad8\u8fbe45%\uff09\uff0c\u5e76\u751f\u6210\u66f4\u7b80\u6d01\u9ad8\u6548\u7684\u4ee3\u7801\u3002", "conclusion": "\u8bed\u4e49\u76f8\u4f3c\u6027\u4e0d\u7b49\u4e8e\u529f\u80fd\u5408\u7406\u6027\uff0c\u5f53\u524dLLM\u751f\u6210\u7684\u667a\u80fd\u5408\u7ea6\u5c1a\u4e0d\u80fd\u76f4\u63a5\u7528\u4e8e\u751f\u4ea7\uff0c\u5373\u4f7f\u4f7f\u7528RAG\u4e5f\u9700\u4e13\u5bb6\u4ed4\u7ec6\u9a8c\u8bc1\uff1b\u5b9e\u73b0\u53ef\u9760\u3001\u751f\u4ea7\u7ea7\u7684\u667a\u80fd\u5408\u7ea6\u81ea\u52a8\u751f\u6210\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002"}}
{"id": "2511.16410", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16410", "abs": "https://arxiv.org/abs/2511.16410", "authors": ["Hina Saeeda", "Tommy Johansson", "Mazen Mohamad", "Eric Knauss"], "title": "Data Annotation Quality Problems in AI-Enabled Perception System Development", "comment": null, "summary": "Data annotation is essential but highly error-prone in the development of AI-enabled perception systems (AIePS) for automated driving, and its quality directly influences model performance, safety, and reliability. However, the industry lacks empirical insights into how annotation errors emerge and spread across the multi-organisational automotive supply chain. This study addresses this gap through a multi-organisation case study involving six companies and four research institutes across Europe and the UK. Based on 19 semi-structured interviews with 20 experts (50 hours of transcripts) and a six-phase thematic analysis, we develop a taxonomy of 18 recurring annotation error types across three data-quality dimensions: completeness (e.g., attribute omission, missing feedback loops, edge-case omissions, selection bias), accuracy (e.g., mislabelling, bounding-box inaccuracies, granularity mismatches, bias-driven errors), and consistency (e.g., inter-annotator disagreement, ambiguous instructions, misaligned hand-offs, cross-modality inconsistencies). The taxonomy was validated with industry practitioners, who reported its usefulness for root-cause analysis, supplier quality reviews, onboarding, and improving annotation guidelines. They described it as a failure-mode catalogue similar to FMEA. By conceptualising annotation quality as a lifecycle and supply-chain issue, this study contributes to SE4AI by offering a shared vocabulary, diagnostic toolset, and actionable guidance for building trustworthy AI-enabled perception systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u591a\u7ec4\u7ec7\u6848\u4f8b\u5206\u6790\uff0c\u8bc6\u522b\u5e76\u5206\u7c7b\u4e86\u81ea\u52a8\u9a7e\u9a76AI\u611f\u77e5\u7cfb\u7edf\u6570\u636e\u6807\u6ce8\u4e2d\u768418\u79cd\u5e38\u89c1\u9519\u8bef\u7c7b\u578b\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8be5\u5206\u7c7b\u6cd5\u5728\u5de5\u4e1a\u5b9e\u8df5\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u4e3a\u63d0\u5347\u6807\u6ce8\u8d28\u91cf\u548c\u6784\u5efa\u53ef\u4fe1AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8bca\u65ad\u5de5\u5177\u4e0e\u6307\u5bfc\u3002", "motivation": "\u6570\u636e\u6807\u6ce8\u5bf9\u81ea\u52a8\u9a7e\u9a76AI\u611f\u77e5\u7cfb\u7edf\u7684\u5f00\u53d1\u81f3\u5173\u91cd\u8981\u4f46\u6781\u6613\u51fa\u9519\uff0c\u800c\u4e1a\u754c\u7f3a\u4e4f\u5bf9\u6807\u6ce8\u9519\u8bef\u5982\u4f55\u5728\u591a\u7ec4\u7ec7\u6c7d\u8f66\u4f9b\u5e94\u94fe\u4e2d\u4ea7\u751f\u548c\u4f20\u64ad\u7684\u5b9e\u8bc1\u6d1e\u5bdf\u3002", "method": "\u5f00\u5c55\u6d89\u53ca\u516d\u5bb6\u516c\u53f8\u548c\u56db\u5bb6\u7814\u7a76\u673a\u6784\u7684\u591a\u7ec4\u7ec7\u6848\u4f8b\u7814\u7a76\uff0c\u57fa\u4e8e20\u4f4d\u4e13\u5bb6\u768419\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff08\u517150\u5c0f\u65f6\u8f6c\u5f55\u6587\u672c\uff09\uff0c\u91c7\u7528\u516d\u9636\u6bb5\u4e3b\u9898\u5206\u6790\u65b9\u6cd5\u6784\u5efa\u6807\u6ce8\u9519\u8bef\u5206\u7c7b\u4f53\u7cfb\u3002", "result": "\u63d0\u51fa\u4e86\u5305\u542b18\u79cd\u6807\u6ce8\u9519\u8bef\u7c7b\u578b\u7684\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d6\u5b8c\u6574\u6027\u3001\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u4e09\u4e2a\u6570\u636e\u8d28\u91cf\u7ef4\u5ea6\uff0c\u5e76\u7ecf\u884c\u4e1a\u4ece\u4e1a\u8005\u9a8c\u8bc1\uff0c\u53ef\u7528\u4e8e\u6839\u672c\u539f\u56e0\u5206\u6790\u3001\u4f9b\u5e94\u5546\u8bc4\u4f30\u3001\u65b0\u4eba\u57f9\u8bad\u53ca\u6807\u6ce8\u6307\u5357\u4f18\u5316\u3002", "conclusion": "\u5c06\u6807\u6ce8\u8d28\u91cf\u95ee\u9898\u89c6\u4e3a\u751f\u547d\u5468\u671f\u4e0e\u4f9b\u5e94\u94fe\u95ee\u9898\uff0c\u672c\u7814\u7a76\u4e3a\u9762\u5411AI\u7684\u8f6f\u4ef6\u5de5\u7a0b\uff08SE4AI\uff09\u63d0\u4f9b\u4e86\u5171\u4eab\u672f\u8bed\u3001\u8bca\u65ad\u5de5\u5177\u96c6\u548c\u53ef\u64cd\u4f5c\u5efa\u8bae\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u53ef\u9760\u53ef\u4fe1\u7684AI\u611f\u77e5\u7cfb\u7edf\u3002"}}
{"id": "2511.16593", "categories": ["cs.SE", "cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.16593", "abs": "https://arxiv.org/abs/2511.16593", "authors": ["Diaeddin Rimawi"], "title": "Green Resilience of Cyber-Physical Systems: Doctoral Dissertation", "comment": null, "summary": "Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness. This research addresses how to balance these two properties in OL-CAIS. It aims to model resilience for automatic state detection, develop agent-based policies that optimize the greenness-resilience trade-off, and understand catastrophic forgetting to maintain performance consistency. We model OL-CAIS behavior through three operational states: steady, disruptive, and final. To support recovery during disruptions, we introduce the GResilience framework, which provides recovery strategies through multi-objective optimization (one-agent), game-theoretic decision-making (two-agent), and reinforcement learning (RL-agent). We also design a measurement framework to quantify resilience and greenness. Empirical evaluation uses real and simulated experiments with a collaborative robot learning object classification from human demonstrations. Results show that the resilience model captures performance transitions during disruptions, and that GResilience policies improve green recovery by shortening recovery time, stabilizing performance, and reducing human dependency. RL-agent policies achieve the strongest results, although with a marginal increase in CO2 emissions. We also observe catastrophic forgetting after repeated disruptions, while our policies help maintain steadiness. A comparison with containerized execution shows that containerization cuts CO2 emissions by half. Overall, this research provides models, metrics, and policies that ensure the green recovery of OL-CAIS.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5728\u7ebf\u534f\u4f5c\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\uff08OL-CAIS\uff09\u5728\u906d\u9047\u5e72\u6270\u4e8b\u4ef6\u65f6\u5982\u4f55\u5728\u6062\u590d\u6027\u80fd\uff08\u97e7\u6027\uff09\u4e0e\u964d\u4f4e\u80fd\u8017\uff08\u7eff\u8272\u6027\uff09\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u63d0\u51fa\u4e86GResilience\u6846\u67b6\u53ca\u591a\u79cd\u667a\u80fd\u4f53\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "motivation": "OL-CAIS\u4f5c\u4e3a\u4e00\u7c7b\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\uff0c\u5728\u4e0e\u4eba\u7c7b\u534f\u4f5c\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u6613\u53d7\u5e72\u6270\u4e8b\u4ef6\u5f71\u54cd\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff1b\u51b3\u7b56\u8005\u9700\u5728\u6062\u590d\u6027\u80fd\u7684\u540c\u65f6\u63a7\u5236\u80fd\u6e90\u6d88\u8017\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u65b9\u6cd5\u6765\u534f\u8c03\u97e7\u6027\u4e0e\u7eff\u8272\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u4f5c\u8005\u5c06OL-CAIS\u8fd0\u884c\u72b6\u6001\u5efa\u6a21\u4e3a\u7a33\u6001\u3001\u5e72\u6270\u6001\u548c\u7ec8\u6001\u4e09\u7c7b\uff0c\u63d0\u51faGResilience\u6846\u67b6\uff0c\u5305\u542b\u57fa\u4e8e\u591a\u76ee\u6807\u4f18\u5316\u7684\u5355\u667a\u80fd\u4f53\u3001\u535a\u5f08\u8bba\u7684\u53cc\u667a\u80fd\u4f53\u548c\u5f3a\u5316\u5b66\u4e60\u7684RL\u667a\u80fd\u4f53\u4e09\u79cd\u6062\u590d\u7b56\u7565\uff0c\u5e76\u8bbe\u8ba1\u4e86\u8861\u91cf\u97e7\u6027\u548c\u7eff\u8272\u6027\u7684\u6307\u6807\u4f53\u7cfb\u3002\u901a\u8fc7\u771f\u5b9e\u4e0e\u4eff\u771f\u5b9e\u9a8c\uff08\u534f\u4f5c\u673a\u5668\u4eba\u4ece\u4eba\u7c7b\u793a\u8303\u4e2d\u5b66\u4e60\u7269\u4f53\u5206\u7c7b\uff09\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6240\u63d0\u51fa\u7684\u97e7\u6027\u6a21\u578b\u80fd\u51c6\u786e\u6355\u6349\u5e72\u6270\u671f\u95f4\u7684\u6027\u80fd\u53d8\u5316\uff1bGResilience\u7b56\u7565\u53ef\u7f29\u77ed\u6062\u590d\u65f6\u95f4\u3001\u7a33\u5b9a\u6027\u80fd\u5e76\u51cf\u5c11\u5bf9\u4eba\u7c7b\u4f9d\u8d56\uff0c\u5176\u4e2dRL\u667a\u80fd\u4f53\u6548\u679c\u6700\u4f73\uff0c\u4f46\u4f34\u968f\u8f7b\u5faeCO\u2082\u6392\u653e\u589e\u52a0\uff1b\u91cd\u590d\u5e72\u6270\u4f1a\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\uff0c\u800c\u6240\u63d0\u7b56\u7565\u6709\u52a9\u4e8e\u7ef4\u6301\u7cfb\u7edf\u7a33\u5b9a\u6027\uff1b\u5bb9\u5668\u5316\u6267\u884c\u53ef\u4f7fCO\u2082\u6392\u653e\u51cf\u534a\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u7528\u4e8e\u4fdd\u969cOL-CAIS\u7eff\u8272\u6062\u590d\u7684\u6a21\u578b\u3001\u5ea6\u91cf\u65b9\u6cd5\u4e0e\u7b56\u7565\uff0c\u4e3a\u5728\u97e7\u6027\u4e0e\u7eff\u8272\u6027\u4e4b\u95f4\u5b9e\u73b0\u6709\u6548\u5e73\u8861\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
