<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 18]
- [cs.DC](#cs.DC) [Total: 5]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.PF](#cs.PF) [Total: 1]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [SELF-REDRAFT: Eliciting Intrinsic Exploration-Exploitation Balance in Test-Time Scaling for Code Generation](https://arxiv.org/abs/2511.02854)
*Yixiang Chen,Tianshi Zheng,Shijue Huang,Zhitao He,Yi R. Fung*

Main category: cs.SE

TL;DR: 本文提出SELF-REDRAFT框架，在无测试反馈场景下探索大语言模型在代码生成中自主平衡“利用”与“探索”的能力，发现其优于Self-Refine但仍有改进空间，关键瓶颈在于反馈生成与判别判断能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界代码生成常缺乏即时测试反馈，现有方法在贪婪优化（迭代精炼）与随机探索（采样投票/重排序）之间缺乏有效平衡，作者希望探究大语言模型能否内在地协调这两种策略。

Method: 基于Self-Refine构建SELF-REDRAFT框架，引导模型对存在根本缺陷的解法主动提出全新草稿，从而在不依赖外部反馈的情况下实现内在探索与利用的平衡。

Result: SELF-REDRAFT在相同最大迭代次数下性能持续优于Self-Refine；不同大模型展现出各异的平衡策略；当前方法受限于生成指导性反馈的能力不足和判别判断脆弱。

Conclusion: 该研究为测试时缩放中的内在探索-利用平衡建立了基线，并指出反馈生成与判别能力是未来提升的关键方向。

Abstract: Test-time scaling without interpreter feedback is essential for real-world
code generation scenarios where test cases are not readily available. While
existing paradigms often rely on either greedy exploitation (i.e., iterative
refinement) or stochastic exploration (i.e., relying on sample-based voting or
reranking mechanisms), the balance between these two dimensions remains
underexplored. To investigate the LLM's intrinsic ability to balance
exploitation and exploration, we introduce SELF-REDRAFT, a framework built upon
Self-Refine that encourages the model to propose new drafts for solutions that
are fundamentally flawed. Our results show that SELF-REDRAFT consistently
achieves better performance than Self-Refine when converged under the same
maximum number of iterations. Still, we observe that significant room for
improvement remains, largely due to two core aspects of current self-redraft
capabilities: constrained capacity for generating instructive feedback and
fragile discriminative judgment. We also find that balancing strategies vary
notably across different LLMs, reflecting distinct, model-specific behaviors.
Overall, our study establishes a baseline for intrinsic
exploration-exploitation balancing in test-time scaling and identifies feedback
and discrimination as key areas with potential for future advances.

</details>


### [2] [LM-Fix: Lightweight Bit-Flip Detection and Rapid Recovery Framework for Language Models](https://arxiv.org/abs/2511.02866)
*Ahmad Tahmasivand,Noureldin Zahran,Saba Al-Sayouri,Mohammed Fouda,Khaled N. Khasawneh*

Main category: cs.SE

TL;DR: LM-Fix 是一种轻量级的大语言模型故障检测与快速恢复框架，能高效检测并修复位翻转错误，显著降低运行开销并加速恢复过程。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的完整性保障方法通常计算开销大或响应慢，难以满足实际部署需求，因此需要一种轻量且高效的故障检测与恢复机制。

Method: LM-Fix 通过短测试向量传递和哈希引导检查来检测位翻转故障，并在不重新加载整个模型的情况下进行局部修复。

Result: 在多种模型上，LM-Fix 在 TVL=200 时可检测超过 94% 的单位翻转错误，几乎 100% 检测多位翻转错误，运行时开销仅为 1% 至 7.7%，恢复速度比完整重载快 100 倍以上。

Conclusion: LM-Fix 提供了一种实用且低开销的解决方案，有效提升大语言模型在生产环境中的可靠性。

Abstract: This paper presents LM-Fix, a lightweight detection and rapid recovery
framework for faults in large language models (LLMs). Existing integrity
approaches are often heavy or slow for modern LLMs. LM-Fix runs a short
test-vector pass and uses hash-guided checks to detect bit-flip faults, then
repairs them locally without a full reload. Across multiple models, it detects
over 94% of single-bit flips at TVL=200 and nearly 100% of multi-bit flips with
approximately 1% to 7.7% runtime overhead; recovery is more than 100x faster
than reloading. These results show a practical, low-overhead solution to keep
LLMs reliable in production

</details>


### [3] [Analysis of AdvFusion: Adapter-based Multilingual Learning for Code Large Language Models](https://arxiv.org/abs/2511.02869)
*Amirreza Esmaeili,Fahd Seddik,Yongyi Ji,Fatemeh Fard,Fuxiang Chen*

Main category: cs.SE

TL;DR: 本文扩展了先前提出的AdvFusion方法，在更大的代码大语言模型（Code-LLMs）上评估其在三种新任务（代码生成、代码翻译和提交信息生成）中的表现，并与多种参数高效微调（PEFT）方法进行比较，发现AdvFusion在不同任务中表现不一，有时优于、有时劣于其他方法。


<details>
  <summary>Details</summary>
Motivation: 探索AdvFusion这一新型参数高效微调方法在更广泛任务和更大规模代码语言模型上的适用性和有效性，以验证其跨编程语言知识迁移能力的泛化性。

Method: 在多个Code-LLMs上应用AdvFusion方法，针对代码生成、代码翻译和提交信息生成三项任务进行实验，并与AdapterFusion、LoRA、Compacter和TaskAdapter等PEFT方法进行性能对比。

Result: 在代码生成任务中，AdvFusion优于AdapterFusion但不及其他PEFT方法；在提交信息生成任务中，AdapterFusion表现更好，且其他PEFT方法未显示出优势；在代码翻译任务中，AdvFusion整体表现不如AdapterFusion，且随着模型规模增大差距略有扩大，但其他PEFT方法仍表现更佳。

Conclusion: AdvFusion在不同任务和模型上表现存在差异，说明其有效性依赖于具体任务特性，未来需进一步优化以提升其在各类软件工程任务中的通用性和稳定性。

Abstract: Programming languages can benefit from one another by utilizing a language
model for software engineering tasks. Full fine-tuning and Parameter Efficient
Fine-Tuning (PEFT) of Code Language Models (Code-LMs) has been explored for
multilingual knowledge transfer. AdapterFusion is a PEFT architecture that aims
to enhance task performance by leveraging information from multiple programming
languages, but primarily focuses on the target programming language.
  In our previous work, we proposed AdvFusion, a novel PEFT-based approach that
effectively learns from other programming languages before adapting to the
target task. Though previous experiments showed that AdvFusion outperformed
AdapterFusion and LoRA, it was applied on pre-trained Code-LMs and was limited
to only two tasks, code summarization and method name prediction. In this
study, we expanded our work and investigated AdvFusion on Code Large Language
Models (Code-LLMs), considering three new tasks: code generation, code
translation, and commit message generation. We observed that different
Code-LLMs/tasks exhibit different characteristics. In code generation,
AdvFusion outperformed AdapterFusion but not other PEFT methods (LoRA,
Compacter, and TaskAdapter). In commit message generation, AdapterFusion
performed better than AdvFusion, and contrary to code generation, we found that
the other PEFT methods do not have better performance. In code translation,
AdvFusion performed worse than AdapterFusion overall, with the performance gap
marginally widening as the model size increases. However, consistent with code
generation, other PEFT methods showed better performance.

</details>


### [4] [An Analysis of Early-Stage Functional Safety Analysis Methods and Their Integration into Model-Based Systems Engineering](https://arxiv.org/abs/2511.02874)
*Jannatul Shefa,Taylan G. Topcu*

Main category: cs.SE

TL;DR: 本文对比了FMEA、FHA和FFIP三种安全分析技术，并综述了它们在基于模型的系统工程（MBSE）中的集成现状，指出FFIP更适合现代互联系统的安全需求，而目前MBSE集成主要集中在FMEA，缺乏统一标准。


<details>
  <summary>Details</summary>
Motivation: 随着系统日益复杂，在系统生命周期早期开展有效的安全分析对于识别和缓解风险至关重要。因此，有必要评估主流安全分析方法的能力及其与MBSE的集成程度，以支持数字化工程转型。

Method: 采用两阶段方法：第一阶段对比FMEA、FHA和FFIP的技术流程、优势与局限；第二阶段综述现有文献中这三种方法与MBSE集成的研究进展。

Result: 分析表明FFIP在识别涌现行为、二阶效应和故障传播方面更具优势；MBSE集成研究主要集中于FMEA，可分为四类方法，而FHA和FFIP的集成尚处于初期阶段，且缺乏通用框架或标准。

Conclusion: 当前MBSE与安全分析技术的集成尚不成熟，尤其对FHA和FFIP支持不足，亟需开发一种能支持全生命周期安全管理并与数字工程转型协同的统一集成方法。

Abstract: As systems become increasingly complex, conducting effective safety analysis
in the earlier phases of a system's lifecycle is essential to identify and
mitigate risks before they escalate. To that end, this paper investigates the
capabilities of key safety analysis techniques, namely: Failure Mode and
Effects Analysis (FMEA), Functional Hazard Analysis (FHA), and Functional
Failure Identification and Propagation (FFIP), along with the current state of
the literature in terms of their integration into Model-Based Systems
Engineering (MBSE). A two-phase approach is adopted. The first phase is focused
on contrasting FMEA, FHA, and FFIP techniques, examining their procedures,
along with a documentation of their relative strengths and limitations. Our
analysis highlights FFIP's capability in identifying emergent system behaviors,
second-order effects, and fault propagation; thus, suggesting it is better
suited for the safety needs of modern interconnected systems. Second, we review
the existing research on the efforts to integrate each of these methods into
MBSE. We find that MBSE integration efforts primarily focus on FMEA, and
integration of FHA and FFIP is nascent. Additionally, FMEA-MBSE integration
efforts could be organized into four categories: model-to-model transformation,
use of external customized algorithms, built-in MBSE packages, and manual use
of standard MBSE diagrams. While our findings indicate a variety of MBSE
integration approaches, there is no universally established framework or
standard. This leaves room for an integration approach that could support the
ongoing Digital Engineering transformation efforts by enabling a more
synergistic lifecycle safety management methods and tools.

</details>


### [5] [CS Educator challenges and their solutions : A systematic mapping study](https://arxiv.org/abs/2511.02876)
*Anjali Chouhan,Sruti Srinivasa Ragavan,Amey Karkare*

Main category: cs.SE

TL;DR: 本文通过结构化文献综述，系统梳理了过去五年计算机科学教育中教师面临的挑战及应对策略，涵盖教学、情感、技术和制度等十个主题，揭示了评估实践、师资培训、课堂管理和情绪健康等方面的常见问题，并指出若干研究不足的领域。


<details>
  <summary>Details</summary>
Motivation: 当前计算机科学教育虽快速发展，但缺乏对教师所面临具体挑战及其应对措施的系统性分类与整合，导致难以判断哪些问题已被充分研究、哪些仍需关注。

Method: 开展结构化文献综述，分析近五年发表的同行评审研究论文，聚焦于十大主题下的挑战与对策。

Result: 发现评估实践、教师培训、课堂管理与情绪健康等领域存在反复出现的问题，并识别出专业发展项目和政策干预等缓解策略，同时揭示若干研究不足的空白领域。

Conclusion: 本综述为研究人员、课程设计者和政策制定者提供了对计算机科学教育现状的整合性理解，有助于提升教学效果与教师支持。

Abstract: Computer Science (CS) education is expanding rapidly, but educators continue
to face persistent challenges in teaching and learning environments.Despite
growing interest, limited systematic work exists to categorize and synthesize
the specific challenges faced by CS educators and the remedies adopted in
response.This is problematic because it remains unclear which areas have been
thoroughly addressed and which still lack sufficient scholarly attention. In
this study, we conducted a structured literature review of peer-reviewed
research papers published over the last five years, focusing on challenges and
remedies across ten categorized themes, including pedagogical, emotional,
technological, and institutional dimensions.Our analysis revealed recurring
issues in areas such as assessment practices, teacher training, classroom
management, and emotional well-being, along with various strategies such as
professional development programs and policy interventions adopted to mitigate
them while also revealing several areas that have received insufficient
attention.This review offers a consolidated understanding of the CS education
landscape, providing valuable insights for researchers, curriculum designers,
and policymakers aiming to improve teaching effectiveness and educator support.

</details>


### [6] [AgentSLA : Towards a Service Level Agreement for AI Agents](https://arxiv.org/abs/2511.02885)
*Gwendal Jouneaux,Jordi Cabot*

Main category: cs.SE

TL;DR: 本文针对AI智能体服务质量（QoS）与服务等级协议（SLA）缺乏规范的问题，提出了一种基于ISO/IEC 25010标准的质量模型和一种领域特定语言（DSL）用于定义AI智能体的SLA。


<details>
  <summary>Details</summary>
Motivation: 随着AI智能体在软件系统中的广泛应用，其自主性增强带来了新的开发挑战，尤其是在服务质量（QoS）规范和服务等级协议（SLA）定义方面缺乏共识和有效方法，导致AI组件的质量保障（QA）难以实施。

Method: 作者基于ISO/IEC 25010标准构建了一个适用于AI智能体的质量模型，并设计了一种领域特定语言（DSL）以支持对AI智能体所提供服务的SLA进行形式化定义。

Result: 该研究为AI智能体的服务质量提供了结构化的评估框架，并通过DSL实现了SLA的可操作化定义，有助于提升智能软件系统的可靠性与可控性。

Conclusion: 本文提出的质量模型和DSL为AI智能体的QoS与SLA规范提供了可行路径，填补了当前AI系统质量保障方面的空白，为未来智能软件系统的工程化开发奠定了基础。

Abstract: AI components are increasingly becoming a key element of all types of
software systems to enhance their functionality. These AI components are often
implemented as AI Agents, offering more autonomy than a plain integration of
Large Language Models (LLMs), moving from a Model-as-a-Service paradigm to an
Agent-as-a-Service one, bringing new challenges to the development of smart
software systems. Indeed, while support for the design, implementation, and
deployment of those agents exist, the specification of Quality of Service (QoS)
and definition of Service Level Agreements (SLAs) aspects for those agents,
important to ensure the quality of the resulting systems, remains an open
challenge. Part of this is due to the difficulty to clearly define quality in
the context of AI components, resulting in a lack of consensus on how to best
approach Quality Assurance (QA) for these types of systems. To address this
challenge, this paper proposes both a quality model for AI agents based on the
ISO/IEC 25010 standard, and a domain specific language to support the
definition of SLAs for the services provided by these AI agents.

</details>


### [7] [Comprehension-Performance Gap in GenAI-Assisted Brownfield Programming: A Replication and Extension](https://arxiv.org/abs/2511.02922)
*Yunhan Qiao,Christopher Hundhausen,Summit Haque,Md Istiak Hossain Shihab*

Main category: cs.SE

TL;DR: GitHub Copilot improves task performance in brownfield programming but does not enhance code comprehension, revealing a gap between performance and understanding.


<details>
  <summary>Details</summary>
Motivation: To investigate whether generative AI coding assistants like GitHub Copilot improve not only developer productivity but also code comprehension during brownfield programming tasks involving legacy codebases.

Method: A within-subjects experimental study with 18 computer science graduate students performing feature implementation tasks with and without GitHub Copilot, measuring task time, test cases passed, and comprehension scores.

Result: Copilot significantly reduced task time and increased test cases passed, but comprehension scores showed no improvement, and no correlation was found between comprehension and performance.

Conclusion: GenAI tools can accelerate programming in legacy codebases without necessarily improving developers' understanding, highlighting implications for programming education and AI tool design.

Abstract: Code comprehension is essential for brownfield programming tasks, in which
developers maintain and enhance legacy code bases. Generative AI (GenAI) coding
assistants such as GitHub Copilot have been shown to improve developer
productivity, but their impact on code understanding is less clear. We
replicate and extend a previous study by exploring both performance and
comprehension in GenAI-assisted brownfield programming tasks. In a
within-subjects experimental study, 18 computer science graduate students
completed feature implementation tasks with and without Copilot. Results show
that Copilot significantly reduced task time and increased the number of test
cases passed. However, comprehension scores did not differ across conditions,
revealing a comprehension-performance gap: participants passed more test cases
with Copilot, but did not demonstrate greater understanding of the legacy
codebase. Moreover, we failed to find a correlation between comprehension and
task performance. These findings suggest that while GenAI tools can accelerate
programming progress in a legacy codebase, such progress may come without an
improved understanding of that codebase. We consider the implications of these
findings for programming education and GenAI tool design.

</details>


### [8] [Risk Estimation in Differential Fuzzing via Extreme Value Theory](https://arxiv.org/abs/2511.02927)
*Rafael Baez,Alejandro Olivas,Nathan K. Diamond,Marcelo Frias,Yannic Noller,Saeid Tizpaz-Niari*

Main category: cs.SE

TL;DR: 本文将极值理论（EVT）应用于差分模糊测试中，以评估遗漏或低估漏洞的风险，并在真实Java库实验中验证其有效性，结果表明EVT方法优于或等同于传统统计方法，并能显著减少字节码执行次数。


<details>
  <summary>Details</summary>
Motivation: 差分模糊测试虽能有效发现软件缺陷，但缺乏对“未发现缺陷”风险的量化保证。作者旨在通过极值理论对差分模糊测试中观察到的最大差异分布进行建模，从而评估继续运行模糊器时发现更大差异或漏洞的可能性。

Method: 作者利用极值理论（EVT）对差分模糊测试过程中产生的输出差异极值进行建模，通过实验确定EVT分布的最佳超参数，并与马尔可夫不等式、切比雪夫不等式和贝叶斯因子等基线统计方法进行比较。

Result: 在真实Java库上的实验表明，EVT方法在14.3%的情况下优于基线方法，在64.2%的情况下与之持平；同时，基于EVT的提前终止策略平均节省了数千万次字节码执行。

Conclusion: 极值理论为差分模糊测试提供了一个有效的统计框架，可用于量化漏报风险并优化测试效率，在实践中具有显著的性能收益。

Abstract: Differential testing is a highly effective technique for automatically
detecting software bugs and vulnerabilities when the specifications involve an
analysis over multiple executions simultaneously. Differential fuzzing, in
particular, operates as a guided randomized search, aiming to find (similar)
inputs that lead to a maximum difference in software outputs or their
behaviors. However, fuzzing, as a dynamic analysis, lacks any guarantees on the
absence of bugs: from a differential fuzzing campaign that has observed no bugs
(or a minimal difference), what is the risk of observing a bug (or a larger
difference) if we run the fuzzer for one or more steps?
  This paper investigates the application of Extreme Value Theory (EVT) to
address the risk of missing or underestimating bugs in differential fuzzing.
The key observation is that differential fuzzing as a random process resembles
the maximum distribution of observed differences. Hence, EVT, a branch of
statistics dealing with extreme values, is an ideal framework to analyze the
tail of the differential fuzzing campaign to contain the risk. We perform
experiments on a set of real-world Java libraries and use differential fuzzing
to find information leaks via side channels in these libraries. We first
explore the feasibility of EVT for this task and the optimal hyperparameters
for EVT distributions. We then compare EVT-based extrapolation against baseline
statistical methods like Markov's as well as Chebyshev's inequalities, and the
Bayes factor. EVT-based extrapolations outperform the baseline techniques in
14.3% of cases and tie with the baseline in 64.2% of cases. Finally, we
evaluate the accuracy and performance gains of EVT-enabled differential fuzzing
in real-world Java libraries, where we reported an average saving of tens of
millions of bytecode executions by an early stop.

</details>


### [9] [Assurance Case Development for Evolving Software Product Lines: A Formal Approach](https://arxiv.org/abs/2511.03026)
*Logan Murphy,Torin Viger,Alessio Di Sandro,Aren A. Babikian,Marsha Chechik*

Main category: cs.SE

TL;DR: 本文提出了一种面向软件产品线（SPL）的可变性感知保障案例（AC）形式化方法，支持为整个产品线统一构建AC，并在SPL演化时进行回归分析，以应对为每个产品单独构建AC不可行的问题。


<details>
  <summary>Details</summary>
Motivation: 在软件产品线（SPL）中，由于产品数量庞大且具有差异化的功能与行为，为每个产品单独构建严谨的保障案例（AC）不可行；同时，当SPL演化时，难以评估变更对已有AC的影响。因此需要一种能为整个SPL统一开发并支持可变性感知回归分析的AC方法。

Method: 作者形式化了一种支持可变性的保障案例语言，研究了基于模板的AC提升（lifting）开发方法，并定义了用于评估SPL演化对AC影响的回归分析技术；同时实现了一个基于模型的保障管理工具来支持这些方法。

Result: 该方法成功应用于一个医疗设备产品线的保障案例开发，验证了其在统一构建和维护SPL保障案例方面的可行性与有效性。

Conclusion: 通过将保障案例开发提升到软件产品线层面并引入可变性感知机制，可以有效解决大规模产品线中保障案例构建与演化维护的难题。

Abstract: In critical software engineering, structured assurance cases (ACs) are used
to demonstrate how key system properties are supported by evidence (e.g., test
results, proofs). Creating rigorous ACs is particularly challenging in the
context of software product lines (SPLs), i.e, sets of software products with
overlapping but distinct features and behaviours. Since SPLs can encompass very
large numbers of products, developing a rigorous AC for each product
individually is infeasible. Moreover, if the SPL evolves, e.g., by the
modification or introduction of features, it can be infeasible to assess the
impact of this change. Instead, the development and maintenance of ACs ought to
be lifted such that a single AC can be developed for the entire SPL
simultaneously, and be analyzed for regression in a variability-aware fashion.
In this article, we describe a formal approach to lifted AC development and
regression analysis. We formalize a language of variability-aware ACs for SPLs
and study the lifting of template-based AC development. We also define a
regression analysis to determine the effects of SPL evolutions on
variability-aware ACs. We describe a model-based assurance management tool
which implements these techniques, and illustrate our contributions by
developing an AC for a product line of medical devices.

</details>


### [10] [Adaptive Detection of Software Aging under Workload Shift](https://arxiv.org/abs/2511.03103)
*Rafael José Moura,Maria Gizele Nascimento,Fumio Machida,Ermeson Andrade*

Main category: cs.SE

TL;DR: 本文提出一种基于机器学习的自适应方法，用于在动态工作负载条件下检测软件老化。通过引入ADWIN等自适应检测器，该方法在多种工作负载变化场景下均保持高于0.93的F1分数，显著优于静态模型。


<details>
  <summary>Details</summary>
Motivation: 软件老化会导致长期运行系统性能逐渐下降并增加故障风险，尤其在动态工作负载环境下，传统静态模型难以有效应对工作负载变化，因此需要一种能自适应调整的老化检测方法。

Method: 采用机器学习方法构建自适应老化检测模型，结合Drift Detection Method（DDM）和Adaptive Windowing（ADWIN）两种自适应检测器，以应对工作负载突变、渐变和周期性变化等场景。

Result: 实验表明，静态模型在面对未见过的工作负载时性能显著下降，而结合ADWIN的自适应模型在所有测试场景中均保持高准确率，F1-Score超过0.93。

Conclusion: 将ADWIN等自适应机制引入软件老化检测可有效提升模型在动态工作负载环境下的鲁棒性和准确性，为实际系统提供更可靠的保障。

Abstract: Software aging is a phenomenon that affects long-running systems, leading to
progressive performance degradation and increasing the risk of failures. To
mitigate this problem, this work proposes an adaptive approach based on machine
learning for software aging detection in environments subject to dynamic
workload conditions. We evaluate and compare a static model with adaptive
models that incorporate adaptive detectors, specifically the Drift Detection
Method (DDM) and Adaptive Windowing (ADWIN), originally developed for concept
drift scenarios and applied in this work to handle workload shifts. Experiments
with simulated sudden, gradual, and recurring workload transitions show that
static models suffer a notable performance drop when applied to unseen workload
profiles, whereas the adaptive model with ADWIN maintains high accuracy,
achieving an F1-Score above 0.93 in all analyzed scenarios.

</details>


### [11] [Automated Prompt Generation for Code Intelligence: An Empirical study and Experience in WeChat](https://arxiv.org/abs/2511.03136)
*Kexing Ji,Shiyun Fu,Cuiyun Gao,Yujia Chen,Zezhou Yang,Chaozheng Wang,Yuetang Deng*

Main category: cs.SE

TL;DR: 本文研究了自动提示生成（APG）在大代码模型（LCM）中的应用，重点评估了指令生成（IG）和多步推理（MSR）两个关键组成部分，并提出了一种结合两者优势的新方法，在多个代码智能任务上显著优于基础提示。


<details>
  <summary>Details</summary>
Motivation: 当前大代码模型（LCM）的性能高度依赖于提示质量，而现有提示设计主要依赖人工，耗时且对特定模型和任务敏感；尽管自然语言处理中已有自动提示生成（APG）方法，但在代码智能领域尚未充分探索，亟需自动化方案以应对多样任务和黑盒LCM的挑战。

Method: 作者实证评估了两种APG核心组件——指令生成（IG）和多步推理（MSR）——在四个开源LCM和三项代码智能任务（代码翻译、代码摘要、API推荐）上的表现，并在此基础上提出一种融合两者最优策略的新型APG方法。

Result: 所提方法相比基础提示，在CodeBLEU（代码翻译）、ROUGE-L（代码摘要）和SuccessRate@1（API推荐）上分别平均提升28.38%、58.11%和84.53%；在微信内部数据集WeChat-Bench上的API推荐任务中，MRR平均提升148.89%。

Conclusion: 自动提示生成能显著提升大代码模型在多种代码智能任务中的性能，结合指令生成与多步推理的策略尤为有效，且在工业场景中也展现出强大潜力。

Abstract: Large Code Models (LCMs) show potential in code intelligence, but their
effectiveness is greatly influenced by prompt quality. Current prompt design is
mostly manual, which is time-consuming and highly dependent on specific LCMs
and tasks. While automated prompt generation (APG) exists in NLP, it is
underexplored for code intelligence. This creates a gap, as automating the
prompt process is essential for developers facing diverse tasks and black-box
LCMs.
  To mitigate this, we empirically investigate two important parts of APG:
Instruction Generation (IG) and Multi-Step Reasoning (MSR). IG provides a
task-related description to instruct LCMs, while MSR guides them to produce
logical steps before the final answer. We evaluate widely-used APG methods for
each part on four open-source LCMs and three code intelligence tasks: code
translation (PL-PL), code summarization (PL-NL), and API recommendation
(NL-PL).Experimental results indicate that both IG and MSR dramatically enhance
performance compared to basic prompts. Based on these results, we propose a
novel APG approach combining the best methods of the two parts. Experiments
show our approach achieves average improvements of 28.38% in CodeBLEU (code
translation), 58.11% in ROUGE-L (code summarization), and 84.53% in
SuccessRate@1 (API recommendation) over basic prompts. To validate its
effectiveness in an industrial scenario, we evaluate our approach on
WeChat-Bench, a proprietary dataset, achieving an average MRR improvement of
148.89% for API recommendation.

</details>


### [12] [RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring](https://arxiv.org/abs/2511.03153)
*Khouloud Oueslati,Maxime Lamothe,Foutse Khomh*

Main category: cs.SE

TL;DR: 本文提出RefAgent，一种基于多智能体大语言模型的端到端软件重构框架，通过规划、执行、测试和自省迭代优化重构任务，在多个开源Java项目中显著提升代码质量与重构效果。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在软件重构中依赖静态指令，缺乏对动态上下文的适应能力；而基于LLM的智能体可自主决策并与工具交互，因此作者探索其在重构任务中的潜力。

Method: 提出RefAgent多智能体框架，包含负责规划、执行、测试和迭代优化的专用智能体，利用自省与工具调用能力进行端到端重构，并在8个开源Java项目上进行评估。

Result: RefAgent中位单元测试通过率达90%，代码异味减少52.5%，关键质量属性（如可重用性）提升8.6%；相比单智能体方法，测试通过率和编译成功率分别提高64.7%和40.1%；在识别重构机会方面F1分数达79.15%（对比开发者）和72.7%（对比搜索式工具）。

Conclusion: 多智能体架构在自动化软件重构中展现出显著优势，能有效提升代码质量和重构准确性，具有广阔应用前景。

Abstract: Large Language Models (LLMs) have substantially influenced various software
engineering tasks. Indeed, in the case of software refactoring, traditional
LLMs have shown the ability to reduce development time and enhance code
quality. However, these LLMs often rely on static, detailed instructions for
specific tasks. In contrast, LLM-based agents can dynamically adapt to evolving
contexts and autonomously make decisions by interacting with software tools and
executing workflows. In this paper, we explore the potential of LLM-based
agents in supporting refactoring activities. Specifically, we introduce
RefAgent, a multi-agent LLM-based framework for end-to-end software
refactoring. RefAgent consists of specialized agents responsible for planning,
executing, testing, and iteratively refining refactorings using self-reflection
and tool-calling capabilities. We evaluate RefAgent on eight open-source Java
projects, comparing its effectiveness against a single-agent approach, a
search-based refactoring tool, and historical developer refactorings. Our
assessment focuses on: (1) the impact of generated refactorings on software
quality, (2) the ability to identify refactoring opportunities, and (3) the
contribution of each LLM agent through an ablation study. Our results show that
RefAgent achieves a median unit test pass rate of 90%, reduces code smells by a
median of 52.5%, and improves key quality attributes (e.g., reusability) by a
median of 8.6%. Additionally, it closely aligns with developer refactorings and
the search-based tool in identifying refactoring opportunities, attaining a
median F1-score of 79.15% and 72.7%, respectively. Compared to single-agent
approaches, RefAgent improves the median unit test pass rate by 64.7% and the
median compilation success rate by 40.1%. These findings highlight the promise
of multi-agent architectures in advancing automated software refactoring.

</details>


### [13] [Understanding Robustness of Model Editing in Code LLMs: An Empirical Study](https://arxiv.org/abs/2511.03182)
*Vinaik Chhetri,A. B Siddique,Umar Farooq*

Main category: cs.SE

TL;DR: 本文系统评估了五种主流模型编辑方法在代码大模型应对API变更时的有效性，发现这些方法普遍无法实现真正的语法和语义适应，反而显著降低模型性能，正确采纳变更的比例仅约6%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLM）在预训练后保持静态，而编程语言和API持续演进，导致模型生成过时或不兼容的代码；重新训练成本高昂，因此轻量级的模型编辑成为潜在替代方案，但其是否能真正实现有效的语法与语义适应尚不清楚。

Method: 对三种主流开源代码大模型（CodeLlama、CodeQwen1.5、DeepSeek-Coder）应用五种先进模型编辑方法（FT、GRACE、MEMIT、PMET、ROME），在受控的API弃用场景下进行即时和序列编辑实验，并通过三个互斥评估集从可靠性、泛化性和特异性三方面评估，衡量指标包括编译成功、部分测试通过和完整测试通过。

Result: 即时编辑导致模型性能显著下降，语法有效性最多下降86个百分点，功能正确性最多下降45个百分点；序列编辑进一步加剧性能退化，有时甚至完全崩溃；大多数通过案例依赖变通方案而非正确采纳变更，正确采纳率仅约6%。

Conclusion: 当前主流模型编辑方法在代码大模型中难以实现有效的API变更适应，往往产生表面修复甚至有害输出，表明该领域亟需更鲁棒、语义感知的编辑技术。

Abstract: Large language models (LLMs) are increasingly used in software development.
However, while LLMs remain static after pretraining, programming languages and
APIs continue to evolve, leading to the generation of deprecated or
incompatible code that undermines reliability. Retraining LLMs from scratch to
reflect such changes is computationally expensive, making model editing a
promising lightweight alternative that updates only a small subset of
parameters. Despite its potential, it remains unclear whether model editing
yields genuine syntactic and semantic adaptations or merely superficial fixes.
In this work, we present a systematic study of five state-of-the-art model
editing methods: Constrained Fine-Tuning (FT), GRACE, MEMIT, PMET, and ROME. We
apply these methods to three leading open-source code LLMs, CodeLlama,
CodeQwen1.5, and DeepSeek-Coder, under controlled API deprecation scenarios.
Our evaluation covers both instant and sequential editing settings, using three
disjoint evaluation sets designed to assess reliability, generalization, and
specificity. We measure model correctness at three levels: successful
compilation, partial test case pass, and full test pass. Our findings show that
instant edits consistently degrade model performance, with syntactic validity
dropping by up to 86 percentage points and functional correctness declining by
45 points even in the best-performing setting. Sequential edits further amplify
this degradation, and in some cases, model performance collapses entirely.
Across all models, most passing generations relied on workarounds rather than
correctly adopting the intended changes, while faulty adoptions that result in
test failures or compilation errors were significantly more frequent. Correct
adoptions, where the model correctly integrates the intended change, occurred
in only about 6% of cases.

</details>


### [14] [Towards Realistic Project-Level Code Generation via Multi-Agent Collaboration and Semantic Architecture Modeling](https://arxiv.org/abs/2511.03404)
*Qianhui Zhao,Li Zhang,Fang Liu,Junhang Cheng,Chengru Wu,Junchen Ai,Qiaoyuanhe Meng,Lichen Zhang,Xiaoli Lian,Shubin Song,Yuanping Guo*

Main category: cs.SE

TL;DR: 本文提出了一个名为ProjectGen的多智能体框架和一个新的项目级代码生成数据集CodeProjectEval，显著提升了从复杂用户需求生成完整软件项目的能力。


<details>
  <summary>Details</summary>
Motivation: 现有项目级代码生成研究存在不切实际的数据集、不可靠的评估指标、用户需求与机器可解释结构之间的语义鸿沟，以及在生成过程中难以管理层次依赖和保持代码质量等问题。

Method: 作者构建了基于18个真实仓库的CodeProjectEval数据集，并提出ProjectGen多智能体框架，该框架通过架构设计、骨架生成和代码填充三个阶段进行迭代优化，并引入语义软件架构树（SSAT）来连接用户需求与代码实现。

Result: ProjectGen在DevBench上通过52/124个测试用例，比基线提升57%；在CodeProjectEval上通过310个测试用例，约为基线的十倍。

Conclusion: ProjectGen结合CodeProjectEval有效推动了项目级代码生成的发展，在真实场景下展现出显著优于现有方法的性能。

Abstract: In recent years, Large Language Models (LLMs) have achieved remarkable
progress in automated code generation. In real-world software engineering, the
growing demand for rapid iteration and continuous delivery underscores the
importance of project-level code generation, where LLMs are expected to
generate complete software projects directly from complex user requirements.
Although existing studies have made initial explorations, they still face key
limitations, including unrealistic datasets and unreliable evaluation metrics
that fail to reflect real-world complexity, the semantic gap between
human-written requirements and machine-interpretable structures, and
difficulties in managing hierarchical dependencies and maintaining quality
throughout the generation process. To address these limitations, we first
introduce CodeProjectEval, a project-level code generation dataset built from
18 real-world repositories with 12.7 files and 2,388.6 lines of code per task
on average, supplemented with documentation and executable test cases for
automatic evaluation. We further propose ProjectGen, a multi-agent framework
that decomposes projects into architecture design, skeleton generation, and
code filling stages with iterative refinement and memory-based context
management. Within this framework, we introduce the Semantic Software
Architecture Tree (SSAT), a structured and semantically rich representation
that effectively bridges user requirements and source code implementation.
Experiments show that ProjectGen achieves state-of-the-art performance, passing
52/124 test cases on the small-scale project-level code generation dataset
DevBench, a 57% improvement over the baseline approaches, and 310 test cases on
CodeProjectEval, representing an improvement of roughly tenfold compared to the
baselines.

</details>


### [15] [Light over Heavy: Automated Performance Requirements Quantification with Linguistic Inducement](https://arxiv.org/abs/2511.03421)
*Shihai Wang,Tao Chen*

Main category: cs.SE

TL;DR: 本文提出LQPR，一种高效自动量化性能需求的方法，通过将量化问题转化为分类任务，并采用轻量级语言匹配机制，在多个数据集上显著优于现有基于学习的方法，且成本降低两个数量级。


<details>
  <summary>Details</summary>
Motivation: 现有性能需求量化方法多依赖人工，成本高且易出错；尽管大语言模型（LLMs）广泛用于需求分析，但在性能需求量化任务中，专门设计的轻量方法可能更有效。

Method: LQPR基于新理论框架，将性能需求量化转化为分类问题，利用性能需求通常简短且具有强模式的特点，设计了一种轻量级的语言诱导匹配机制。

Result: 在多个数据集上与九种先进学习方法对比，LQPR在75%以上的案例中表现最佳，且计算成本低两个数量级。

Conclusion: 针对性能需求量化任务，专门设计的轻量级方法（如LQPR）比通用的大语言模型方法更高效、更适用。

Abstract: Elicited performance requirements need to be quantified for compliance in
different engineering tasks, e.g., configuration tuning and performance
testing. Much existing work has relied on manual quantification, which is
expensive and error-prone due to the imprecision. In this paper, we present
LQPR, a highly efficient automatic approach for performance requirements
quantification.LQPR relies on a new theoretical framework that converts
quantification as a classification problem. Despite the prevalent applications
of Large Language Models (LLMs) for requirement analytics, LQPR takes a
different perspective to address the classification: we observed that
performance requirements can exhibit strong patterns and are often
short/concise, therefore we design a lightweight linguistically induced
matching mechanism. We compare LQPR against nine state-of-the-art
learning-based approaches over diverse datasets, demonstrating that it is
ranked as the sole best for 75% or more cases with two orders less cost. Our
work proves that, at least for performance requirement quantification,
specialized methods can be more suitable than the general LLM-driven
approaches.

</details>


### [16] [U2F: Encouraging SWE-Agent to Seize Novelty without Losing Feasibility](https://arxiv.org/abs/2511.03517)
*Wencheng Ye,Yan Liu*

Main category: cs.SE

TL;DR: 本文提出U2F框架，通过多智能体系统和认知增强机制，在软件工程任务中主动探索“未知的未知”，显著提升解决方案的新颖性而不牺牲可行性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的软件工程智能体多局限于解决定义明确的问题，忽视了在开放世界软件环境中超越既有范式的创新解法。

Method: U2F是一个受认知启发、拥抱不确定性的多智能体框架，包含发现-探索-整合智能体系统，并结合跨领域类比推理、逆向思维和外部验证三种认知增强机制。

Result: 在218个真实软件需求任务上，U2F使人类专家评估的整体新颖性提升14%，语义新颖性提升51%，同时保持高可行性（4.02/5.0）。

Conclusion: 将不确定性视为创新催化剂，U2F展示了在软件工程中系统性发掘创新解决方案的潜力。

Abstract: Large language models (LLMs) have shown strong capabilities in software
engineering tasks, yet most existing LLM-based SWE-Agents mainly tackle
well-defined problems using conventional methods, often overlooking alternative
or innovative solutions beyond their predefined frameworks. This limitation is
evident in open-world software environments, where emerging challenges
transcend established paradigms.
  We propose U2F (Unknown Unknowns to Functional solutions), a
cognitive-inspired, uncertainty-embracing multi-agent framework that
systematically surfaces "Unknown Unknowns" - novel solution pathways absent
from initial formulations but holding innovative potential. U2F consists of two
key components: (1) a Discovery-Exploration-Integration agent system for
uncovering and synthesizing potential solutions, and (2) cognitive enhancement
mechanisms across three dimensions: cross-domain analogical reasoning, reverse
thinking, and external validation, which strategically reframe and extend
conventional solution boundaries.
  Applied to 218 real-world software enabler stories curated from authentic
engineering tasks, U2F achieved notable improvements: human experts reported a
14 percent increase in overall novelty, 51 percent improvement in semantic
novelty, and stable feasibility (4.02/5.0), corroborated by an LLM-based
evaluator. These results highlight the potential of embracing uncertainty as a
catalyst for innovation in software engineering.

</details>


### [17] [Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding](https://arxiv.org/abs/2511.03549)
*Ziv Nevo,Orna Raz,Karen Yorav*

Main category: cs.SE

TL;DR: 本文提出一种利用GitHub自然语言工件（如PR描述、Issue讨论和提交信息）增强大语言模型（LLM）代码理解能力的新方法，通过提取上下文、生成高层解释并验证其准确性，实验证明该方法能生成有帮助且无幻觉的代码洞察。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在解释代码时缺乏对软件工程整体上下文的理解，导致解释可能不够准确或缺乏深度。为提升代码解释的质量与实用性，作者希望借助GitHub上丰富的自然语言工件来增强LLM的代码理解能力。

Method: 系统包含三个组件：1）从GitHub提取并结构化相关上下文；2）利用该上下文生成代码目的的高层解释；3）验证生成解释的准确性。该系统既可作为独立工具，也可作为Model Context Protocol (MCP)中的服务器，与其他AI开发工具集成。

Result: 通过小规模用户研究（涵盖开源项目和私有项目开发者），结果表明系统生成的代码洞察通常具有帮助性、非平凡性，并且没有幻觉问题。

Conclusion: 结合GitHub自然语言工件能有效提升LLM对代码目的的理解，生成更可靠、实用的解释，为软件维护、新人入职和系统现代化等场景提供支持。

Abstract: Understanding the purpose of source code is a critical task in software
maintenance, onboarding, and modernization. While large language models (LLMs)
have shown promise in generating code explanations, they often lack grounding
in the broader software engineering context. We propose a novel approach that
leverages natural language artifacts from GitHub -- such as pull request
descriptions, issue descriptions and discussions, and commit messages -- to
enhance LLM-based code understanding. Our system consists of three components:
one that extracts and structures relevant GitHub context, another that uses
this context to generate high-level explanations of the code's purpose, and a
third that validates the explanation. We implemented this as a standalone tool,
as well as a server within the Model Context Protocol (MCP), enabling
integration with other AI-assisted development tools. Our main use case is that
of enhancing a standard LLM-based code explanation with code insights that our
system generates. To evaluate explanations' quality, we conducted a small scale
user study, with developers of several open projects, as well as developers of
proprietary projects. Our user study indicates that when insights are generated
they often are helpful and non trivial, and are free from hallucinations.

</details>


### [18] [The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents](https://arxiv.org/abs/2511.03690)
*Xingyao Wang,Simon Rosenberg,Juan Michelini,Calvin Smith,Hoang Tran,Engel Nyst,Rohit Malhotra,Xuhui Zhou,Valerie Chen,Robert Brennan,Graham Neubig*

Main category: cs.SE

TL;DR: 本文介绍了 OpenHands Software Agent SDK，这是一个用于构建灵活、安全、可交互的软件开发智能体的新工具包，在多个基准测试中表现出色，并支持大规模部署。


<details>
  <summary>Details</summary>
Motivation: 构建可用于生产的软件工程智能体十分复杂，现有方案在灵活性、安全性、可靠性及用户交互方面存在不足，因此需要一个综合性的开发工具包来满足这些需求。

Method: 作者对流行的 OpenHands 框架进行了完整的架构重构，设计了一个简洁但可扩展的智能体接口，支持自定义工具、内存管理、本地到远程无缝执行、REST/WebSocket 服务以及多种用户交互界面（如 VS Code、VNC、CLI 和 API）。该 SDK 还集成了沙箱执行、生命周期控制、多模型路由和内置安全分析。

Result: 在 SWE-Bench Verified 和 GAIA 基准测试中，OpenHands SDK 展现出强大的性能，优于 OpenAI、Claude 和 Google 现有的 SDK。

Conclusion: OpenHands Software Agent SDK 为软件开发智能体的原型设计、定制化应用开发和大规模可靠部署提供了实用且全面的基础。

Abstract: Agents are now used widely in the process of software development, but
building production-ready software engineering agents is a complex task.
Deploying software agents effectively requires flexibility in implementation
and experimentation, reliable and secure execution, and interfaces for users to
interact with agents. In this paper, we present the OpenHands Software Agent
SDK, a toolkit for implementing software development agents that satisfy these
desiderata. This toolkit is a complete architectural redesign of the agent
components of the popular OpenHands framework for software development agents,
which has 64k+ GitHub stars. To achieve flexibility, we design a simple
interface for implementing agents that requires only a few lines of code in the
default case, but is easily extensible to more complex, full-featured agents
with features such as custom tools, memory management, and more. For security
and reliability, it delivers seamless local-to-remote execution portability,
integrated REST/WebSocket services. For interaction with human users, it can
connect directly to a variety of interfaces, such as visual workspaces (VS
Code, VNC, browser), command-line interfaces, and APIs. Compared with existing
SDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native
sandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and
built-in security analysis. Empirical results on SWE-Bench Verified and GAIA
benchmarks demonstrate strong performance. Put together, these elements allow
the OpenHands Software Agent SDK to provide a practical foundation for
prototyping, unlocking new classes of custom applications, and reliably
deploying agents at scale.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [19] [Harvesting energy consumption on European HPC systems: Sharing Experience from the CEEC project](https://arxiv.org/abs/2511.03029)
*Kajol Kulkarni,Samuel Kemmler,Anna Schwarz,Gulcin Gedik,Yanxiang Chen,Dimitrios Papageorgiou,Ioannis Kavroulakis,Roman Iakymchuk*

Main category: cs.DC

TL;DR: 本文总结了EuroHPC CEEC中心在欧洲主要HPC系统上测量、分析和优化CFD应用能耗的经验，强调加速器和混合精度技术在降低能耗方面的优势，并呼吁加强HPC系统的能耗监测以推动可持续的超算发展。


<details>
  <summary>Details</summary>
Motivation: 现代高性能计算（HPC）系统因计算需求激增和架构复杂性提升而面临严峻的能效挑战，亟需系统性方法来评估与优化能耗。

Method: 通过回顾主流能耗测量方法与工具，定义标准化指标，并在多个欧洲HPC系统（如LUMI、MareNostrum5等）上对代表性CFD应用（waLBerla、FLEXI/GALÆXI、Neko、NekRS）开展案例研究，评估其“能耗-求解时间”和“时间-求解时间”表现。

Result: 实验结果表明，使用加速器（如GPU）和混合精度计算可显著降低能耗，同时保持计算精度。

Conclusion: 应推动在HPC系统中普及能耗测量，提高社区意识，培养相关能力，并采取行动实现更可持续的exascale计算。

Abstract: Energy efficiency has emerged as a central challenge for modern
high-performance computing (HPC) systems, where escalating computational
demands and architectural complexity have led to significant energy footprints.
This paper presents the collective experience of the EuroHPC JU Center of
Excellence in Exascale CFD (CEEC) in measuring, analyzing, and optimizing
energy consumption across major European HPC systems. We briefly review key
methodologies and tools for energy measurement as well as define metrics for
reporting results. Through case studies using representative CFD applications
(waLBerla, FLEXI/GAL{\AE}XI, Neko, and NekRS), we evaluate energy-to-solution
and time-to-solution metrics on diverse architectures, including CPU- and
GPU-based partitions of LUMI, MareNostrum5, MeluXina, and JUWELS Booster. Our
results highlight the advantages of accelerators and mixed-precision techniques
for reducing energy consumption while maintaining computational accuracy.
Finally, we advocate the need to facilitate energy measurements on HPC systems
in order to raise awareness, teach the community, and take actions toward more
sustainable exascale computing.

</details>


### [20] [UMDAM: A Unified Data Layout and DRAM Address Mapping for Heterogenous NPU-PIM](https://arxiv.org/abs/2511.03293)
*Hai Huang,Xuhong Qiang,Weisheng Zhao,Chenchen Liu*

Main category: cs.DC

TL;DR: UMDAM 是一种面向 NPU-PIM 协同执行的统一内存亲和性数据布局与 DRAM 地址映射方案，显著提升边缘设备上大语言模型推理效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在边缘设备上的解码阶段内存密集，限制性能；尽管存内计算（PIM）有潜力，但 NPU-PIM 协同执行面临数据布局不匹配、带宽损失和冗余存储等问题。

Method: 提出 UMDAM 方案，采用列优先的分块数据布局和可配置的 DRAM 映射策略，在不增加内存开销或带宽损失的前提下，兼顾 NPU 计算兼容性与 PIM 效率。

Result: 在 OPT 模型上的评估表明，UMDAM 最多将首 token 延迟（TTFT）降低 3.0 倍，末 token 延迟（TTLT）降低 2.18 倍。

Conclusion: UMDAM 显著提升了边缘设备上大语言模型端到端推理效率，为 NPU-PIM 协同架构提供了高效内存管理方案。

Abstract: Large Language Models (LLMs) are increasingly deployed on edge devices with
Neural Processing Units (NPUs), yet the decode phase remains memory-intensive,
limiting performance. Processing-in-Memory (PIM) offers a promising solution,
but co-executing NPU-PIM systems face challenges such as data layout
mismatches, bandwidth loss, and redundant storage. To address these issues, we
propose UMDAM, a unified memory-affinity data layout and DRAM address mapping
scheme tailored for NPU-PIM co-execution. UMDAM employs a column-major,
tile-based layout and a configurable DRAM mapping strategy to ensure
compatibility with NPU computation while maximizing PIM efficiency -- without
introducing extra memory overhead or bandwidth loss. Comprehensive evaluations
on OPT models demonstrate that UMDAM reduces time-to-first-token (TTFT) by up
to 3.0x and time-to-last-token (TTLT) by 2.18x, significantly improving
end-to-end LLM inference efficiency on edge devices.

</details>


### [21] [Investigating the Impact of Isolation on Synchronized Benchmarks](https://arxiv.org/abs/2511.03533)
*Nils Japke,Furat Hamdan,Diana Baumann,David Bermbach*

Main category: cs.DC

TL;DR: Duet benchmarking reduces cloud performance variability by running two synchronized workloads on the same VM; this paper evaluates three isolation strategies—cgroups/CPU pinning, Docker containers, and Firecracker MicroVMs—and finds that process-level isolation (except Docker) effectively reduces false positives under resource contention.


<details>
  <summary>Details</summary>
Motivation: Cloud benchmarking is affected by performance variability due to multi-tenant interference; duet benchmarking addresses this by co-locating workloads but introduces intra-VM contention, necessitating effective isolation mechanisms.

Method: The authors evaluate three isolation strategies—cgroups with CPU pinning, Docker containers, and Firecracker MicroVMs—using a duet benchmarking setup combined with a noise generator that simulates resource contention. Performance is compared against an unisolated baseline.

Result: All isolation methods altered latency distributions under noise, but process isolation (cgroups/CPU pinning and Firecracker) reduced false positives. Docker containers, despite using cgroups internally, showed higher susceptibility to performance degradation.

Conclusion: Process-level isolation is recommended for synchronized duet workloads in cloud benchmarking, but Docker containers should be avoided due to their vulnerability to noise-induced performance degradation.

Abstract: Benchmarking in cloud environments suffers from performance variability from
multi-tenant resource contention. Duet benchmarking mitigates this by running
two workload versions concurrently on the same VM, exposing them to identical
external interference. However, intra-VM contention between synchronized
workloads necessitates additional isolation mechanisms.
  This work evaluates three such strategies: cgroups and CPU pinning, Docker
containers, and Firecracker MicroVMs. We compare all strategies with an
unisolated baseline experiment, by running benchmarks with a duet setup
alongside a noise generator. This noise generator "steals" compute resources to
degrade performance measurements.
  All experiments showed different latency distributions while under the
effects of noise generation, but results show that process isolation generally
lowered false positives, except for our experiments with Docker containers.
Even though Docker containers rely internally on cgroups and CPU pinning, they
were more susceptible to performance degradation due to noise influence.
Therefore, we recommend to use process isolation for synchronized workloads,
with the exception of Docker containers.

</details>


### [22] [Stone Duality Proofs for Colorless Distributed Computability Theorems](https://arxiv.org/abs/2511.03609)
*Cameron Calk,Emmanuel Godard*

Main category: cs.DC

TL;DR: 本文通过引入谱空间作为新的拓扑编码工具，对基于轮次的全信息敌手模型中的执行进行建模，并给出了针对紧致敌手的无色任务可解性的完整刻画。利用Alexandrov拓扑和Stone对偶性，作者建立了新的分布式可计算性定理，并揭示了有色与无色模型在可计算能力上的等价性具有深刻的拓扑根源。


<details>
  <summary>Details</summary>
Motivation: 传统上使用抽象单纯复形对分布式协议的全局状态进行拓扑建模，但这种方法在处理某些表达力强的敌手模型（如消息敌手）时存在局限。为统一并拓展拓扑方法在分布式计算中的应用，作者寻求一种更合适的拓扑结构来刻画执行空间，特别是针对无色任务在紧致敌手下的可解性问题。

Method: 作者将有限执行后的全局状态视为面偏序集上的Alexandrov拓扑所诱导的谱空间，而非传统的抽象单纯复形。对于给定敌手ℳ和输入集合ℐ，他们在谱空间范畴中通过射影极限构造了一个极限对象Π^∞_ℳ(ℐ)。然后利用Stone对偶性，将任务可解性问题转化为是否存在一个与任务规范Δ兼容的谱映射f: Π^∞_ℳ(ℐ) → 𝒪。

Result: 提出了一个新的通用分布式可计算性定理：无色任务(ℐ,𝒪,Δ)在紧致敌手ℳ下可解当且仅当存在满足条件的谱映射。该框架不仅推导出许多已知的无色可计算性定理，还从拓扑角度解释了有色模型与无色模型在可计算能力上的等价性。

Conclusion: 通过采用谱空间和Stone对偶性，本文为分布式计算中的拓扑方法提供了更强大和统一的理论基础，深化了对无色任务可解性以及不同计算模型间等价性的理解。

Abstract: We introduce a new topological encoding by spectral spaces of executions of
  round-based full-information adversaries, a model of distributed computations
that is functorially presented and that
  contains many message adversaries. We give a characterization of the
solvability of colorless tasks against compact adversaries.
  Message adversaries are distributed
  models that are known to be very expressive despite being
  round-based and crash-free. Colorless tasks are
  an important class of distributed tasks. For a colorless task, the
  specification does not depend upon the multiplicity of input or
  output values, like the ubiquitous agreement tasks.
  Therefore, our result is a significant
  step toward unifying topological methods in distributed computing.
  The main insight is to consider global states obtained after finite
executions of a distributed protocol
  not as abstract
  simplicial complexes as previously done, but as spectral
  spaces, considering the Alexandrov topology on the faces poset. Given
  an adversary $\mathcal M$ with a set of inputs $\mathcal I$,
  we define a limit object $\Pi^\infty_\mathcal M(\mathcal I)$
  by projective limit in the category of spectral spaces. We derive a new
general distributed computability
  theorem using Stone duality: there exists an algorithm solving a colorless
task $(\mathcal I,\mathcal O,\Delta)$
  against the compact adversary $\mathcal M$ if and only if there exists a
spectral
  map $f:\Pi^\infty_\mathcal M(\mathcal I)\longrightarrow\mathcal O$ compatible
with $\Delta$.
  From this general characterization are derived many known colorless
computability
  theorems.
  Quite surprisingly, colored and uncolored models have the same
  computability power (they solve the same tasks). Our new proofs give
  topological reasons for this equivalence, previously known through
  algorithmic reductions.

</details>


### [23] [A General Input-Dependent Colorless Computability Theorem and Applications to Core-Dependent Adversaries](https://arxiv.org/abs/2511.03662)
*Yannis Coutouly,Emmanuel Godard*

Main category: cs.DC

TL;DR: 本文将颜色无关可计算性定理推广至输入依赖的敌手模型，证明了IIS_n中核心弹性敌手与仅在初始时刻发生崩溃的核心弹性敌手具有相同的计算能力，并基于此给出了条件驱动、核心依赖敌手下k-集共识问题可解的充要条件。


<details>
  <summary>Details</summary>
Motivation: 现有工作已对IIS模型中的无色任务可解性进行了刻画，并推广到任意消息敌手；同时，条件敌手模型研究了特定输入子集下的k-集共识问题。然而，尚未有工作将这些结果统一并扩展到输入依赖型敌手的情形，也缺乏对条件驱动、核心依赖敌手下k-集共识问题的完整刻画。

Method: 利用分布式计算中的拓扑框架和几何构造方法，将已有定理推广到输入依赖敌手模型，分析核心弹性敌手的计算能力，并结合前两项贡献推导出k-集共识在条件驱动、核心依赖敌手下可解的充要条件。

Result: 1）成功将CG-24的结果推广至输入依赖敌手；2）证明IIS_n中两类核心弹性敌手计算能力等价；3）给出条件驱动、核心依赖敌手下k-集共识可解的充要条件，并识别出任务表示中的四种情形；4）提出载体映射Δ的结构性质以简化证明。

Conclusion: 通过拓扑与几何方法，本文系统地扩展了无色任务可计算性理论，为更复杂的敌手模型（如输入依赖、条件驱动和核心依赖）下的分布式任务可解性提供了完整的刻画，尤其解决了k-集共识问题的判定条件。

Abstract: Distributed computing tasks can be presented with a triple $(\I,\Ou,\Delta)$.
The solvability of a colorless task on the Iterated Immediate Snapshot model
(IIS) has been characterized by the Colorless Computability Theorem
\cite[Th.4.3.1]{HKRbook}. A recent paper~\cite{CG-24} generalizes this theorem
for any message adversaries $\ma \subseteq IIS$ by geometric methods. In 2001,
Most\'efaoui, Rajsbaum, Raynal, and Roy \cite{condbased} introduced
\emph{condition-based adversaries}. This setting considers a particular
adversary that will be applied only to a subset of input configurations. In
this setting, they studied the $k$-set agreement task with condition-based
$t$-resilient adversaries and obtained a sufficient condition on the conditions
that make $k$-Set Agreement solvable. In this paper we have three
contributions:
  -We generalize the characterization of~\cite{CG-24} to \emph{input-dependent}
adversaries, which means that the adversaries can change depending on the input
configuration.
  - We show that core-resilient adversaries of $IIS_n$ have the same
computability power as the core-resilient adversaries of $IIS_n$ where crashes
only happen at the start.
  - Using the two previous contributions, we provide a necessary and sufficient
characterization of the condition-based, core-dependent adversaries that can
solve $k$-Set Agreement. We also distinguish four settings that may appear when
presenting a distributed task as $(\I,\Ou,\Delta)$. Finally, in a later
section, we present structural properties on the carrier map $\Delta$. Such
properties allow simpler proof, without changing the computability power of the
task. Most of the proofs in this article leverage the topological framework
used in distributed computing by using simple geometric constructions.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [24] [An Event-Driven Spiking Compute-In-Memory Macro based on SOT-MRAM](https://arxiv.org/abs/2511.03203)
*Deyang Yu,Chenchen Liu,Chuanjie Zhang,Xiao Fang,Weisheng Zhao*

Main category: cs.AR

TL;DR: 本文提出了一种基于SOT-MRAM的事件驱动型存内计算宏架构，通过轻量级脉冲编码电路和混合串并联单元结构实现高效能矩阵向量乘法，显著降低能耗，在28nm工艺下达到243.6 TOPS/W的能效。


<details>
  <summary>Details</summary>
Motivation: 现有MRAM存内计算设计依赖复杂的模拟电路进行运算，导致高能耗问题，亟需一种更节能的替代方案。

Method: 采用自旋轨道矩MRAM（SOT-MRAM）交叉阵列，结合混合串并联存储单元结构，并利用轻量级电路将信号信息以脉冲形式编码/解码，实现事件驱动的脉冲处理机制，避免使用传统高功耗模拟电路。

Result: 在28nm工艺下实现的SOT-MRAM存内计算宏达到峰值能效243.6 TOPS/W，显著优于现有设计。

Conclusion: 所提出的SOT-MRAM存内计算架构通过事件驱动与脉冲编码方式有效提升了能效，为低功耗存内计算提供了可行路径。

Abstract: The application of Magnetic Random-Access Memory (MRAM) in
computing-in-memory (CIM) has gained significant attention. However, existing
designs often suffer from high energy consumption due to their reliance on
complex analog circuits for computation. In this work, we present a Spin-Orbit-
Torque MRAM(SOT-MRAM)-based CIM macro that employs an event-driven spiking
processing for high energy efficiency. The SOT-MRAM crossbar adopts a hybrid
series-parallel cell structure to efficiently support matrix-vector
multiplication (MVM). Signal information is (en) decoded as spikes using
lightweight circuits, eliminating the need for conventional area- and
powerintensive analog circuits. The SOT-MRAM macro is designed and evaluated in
28nm technology, and experimental results show that it achieves a peak energy
efficiency of 243.6 TOPS/W, significantly outperforming existing designs.

</details>


### [25] [Design and Optimization of Mixed-Kernel Mixed-Signal SVMs for Flexible Electronics](https://arxiv.org/abs/2511.03427)
*Florentia Afentaki,Maha Shatta,Konstantinos Balaskas,Georgios Panagopoulos,Georgios Zervakis,Mehdi B. Tahoori*

Main category: cs.AR

TL;DR: 本文提出了一种面向柔性电子（FE）的混合核与混合信号支持向量机（SVM）设计，通过联合优化训练与映射策略，在保持高准确率的同时显著降低面积和功耗。


<details>
  <summary>Details</summary>
Motivation: 柔性电子器件受限于较大的特征尺寸，难以实现高集成度的机器学习电路；现有SVM设计在硬件成本与准确率之间存在权衡，线性核精度不足，RBF核则面积和功耗过高。

Method: 提出首个混合核（线性+RBF）与混合信号（数字+模拟）SVM架构，并引入协同优化方法，将二元分类器智能分配至合适的核类型与信号域，以在控制RBF使用数量的同时最大化准确率。

Result: 相比最先进的单一线性核SVM，准确率提升7.7%；相比全数字RBF实现，平均面积减少108倍，功耗降低17倍。

Conclusion: 所提出的混合核混合信号SVM设计有效平衡了柔性电子中准确率与资源开销之间的矛盾，为近传感器智能应用提供了可行的低功耗高精度解决方案。

Abstract: Flexible Electronics (FE) have emerged as a promising alternative to
silicon-based technologies, offering on-demand low-cost fabrication,
conformality, and sustainability. However, their large feature sizes severely
limit integration density, imposing strict area and power constraints, thus
prohibiting the realization of Machine Learning (ML) circuits, which can
significantly enhance the capabilities of relevant near-sensor applications.
Support Vector Machines (SVMs) offer high accuracy in such applications at
relatively low computational complexity, satisfying FE technologies'
constraints. Existing SVM designs rely solely on linear or Radial Basis
Function (RBF) kernels, forcing a trade-off between hardware costs and
accuracy. Linear kernels, implemented digitally, minimize overhead but
sacrifice performance, while the more accurate RBF kernels are prohibitively
large in digital, and their analog realization contains inherent functional
approximation. In this work, we propose the first mixed-kernel and mixed-signal
SVM design in FE, which unifies the advantages of both implementations and
balances the cost/accuracy trade-off. To that end, we introduce a
co-optimization approach that trains our mixed-kernel SVMs and maps binary SVM
classifiers to the appropriate kernel (linear/RBF) and domain (digital/analog),
aiming to maximize accuracy whilst reducing the number of costly RBF
classifiers. Our designs deliver 7.7% higher accuracy than state-of-the-art
single-kernel linear SVMs, and reduce area and power by 108x and 17x on average
compared to digital RBF implementations.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [26] [PerfDojo: Automated ML Library Generation for Heterogeneous Architectures](https://arxiv.org/abs/2511.03586)
*Andrei Ivanov,Siyuan Shen,Gioele Gottardo,Marcin Chrapek,Afif Boudaoud,Timo Schneider,Luca Benini,Torsten Hoefler*

Main category: cs.PF

TL;DR: PerfLLM 是一种结合大语言模型（LLM）与强化学习（RL）的新型自动优化方法，通过名为 PerfDojo 的环境，利用人类可读且语义有效的代码表示，在无需硬件先验知识的情况下实现跨 CPU 和 GPU 架构的高性能优化。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型日益复杂，加上硬件架构（如 CPU、GPU、加速器）的多样性，使得实现最优性能极具挑战。现有自动优化方法依赖复杂的硬件特定启发式和不可解释的中间表示，难以实现性能可移植性。

Method: 提出 PerfLLM 方法，结合大语言模型与强化学习；核心是 PerfDojo 环境，将优化问题建模为 RL 游戏，使用数学启发、人类可读且语义有效的代码表示进行变换。

Result: 在多种 CPU（x86、Arm、RISC-V）和 GPU 架构上实现了显著的性能提升。

Conclusion: PerfLLM 能在无需硬件先验知识的前提下，有效实现跨架构性能优化，同时支持人类分析与 RL 训练，提升了优化的可解释性与可移植性。

Abstract: The increasing complexity of machine learning models and the proliferation of
diverse hardware architectures (CPUs, GPUs, accelerators) make achieving
optimal performance a significant challenge. Heterogeneity in instruction sets,
specialized kernel requirements for different data types and model features
(e.g., sparsity, quantization), and architecture-specific optimizations
complicate performance tuning. Manual optimization is resource-intensive, while
existing automatic approaches often rely on complex hardware-specific
heuristics and uninterpretable intermediate representations, hindering
performance portability. We introduce PerfLLM, a novel automatic optimization
methodology leveraging Large Language Models (LLMs) and Reinforcement Learning
(RL). Central to this is PerfDojo, an environment framing optimization as an RL
game using a human-readable, mathematically-inspired code representation that
guarantees semantic validity through transformations. This allows effective
optimization without prior hardware knowledge, facilitating both human analysis
and RL agent training. We demonstrate PerfLLM's ability to achieve significant
performance gains across diverse CPU (x86, Arm, RISC-V) and GPU architectures.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [27] [DecodeX: Exploring and Benchmarking of LDPC Decoding across CPU, GPU, and ASIC Platforms](https://arxiv.org/abs/2511.02952)
*Zhenzhou Qi,Yuncheng Yao,Yiming Li,Chung-Hsuan Tung,Junyao Zheng,Danyang Zhuo,Tingjun Chen*

Main category: cs.NI

TL;DR: DecodeX 是一个统一的基准测试框架，用于评估不同硬件平台（CPU、GPU、ASIC）上 LDPC 解码加速性能，揭示了并行效率与卸载开销之间的权衡，并为未来异构 vRAN 的自适应调度与协同设计提供依据。


<details>
  <summary>Details</summary>
Motivation: 新兴的虚拟化无线接入网（vRAN）需要在异构计算平台上实现灵活高效的基带处理，但缺乏统一的基准工具来系统评估 LDPC 解码在不同硬件上的性能表现。

Method: 提出 DecodeX 框架，集成多种 LDPC 解码器实现（包括 CPU、GPU 和 ASIC），通过统一接口和测试向量，系统评估各平台在计算调度、内存管理、数据移动和加速器卸载等方面的性能，并测量不同物理层参数下的解码延迟。

Result: 实验揭示了不同平台在并行效率与卸载开销方面的显著差异，表明加速器收益高度依赖于数据移动成本和任务粒度。

Conclusion: 跨平台基准测试可为未来异构 vRAN 中的自适应调度和软硬件协同设计提供关键指导，从而实现可扩展且能效高的基带处理，支持下一代无线系统。

Abstract: Emerging virtualized radio access networks (vRANs) demand flexible and
efficient baseband processing across heterogeneous compute substrates. In this
paper, we present DecodeX, a unified benchmarking framework for evaluating
low-density parity-check (LDPC) decoding acceleration across different hardware
platforms. DecodeX integrates a comprehensive suite of LDPC decoder
implementations, including kernels, APIs, and test vectors for CPUs (FlexRAN),
GPUs (Aerial and Sionna-RK), and ASIC (ACC100), and can be readily extended to
additional architectures and configurations. Using DecodeX, we systematically
characterize how different platforms orchestrate computation-from threading and
memory management to data movement and accelerator offload-and quantify the
resulting decoding latency under varying Physical layer parameters. Our
observations reveal distinct trade-offs in parallel efficiency and offload
overhead, showing that accelerator gains strongly depend on data-movement and
workload granularity. Building on these insights, we discuss how cross-platform
benchmarking can inform adaptive scheduling and co-design for future
heterogeneous vRANs, enabling scalable and energy-efficient baseband processing
for NextG wireless systems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [28] [ALAS: Transactional and Dynamic Multi-Agent LLM Planning](https://arxiv.org/abs/2511.03094)
*Longling Geng,Edward Y. Chang*

Main category: cs.MA

TL;DR: ALAS is a stateful, disruption-aware framework for multi-agent LLM planning that improves reliability and efficiency by decoupling non-circular validation, maintaining versioned execution logs, and enabling localized repair—outperforming baselines in success rate, speed, and token usage on job-shop scheduling benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing large language model–based multi-agent planning systems suffer from fragility: they often rely on circular verification, fail to track state changes for effective repair, and resort to expensive global recomputation when errors occur.

Method: ALAS introduces a framework that separates planning from independent, non-circular validation using fresh bounded context; records a versioned execution log for grounded checks and restore points; and applies localized repair via minimal edits guided by explicit policies (e.g., retry, timeout, compensation) encoded in a canonical workflow IR compatible with Amazon States Language and Argo Workflows.

Result: On job-shop scheduling benchmarks (DMU, TA), ALAS achieves 83.7% success rate, reduces token usage by 60%, and runs 1.82× faster than strong single-LLM and multi-agent baselines. It also effectively detects injected faults with low overhead and limits makespan degradation through bounded, localized repairs.

Conclusion: The integration of validator isolation, versioned execution logs, and policy-driven localized repair significantly enhances the efficiency, feasibility, and scalability of multi-agent LLM planning systems.

Abstract: Large language models enable flexible multi-agent planning but remain fragile
in practice: verification is often circular, state changes are not tracked for
repair, and small faults trigger costly global recomputation. We present ALAS,
a stateful, disruption-aware framework that separates planning from
non-circular validation, records a versioned execution log for grounded checks
and restore points, and performs localized repair that preserves work in
progress. The validator operates independently of the planning LLM with fresh,
bounded context, avoiding self-check loops and mid-context attrition. The
repair protocol edits only the minimal affected region under explicit policies
(retry, catch, timeout, backoff, idempotency keys, compensation, loop guards)
defined in a canonical workflow IR that maps to Amazon States Language and Argo
Workflows. On job-shop scheduling suites (DMU, TA) across five classical
benchmarks, ALAS matches or exceeds strong single-LLM and multi-agent
baselines, achieving 83.7% success, reducing token usage by 60%, and running
1.82times faster under comparable settings. A minimal reliability study shows
that the validator detects injected structural faults with low overhead, and
that localized repair contains runtime perturbations with a bounded edit radius
and less makespan degradation than global recompute. Results indicate that the
combination of validator isolation, versioned execution logs, and localized
repair provides measurable efficiency, feasibility, and scalability for
multi-agent LLM planning. Code and seeds will be released.

</details>
