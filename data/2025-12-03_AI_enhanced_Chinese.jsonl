{"id": "2512.02300", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.02300", "abs": "https://arxiv.org/abs/2512.02300", "authors": ["Haoyu Zheng", "Shouwei Gao", "Jie Ren", "Wenqian Dong"], "title": "DOLMA: A Data Object Level Memory Disaggregation Framework for HPC Applications", "comment": null, "summary": "Memory disaggregation is promising to scale memory capacity and improves utilization in HPC systems. However, the performance overhead of accessing remote memory poses a significant challenge, particularly for compute-intensive HPC applications where execution times are highly sensitive to data locality. In this work, we present DOLMA, a Data Object Level M emory dis Aggregation framework designed for HPC applications. DOLMA intelligently identifies and offloads data objects to remote memory, while providing quantitative analysis to decide a suitable local memory size. Furthermore, DOLMA leverages the predictable memory access patterns typical in HPC applications and enables remote memory prefetch via a dual-buffer design. By carefully balancing local and remote memory usage and maintaining multi-thread concurrency, DOLMA provides a flexible and efficient solution for leveraging disaggregated memory in HPC domains while minimally compromising application performance. Evaluating with eight HPC workloads and computational kernels, DOLMA limits performance degradation to less than 16% while reducing local memory usage by up to 63%, on average.", "AI": {"tldr": "DOLMA \u662f\u4e00\u79cd\u9762\u5411\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u7684\u6570\u636e\u5bf9\u8c61\u7ea7\u5185\u5b58\u89e3\u8026\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u8bc6\u522b\u6570\u636e\u5bf9\u8c61\u3001\u5b9a\u91cf\u5206\u6790\u672c\u5730\u5185\u5b58\u9700\u6c42\u3001\u5229\u7528\u53ef\u9884\u6d4b\u7684\u8bbf\u95ee\u6a21\u5f0f\u8fdb\u884c\u8fdc\u7a0b\u9884\u53d6\uff0c\u5728\u663e\u8457\u964d\u4f4e\u672c\u5730\u5185\u5b58\u4f7f\u7528\u7684\u540c\u65f6\u5c06\u6027\u80fd\u635f\u5931\u63a7\u5236\u572816%\u4ee5\u5185\u3002", "motivation": "\u5185\u5b58\u89e3\u8026\u867d\u80fd\u63d0\u5347HPC\u7cfb\u7edf\u5185\u5b58\u5bb9\u91cf\u548c\u5229\u7528\u7387\uff0c\u4f46\u8fdc\u7a0b\u5185\u5b58\u8bbf\u95ee\u5e26\u6765\u7684\u6027\u80fd\u5f00\u9500\u5bf9\u8ba1\u7b97\u5bc6\u96c6\u578bHPC\u5e94\u7528\u5f71\u54cd\u663e\u8457\uff0c\u56e0\u5176\u6267\u884c\u65f6\u95f4\u9ad8\u5ea6\u4f9d\u8d56\u6570\u636e\u5c40\u90e8\u6027\u3002", "method": "DOLMA \u6846\u67b6\u901a\u8fc7\u667a\u80fd\u8bc6\u522b\u5e76\u5378\u8f7d\u6570\u636e\u5bf9\u8c61\u81f3\u8fdc\u7a0b\u5185\u5b58\uff0c\u63d0\u4f9b\u672c\u5730\u5185\u5b58\u5927\u5c0f\u7684\u5b9a\u91cf\u5206\u6790\uff1b\u5229\u7528HPC\u5e94\u7528\u4e2d\u53ef\u9884\u6d4b\u7684\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff0c\u91c7\u7528\u53cc\u7f13\u51b2\u8bbe\u8ba1\u5b9e\u73b0\u8fdc\u7a0b\u5185\u5b58\u9884\u53d6\uff0c\u5e76\u5e73\u8861\u672c\u5730/\u8fdc\u7a0b\u5185\u5b58\u4f7f\u7528\u4e0e\u591a\u7ebf\u7a0b\u5e76\u53d1\u3002", "result": "\u57288\u4e2aHPC\u5de5\u4f5c\u8d1f\u8f7d\u548c\u8ba1\u7b97\u6838\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cDOLMA \u5e73\u5747\u6700\u591a\u51cf\u5c1163%\u7684\u672c\u5730\u5185\u5b58\u4f7f\u7528\uff0c\u540c\u65f6\u5c06\u6027\u80fd\u4e0b\u964d\u63a7\u5236\u572816%\u4ee5\u5185\u3002", "conclusion": "DOLMA \u4e3aHPC\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u9ad8\u6548\u7684\u5185\u5b58\u89e3\u8026\u65b9\u6848\uff0c\u5728\u5927\u5e45\u964d\u4f4e\u672c\u5730\u5185\u5b58\u9700\u6c42\u7684\u540c\u65f6\uff0c\u5bf9\u5e94\u7528\u6027\u80fd\u5f71\u54cd\u6781\u5c0f\u3002"}}
{"id": "2512.02646", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.02646", "abs": "https://arxiv.org/abs/2512.02646", "authors": ["Alex Barcel\u00f3", "Sebasti\u00e1n A. Cajas Ordo\u00f1ez", "Jaydeep Samanta", "Andr\u00e9s L. Su\u00e1rez-Cetrulo", "Romila Ghosh", "Ricardo Sim\u00f3n Carbajo", "Anna Queralt"], "title": "Offloading Artificial Intelligence Workloads across the Computing Continuum by means of Active Storage Systems", "comment": "17 pages, 7 tables, 12 figures", "summary": "The increasing demand for artificial intelligence (AI) workloads across diverse computing environments has driven the need for more efficient data management strategies. Traditional cloud-based architectures struggle to handle the sheer volume and velocity of AI-driven data, leading to inefficiencies in storage, computation, and data movement. This paper explores the integration of active storage systems within the computing continuum to optimize AI workload distribution.\n  By embedding computation directly into storage architectures, active storage is able to reduce data transfer overhead, enhancing performance and improving resource utilization. Other existing frameworks and architectures offer mechanisms to distribute certain AI processes across distributed environments; however, they lack the flexibility and adaptability that the continuum requires, both regarding the heterogeneity of devices and the rapid-changing algorithms and models being used by domain experts and researchers.\n  This article proposes a software architecture aimed at seamlessly distributing AI workloads across the computing continuum, and presents its implementation using mainstream Python libraries and dataClay, an active storage platform. The evaluation shows the benefits and trade-offs regarding memory consumption, storage requirements, training times, and execution efficiency across different devices. Experimental results demonstrate that the process of offloading workloads through active storage significantly improves memory efficiency and training speeds while maintaining accuracy. Our findings highlight the potential of active storage to revolutionize AI workload management, making distributed AI deployments more scalable and resource-efficient with a very low entry barrier for domain experts and application developers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e3b\u52a8\u5b58\u50a8\u7684\u8f6f\u4ef6\u67b6\u6784\uff0c\u7528\u4e8e\u5728\u8ba1\u7b97\u8fde\u7eed\u4f53\u4e2d\u9ad8\u6548\u5206\u53d1AI\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u663e\u8457\u63d0\u5347\u5185\u5b58\u6548\u7387\u548c\u8bad\u7ec3\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edf\u4e91\u67b6\u6784\u96be\u4ee5\u5e94\u5bf9AI\u5de5\u4f5c\u8d1f\u8f7d\u5e26\u6765\u7684\u6d77\u91cf\u6570\u636e\u5904\u7406\u9700\u6c42\uff0c\u5b58\u5728\u5b58\u50a8\u3001\u8ba1\u7b97\u548c\u6570\u636e\u4f20\u8f93\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff1b\u73b0\u6709\u5206\u5e03\u5f0f\u6846\u67b6\u7f3a\u4e4f\u5bf9\u8bbe\u5907\u5f02\u6784\u6027\u548c\u7b97\u6cd5\u5feb\u901f\u6f14\u8fdb\u7684\u9002\u5e94\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5c06\u8ba1\u7b97\u5d4c\u5165\u5b58\u50a8\u67b6\u6784\uff08\u5373\u4e3b\u52a8\u5b58\u50a8\uff09\uff0c\u5229\u7528dataClay\u5e73\u53f0\u4e0e\u4e3b\u6d41Python\u5e93\u5b9e\u73b0\u4e00\u4e2a\u53ef\u5728\u8ba1\u7b97\u8fde\u7eed\u4f53\u4e2d\u65e0\u7f1d\u5206\u53d1AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u8f6f\u4ef6\u67b6\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u4e3b\u52a8\u5b58\u50a8\u5378\u8f7d\u5de5\u4f5c\u8d1f\u8f7d\u53ef\u663e\u8457\u63d0\u9ad8\u5185\u5b58\u6548\u7387\u548c\u8bad\u7ec3\u901f\u5ea6\uff0c\u540c\u65f6\u5728\u4e0d\u540c\u8bbe\u5907\u4e0a\u4fdd\u6301\u6a21\u578b\u51c6\u786e\u6027\uff0c\u5e76\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u3002", "conclusion": "\u4e3b\u52a8\u5b58\u50a8\u6709\u671b\u9769\u65b0AI\u5de5\u4f5c\u8d1f\u8f7d\u7ba1\u7406\u65b9\u5f0f\uff0c\u4f7f\u5206\u5e03\u5f0fAI\u90e8\u7f72\u66f4\u5177\u53ef\u6269\u5c55\u6027\u548c\u8d44\u6e90\u6548\u7387\uff0c\u4e14\u5bf9\u9886\u57df\u4e13\u5bb6\u548c\u5f00\u53d1\u8005\u5177\u6709\u8f83\u4f4e\u4f7f\u7528\u95e8\u69db\u3002"}}
{"id": "2512.02189", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02189", "abs": "https://arxiv.org/abs/2512.02189", "authors": ["Aaron Jarmusch", "Sunita Chandrasekaran"], "title": "Microbenchmarking NVIDIA's Blackwell Architecture: An in-depth Architectural Analysis", "comment": null, "summary": "As GPU architectures rapidly evolve to meet the overcoming demands of exascale computing and machine learning, the performance implications of architectural innovations remain poorly understood across diverse workloads. NVIDIA's Blackwell (B200) generation introduce significant architectural advances including the 5th generation tensor cores, tensor memory (TMEM), decompression engine (DE), and dual chips; however systematic methodologies for quantifying these improvements lag behind hardware development cycles. We contribute an open-source microbenchmark suite that offers practical insights into optimizing workloads to fully utilize the rich feature sets of the modern GPU architecture. This work aims to enable application developers make informed architectural decisions and guide future GPU design directions.\n  Our work studies Blackwell GPUs, compares them to H200 generation with regards to the memory subsystem, tensor core pipeline and floating-point precisions (FP32, FP16, FP8, FP6, FP4). Our systematic evaluation of dense/sparse GEMM, transformer inference, and training workloads demonstrate that B200's tensor core enhancements achieves 1.56x higher mixed-precision throughput and 42% better energy efficiency than H200. Our memory analysis reveals 58% reduction in memory access latency in cache-misses, fundamentally changing optimal algorithm design strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u5f00\u6e90\u5fae\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86NVIDIA Blackwell\uff08B200\uff09GPU\u76f8\u8f83\u4e8eH200\u5728\u5f20\u91cf\u6838\u5fc3\u3001\u5185\u5b58\u5b50\u7cfb\u7edf\u548c\u591a\u79cd\u6d6e\u70b9\u7cbe\u5ea6\u4e0b\u7684\u6027\u80fd\u63d0\u5347\uff0c\u53d1\u73b0B200\u5728\u6df7\u5408\u7cbe\u5ea6\u541e\u5410\u91cf\u4e0a\u63d0\u53471.56\u500d\uff0c\u80fd\u6548\u63d0\u9ad842%\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u7f13\u5b58\u672a\u547d\u4e2d\u65f6\u7684\u5185\u5b58\u8bbf\u95ee\u5ef6\u8fdf\u3002", "motivation": "\u968f\u7740GPU\u67b6\u6784\u5feb\u901f\u6f14\u8fdb\u4ee5\u6ee1\u8db3E\u7ea7\u8ba1\u7b97\u548c\u673a\u5668\u5b66\u4e60\u9700\u6c42\uff0c\u4e1a\u754c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u65b9\u6cd5\u6765\u91cf\u5316\u65b0\u67b6\u6784\u7279\u6027\u5bf9\u591a\u6837\u5316\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6027\u80fd\u5f71\u54cd\uff0c\u963b\u788d\u4e86\u5f00\u53d1\u8005\u4f18\u5316\u5e94\u7528\u548c\u6307\u5bfc\u672a\u6765\u786c\u4ef6\u8bbe\u8ba1\u3002", "method": "\u6784\u5efa\u5f00\u6e90\u5fae\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5bf9Blackwell\uff08B200\uff09\u4e0eH200 GPU\u5728\u5185\u5b58\u5b50\u7cfb\u7edf\u3001\u5f20\u91cf\u6838\u5fc3\u6d41\u6c34\u7ebf\u53caFP32/FP16/FP8/FP6/FP4\u7b49\u7cbe\u5ea6\u4e0b\u8fdb\u884c\u7cfb\u7edf\u6027\u5bf9\u6bd4\u8bc4\u4f30\uff0c\u6db5\u76d6\u7a20\u5bc6/\u7a00\u758fGEMM\u3001Transformer\u63a8\u7406\u4e0e\u8bad\u7ec3\u7b49\u5de5\u4f5c\u8d1f\u8f7d\u3002", "result": "B200\u76f8\u6bd4H200\u5b9e\u73b01.56\u500d\u66f4\u9ad8\u7684\u6df7\u5408\u7cbe\u5ea6\u541e\u5410\u91cf\u300142%\u66f4\u4f18\u7684\u80fd\u6548\uff0c\u5e76\u5728\u7f13\u5b58\u672a\u547d\u4e2d\u573a\u666f\u4e0b\u5c06\u5185\u5b58\u8bbf\u95ee\u5ef6\u8fdf\u964d\u4f4e58%\uff0c\u663e\u8457\u5f71\u54cd\u7b97\u6cd5\u8bbe\u8ba1\u7b56\u7565\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5fae\u57fa\u51c6\u5957\u4ef6\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u4ee5\u5145\u5206\u5229\u7528\u73b0\u4ee3GPU\u67b6\u6784\u7279\u6027\uff0c\u6709\u52a9\u4e8e\u505a\u51fa\u66f4\u4f18\u7684\u67b6\u6784\u51b3\u7b56\uff0c\u5e76\u4e3a\u672a\u6765GPU\u8bbe\u8ba1\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002"}}
{"id": "2512.02683", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.02683", "abs": "https://arxiv.org/abs/2512.02683", "authors": ["Luiz A. Rodrigues", "Elias P. Duarte", "Luciana Arantes"], "title": "Distributed and Autonomic Minimum Spanning Trees", "comment": "This preprint is an English translation and slightly extended version of the paper published in Portuguese at the 32nd Brazilian Symposium on Computer Networks and Distributed Systems (2014), reference [1]", "summary": "The most common strategy for enabling a process in a distributed system to broadcast a message is one-to-all communication. However, this approach is not scalable, as it places a heavy load on the sender. This work presents an autonomic algorithm that enables the $n$ processes in a distributed system to build and maintain a spanning tree connecting themselves. In this context, processes are the vertices of the spanning tree. By definition, a spanning tree connects all processes without forming cycles. The proposed algorithm ensures that every vertex in the spanning tree has both an in-degree and the tree depth of at most $log_2 n$. When all processes are correct, the degree of each process is exactly $log_2 n$. A spanning tree is dynamically created from any source process and is transparently reconstructed as processes fail or recover. Up to $n-1$ processes can fail, and the correct processes remain connected through a scalable, functioning spanning tree. To build and maintain the tree, processes use the VCube virtual topology, which also serves as a failure detector. Two broadcast algorithms based on the autonomic spanning tree algorithm are presented: one for best-effort broadcast and one for reliable broadcast. Simulation results are provided, including comparisons with other alternatives.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u6784\u5efa\u548c\u7ef4\u62a4\u4e00\u79cd\u6df1\u5ea6\u4e0e\u8282\u70b9\u5165\u5ea6\u5747\u4e0d\u8d85\u8fc7 log\u2082n \u7684\u751f\u6210\u6811\uff0c\u5e76\u57fa\u4e8e\u8be5\u7ed3\u6784\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u5c3d\u529b\u800c\u4e3a\u548c\u53ef\u9760\u5e7f\u64ad\u673a\u5236\u3002", "motivation": "\u4f20\u7edf\u7684\u4e00\u5bf9\u591a\u5e7f\u64ad\u65b9\u6cd5\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u4e0d\u53ef\u6269\u5c55\uff0c\u4f1a\u7ed9\u53d1\u9001\u65b9\u5e26\u6765\u6c89\u91cd\u8d1f\u8f7d\uff1b\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u52a8\u6784\u5efa\u3001\u5bb9\u9519\u4e14\u53ef\u6269\u5c55\u7684\u901a\u4fe1\u7ed3\u6784\u6765\u652f\u6301\u9ad8\u6548\u5e7f\u64ad\u3002", "method": "\u5229\u7528VCube\u865a\u62df\u62d3\u6251\u4f5c\u4e3a\u6545\u969c\u68c0\u6d4b\u5668\uff0c\u8bbe\u8ba1\u4e00\u79cd\u81ea\u9002\u5e94\u7b97\u6cd5\uff0c\u52a8\u6001\u6784\u5efa\u5e76\u7ef4\u62a4\u4e00\u4e2a\u6240\u6709\u8282\u70b9\u5165\u5ea6\u548c\u6811\u6df1\u5ea6\u81f3\u591a\u4e3a log\u2082n \u7684\u751f\u6210\u6811\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u5b9e\u73b0\u4e24\u79cd\u5e7f\u64ad\u7b97\u6cd5\uff1a\u5c3d\u529b\u800c\u4e3a\u5e7f\u64ad\u548c\u53ef\u9760\u5e7f\u64ad\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5bb9\u9519\u6027\uff08\u6700\u591a\u5bb9\u5fcd n\u22121 \u4e2a\u8fdb\u7a0b\u5931\u6548\uff09\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u65b9\u6848\uff0c\u4e14\u5728\u6240\u6709\u8fdb\u7a0b\u6b63\u5e38\u65f6\u6bcf\u4e2a\u8282\u70b9\u7684\u5ea6\u6570\u6070\u597d\u4e3a log\u2082n\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u751f\u6210\u6811\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u652f\u6301\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u53ef\u6269\u5c55\u3001\u5bb9\u9519\u5e7f\u64ad\u901a\u4fe1\uff0c\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2512.02410", "categories": ["cs.MA", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.02410", "abs": "https://arxiv.org/abs/2512.02410", "authors": ["Yepeng Ding", "Ahmed Twabi", "Junwei Yu", "Lingfeng Zhang", "Tohru Kondo", "Hiroyuki Sato"], "title": "Decentralized Multi-Agent System with Trust-Aware Communication", "comment": null, "summary": "The emergence of Large Language Models (LLMs) is rapidly accelerating the development of autonomous multi-agent systems (MAS), paving the way for the Internet of Agents. However, traditional centralized MAS architectures present significant challenges, including single points of failure, vulnerability to censorship, inherent scalability limitations, and critical trust issues. We propose a novel Decentralized Multi-Agent System (DMAS) architecture designed to overcome these fundamental problems by enabling trust-aware, scalable, and censorship-resistant interactions among autonomous agents. Our DMAS features a decentralized agent runtime underpinned by a blockchain-based architecture. We formalize a trust-aware communication protocol that leverages cryptographic primitives and on-chain operations to provide security properties: verifiable interaction cycles, communication integrity, authenticity, non-repudiation, and conditional confidentiality, which we further substantiate through a comprehensive security analysis. Our performance analysis validates the DMAS as a scalable and efficient solution for building trustworthy multi-agent systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08DMAS\uff09\u67b6\u6784\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u96c6\u4e2d\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u5355\u70b9\u6545\u969c\u3001\u5ba1\u67e5\u98ce\u9669\u3001\u53ef\u6269\u5c55\u6027\u9650\u5236\u548c\u4fe1\u4efb\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u96c6\u4e2d\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b58\u5728\u5355\u70b9\u6545\u969c\u3001\u6613\u53d7\u5ba1\u67e5\u3001\u53ef\u6269\u5c55\u6027\u5dee\u548c\u4fe1\u4efb\u673a\u5236\u8584\u5f31\u7b49\u5173\u952e\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u5b89\u5168\u3001\u53ef\u6269\u5c55\u4e14\u6297\u5ba1\u67e5\u7684\u65b0\u67b6\u6784\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u67b6\u6784\uff08DMAS\uff09\uff0c\u5176\u6838\u5fc3\u5305\u62ec\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u53bb\u4e2d\u5fc3\u5316\u667a\u80fd\u4f53\u8fd0\u884c\u65f6\u73af\u5883\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5bc6\u7801\u5b66\u539f\u8bed\u4e0e\u94fe\u4e0a\u64cd\u4f5c\u7684\u4fe1\u4efb\u611f\u77e5\u901a\u4fe1\u534f\u8bae\u3002", "result": "\u8be5\u67b6\u6784\u5b9e\u73b0\u4e86\u53ef\u9a8c\u8bc1\u7684\u4ea4\u4e92\u5468\u671f\u3001\u901a\u4fe1\u5b8c\u6574\u6027\u3001\u8eab\u4efd\u771f\u5b9e\u6027\u3001\u4e0d\u53ef\u5426\u8ba4\u6027\u4ee5\u53ca\u6761\u4ef6\u4fdd\u5bc6\u6027\uff1b\u6027\u80fd\u5206\u6790\u8868\u660eDMAS\u5177\u5907\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684DMAS\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6839\u672c\u7f3a\u9677\uff0c\u4e3a\u6784\u5efa\u53ef\u4fe1\u3001\u5b89\u5168\u3001\u53ef\u6269\u5c55\u7684\u81ea\u4e3b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2512.02329", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02329", "abs": "https://arxiv.org/abs/2512.02329", "authors": ["Hoa Khanh Dam", "Geeta Mahala", "Rashina Hoda", "Xi Zheng", "Cristina Conati"], "title": "Towards autonomous normative multi-agent systems for Human-AI software engineering teams", "comment": null, "summary": "This paper envisions a transformative paradigm in software engineering, where Artificial Intelligence, embodied in fully autonomous agents, becomes the primary driver of the core software development activities. We introduce a new class of software engineering agents, empowered by Large Language Models and equipped with beliefs, desires, intentions, and memory to enable human-like reasoning. These agents collaborate with humans and other agents to design, implement, test, and deploy software systems with a level of speed, reliability, and adaptability far beyond the current software development processes. Their coordination and collaboration are governed by norms expressed as deontic modalities - commitments, obligations, prohibitions and permissions - that regulate interactions and ensure regulatory compliance. These innovations establish a scalable, transparent and trustworthy framework for future Human-AI software engineering teams.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7531\u5177\u5907\u7c7b\u4eba\u63a8\u7406\u80fd\u529b\u7684\u81ea\u4e3bAI\u667a\u80fd\u4f53\u9a71\u52a8\u7684\u65b0\u578b\u8f6f\u4ef6\u5de5\u7a0b\u8303\u5f0f\uff0c\u901a\u8fc7\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u7684\u901f\u5ea6\u3001\u53ef\u9760\u6027\u4e0e\u9002\u5e94\u6027\uff0c\u5e76\u5229\u7528\u89c4\u8303\u903b\u8f91\u786e\u4fdd\u5408\u89c4\u4e0e\u53ef\u4fe1\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u5f00\u53d1\u6d41\u7a0b\u5728\u901f\u5ea6\u3001\u53ef\u9760\u6027\u548c\u9002\u5e94\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u4e9f\u9700\u5f15\u5165\u66f4\u667a\u80fd\u3001\u81ea\u4e3b\u548c\u534f\u4f5c\u80fd\u529b\u5f3a\u7684AI\u7cfb\u7edf\u6765\u9769\u65b0\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u3002", "method": "\u6784\u5efa\u4e00\u7c7b\u65b0\u578b\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\uff0c\u878d\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u8d4b\u4e88\u5176\u4fe1\u5ff5\u3001\u613f\u671b\u3001\u610f\u56fe\u548c\u8bb0\u5fc6\u7b49\u7c7b\u4eba\u8ba4\u77e5\u673a\u5236\uff1b\u667a\u80fd\u4f53\u4e4b\u95f4\u53ca\u4e0e\u4eba\u7c7b\u901a\u8fc7\u4ee5\u9053\u4e49\u6a21\u6001\uff08\u627f\u8bfa\u3001\u4e49\u52a1\u3001\u7981\u6b62\u3001\u8bb8\u53ef\uff09\u8868\u8fbe\u7684\u89c4\u8303\u8fdb\u884c\u534f\u8c03\u4e0e\u5408\u4f5c\u3002", "result": "\u5b9e\u73b0\u4e86\u80fd\u9ad8\u6548\u534f\u540c\u5b8c\u6210\u8bbe\u8ba1\u3001\u5b9e\u73b0\u3001\u6d4b\u8bd5\u548c\u90e8\u7f72\u7b49\u6838\u5fc3\u5f00\u53d1\u4efb\u52a1\u7684AI\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5c55\u73b0\u51fa\u8d85\u8d8a\u73b0\u6709\u6d41\u7a0b\u7684\u6027\u80fd\uff0c\u5e76\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u3001\u900f\u660e\u4e14\u53ef\u4fe1\u7684\u4eba\u673a\u534f\u4f5c\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u4eba\u673a\u534f\u540c\u7684\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ee5\u89c4\u8303\u9a71\u52a8\u3001\u9ad8\u5ea6\u81ea\u4e3b\u4e14\u53ef\u4fe1\u8d56\u7684\u65b0\u578b\u5f00\u53d1\u8303\u5f0f\u3002"}}
{"id": "2512.02346", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02346", "abs": "https://arxiv.org/abs/2512.02346", "authors": ["Hongyang Shang", "An Guo", "Shuai Dong", "Junyi Yang", "Ye Ke", "Arindam Basu"], "title": "Near-Memory Architecture for Threshold-Ordinal Surface-Based Corner Detection of Event Cameras", "comment": null, "summary": "Event-based Cameras (EBCs) are widely utilized in surveillance and autonomous driving applications due to their high speed and low power consumption. Corners are essential low-level features in event-driven computer vision, and novel algorithms utilizing event-based representations, such as Threshold-Ordinal Surface (TOS), have been developed for corner detection. However, the implementation of these algorithms on resource-constrained edge devices is hindered by significant latency, undermining the advantages of EBCs. To address this challenge, a near-memory architecture for efficient TOS updates (NM-TOS) is proposed. This architecture employs a read-write decoupled 8T SRAM cell and optimizes patch update speed through pipelining. Hardware-software co-optimized peripheral circuits and dynamic voltage and frequency scaling (DVFS) enable power and latency reductions. Compared to traditional digital implementations, our architecture reduces latency/energy by 24.7x/1.2x at Vdd = 1.2 V or 1.93x/6.6x at Vdd = 0.6 V based on 65nm CMOS process. Monte Carlo simulations confirm robust circuit operation, demonstrating zero bit error rate at operating voltages above 0.62 V, with only 0.2% at 0.61 V and 2.5% at 0.6 V. Corner detection evaluation using precision-recall area under curve (AUC) metrics reveals minor AUC reductions of 0.027 and 0.015 at 0.6 V for two popular EBC datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u4e8b\u4ef6\u76f8\u673a\u89d2\u70b9\u68c0\u6d4b\u7684\u8fd1\u5b58\u67b6\u6784NM-TOS\uff0c\u901a\u8fc7\u8bfb\u5199\u89e3\u8026\u76848T SRAM\u5355\u5143\u3001\u6d41\u6c34\u7ebf\u4f18\u5316\u3001\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u53caDVFS\u6280\u672f\uff0c\u572865nm\u5de5\u827a\u4e0b\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u4e0e\u80fd\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u4e8b\u4ef6\u76f8\u673a\u867d\u5177\u5907\u9ad8\u901f\u4e0e\u4f4e\u529f\u8017\u4f18\u52bf\uff0c\u4f46\u5176\u57fa\u4e8eTOS\u7b49\u8868\u793a\u7684\u89d2\u70b9\u68c0\u6d4b\u7b97\u6cd5\u5728\u8d44\u6e90\u53d7\u9650\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b58\u5728\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faNM-TOS\u8fd1\u5b58\u67b6\u6784\uff0c\u91c7\u7528\u8bfb\u5199\u89e3\u80268T SRAM\u5355\u5143\u3001\u6d41\u6c34\u7ebf\u52a0\u901f\u5c40\u90e8\u5757\u66f4\u65b0\uff0c\u5e76\u7ed3\u5408\u8f6f\u786c\u4ef6\u534f\u540c\u4f18\u5316\u7684\u5916\u56f4\u7535\u8def\u4e0e\u52a8\u6001\u7535\u538b\u9891\u7387\u8c03\u8282\uff08DVFS\uff09\u7b56\u7565\u3002", "result": "\u572865nm CMOS\u5de5\u827a\u4e0b\uff0c\u76f8\u6bd4\u4f20\u7edf\u6570\u5b57\u5b9e\u73b0\uff0c\u8be5\u67b6\u6784\u57281.2V\u65f6\u5ef6\u8fdf/\u80fd\u8017\u964d\u4f4e24.7\u500d/1.2\u500d\uff0c\u57280.6V\u65f6\u5206\u522b\u964d\u4f4e1.93\u500d/6.6\u500d\uff1b\u8499\u7279\u5361\u6d1b\u4eff\u771f\u663e\u793a0.62V\u4ee5\u4e0a\u7535\u538b\u96f6\u8bef\u7801\u7387\uff0c\u89d2\u70b9\u68c0\u6d4bAUC\u4ec5\u8f7b\u5fae\u4e0b\u964d0.015\u20130.027\u3002", "conclusion": "\u6240\u63d0NM-TOS\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u4e8b\u4ef6\u76f8\u673a\u89d2\u70b9\u68c0\u6d4b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5ef6\u8fdf\u4e0e\u80fd\u6548\u74f6\u9888\uff0c\u5728\u4fdd\u8bc1\u9c81\u68d2\u6027\u4e0e\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6548\u7387\u3002"}}
{"id": "2512.02398", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02398", "abs": "https://arxiv.org/abs/2512.02398", "authors": ["Zhiyu Zhou", "Xin Zhe Khooi", "Satis Kumar Permal", "Mun Choon Chan"], "title": "ProtO-RU: An O-RAN Split-7.2 Radio Unit using SDRs", "comment": "9 pages, 12 figures", "summary": "We present ProtO-RU, the first open source, software-defined O-RAN Split-7.2 Radio Unit built using SDRs and commodity CPUs. Unlike proprietary hardware-based commercial O-RUs, ProtO-RU is built on the open-source srsRAN software stack, and it is fully programmable. We demonstrate that ProtO-RU integrates with the srsRAN and OpenAirInterface5G CU/DU stacks, supports both TDD and FDD duplexing modes, and interoperates with commercial 5G UEs. Our evaluation shows that ProtO-RU remains stable under sustained load with multiple UEs and delivers throughput comparable to Split-8 and commercial O-RUs. ProtO-RU opens up new opportunities for RU-level innovations and lowers the barrier of entry for end-to-end O-RAN research.", "AI": {"tldr": "ProtO-RU \u662f\u9996\u4e2a\u57fa\u4e8e\u5f00\u6e90\u8f6f\u4ef6\u548c\u901a\u7528\u786c\u4ef6\u5b9e\u73b0\u7684 O-RAN Split-7.2 \u5c04\u9891\u5355\u5143\uff0c\u5177\u5907\u53ef\u7f16\u7a0b\u6027\u3001\u517c\u5bb9\u6027\u548c\u5546\u7528\u7ea7\u6027\u80fd\uff0c\u63a8\u52a8\u4e86 O-RAN \u7aef\u5230\u7aef\u7814\u7a76\u7684\u666e\u53ca\u3002", "motivation": "\u73b0\u6709\u5546\u7528 O-RU \u591a\u4e3a\u5c01\u95ed\u5f0f\u786c\u4ef6\u5b9e\u73b0\uff0c\u9650\u5236\u4e86\u5c04\u9891\u5355\u5143\u5c42\u9762\u7684\u521b\u65b0\u4e0e\u7814\u7a76\uff1b\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u5f00\u6e90\u3001\u53ef\u7f16\u7a0b\u4e14\u80fd\u4e0e\u73b0\u6709 5G \u8f6f\u4ef6\u6808\u517c\u5bb9\u7684 O-RU \u5b9e\u73b0\u3002", "method": "\u57fa\u4e8e\u5f00\u6e90 srsRAN \u8f6f\u4ef6\u6808\uff0c\u5728 SDR \u548c\u901a\u7528 CPU \u4e0a\u6784\u5efa\u5b8c\u5168\u53ef\u7f16\u7a0b\u7684 O-RAN Split-7.2 \u5c04\u9891\u5355\u5143\uff08ProtO-RU\uff09\uff0c\u5e76\u96c6\u6210 srsRAN \u4e0e OpenAirInterface5G \u7684 CU/DU \u8f6f\u4ef6\u6808\u3002", "result": "ProtO-RU \u652f\u6301 TDD/FDD \u53cc\u5de5\u6a21\u5f0f\uff0c\u53ef\u4e0e\u5546\u7528 5G \u7ec8\u7aef\u4e92\u64cd\u4f5c\uff0c\u5728\u591a\u7528\u6237\u6301\u7eed\u8d1f\u8f7d\u4e0b\u4fdd\u6301\u7a33\u5b9a\uff0c\u5e76\u5b9e\u73b0\u4e0e Split-8 \u53ca\u5546\u7528 O-RU \u76f8\u5f53\u7684\u541e\u5410\u6027\u80fd\u3002", "conclusion": "ProtO-RU \u4e3a O-RAN \u5c04\u9891\u5355\u5143\u5c42\u7ea7\u7684\u7814\u7a76\u4e0e\u521b\u65b0\u63d0\u4f9b\u4e86\u5f00\u653e\u5e73\u53f0\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u7aef\u5230\u7aef O-RAN \u7814\u7a76\u7684\u95e8\u69db\u3002"}}
{"id": "2512.02818", "categories": ["cs.DC", "cs.DL"], "pdf": "https://arxiv.org/pdf/2512.02818", "abs": "https://arxiv.org/abs/2512.02818", "authors": ["Sean R. Wilkinson", "Patrick Widener", "Sarp Oral", "Rafael Ferreira da Silva"], "title": "Designing FAIR Workflows at OLCF: Building Scalable and Reusable Ecosystems for HPC Science", "comment": null, "summary": "High Performance Computing (HPC) centers provide advanced infrastructure that enables scientific research at extreme scale. These centers operate with hardware configurations, software environments, and security requirements that differ substantially from most users' local systems. As a result, users often develop customized digital artifacts that are tightly coupled to a given HPC center. This practice can lead to significant duplication of effort as multiple users independently create similar solutions to common problems. The FAIR Principles offer a framework to address these challenges. Initially designed to improve data stewardship, the FAIR approach has since been extended to encompass software, workflows, models, and infrastructure. By encouraging the use of rich metadata and community standards, FAIR practices aim to make digital artifacts easier to share and reuse, both within and across scientific domains. Many FAIR initiatives have emerged within individual research communities, often aligned by discipline (e.g. bioinformatics, earth sciences). These communities have made progress in adopting FAIR practices, but their domain-specific nature can lead to silos that limit broader collaboration. Thus, we propose that HPC centers play a more active role in fostering FAIR ecosystems that support research across multiple disciplines. This requires designing infrastructure that enables researchers to discover, share, and reuse computational components more effectively. Here, we build on the architecture of the European Open Science Cloud (EOSC) EOSC-Life FAIR Workflows Collaboratory to propose a model tailored to the needs of HPC. Rather than focusing on entire workflows, we emphasize the importance of making individual workflow components FAIR. This component-based approach better supports the diverse and evolving needs of HPC users while maximizing the long-term value of their work.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHPC\u4e2d\u5fc3\u5e94\u79ef\u6781\u63a8\u52a8\u8de8\u5b66\u79d1\u7684FAIR\u751f\u6001\u7cfb\u7edf\u5efa\u8bbe\uff0c\u901a\u8fc7\u4f7f\u5de5\u4f5c\u6d41\u4e2d\u7684\u5355\u4e2a\u7ec4\u4ef6\uff08\u800c\u975e\u6574\u4e2a\u5de5\u4f5c\u6d41\uff09\u7b26\u5408FAIR\u539f\u5219\uff0c\u63d0\u5347\u79d1\u7814\u6570\u5b57\u6210\u679c\u7684\u53ef\u53d1\u73b0\u6027\u3001\u5171\u4eab\u6027\u548c\u590d\u7528\u6027\u3002", "motivation": "\u5f53\u524dHPC\u7528\u6237\u5e38\u56e0\u7cfb\u7edf\u73af\u5883\u5dee\u5f02\u800c\u91cd\u590d\u5f00\u53d1\u4e0e\u7279\u5b9a\u4e2d\u5fc3\u7ed1\u5b9a\u7684\u6570\u5b57\u5de5\u4ef6\uff0c\u9020\u6210\u8d44\u6e90\u6d6a\u8d39\uff1b\u5c3d\u7ba1\u5404\u5b66\u79d1\u793e\u533a\u5df2\u5f00\u5c55FAIR\u5b9e\u8df5\uff0c\u4f46\u5b58\u5728\u9886\u57df\u5b64\u5c9b\u95ee\u9898\uff0c\u9650\u5236\u4e86\u8de8\u5b66\u79d1\u534f\u4f5c\u3002", "method": "\u501f\u9274\u6b27\u6d32\u5f00\u653e\u79d1\u5b66\u4e91\uff08EOSC\uff09\u4e2dEOSC-Life FAIR\u5de5\u4f5c\u6d41\u534f\u4f5c\u5e73\u53f0\u7684\u67b6\u6784\uff0c\u8bbe\u8ba1\u4e00\u79cd\u9762\u5411HPC\u73af\u5883\u7684\u7ec4\u4ef6\u7ea7FAIR\u6a21\u578b\uff0c\u5f3a\u8c03\u5bf9\u5de5\u4f5c\u6d41\u4e2d\u72ec\u7acb\u7ec4\u4ef6\u5b9e\u65bdFAIR\u539f\u5219\u3002", "result": "\u8be5\u6a21\u578b\u80fd\u66f4\u597d\u5730\u9002\u5e94HPC\u7528\u6237\u591a\u6837\u5316\u548c\u52a8\u6001\u53d8\u5316\u7684\u9700\u6c42\uff0c\u63d0\u5347\u6570\u5b57\u5de5\u4ef6\u7684\u957f\u671f\u4ef7\u503c\uff0c\u5e76\u4fc3\u8fdb\u8de8\u5b66\u79d1\u7814\u7a76\u4e2d\u7684\u8d44\u6e90\u5171\u4eab\u4e0e\u91cd\u7528\u3002", "conclusion": "HPC\u4e2d\u5fc3\u5e94\u5728\u63a8\u52a8\u8de8\u5b66\u79d1FAIR\u751f\u6001\u4e2d\u53d1\u6325\u66f4\u79ef\u6781\u4f5c\u7528\uff0c\u901a\u8fc7\u57fa\u7840\u8bbe\u65bd\u8bbe\u8ba1\u652f\u6301\u7ec4\u4ef6\u7ea7FAIR\u5b9e\u8df5\uff0c\u4ece\u800c\u589e\u5f3a\u79d1\u7814\u6548\u7387\u4e0e\u534f\u4f5c\u5e7f\u5ea6\u3002"}}
{"id": "2512.02561", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02561", "abs": "https://arxiv.org/abs/2512.02561", "authors": ["Jinming Yang", "Zimu Ji", "Weiqi Luo", "Gaoxi Wang", "Bin Ma", "Yueling Deng"], "title": "EZYer: A simulacrum of high school with generative agent", "comment": "AgentIR@SIGIR 2025", "summary": "With the rapid development of the online education and large language model, the existing educational tools still suffer from incomplete service, insufficient performance and weak interactivity in terms of courseware generation, interactive notes and quality assurance of content. In particular, the proposed generative agent EZYer : 1) Teacher Module: Integrating the Text Corpus retrieval and in-depth generation technologies, it automatically generates structured teaching materials and LaTeX Beamer courseware in line with the high school mathematics syllabus and supports user-defined image insertion. 2) Student Module: Throughout the collaborative interaction of the four roles of Teacher, Assistant, Top Student and Struggling Student, Note Taker summarizes and generates academic notes to enhance the depth and interest of learning. 3) Controller: set up keyword filtering system, content scoring system, role co-validation system, and dynamic content correction system. This ensure academic strictness and pedagogical propriety of EZYer inputs and outputs. In order to evaluate EZYer, this paper designs five-dimensional evaluation indexes of content accuracy, knowledge coverage, usability, formatting correctness and visual design and appeal, and scores 100 Beamer and Notes generated by EZYer by five large language models, separately, and the results show that the quality of EZYer-generated content is excellent and has a good application prospect.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a EZYer \u7684\u751f\u6210\u5f0f\u6559\u80b2\u667a\u80fd\u4f53\uff0c\u5305\u542b\u6559\u5e08\u6a21\u5757\u3001\u5b66\u751f\u6a21\u5757\u548c\u63a7\u5236\u5668\u4e09\u90e8\u5206\uff0c\u5206\u522b\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u7ed3\u6784\u5316\u6559\u5b66\u6750\u6599\u4e0e\u8bfe\u4ef6\u3001\u534f\u4f5c\u751f\u6210\u5b66\u4e60\u7b14\u8bb0\u4ee5\u53ca\u4fdd\u969c\u5185\u5bb9\u7684\u5b66\u672f\u4e25\u8c28\u6027\uff0c\u5e76\u901a\u8fc7\u4e94\u7ef4\u6307\u6807\u8bc4\u4f30\u8bc1\u660e\u5176\u751f\u6210\u5185\u5bb9\u8d28\u91cf\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u5728\u7ebf\u6559\u80b2\u5de5\u5177\u5728\u8bfe\u4ef6\u751f\u6210\u3001\u4ea4\u4e92\u5f0f\u7b14\u8bb0\u548c\u5185\u5bb9\u8d28\u91cf\u4fdd\u969c\u65b9\u9762\u5b58\u5728\u670d\u52a1\u4e0d\u5b8c\u6574\u3001\u6027\u80fd\u4e0d\u8db3\u548c\u4e92\u52a8\u6027\u5f31\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u6280\u672f\u63d0\u5347\u6559\u80b2\u667a\u80fd\u5316\u6c34\u5e73\u3002", "method": "EZYer \u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a1\uff09\u6559\u5e08\u6a21\u5757\u878d\u5408\u6587\u672c\u8bed\u6599\u68c0\u7d22\u4e0e\u6df1\u5ea6\u751f\u6210\u6280\u672f\uff0c\u81ea\u52a8\u751f\u6210\u7b26\u5408\u9ad8\u4e2d\u6570\u5b66\u6559\u5b66\u5927\u7eb2\u7684\u7ed3\u6784\u5316\u6559\u6750\u548c LaTeX Beamer \u8bfe\u4ef6\uff0c\u652f\u6301\u7528\u6237\u63d2\u5165\u56fe\u7247\uff1b2\uff09\u5b66\u751f\u6a21\u5757\u901a\u8fc7\u6559\u5e08\u3001\u52a9\u6559\u3001\u4f18\u7b49\u751f\u548c\u540e\u8fdb\u751f\u56db\u89d2\u8272\u534f\u4f5c\u4e92\u52a8\uff0c\u7531\u7b14\u8bb0\u8bb0\u5f55\u8005\u751f\u6210\u5b66\u672f\u7b14\u8bb0\uff1b3\uff09\u63a7\u5236\u5668\u8bbe\u7f6e\u5173\u952e\u8bcd\u8fc7\u6ee4\u3001\u5185\u5bb9\u8bc4\u5206\u3001\u89d2\u8272\u4e92\u9a8c\u548c\u52a8\u6001\u4fee\u6b63\u673a\u5236\uff0c\u786e\u4fdd\u8f93\u5165\u8f93\u51fa\u7684\u5b66\u672f\u89c4\u8303\u6027\u3002\u8bc4\u4f30\u91c7\u7528\u5185\u5bb9\u51c6\u786e\u6027\u3001\u77e5\u8bc6\u8986\u76d6\u5ea6\u3001\u53ef\u7528\u6027\u3001\u683c\u5f0f\u6b63\u786e\u6027\u53ca\u89c6\u89c9\u8bbe\u8ba1\u4e94\u4e2a\u7ef4\u5ea6\uff0c\u7531\u4e94\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5bf9100\u4efd\u751f\u6210\u5185\u5bb9\u6253\u5206\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a EZYer \u751f\u6210\u7684 Beamer \u8bfe\u4ef6\u548c\u5b66\u4e60\u7b14\u8bb0\u5728\u4e94\u9879\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u79c0\uff0c\u5177\u5907\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002", "conclusion": "EZYer \u6709\u6548\u89e3\u51b3\u4e86\u5f53\u524d\u6559\u80b2\u5de5\u5177\u5728\u5185\u5bb9\u751f\u6210\u4e0e\u4e92\u52a8\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5176\u591a\u6a21\u5757\u534f\u540c\u67b6\u6784\u548c\u4e25\u683c\u7684\u5185\u5bb9\u63a7\u5236\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u4e0e\u6559\u5b66\u9002\u7528\u6027\u3002"}}
{"id": "2512.02393", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.02393", "abs": "https://arxiv.org/abs/2512.02393", "authors": ["Shuyang Liu", "Yang Chen", "Rahul Krishna", "Saurabh Sinha", "Jatin Ganhotra", "Reyhan Jabbarvand"], "title": "Process-Centric Analysis of Agentic Software Systems", "comment": null, "summary": "Agentic systems are modern software systems: they consist of orchestrated modules, expose interfaces, and are deployed in software pipelines. Unlike conventional programs, their execution (i.e., trajectories) is inherently stochastic and adaptive to the problem they are solving. Evaluation of such systems is often outcome-centric, judging their performance based on success or failure at the final step. This narrow focus overlooks detailed insights about such systems, failing to explain how agents reason, plan, act, or change their strategies over time. Inspired by the structured representation of conventional software systems as graphs, we introduce Graphectory to systematically encode the temporal and semantic relations in such software systems. Graphectory facilitates the design of process-centric metrics and analyses to assess the quality of agentic workflows independent of final success.\n  Using Graphectory, we analyze 4000 trajectories of two dominant agentic programming workflows, namely SWE-agent and OpenHands, with a combination of four backbone Large Language Models (LLMs), attempting to resolve SWE-bench Verified issues. Our fully automated analyses reveal that: (1) agents using richer prompts or stronger LLMs exhibit more complex Graphectory, reflecting deeper exploration, broader context gathering, and more thorough validation before patch submission; (2) agents' problem-solving strategies vary with both problem difficulty and the underlying LLM -- for resolved issues, the strategies often follow coherent localization-patching-validation steps, while unresolved ones exhibit chaotic, repetitive, or backtracking behaviors; (3) even when successful, agentic programming systems often display inefficient processes, leading to unnecessarily prolonged trajectories.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGraphectory\uff0c\u4e00\u79cd\u7528\u4e8e\u7cfb\u7edf\u5316\u5efa\u6a21\u667a\u80fd\u4f53\u7cfb\u7edf\u6267\u884c\u8f68\u8ff9\u7684\u56fe\u7ed3\u6784\u65b9\u6cd5\uff0c\u4ee5\u652f\u6301\u8fc7\u7a0b\u5bfc\u5411\u7684\u8bc4\u4f30\u3002\u901a\u8fc7\u5bf94000\u6761SWE-agent\u548cOpenHands\u5728SWE-bench\u4e0a\u7684\u8f68\u8ff9\u5206\u6790\uff0c\u53d1\u73b0\u66f4\u5f3a\u7684LLM\u6216\u66f4\u4e30\u5bcc\u7684\u63d0\u793a\u80fd\u4ea7\u751f\u66f4\u590d\u6742\u7684\u63a8\u7406\u8def\u5f84\uff0c\u6210\u529f\u6848\u4f8b\u901a\u5e38\u9075\u5faa\u5b9a\u4f4d-\u4fee\u590d-\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u800c\u5931\u8d25\u6848\u4f8b\u5219\u8868\u73b0\u51fa\u6df7\u4e71\u6216\u91cd\u590d\u884c\u4e3a\uff0c\u4e14\u5373\u4f7f\u6210\u529f\u4e5f\u5e38\u4f34\u968f\u4f4e\u6548\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u5bf9\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8bc4\u4f30\u8fc7\u4e8e\u5173\u6ce8\u6700\u7ec8\u6210\u8d25\uff0c\u5ffd\u89c6\u4e86\u5176\u63a8\u7406\u3001\u89c4\u5212\u4e0e\u7b56\u7565\u8c03\u6574\u7b49\u8fc7\u7a0b\u7ec6\u8282\uff0c\u7f3a\u4e4f\u5bf9\u6267\u884c\u8f68\u8ff9\u7684\u6df1\u5165\u7406\u89e3\u3002", "method": "\u63d0\u51faGraphectory\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6267\u884c\u8f68\u8ff9\u7f16\u7801\u4e3a\u5305\u542b\u65f6\u5e8f\u4e0e\u8bed\u4e49\u5173\u7cfb\u7684\u56fe\u7ed3\u6784\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u8fc7\u7a0b\u5bfc\u5411\u7684\u8bc4\u4f30\u6307\u6807\uff1b\u5728SWE-bench\u4e0a\u5bf9SWE-agent\u548cOpenHands\u7ed3\u5408\u56db\u79cd\u4e3b\u6d41LLM\u751f\u6210\u76844000\u6761\u8f68\u8ff9\u8fdb\u884c\u81ea\u52a8\u5316\u5206\u6790\u3002", "result": "1\uff09\u4f7f\u7528\u66f4\u5f3aLLM\u6216\u66f4\u4e30\u5bcc\u63d0\u793a\u7684\u667a\u80fd\u4f53\u5c55\u73b0\u51fa\u66f4\u590d\u6742\u7684Graphectory\uff0c\u4f53\u73b0\u66f4\u6df1\u5165\u7684\u63a2\u7d22\u4e0e\u9a8c\u8bc1\uff1b2\uff09\u6210\u529f\u6848\u4f8b\u591a\u5448\u73b0\u8fde\u8d2f\u7684\u5b9a\u4f4d-\u4fee\u590d-\u9a8c\u8bc1\u7b56\u7565\uff0c\u5931\u8d25\u6848\u4f8b\u5219\u8868\u73b0\u4e3a\u6df7\u4e71\u6216\u91cd\u590d\u884c\u4e3a\uff1b3\uff09\u5373\u4f7f\u6210\u529f\uff0c\u667a\u80fd\u4f53\u6d41\u7a0b\u5e38\u5b58\u5728\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\u3002", "conclusion": "Graphectory\u4e3a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7ec6\u7c92\u5ea6\u3001\u8fc7\u7a0b\u5bfc\u5411\u7684\u5206\u6790\u5de5\u5177\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u667a\u80fd\u4f53\u7f16\u7a0b\u5de5\u4f5c\u6d41\u5728\u7b56\u7565\u8fde\u8d2f\u6027\u4e0e\u6267\u884c\u6548\u7387\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5f3a\u8c03\u9700\u8d85\u8d8a\u7ed3\u679c\u5bfc\u5411\u7684\u8bc4\u4f30\u8303\u5f0f\u3002"}}
{"id": "2512.02682", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02682", "abs": "https://arxiv.org/abs/2512.02682", "authors": ["Piercosma Bisconti", "Marcello Galisai", "Federico Pierucci", "Marcantonio Bracale", "Matteo Prandi"], "title": "Beyond Single-Agent Safety: A Taxonomy of Risks in LLM-to-LLM Interactions", "comment": null, "summary": "This paper examines why safety mechanisms designed for human-model interaction do not scale to environments where large language models (LLMs) interact with each other. Most current governance practices still rely on single-agent safety containment, prompts, fine-tuning, and moderation layers that constrain individual model behavior but leave the dynamics of multi-model interaction ungoverned. These mechanisms assume a dyadic setting: one model responding to one user under stable oversight. Yet research and industrial development are rapidly shifting toward LLM-to-LLM ecosystems, where outputs are recursively reused as inputs across chains of agents. In such systems, local compliance can aggregate into collective failure even when every model is individually aligned. We propose a conceptual transition from model-level safety to system-level safety, introducing the framework of the Emergent Systemic Risk Horizon (ESRH) to formalize how instability arises from interaction structure rather than from isolated misbehavior. The paper contributes (i) a theoretical account of collective risk in interacting LLMs, (ii) a taxonomy connecting micro, meso, and macro-level failure modes, and (iii) a design proposal for InstitutionalAI, an architecture for embedding adaptive oversight within multi-agent systems.", "AI": {"tldr": "\u5f53\u524d\u9488\u5bf9\u4eba\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ea4\u4e92\u8bbe\u8ba1\u7684\u5b89\u5168\u673a\u5236\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u591a\u4e2aLLM\u76f8\u4e92\u4f5c\u7528\u7684\u590d\u6742\u73af\u5883\uff0c\u672c\u6587\u63d0\u51fa\u4ece\u6a21\u578b\u7ea7\u5b89\u5168\u8f6c\u5411\u7cfb\u7edf\u7ea7\u5b89\u5168\uff0c\u5e76\u5f15\u5165\u201c\u6d8c\u73b0\u7cfb\u7edf\u6027\u98ce\u9669\u89c6\u754c\u201d\uff08ESRH\uff09\u6846\u67b6\u548cInstitutionalAI\u67b6\u6784\u4ee5\u5e94\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u96c6\u4f53\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u673a\u5236\u4e3b\u8981\u9488\u5bf9\u5355\u4e2aLLM\u5728\u4eba\u7c7b\u76d1\u7763\u4e0b\u7684\u884c\u4e3a\u8fdb\u884c\u7ea6\u675f\uff0c\u4f46\u968f\u7740LLM\u4e4b\u95f4\u76f8\u4e92\u4ea4\u4e92\u7684\u751f\u6001\u7cfb\u7edf\u8fc5\u901f\u53d1\u5c55\uff0c\u8fd9\u4e9b\u673a\u5236\u65e0\u6cd5\u7ba1\u63a7\u591a\u6a21\u578b\u4ea4\u4e92\u4e2d\u4ea7\u751f\u7684\u7cfb\u7edf\u6027\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u201c\u6d8c\u73b0\u7cfb\u7edf\u6027\u98ce\u9669\u89c6\u754c\u201d\uff08ESRH\uff09\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u4ea4\u4e92\u7ed3\u6784\u5982\u4f55\u5f15\u53d1\u7cfb\u7edf\u4e0d\u7a33\u5b9a\uff1b\u6784\u5efa\u5fae-\u4e2d-\u5b8f\u89c2\u5c42\u9762\u7684\u5931\u8d25\u6a21\u5f0f\u5206\u7c7b\u6cd5\uff1b\u8bbe\u8ba1InstitutionalAI\u67b6\u6784\uff0c\u5c06\u81ea\u9002\u5e94\u76d1\u7ba1\u5d4c\u5165\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "result": "\u63ed\u793a\u4e86\u5373\u4f7f\u6bcf\u4e2aLLM\u4e2a\u4f53\u5bf9\u9f50\u826f\u597d\uff0c\u5176\u4ea4\u4e92\u4ecd\u53ef\u80fd\u5bfc\u81f4\u96c6\u4f53\u5931\u6548\uff1b\u63d0\u4f9b\u4e86\u7406\u89e3\u4e0e\u6cbb\u7406\u591aLLM\u7cfb\u7edf\u98ce\u9669\u7684\u65b0\u7406\u8bba\u89c6\u89d2\u4e0e\u6280\u672f\u8def\u5f84\u3002", "conclusion": "\u9700\u5c06\u5b89\u5168\u6cbb\u7406\u8303\u5f0f\u4ece\u5355\u6a21\u578b\u6269\u5c55\u81f3\u6574\u4e2a\u7cfb\u7edf\u5c42\u9762\uff0c\u901a\u8fc7\u5236\u5ea6\u5316\u3001\u81ea\u9002\u5e94\u7684\u76d1\u7ba1\u673a\u5236\u5e94\u5bf9LLM\u4ea4\u4e92\u5e26\u6765\u7684\u6d8c\u73b0\u6027\u98ce\u9669\u3002"}}
{"id": "2512.02567", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02567", "abs": "https://arxiv.org/abs/2512.02567", "authors": ["Martin Weiss", "Jesko Hecking-Harbusch", "Jochen Quante", "Matthias Woehrle"], "title": "Feedback Loops and Code Perturbations in LLM-based Software Engineering: A Case Study on a C-to-Rust Translation System", "comment": "10 pages, 9 figures", "summary": "The advent of strong generative AI has a considerable impact on various software engineering tasks such as code repair, test generation, or language translation. While tools like GitHub Copilot are already in widespread use in interactive settings, automated approaches require a higher level of reliability before being usable in industrial practice. In this paper, we focus on three aspects that directly influence the quality of the results: a) the effect of automated feedback loops, b) the choice of Large Language Model (LLM), and c) the influence of behavior-preserving code changes.\n  We study the effect of these three variables on an automated C-to-Rust translation system. Code translation from C to Rust is an attractive use case in industry due to Rust's safety guarantees. The translation system is based on a generate-and-check pattern, in which Rust code generated by the LLM is automatically checked for compilability and behavioral equivalence with the original C code. For negative checking results, the LLM is re-prompted in a feedback loop to repair its output. These checks also allow us to evaluate and compare the respective success rates of the translation system when varying the three variables.\n  Our results show that without feedback loops LLM selection has a large effect on translation success. However, when the translation system uses feedback loops the differences across models diminish. We observe this for the average performance of the system as well as its robustness under code perturbations. Finally, we also identify that diversity provided by code perturbations can even result in improved system performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53cd\u9988\u5faa\u73af\u3001\u5927\u8bed\u8a00\u6a21\u578b\u9009\u62e9\u548c\u884c\u4e3a\u4fdd\u6301\u7684\u4ee3\u7801\u53d8\u6362\u5bf9C\u5230Rust\u81ea\u52a8\u7ffb\u8bd1\u7cfb\u7edf\u6548\u679c\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u53cd\u9988\u673a\u5236\u80fd\u663e\u8457\u7f29\u5c0f\u4e0d\u540c\u6a21\u578b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u63d0\u5347\u7cfb\u7edf\u9c81\u68d2\u6027\u751a\u81f3\u6574\u4f53\u8868\u73b0\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u81ea\u52a8\u5316\u65b9\u6cd5\u9700\u5177\u5907\u66f4\u9ad8\u53ef\u9760\u6027\u624d\u80fd\u7528\u4e8e\u5de5\u4e1a\u5b9e\u8df5\u3002\u4f5c\u8005\u805a\u7126\u5f71\u54cd\u7ed3\u679c\u8d28\u91cf\u7684\u4e09\u4e2a\u5173\u952e\u56e0\u7d20\uff1a\u81ea\u52a8\u5316\u53cd\u9988\u5faa\u73af\u3001\u5927\u8bed\u8a00\u6a21\u578b\u9009\u62e9\u548c\u884c\u4e3a\u4fdd\u6301\u7684\u4ee3\u7801\u53d8\u6362\uff0c\u4ee5C\u5230Rust\u7ffb\u8bd1\u4e3a\u6848\u4f8b\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u201c\u751f\u6210-\u6821\u9a8c\u201d\u6a21\u5f0f\u7684C-to-Rust\u81ea\u52a8\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210Rust\u4ee3\u7801\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u68c0\u67e5\u5176\u53ef\u7f16\u8bd1\u6027\u548c\u4e0e\u539f\u59cbC\u4ee3\u7801\u7684\u884c\u4e3a\u7b49\u4ef7\u6027\uff1b\u82e5\u6821\u9a8c\u5931\u8d25\uff0c\u5219\u901a\u8fc7\u53cd\u9988\u5faa\u73af\u91cd\u65b0\u63d0\u793a\u6a21\u578b\u4fee\u590d\u8f93\u51fa\uff0c\u5e76\u5728\u6b64\u6846\u67b6\u4e0b\u5bf9\u6bd4\u4e0d\u540c\u53d8\u91cf\u914d\u7f6e\u4e0b\u7684\u6210\u529f\u7387\u3002", "result": "\u65e0\u53cd\u9988\u5faa\u73af\u65f6\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9009\u62e9\u5bf9\u7ffb\u8bd1\u6210\u529f\u7387\u5f71\u54cd\u663e\u8457\uff1b\u5f15\u5165\u53cd\u9988\u5faa\u73af\u540e\uff0c\u4e0d\u540c\u6a21\u578b\u95f4\u6027\u80fd\u5dee\u5f02\u660e\u663e\u7f29\u5c0f\uff0c\u4e14\u7cfb\u7edf\u5728\u9762\u5bf9\u4ee3\u7801\u6270\u52a8\u65f6\u8868\u73b0\u51fa\u66f4\u5f3a\u9c81\u68d2\u6027\uff1b\u6b64\u5916\uff0c\u4ee3\u7801\u6270\u52a8\u5e26\u6765\u7684\u591a\u6837\u6027\u751a\u81f3\u80fd\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "\u53cd\u9988\u5faa\u73af\u5728\u81ea\u52a8\u5316\u4ee3\u7801\u7ffb\u8bd1\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u4e0d\u4ec5\u80fd\u7f13\u89e3\u6a21\u578b\u9009\u62e9\u5e26\u6765\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u8fd8\u80fd\u589e\u5f3a\u7cfb\u7edf\u9c81\u68d2\u6027\uff1b\u884c\u4e3a\u4fdd\u6301\u7684\u4ee3\u7801\u6270\u52a8\u4e0d\u4ec5\u65e0\u5bb3\uff0c\u53cd\u800c\u6709\u52a9\u4e8e\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\uff0c\u8fd9\u5bf9\u5de5\u4e1a\u7ea7AI\u8f85\u52a9\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u7684\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2512.02875", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02875", "abs": "https://arxiv.org/abs/2512.02875", "authors": ["Cristian Tirelli", "Lorenzo Ferretti", "Laura Pozzi"], "title": "SAT-MapIt: A SAT-based Modulo Scheduling Mapper for Coarse Grain Reconfigurable Architectures", "comment": null, "summary": "Coarse-Grain Reconfigurable Arrays (CGRAs) are emerging low-power architectures aimed at accelerating compute-intensive application loops. The acceleration that a CGRA can ultimately provide, however, heavily depends on the quality of the mapping, i.e. on how effectively the loop is compiled onto the given platform. State of the Art compilation techniques achieve mapping through modulo scheduling, a strategy which attempts to minimize the II (Iteration Interval) needed to execute a loop, and they do so usually through well known graph algorithms, such as Max-Clique Enumeration.\n  We address the mapping problem through a SAT formulation, instead, and thus explore the solution space more effectively than current SoA tools. To formulate the SAT problem, we introduce an ad-hoc schedule called the \\textit{kernel mobility schedule} (KMS), which we use in conjunction with the data-flow graph and the architectural information of the CGRA in order to create a set of boolean statements that describe all constraints to be obeyed by the mapping for a given II. We then let the SAT solver efficiently navigate this complex space. As in other SoA techniques, the process is iterative: if a valid mapping does not exist for the given II, the II is increased and a new KMS and set of constraints is generated and solved.\n  Our experimental results show that SAT-MapIt obtains better results compared to SoA alternatives in $47.72\\%$ of the benchmarks explored: sometimes finding a lower II, and others even finding a valid mapping when none could previously be found.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eSAT\uff08\u5e03\u5c14\u53ef\u6ee1\u8db3\u6027\uff09\u7684\u65b0\u578b\u6620\u5c04\u65b9\u6cd5SAT-MapIt\uff0c\u7528\u4e8e\u5c06\u8ba1\u7b97\u5bc6\u96c6\u578b\u5faa\u73af\u9ad8\u6548\u6620\u5c04\u5230\u7c97\u7c92\u5ea6\u53ef\u91cd\u6784\u9635\u5217\uff08CGRAs\uff09\u4e0a\u3002\u8be5\u65b9\u6cd5\u5f15\u5165\u201c\u6838\u8fc1\u79fb\u8c03\u5ea6\u201d\uff08KMS\uff09\u6765\u6784\u5efa\u7ea6\u675f\uff0c\u5e76\u5229\u7528SAT\u6c42\u89e3\u5668\u63a2\u7d22\u89e3\u7a7a\u95f4\uff0c\u572847.72%\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u6709\u65f6\u80fd\u83b7\u5f97\u66f4\u4f4e\u7684\u8fed\u4ee3\u95f4\u9694\uff08II\uff09\u6216\u627e\u5230\u6b64\u524d\u65e0\u6cd5\u83b7\u5f97\u7684\u6709\u6548\u6620\u5c04\u3002", "motivation": "\u73b0\u6709CGRAs\u6620\u5c04\u65b9\u6cd5\u4f9d\u8d56\u6a21\u8c03\u5ea6\u548c\u56fe\u7b97\u6cd5\uff08\u5982\u6700\u5927\u56e2\u679a\u4e3e\uff09\uff0c\u96be\u4ee5\u5145\u5206\u63a2\u7d22\u89e3\u7a7a\u95f4\uff0c\u9650\u5236\u4e86\u6620\u5c04\u8d28\u91cf\uff1b\u4f5c\u8005\u65e8\u5728\u901a\u8fc7SAT\u5f62\u5f0f\u5316\u65b9\u6cd5\u66f4\u6709\u6548\u5730\u641c\u7d22\u9ad8\u8d28\u91cf\u6620\u5c04\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eSAT\u7684\u6620\u5c04\u65b9\u6cd5\uff1a\u5f15\u5165\u201c\u6838\u8fc1\u79fb\u8c03\u5ea6\u201d\uff08KMS\uff09\uff0c\u7ed3\u5408\u6570\u636e\u6d41\u56fe\u548cCGRA\u67b6\u6784\u4fe1\u606f\uff0c\u5c06\u6620\u5c04\u95ee\u9898\u8f6c\u5316\u4e3a\u4e00\u7ec4\u5e03\u5c14\u7ea6\u675f\uff1b\u5229\u7528SAT\u6c42\u89e3\u5668\u5728\u7ed9\u5b9a\u8fed\u4ee3\u95f4\u9694\uff08II\uff09\u4e0b\u5bfb\u627e\u53ef\u884c\u6620\u5c04\uff0c\u82e5\u5931\u8d25\u5219\u9012\u589eII\u5e76\u91cd\u590d\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSAT-MapIt\u572847.72%\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u90e8\u5206\u60c5\u51b5\u4e0b\u83b7\u5f97\u66f4\u4f4e\u7684II\uff0c\u751a\u81f3\u5728\u539f\u6709\u65b9\u6cd5\u65e0\u6cd5\u627e\u5230\u6709\u6548\u6620\u5c04\u65f6\u6210\u529f\u627e\u5230\u3002", "conclusion": "\u57fa\u4e8eSAT\u7684\u6620\u5c04\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u63a2\u7d22CGRAs\u6620\u5c04\u89e3\u7a7a\u95f4\uff0c\u663e\u8457\u63d0\u5347\u6620\u5c04\u8d28\u91cf\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u52a0\u901f\u8ba1\u7b97\u5bc6\u96c6\u578b\u5faa\u73af\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.02455", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2512.02455", "abs": "https://arxiv.org/abs/2512.02455", "authors": ["Pietro Chiavassa", "Stefano Scanzio", "Gianluca Cena"], "title": "Wi-Fi Rate Adaptation for Moving Equipment in Industrial Environments", "comment": "preprint accepted, 4 pages, 2025", "summary": "Wi-Fi is currently considered one of the most promising solutions for interconnecting mobile equipment (e.g., autonomous mobile robots and active exoskeletons) in industrial environments. However, relability requirements imposed by the industrial context, such as ensuring bounded transmission latency, are a major challenge for over-the-air communication. One of the aspects of Wi-Fi technology that greatly affects the probability of a packet reaching its destination is the selection of the appropriate transmission rate. Rate adaptation algorithms are in charge of this operation, but their design and implementation are not regulated by the IEEE 802.11 standard. One of the most popular solutions, available as open source, is Minstrel, which is the default choice for the Linux Kernel. In this paper, Minstrel performance is evaluated for both static and mobility scenarios. Our analysis focuses on metrics of interest for industrial contexts, i.e., latency and packet loss ratio, and serves as a preliminary evaluation for the future development of enhanced rate adaptation algorithms based on centralized digital twins.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86Minstrel\u901f\u7387\u81ea\u9002\u5e94\u7b97\u6cd5\u5728\u9759\u6001\u548c\u79fb\u52a8\u573a\u666f\u4e0b\u7684\u6027\u80fd\uff0c\u91cd\u70b9\u5173\u6ce8\u5de5\u4e1a\u73af\u5883\u4e2d\u5173\u952e\u7684\u5ef6\u8fdf\u548c\u4e22\u5305\u7387\u6307\u6807\uff0c\u4e3a\u672a\u6765\u57fa\u4e8e\u96c6\u4e2d\u5f0f\u6570\u5b57\u5b6a\u751f\u7684\u589e\u5f3a\u578b\u901f\u7387\u81ea\u9002\u5e94\u7b97\u6cd5\u5f00\u53d1\u63d0\u4f9b\u521d\u6b65\u4f9d\u636e\u3002", "motivation": "\u5de5\u4e1a\u73af\u5883\u4e2d\u5bf9\u65e0\u7ebf\u901a\u4fe1\uff08\u5982Wi-Fi\uff09\u63d0\u51fa\u4e86\u4e25\u683c\u7684\u53ef\u9760\u6027\u8981\u6c42\uff0c\u5c24\u5176\u662f\u6709\u754c\u4f20\u8f93\u5ef6\u8fdf\u3002\u800cWi-Fi\u7684\u4f20\u8f93\u901f\u7387\u9009\u62e9\u663e\u8457\u5f71\u54cd\u6570\u636e\u5305\u6210\u529f\u9001\u8fbe\u7684\u6982\u7387\uff0c\u73b0\u6709\u901f\u7387\u81ea\u9002\u5e94\u7b97\u6cd5\uff08\u5982Minstrel\uff09\u5728\u5de5\u4e1a\u573a\u666f\u4e0b\u7684\u6027\u80fd\u5c1a\u9700\u8bc4\u4f30\uff0c\u4ee5\u652f\u6301\u672a\u6765\u66f4\u4f18\u7b97\u6cd5\u7684\u8bbe\u8ba1\u3002", "method": "\u5bf9Linux\u5185\u6838\u9ed8\u8ba4\u7684\u5f00\u6e90\u901f\u7387\u81ea\u9002\u5e94\u7b97\u6cd5Minstrel\u5728\u9759\u6001\u548c\u79fb\u52a8\u4e24\u79cd\u573a\u666f\u4e0b\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\uff0c\u91cd\u70b9\u8003\u5bdf\u5176\u5728\u5de5\u4e1a\u5e94\u7528\u4e2d\u5173\u6ce8\u7684\u5ef6\u8fdf\u548c\u4e22\u5305\u7387\u7b49\u6307\u6807\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86Minstrel\u7b97\u6cd5\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u5173\u4e8e\u5ef6\u8fdf\u548c\u4e22\u5305\u7387\u7684\u5177\u4f53\u6027\u80fd\u6570\u636e\uff0c\u4f5c\u4e3a\u540e\u7eed\u7814\u7a76\u7684\u57fa\u7ebf\u3002", "conclusion": "\u5bf9Minstrel\u7684\u8bc4\u4f30\u7ed3\u679c\u53ef\u4f5c\u4e3a\u521d\u6b65\u53c2\u8003\uff0c\u7528\u4e8e\u6307\u5bfc\u672a\u6765\u9762\u5411\u5de5\u4e1a\u5e94\u7528\u3001\u57fa\u4e8e\u96c6\u4e2d\u5f0f\u6570\u5b57\u5b6a\u751f\u6280\u672f\u7684\u589e\u5f3a\u578b\u901f\u7387\u81ea\u9002\u5e94\u7b97\u6cd5\u7684\u5f00\u53d1\u3002"}}
{"id": "2512.02884", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02884", "abs": "https://arxiv.org/abs/2512.02884", "authors": ["Cristian Tirelli", "Laura Pozzi"], "title": "Mapping code on Coarse Grained Reconfigurable Arrays using a SAT solver", "comment": null, "summary": "Emerging low-powered architectures like Coarse-Grain Reconfigurable Arrays (CGRAs) are becoming more common. Often included as co-processors, they are used to accelerate compute-intensive workloads like loops. The speedup obtained is defined by the hardware design of the accelerator and by the quality of the compilation. State of the art (SoA) compilation techniques leverage modulo scheduling to minimize the Iteration Interval (II), exploit the architecture parallelism and, consequentially, reduce the execution time of the accelerated workload. In our work, we focus on improving the compilation process by finding the lowest II for any given topology, through a satisfiability (SAT) formulation of the mapping problem. We introduce a novel schedule, called Kernel Mobility Schedule, to encode all the possible mappings for a given Data Flow Graph (DFG) and for a given II. The schedule is used together with the CGRA architectural information to generate all the constraints necessary to find a valid mapping. Experimental results demonstrate that our method not only reduces compilation time on average but also achieves higher quality mappings compared to existing SoA techniques.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eSAT\u6c42\u89e3\u7684\u65b0\u578b\u7f16\u8bd1\u65b9\u6cd5\u2014\u2014\u6838\u8fc1\u79fb\u8c03\u5ea6\uff08Kernel Mobility Schedule\uff09\uff0c\u7528\u4e8e\u5728\u7c97\u7c92\u5ea6\u53ef\u91cd\u6784\u9635\u5217\uff08CGRA\uff09\u4e0a\u4e3a\u7ed9\u5b9a\u6570\u636e\u6d41\u56fe\u5bfb\u627e\u6700\u5c0f\u8fed\u4ee3\u95f4\u9694\uff08II\uff09\u7684\u6620\u5c04\uff0c\u4ece\u800c\u63d0\u5347\u6620\u5c04\u8d28\u91cf\u5e76\u7f29\u77ed\u7f16\u8bd1\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709CGRA\u7f16\u8bd1\u6280\u672f\u867d\u4f7f\u7528\u6a21\u8c03\u5ea6\u4f18\u5316\u8fed\u4ee3\u95f4\u9694\uff08II\uff09\uff0c\u4f46\u5728\u6620\u5c04\u8d28\u91cf\u548c\u7f16\u8bd1\u6548\u7387\u65b9\u9762\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\uff1b\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u66f4\u4f18\u7684\u8c03\u5ea6\u5efa\u6a21\u65b9\u6cd5\uff0c\u4e3a\u4efb\u610fCGRA\u62d3\u6251\u7ed3\u6784\u627e\u5230\u6700\u4f4eII\u7684\u6709\u6548\u6620\u5c04\u3002", "method": "\u5c06CGRA\u6620\u5c04\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u53ef\u6ee1\u8db3\u6027\uff08SAT\uff09\u95ee\u9898\uff0c\u63d0\u51fa\u201c\u6838\u8fc1\u79fb\u8c03\u5ea6\u201d\u6765\u7f16\u7801\u7ed9\u5b9a\u6570\u636e\u6d41\u56fe\uff08DFG\uff09\u548c\u76ee\u6807II\u4e0b\u6240\u6709\u53ef\u80fd\u7684\u6620\u5c04\uff0c\u5e76\u7ed3\u5408CGRA\u67b6\u6784\u4fe1\u606f\u751f\u6210\u7ea6\u675f\u6761\u4ef6\uff0c\u5229\u7528SAT\u6c42\u89e3\u5668\u5bfb\u627e\u6709\u6548\u6620\u5c04\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u5148\u8fdb\u6280\u672f\uff0c\u4e0d\u4ec5\u5e73\u5747\u7f16\u8bd1\u65f6\u95f4\u66f4\u77ed\uff0c\u800c\u4e14\u80fd\u83b7\u5f97\u66f4\u9ad8\u8d28\u91cf\u7684\u6620\u5c04\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8eSAT\u4e0e\u6838\u8fc1\u79fb\u8c03\u5ea6\u7684\u7f16\u8bd1\u65b9\u6cd5\u5728CGRA\u6620\u5c04\u4e2d\u517c\u987e\u4e86\u6548\u7387\u4e0e\u8d28\u91cf\uff0c\u4f18\u4e8e\u5f53\u524d\u4e3b\u6d41\u6280\u672f\u3002"}}
{"id": "2512.02728", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02728", "abs": "https://arxiv.org/abs/2512.02728", "authors": ["Sabrina Delmondes da Costa Feitosa"], "title": "Integrative Analysis of Risk Management Methodologies in Data Science Projects", "comment": "13 p\u00e1ginas, in Portuguese language", "summary": "Data science initiatives frequently exhibit high failure rates, driven by technical constraints, organizational limitations and insufficient risk management practices. Challenges such as low data maturity, lack of governance, misalignment between technical and business teams, and the absence of structured mechanisms to address ethical and sociotechnical risks have been widely identified in the literature. In this context, the purpose of this study is to conduct a comparative analysis of the main risk management methodologies applied to data science projects, aiming to identify, classify, and synthesize their similarities, differences and existing gaps. An integrative literature review was performed using indexed databases and a structured protocol for selection and content analysis. The study examines widely adopted risk management standards ISO 31000, PMBOK Risk Management and NIST RMF, as well as frameworks specific to data science workflows, such as CRISP DM and the recently proposed DS EthiCo RMF, which incorporates ethical and sociotechnical dimensions into the project life cycle. The findings reveal that traditional approaches provide limited coverage of emerging risks, whereas contemporary models propose multidimensional structures capable of integrating ethical oversight, governance and continuous monitoring. As a contribution, this work offers theoretical support for the development of hybrid frameworks that balance technical efficiency, organizational alignment and responsible data practices, while highlighting research gaps that can guide future investigations.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6574\u5408\u6027\u6587\u732e\u7efc\u8ff0\uff0c\u6bd4\u8f83\u4e86\u6570\u636e\u79d1\u5b66\u9879\u76ee\u4e2d\u4e3b\u6d41\u7684\u98ce\u9669\u7ba1\u7406\u65b9\u6cd5\uff0c\u53d1\u73b0\u4f20\u7edf\u6807\u51c6\uff08\u5982ISO 31000\u3001PMBOK\u3001NIST RMF\uff09\u5bf9\u65b0\u5174\u98ce\u9669\u8986\u76d6\u6709\u9650\uff0c\u800c\u65b0\u5174\u6846\u67b6\uff08\u5982DS EthiCo RMF\uff09\u66f4\u5f3a\u8c03\u4f26\u7406\u4e0e\u793e\u4f1a\u6280\u672f\u7ef4\u5ea6\uff1b\u7814\u7a76\u5efa\u8bae\u6784\u5efa\u878d\u5408\u6280\u672f\u6548\u7387\u3001\u7ec4\u7ec7\u534f\u540c\u4e0e\u8d1f\u8d23\u4efb\u6570\u636e\u5b9e\u8df5\u7684\u6df7\u5408\u578b\u98ce\u9669\u7ba1\u7406\u6846\u67b6\u3002", "motivation": "\u6570\u636e\u79d1\u5b66\u9879\u76ee\u5931\u8d25\u7387\u9ad8\uff0c\u539f\u56e0\u5305\u62ec\u6280\u672f\u9650\u5236\u3001\u7ec4\u7ec7\u80fd\u529b\u4e0d\u8db3\u53ca\u98ce\u9669\u7ba1\u7406\u4e0d\u5584\uff0c\u5c24\u5176\u7f3a\u4e4f\u5bf9\u4f26\u7406\u4e0e\u793e\u4f1a\u6280\u672f\u98ce\u9669\u7684\u7cfb\u7edf\u5e94\u5bf9\u673a\u5236\u3002", "method": "\u91c7\u7528\u6574\u5408\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u57fa\u4e8e\u7ed3\u6784\u5316\u7b5b\u9009\u4e0e\u5185\u5bb9\u5206\u6790\u534f\u8bae\uff0c\u4ece\u7d22\u5f15\u6570\u636e\u5e93\u4e2d\u7cfb\u7edf\u5206\u6790\u4e3b\u6d41\u98ce\u9669\u7ba1\u7406\u6807\u51c6\uff08ISO 31000\u3001PMBOK\u3001NIST RMF\uff09\u4e0e\u6570\u636e\u79d1\u5b66\u4e13\u7528\u6846\u67b6\uff08CRISP-DM\u3001DS EthiCo RMF\uff09\u3002", "result": "\u4f20\u7edf\u98ce\u9669\u7ba1\u7406\u65b9\u6cd5\u5728\u5e94\u5bf9\u6570\u636e\u79d1\u5b66\u4e2d\u7684\u65b0\u5174\u98ce\u9669\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff1b\u800c\u65b0\u8fd1\u63d0\u51fa\u7684\u6846\u67b6\uff08\u5982DS EthiCo RMF\uff09\u901a\u8fc7\u591a\u7ef4\u7ed3\u6784\u6574\u5408\u4f26\u7406\u76d1\u7763\u3001\u6cbb\u7406\u673a\u5236\u4e0e\u6301\u7eed\u76d1\u63a7\uff0c\u66f4\u5177\u9002\u5e94\u6027\u3002", "conclusion": "\u5e94\u53d1\u5c55\u517c\u987e\u6280\u672f\u6548\u7387\u3001\u7ec4\u7ec7\u5bf9\u9f50\u4e0e\u8d1f\u8d23\u4efb\u6570\u636e\u5b9e\u8df5\u7684\u6df7\u5408\u578b\u98ce\u9669\u7ba1\u7406\u6846\u67b6\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u53ef\u805a\u7126\u4e8e\u586b\u8865\u73b0\u6709\u65b9\u6cd5\u5728\u4f26\u7406\u6574\u5408\u4e0e\u52a8\u6001\u98ce\u9669\u76d1\u6d4b\u65b9\u9762\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.02750", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.02750", "abs": "https://arxiv.org/abs/2512.02750", "authors": ["Kiev Gama", "Filipe Calegario", "Victoria Jackson", "Alexander Nolte", "Luiz Augusto Morais", "Vinicius Garcia"], "title": "\"Can you feel the vibes?\": An exploration of novice programmer engagement with vibe coding", "comment": "International Conference on Software Engineering, Education Track (SEET) 2026", "summary": "Emerging alongside generative AI and the broader trend of AI-assisted coding, the term \"vibe coding\" refers to creating software via natural language prompts rather than direct code authorship. This approach promises to democratize software development, but its educational implications remain underexplored. This paper reports on a one-day educational hackathon investigating how novice programmers and mixed-experience teams engage with vibe coding. We organized an inclusive event at a Brazilian public university with 31 undergraduate participants from computing and non-computing disciplines, divided into nine teams. Through observations, an exit survey, and semi-structured interviews, we examined creative processes, tool usage patterns, collaboration dynamics, and learning outcomes. Findings reveal that vibe coding enabled rapid prototyping and cross-disciplinary collaboration, with participants developing prompt engineering skills and delivering functional demonstrations within time constraints. However, we observed premature convergence in ideation, uneven code quality requiring rework, and limited engagement with core software engineering practices. Teams adopted sophisticated workflows combining multiple AI tools in pipeline configurations, with human judgment remaining essential for critical refinement. The short format (9 hours) proved effective for confidence-building among newcomers while accommodating participants with limited availability. We conclude that vibe coding hackathons can serve as valuable low-stakes learning environments when coupled with explicit scaffolds for divergent thinking, critical evaluation of AI outputs, and realistic expectations about production quality.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5728\u5df4\u897f\u4e00\u6240\u516c\u7acb\u5927\u5b66\u4e3e\u529e\u7684\u4e00\u573a\u4e3a\u671f\u4e00\u5929\u7684\u201c\u6c1b\u56f4\u7f16\u7a0b\u201d\uff08vibe coding\uff09\u9ed1\u5ba2\u677e\uff0c\u7814\u7a76\u4e86\u65b0\u624b\u7a0b\u5e8f\u5458\u548c\u6df7\u5408\u7ecf\u9a8c\u56e2\u961f\u5982\u4f55\u5229\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8fdb\u884c\u8f6f\u4ef6\u5f00\u53d1\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4fc3\u8fdb\u4e86\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u548c\u8de8\u5b66\u79d1\u534f\u4f5c\uff0c\u4f46\u4e5f\u66b4\u9732\u51fa\u521b\u610f\u8fc7\u65e9\u6536\u655b\u3001\u4ee3\u7801\u8d28\u91cf\u4e0d\u5747\u4ee5\u53ca\u5bf9\u6838\u5fc3\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u53c2\u4e0e\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u548cAI\u8f85\u52a9\u7f16\u7a0b\u7684\u5174\u8d77\uff0c\u201c\u6c1b\u56f4\u7f16\u7a0b\u201d\u4f5c\u4e3a\u4e00\u79cd\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u800c\u975e\u76f4\u63a5\u7f16\u5199\u4ee3\u7801\u6765\u521b\u5efa\u8f6f\u4ef6\u7684\u65b0\u8303\u5f0f\uff0c\u6709\u671b\u964d\u4f4e\u7f16\u7a0b\u95e8\u69db\u3002\u7136\u800c\uff0c\u5176\u5728\u6559\u80b2\u573a\u666f\u4e2d\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u5c24\u5176\u662f\u5728\u65b0\u624b\u5b66\u4e60\u8005\u548c\u591a\u5143\u80cc\u666f\u56e2\u961f\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "method": "\u7814\u7a76\u8005\u7ec4\u7ec7\u4e86\u4e00\u573a\u5305\u542b31\u540d\u6765\u81ea\u8ba1\u7b97\u673a\u4e0e\u975e\u8ba1\u7b97\u673a\u4e13\u4e1a\u7684\u672c\u79d1\u751f\u53c2\u4e0e\u76849\u5c0f\u65f6\u9ed1\u5ba2\u677e\u6d3b\u52a8\uff0c\u5c06\u5176\u5206\u4e3a9\u4e2a\u56e2\u961f\u3002\u901a\u8fc7\u73b0\u573a\u89c2\u5bdf\u3001\u9000\u51fa\u95ee\u5377\u548c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u6536\u96c6\u4e86\u5173\u4e8e\u521b\u610f\u8fc7\u7a0b\u3001\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\u3001\u534f\u4f5c\u52a8\u6001\u548c\u5b66\u4e60\u6210\u679c\u7684\u6570\u636e\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u201c\u6c1b\u56f4\u7f16\u7a0b\u201d\u652f\u6301\u5feb\u901f\u539f\u578b\u5f00\u53d1\u548c\u8de8\u5b66\u79d1\u5408\u4f5c\uff0c\u53c2\u4e0e\u8005\u5728\u77ed\u65f6\u95f4\u5185\u638c\u63e1\u4e86\u63d0\u793a\u5de5\u7a0b\u6280\u80fd\u5e76\u5b8c\u6210\u4e86\u53ef\u8fd0\u884c\u7684\u6f14\u793a\u3002\u4f46\u540c\u65f6\u4e5f\u51fa\u73b0\u4e86\u521b\u610f\u9636\u6bb5\u8fc7\u65e9\u6536\u655b\u3001\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\u9700\u5927\u91cf\u8fd4\u5de5\u3001\u4ee5\u53ca\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u6838\u5fc3\u5b9e\u8df5\uff08\u5982\u6d4b\u8bd5\u3001\u67b6\u6784\u8bbe\u8ba1\uff09\u5173\u6ce8\u4e0d\u8db3\u7b49\u95ee\u9898\u3002\u56e2\u961f\u666e\u904d\u91c7\u7528\u591aAI\u5de5\u5177\u4e32\u8054\u7684\u5de5\u4f5c\u6d41\uff0c\u4e14\u4eba\u7c7b\u5224\u65ad\u5728\u5173\u952e\u4f18\u5316\u73af\u8282\u4e0d\u53ef\u6216\u7f3a\u3002\u77ed\u65f6\u6d3b\u52a8\u6709\u6548\u63d0\u5347\u4e86\u65b0\u624b\u4fe1\u5fc3\uff0c\u5e76\u9002\u5408\u65f6\u95f4\u6709\u9650\u7684\u53c2\u4e0e\u8005\u3002", "conclusion": "\u201c\u6c1b\u56f4\u7f16\u7a0b\u201d\u9ed1\u5ba2\u677e\u53ef\u4f5c\u4e3a\u4f4e\u98ce\u9669\u3001\u9ad8\u5305\u5bb9\u6027\u7684\u5b66\u4e60\u73af\u5883\uff0c\u4f46\u9700\u8f85\u4ee5\u660e\u786e\u7684\u6559\u5b66\u652f\u67b6\uff0c\u5305\u62ec\u4fc3\u8fdb\u53d1\u6563\u601d\u7ef4\u3001\u57f9\u517b\u5bf9AI\u8f93\u51fa\u7684\u6279\u5224\u6027\u8bc4\u4f30\u80fd\u529b\uff0c\u4ee5\u53ca\u5efa\u7acb\u5bf9\u4ea7\u51fa\u8d28\u91cf\u7684\u5408\u7406\u9884\u671f\u3002"}}
{"id": "2512.02795", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02795", "abs": "https://arxiv.org/abs/2512.02795", "authors": ["Marcus Kessel"], "title": "Towards Observation Lakehouses: Living, Interactive Archives of Software Behavior", "comment": null, "summary": "Code-generating LLMs are trained largely on static artifacts (source, comments, specifications) and rarely on materializations of run-time behavior. As a result, they readily internalize buggy or mislabeled code. Since non-trivial semantic properties are undecidable in general, the only practical way to obtain ground-truth functionality is by dynamic observation of executions. In prior work, we addressed representation with Sequence Sheets, Stimulus-Response Matrices (SRMs), and Stimulus-Response Cubes (SRCs) to capture and compare behavior across tests, implementations, and contexts. These structures make observation data analyzable offline and reusable, but they do not by themselves provide persistence, evolution, or interactive analytics at scale. In this paper, therefore, we introduce observation lakehouses that operationalize continual SRCs: a tall, append-only observations table storing every actuation (stimulus, response, context) and SQL queries that materialize SRC slices on demand. Built on Apache Parquet + Iceberg + DuckDB, the lakehouse ingests data from controlled pipelines (LASSO) and CI pipelines (e.g., unit test executions), enabling n-version assessment, behavioral clustering, and consensus oracles without re-execution. On a 509-problem benchmark, we ingest $\\approx$8.6M observation rows ($<$51MiB) and reconstruct SRM/SRC views and clusters in $<$100ms on a laptop, demonstrating that continual behavior mining is practical without a distributed cluster of machines. This makes behavioral ground truth first-class alongside other run-time data and provides an infrastructure path toward behavior-aware evaluation and training. The Observation Lakehouse, together with the accompanying dataset, is publicly available as an open-source project on GitHub: https://github.com/SoftwareObservatorium/observation-lakehouse", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u201c\u89c2\u6d4b\u6e56\u4ed3\u201d\uff08Observation Lakehouse\uff09\u67b6\u6784\uff0c\u901a\u8fc7\u6301\u7eed\u8bb0\u5f55\u548c\u5b58\u50a8\u4ee3\u7801\u6267\u884c\u8fc7\u7a0b\u4e2d\u7684\u523a\u6fc0-\u54cd\u5e94-\u4e0a\u4e0b\u6587\u4e09\u5143\u7ec4\uff08SRC\uff09\uff0c\u5b9e\u73b0\u5bf9\u7a0b\u5e8f\u884c\u4e3a\u7684\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u5206\u6790\uff0c\u652f\u6301\u65e0\u9700\u91cd\u65b0\u6267\u884c\u5373\u53ef\u8fdb\u884c\u591a\u7248\u672c\u8bc4\u4f30\u3001\u884c\u4e3a\u805a\u7c7b\u548c\u5171\u8bc6\u9884\u8a00\u7b49\u4efb\u52a1\uff0c\u5e76\u5728\u5355\u673a\u4e0a\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u751f\u6210\u5927\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u9759\u6001\u4ee3\u7801\u8bad\u7ec3\uff0c\u5bb9\u6613\u5b66\u4e60\u5230\u9519\u8bef\u6216\u6807\u6ce8\u4e0d\u5f53\u7684\u4ee3\u7801\uff1b\u800c\u7a0b\u5e8f\u7684\u771f\u5b9e\u8bed\u4e49\u884c\u4e3a\u53ea\u80fd\u901a\u8fc7\u52a8\u6001\u6267\u884c\u89c2\u5bdf\u83b7\u5f97\u3002\u5df2\u6709\u5de5\u4f5c\u867d\u63d0\u51fa\u4e86SRM/SRC\u7b49\u7ed3\u6784\u6765\u8868\u793a\u884c\u4e3a\uff0c\u4f46\u7f3a\u4e4f\u53ef\u6269\u5c55\u7684\u6301\u4e45\u5316\u3001\u6f14\u5316\u4e0e\u4ea4\u4e92\u5206\u6790\u80fd\u529b\u3002", "method": "\u6784\u5efa\u57fa\u4e8eApache Parquet + Iceberg + DuckDB\u7684\u89c2\u6d4b\u6e56\u4ed3\u7cfb\u7edf\uff0c\u4ee5\u8ffd\u52a0\u5f0f\u8868\u683c\u6301\u7eed\u5b58\u50a8\u6240\u6709\u6267\u884c\u89c2\u6d4b\u6570\u636e\uff08\u523a\u6fc0\u3001\u54cd\u5e94\u3001\u4e0a\u4e0b\u6587\uff09\uff0c\u5e76\u901a\u8fc7SQL\u6309\u9700\u7269\u5316SRC\u5207\u7247\uff1b\u6570\u636e\u6765\u6e90\u4e8eLASSO\u63a7\u5236\u7ba1\u9053\u548cCI\u6d41\u6c34\u7ebf\uff08\u5982\u5355\u5143\u6d4b\u8bd5\uff09\u3002", "result": "\u5728\u5305\u542b509\u4e2a\u95ee\u9898\u7684\u57fa\u51c6\u4e0a\uff0c\u7cfb\u7edf\u6444\u5165\u7ea6860\u4e07\u6761\u89c2\u6d4b\u8bb0\u5f55\uff08<51MiB\uff09\uff0c\u5728\u666e\u901a\u7b14\u8bb0\u672c\u7535\u8111\u4e0a\u53ef\u5728100\u6beb\u79d2\u5185\u91cd\u5efaSRM/SRC\u89c6\u56fe\u548c\u805a\u7c7b\u7ed3\u679c\uff0c\u8bc1\u660e\u65e0\u9700\u5206\u5e03\u5f0f\u96c6\u7fa4\u5373\u53ef\u9ad8\u6548\u5b9e\u73b0\u6301\u7eed\u884c\u4e3a\u6316\u6398\u3002", "conclusion": "\u89c2\u6d4b\u6e56\u4ed3\u4f7f\u7a0b\u5e8f\u884c\u4e3a\u7684\u52a8\u6001\u89c2\u6d4b\u6570\u636e\u6210\u4e3a\u4e00\u7c7b\u4e00\u7b49\u516c\u6c11\uff0c\u4e3a\u884c\u4e3a\u611f\u77e5\u7684\u6a21\u578b\u8bc4\u4f30\u4e0e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u5e76\u5df2\u4f5c\u4e3a\u5f00\u6e90\u9879\u76ee\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2512.02898", "categories": ["cs.SE", "cs.AI", "cs.LO", "cs.SC"], "pdf": "https://arxiv.org/pdf/2512.02898", "abs": "https://arxiv.org/abs/2512.02898", "authors": ["Pedro Orvalho", "Marta Kwiatkowska", "Mikol\u00e1\u0161 Janota", "Vasco Manquinho"], "title": "Model-Based Diagnosis with Multiple Observations: A Unified Approach for C Software and Boolean Circuits", "comment": "50 pages, 9 figures, 6 tables, 5 listings", "summary": "Debugging is one of the most time-consuming and expensive tasks in software development and circuit design. Several formula-based fault localisation (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs/circuits with multiple faults.\n  This paper introduces CFaults, a novel fault localisation tool for C software and Boolean circuits with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified Maximum Satisfiability (MaxSAT) formula. Consequently, our method guarantees consistency across observations and simplifies the fault localisation procedure. Experimental results on three benchmark sets, two of C programs, TCAS and C-Pack-IPAs, and one of Boolean circuits, ISCAS85, show that CFaults is faster at localising faults in C software than other FBFL approaches such as BugAssist, SNIPER, and HSD. On the ISCAS85 benchmark, CFaults is generally slower than HSD; however, it localises faults in only 6% fewer circuits, demonstrating that it remains competitive in this domain. Furthermore, CFaults produces only subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses (e.g., BugAssist and SNIPER).", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCFaults\uff0c\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u8bca\u65ad\uff08MBD\uff09\u4e0eMaxSAT\u7684\u65b0\u578b\u591a\u6545\u969c\u5b9a\u4f4d\u5de5\u5177\uff0c\u9002\u7528\u4e8eC\u7a0b\u5e8f\u548c\u5e03\u5c14\u7535\u8def\u3002\u5b83\u901a\u8fc7\u6574\u5408\u6240\u6709\u5931\u8d25\u6d4b\u8bd5\u7528\u4f8b\u4e3a\u7edf\u4e00MaxSAT\u516c\u5f0f\uff0c\u786e\u4fdd\u8bca\u65ad\u4e00\u81f4\u6027\u5e76\u907f\u514d\u5197\u4f59\u7ed3\u679c\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709FBFL\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u516c\u5f0f\u7684\u6545\u969c\u5b9a\u4f4d\uff08FBFL\uff09\u65b9\u6cd5\u5728\u5904\u7406\u591a\u6545\u969c\u573a\u666f\u65f6\u5b58\u5728\u4e0d\u8db3\uff1a\u65e0\u6cd5\u4fdd\u8bc1\u8986\u76d6\u6240\u6709\u5931\u8d25\u6d4b\u8bd5\u7528\u4f8b\uff0c\u6216\u4ea7\u751f\u975e\u5b50\u96c6\u6700\u5c0f\u7684\u5197\u4f59\u8bca\u65ad\u7ed3\u679c\u3002", "method": "CFaults\u7ed3\u5408\u6a21\u578b\u8bca\u65ad\uff08MBD\uff09\u4e0e\u591a\u89c2\u6d4b\u4fe1\u606f\uff0c\u5c06\u6240\u6709\u5931\u8d25\u6d4b\u8bd5\u7528\u4f8b\u805a\u5408\u4e3a\u4e00\u4e2a\u7edf\u4e00\u7684\u6700\u5927\u53ef\u6ee1\u8db3\u6027\uff08MaxSAT\uff09\u516c\u5f0f\uff0c\u4ece\u800c\u5b9e\u73b0\u4e00\u81f4\u4e14\u7cbe\u7b80\u7684\u6545\u969c\u5b9a\u4f4d\u3002", "result": "\u5728TCAS\u3001C-Pack-IPAs\uff08C\u7a0b\u5e8f\uff09\u548cISCAS85\uff08\u5e03\u5c14\u7535\u8def\uff09\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCFaults\u5728C\u7a0b\u5e8f\u4e0a\u6bd4BugAssist\u3001SNIPER\u548cHSD\u66f4\u5feb\uff1b\u5728ISCAS85\u4e0a\u867d\u7565\u6162\u4e8eHSD\uff0c\u4f46\u4ec5\u5c11\u5b9a\u4f4d6%\u7684\u7535\u8def\uff0c\u5e76\u4e14\u53ea\u751f\u6210\u5b50\u96c6\u6700\u5c0f\u7684\u8bca\u65ad\u7ed3\u679c\uff0c\u907f\u514d\u4e86\u5176\u4ed6\u65b9\u6cd5\u7684\u5197\u4f59\u95ee\u9898\u3002", "conclusion": "CFaults\u662f\u4e00\u79cd\u9ad8\u6548\u3001\u7cbe\u786e\u7684\u591a\u6545\u969c\u5b9a\u4f4d\u5de5\u5177\uff0c\u80fd\u6709\u6548\u514b\u670d\u73b0\u6709FBFL\u65b9\u6cd5\u5728\u4e00\u81f4\u6027\u4e0e\u5197\u4f59\u6027\u65b9\u9762\u7684\u7f3a\u9677\uff0c\u5728\u8f6f\u4ef6\u4e0e\u7535\u8def\u6545\u969c\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u5177\u6709\u7ade\u4e89\u529b\u3002"}}
